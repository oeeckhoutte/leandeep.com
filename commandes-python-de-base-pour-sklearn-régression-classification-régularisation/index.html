<!DOCTYPE html>
<html lang="fr">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author"
  content="Olivier Eeckhoutte">
<meta name="description"
  content="1. L&amp;rsquo;objet estimator Dans Scikit les algorithmes de Machine Learning sont expos√©s via des objets appel√©s &amp;ldquo;estimator&amp;rdquo;.
Exemple pour une r√©gression lin√©aire:
from sklearn.linear_model import LinearRegression # Tous les param√®tres pour configurer l&amp;#39;estimator peuvent √™tre pass√© √† l&amp;#39;objet lors de son instanciation model = LinearRegression(normalize=True) print(model) R√©sultat:
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True) L&amp;rsquo;interface des m√©thodes de scikit-learn sont uniformes.
Pour tous les estimators:
model.fit() : remplit le mod√®le avec des donn√©es d&amp;rsquo;entrainement." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#252627" />
<script>
  
  
  if (!(window.location.host.startsWith("127.0.0.1")) && !(window.location.host.startsWith("localhost"))) {
    if (window.location.protocol != "https:") {
      console.log("Redirecting to https...")
      window.location.protocol = "https";
    }
  }
</script>


<link rel="canonical" href="https://leandeep.com/commandes-python-de-base-pour-sklearn-r%C3%A9gression-classification-r%C3%A9gularisation/" />




<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">



<script src="https://fb.me/react-15.1.0.min.js"></script>
<script src="https://fb.me/react-dom-15.1.0.min.js"></script>
<style>
  .nav-search {
    display: none;
    -webkit-flex-grow: 1;
    -ms-flex-positive: 1;
    position: relative;
    width: 90%;
    height: 47px;
    margin-top: 20px;
    background-color: white;
    z-index: 1000;
  }

  .nav-search.active {
    box-shadow: 0 4px 4px rgba(79, 79, 79, 0.21);
  }

  .nav-search.active .search-dropdown {
    display: block;
  }

  .nav-search.active .search-input {
    -webkit-animation: expand-search-box-animation 0.5s forwards;
    animation: expand-search-box-animation 0.5s forwards;
  }

  .nav-search.active .search-input input {
    border-width: 2px;
  }

  .nav-search.active .search-input .close-search {
    display: inline-block;
  }

  .nav-search.active .search-input .search-dropdown {
    display: block;
  }

  .nav-search .search-input {
    transition: left 0.2s ease-in-out;
    transition: width 0s ease-in-out;
  }

  .nav-search .search-input .search-icon {
    position: absolute;
    left: 15px;
    top: 13px;
    z-index: 999;
    color: black;
  }

  .nav-search .search-input input {
    font: 16px/1.875 "Avenir Next W01", "Avenir Next", "Helvetica Neue", Helvetica, sans-serif;
    height: 50px;
    border: 1px solid #1b98f4;
    border-radius: 4px;
    min-width: 200px;
    width: 100%;
    padding-left: 50px;
    background-color: white;
  }

  .nav-search .search-input input:focus {
    outline: none;
  }

  .nav-search .search-input i.close-search {
    color: #1b98f4;
    display: none;
    position: absolute;
    right: 15px;
    top: 13px;
    cursor: pointer;
  }

  .search-dropdown {
    box-sizing: border-box;
    color: #B3B3B3;
    font: 14px/1.875 "Avenir Next W01", "Avenir Next", "Helvetica Neue", Helvetica, sans-serif;
    opacity: 1.00;
    padding: 20px;
    width: 100%;
    -webkit-animation: expand-search-dropdown-animation 0.5s forwards;
    animation: expand-search-dropdown-animation 0.5s forwards;
    overflow-y: scroll;
    max-height: 400px;
    border-radius: 0 0 4px 4px;
    background-color: #FCFCFC;
    border: 1px solid #E0E0E0;
    box-shadow: 1px 3px 4px rgba(0, 0, 0, 0.09);
    display: none;
    background-color: white;
  }

  .search-dropdown .small {
    -webkit-flex-basis: 35%;
    -ms-flex-preferred-size: 35%;
    flex-basis: 35%;
  }

  .search-dropdown .search-section .hits-blank {
    color: #666;
    text-align: center;
    padding-top: 20px;
  }

  .search-dropdown a {
    text-decoration: none;
    color: inherit;
    z-index: 2000;
  }

  .hit {
    border-bottom: 1px solid #E6E6E6;
    margin-bottom: 20px;
  }

  .hit .hit-title {
    color: #1b98f4;
    font-family: 'bt_mono', monospace;
    font-weight: 500;
    margin-bottom: 0;
    margin-top: 0;
    display: inline-block;
    font-size: 14px;
  }

  .hit .hit-description {
    text-decoration: none;
    color: black;
    font-size: 14px;
    display: block;
    margin-top: 3px;
  }

  .hit .hit-anchor {
    font-size: 13px;
    color: #666;
  }

  .hit .algolia-docsearch-suggestion--highlight {
    background-color: #FFE9A4;
  }

  .hit:last-child {
     
  }

  .ais-hits--item:last-child .hit {
    border: 0;
  }
</style>

<style>
  #app {
    display: none;
     
    border-radius: 10px;
    box-shadow: 2px 5px 12px -1px rgba(0, 0, 0, 0.56);
    padding: 20px;
    background-color: white;
    max-width: 500px;
    margin: 15px auto;
    text-align: center;
    min-height: 500px;
  }

  #app input {
    margin: 0 auto;
    float: none;
    width: 100%;
    max-width: 300px;
    padding: 5px 10px;
    border: 2px solid black;
  }

  #app ul {
    margin: 0;
    padding: 0;
  }

  #app li {
    text-align: left;
    padding: 5px 10px;
    width: 100%;
    max-width: 280px;
    margin: 1px auto;
    background-color: white;
    border: 1px solid black;
    list-style: none;
  }
</style>




<title>
  
  Commandes Python de base pour Sklearn (R√©gression, Classification, R√©gularisation) :: Lean Deep Tech blog 
  
</title>



<link href="//cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
  type="text/css">



<link rel="stylesheet" href="https://leandeep.com/main.min.75f4fccf704dff01fea880bd845a14a4f05d9c04ee40d8b8563f1a6ab98fe848.css">




    <link rel="apple-touch-icon" sizes="180x180" href="https://leandeep.com/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://leandeep.com/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://leandeep.com/favicon-16x16.png">
    <link rel="manifest" href="https://leandeep.com/site.webmanifest">
    <link rel="mask-icon" href="https://leandeep.com/safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="https://leandeep.com/favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">

<meta itemprop="name" content="Commandes Python de base pour Sklearn (R√©gression, Classification, R√©gularisation)">
<meta itemprop="description" content="1. L&rsquo;objet estimator Dans Scikit les algorithmes de Machine Learning sont expos√©s via des objets appel√©s &ldquo;estimator&rdquo;.
Exemple pour une r√©gression lin√©aire:
from sklearn.linear_model import LinearRegression # Tous les param√®tres pour configurer l&#39;estimator peuvent √™tre pass√© √† l&#39;objet lors de son instanciation model = LinearRegression(normalize=True) print(model) R√©sultat:
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True) L&rsquo;interface des m√©thodes de scikit-learn sont uniformes.
Pour tous les estimators:
model.fit() : remplit le mod√®le avec des donn√©es d&rsquo;entrainement."><meta itemprop="datePublished" content="2015-10-15T22:34:00+00:00" />
<meta itemprop="dateModified" content="2015-10-15T22:34:00+00:00" />
<meta itemprop="wordCount" content="1229"><meta itemprop="image" content="https://leandeep.com"/>
<meta itemprop="keywords" content="Python,Machine Learning,sklearn," /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://leandeep.com"/>

<meta name="twitter:title" content="Commandes Python de base pour Sklearn (R√©gression, Classification, R√©gularisation)"/>
<meta name="twitter:description" content="1. L&rsquo;objet estimator Dans Scikit les algorithmes de Machine Learning sont expos√©s via des objets appel√©s &ldquo;estimator&rdquo;.
Exemple pour une r√©gression lin√©aire:
from sklearn.linear_model import LinearRegression # Tous les param√®tres pour configurer l&#39;estimator peuvent √™tre pass√© √† l&#39;objet lors de son instanciation model = LinearRegression(normalize=True) print(model) R√©sultat:
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True) L&rsquo;interface des m√©thodes de scikit-learn sont uniformes.
Pour tous les estimators:
model.fit() : remplit le mod√®le avec des donn√©es d&rsquo;entrainement."/>





<meta property="article:published_time" content="2015-10-15 22:34:00 &#43;0000 UTC" />







    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://leandeep.com/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">$ cd /home/leandeep</span>
            <span class="logo__cursor" style=""></span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://leandeep.com/events/">Featured Articles</a></li><li><a href="https://leandeep.com/posts/">All Articles</a></li><li><a href="https://leandeep.com/about/">About</a></li><li><a href="https://leandeep.com/finance/">Finance</a></li><li><a href="https://leandeep.com/notebooks/">ML Notebooks</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>

            <div class="content">
                
    <main class="post">

        <div class="post-info">
            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>6 minutes

            

            </p>
        </div>

        <article>
            <h1 class="post-title">
                <a href="https://leandeep.com/commandes-python-de-base-pour-sklearn-r%C3%A9gression-classification-r%C3%A9gularisation/">Commandes Python de base pour Sklearn (R√©gression, Classification, R√©gularisation)</a>
            </h1>

            

            <div class="post-content">
                <h1 id="1-lobjet-estimator">1. L&rsquo;objet <em>estimator</em></h1>
<p>Dans Scikit les algorithmes de Machine Learning sont expos√©s via des objets appel√©s <em>&ldquo;estimator&rdquo;</em>.</p>
<p>Exemple pour une r√©gression lin√©aire:</p>
<pre tabindex="0"><code>from sklearn.linear_model import LinearRegression

# Tous les param√®tres pour configurer l&#39;estimator peuvent √™tre pass√© √† l&#39;objet lors de son instanciation
model = LinearRegression(normalize=True)

print(model)
</code></pre><p><em>R√©sultat:</em></p>
<pre tabindex="0"><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)
</code></pre><p>L&rsquo;interface des m√©thodes de scikit-learn sont uniformes.</p>
<br/>
<p><strong>Pour tous les <em>estimators</em>:</strong></p>
<ul>
<li>model.fit() : remplit le mod√®le avec des donn√©es d&rsquo;entrainement. Pour un apprentissage supervis√©, la m√©thode accepte 2 arguments: les donn√©es X et les labels y (i.e. model.fit(X, y)). Pour une apprentissage non supervis√©, la m√©thode ne prend qu&rsquo;un seul arguement, les donn√©es X (i.e. model.fit(X)).</li>
</ul>
<br/>
<p><strong>Pour les <em>estimators</em> en apprentissage supervis√©:</strong></p>
<ul>
<li>model.predict() : pr√©dire le label d&rsquo;un ensemble de features √† partir d&rsquo;un mod√®le entrain√©. La m√©thode accepte un argument, les nouvelles donn√©es X_new (i.e. model.predict(X_new) et retourne les labels pr√©dits pour chaque objet du tableau.</li>
<li>model.predict_proba() : Pour les probl√®mes de classification, certains <em>estimators</em> fournissent cette m√©thode qui retourne la probabilit√© qu&rsquo;une nouvelle observation poss√®de chaque label. La label qui la plus forte probabilit√© est retourn√© par model.predict().</li>
<li>model.score() : Pour les probl√®mes de r√©gession ou de classification, les <em>estimators</em> impl√©mentent une m√©thode de score. Cette derni√®re permet d&rsquo;indiquer si le fit est bon ou pas. Le score peut varier entre 0 et 1.</li>
</ul>
<br/>
<h1 id="2-ajouter-des-donn√©es-√†-lestimator">2. Ajouter des donn√©es √† l&rsquo;<em>estimator</em></h1>
<pre tabindex="0"><code>%matplotlib inline
import numpy as np
from matplotlib import pyplot as plt

x = np.array([0, 1, 2])
y = np.array([0, 1, 2])

_ = plt.plot(x, y, marker=&#39;o&#39;)
</code></pre><br/>
<p><em>R√©sultat:</em></p>
<p><img src="https://leandeep.com/images/plot1.png" alt="image"></p>
<pre tabindex="0"><code>X = x[:, np.newaxis] # On incr√©mente la dimension car scikit prend un tableau √† 2 dimensions en input: (samples == 3 x features == 1)

model.fit(X, y)

model.coef_ # Param√®tre estim√© par scikit √† partir des donn√©es ajout√©es. Tous les param√®tres estim√©s par scikit se terminent un _.
</code></pre><br/>
<h1 id="3-apprentissage-supervis√©-classification-et-r√©gression">3. Apprentissage supervis√©: Classification et R√©gression</h1>
<p>En apprentissage supervis√©, on a un dataset qui contient √† la fois des <em>features</em> et des <em>labels</em>.
L&rsquo;objectif est de construire un <em>estimator</em> qui est capable de pr√©dire le <em>label</em> d&rsquo;un objet √† partir d&rsquo;un ensemble de <em>features</em>.
En classification, le <em>label</em> est valeur discr√®te alors qu&rsquo;en r√©gression le <em>label</em> est une valeur continue.</p>
<br/>
<h2 id="31-classification">3.1. Classification</h2>
<p>KNN (K Nearest Neighbors) ou &ldquo;K voisins les plus proches&rdquo; en fran√ßais est un des algorithmes les plus simples √† appr√©hender:
Pour une toute nouvelle observation, regarder dans une base de r√©f√©rence, quelle observation a ses <em>features</em> les plus proches et  lui assigner la classe pr√©dominante.</p>
<p><img src="https://leandeep.com/images/Petal-sepal.jpg" alt="image"></p>
<pre tabindex="0"><code># On charge d&#39;abord le dataset Iris
from sklearn import neighbors, datasets
iris = datasets.load_iris()

# On extrait les features et labels du dataset
X, y = iris.data, iris.target

# On instancie l&#39;*estimator*
knn = neighbors.KNeighborsClassifier(n_neighbors=1) 
# n_neighbors=1 signifie que le nombre de voisin(s) √† avoir √©gal √† 1

# On remplit l&#39;*estimator* avec les donn√©es
knn.fit(X, y)

# On pr√©dit l&#39;Iris qui a les caract√©ristiques (features) suivantes: 
# s√©pale = 4cm x 3cm et p√©tale = 5cm x 2cm
print(iris.target_names[knn.predict([[4, 3, 5, 2]])])
</code></pre><p><em>R√©sultat:</em></p>
<pre tabindex="0"><code>[&#39;virginica&#39;]
</code></pre><br/>
<h3 id="afficher-un-scatter-plot-des-features-longeur-et-largeur-des-s√©pales-ainsi-que-la-pr√©duction-du-knn">Afficher un scatter plot des features longeur et largeur des s√©pales ainsi que la pr√©duction du KNN</h3>
<p>Exemple complet:</p>
<pre tabindex="0"><code># On charge le dataset
from sklearn import neighbors, datasets
iris = datasets.load_iris()

# On mappe 3 couleurs ou les 3 classes du probl√®me
from matplotlib.colors import ListedColormap
cmap_light = ListedColormap([&#39;#FFAAAA&#39;, &#39;#AAFFAA&#39;, &#39;#AAAAFF&#39;])
cmap_bold = ListedColormap([&#39;#FF0000&#39;, &#39;#00FF00&#39;, &#39;#0000FF&#39;])


X = iris.data[:, :2]  # On prend les 2 features li√©es aux s√©pales
y = iris.target

knn = neighbors.KNeighborsClassifier(n_neighbors=3)
knn.fit(X, y)

x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1
y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                      np.linspace(y_min, y_max, 100))

Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])

# On plot le r√©sultat
Z = Z.reshape(xx.shape)
plt.figure()
plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

# On plot √©galement les points d&#39;entrainement
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)
plt.xlabel(&#39;sepal length (cm)&#39;)
plt.ylabel(&#39;sepal width (cm)&#39;)
plt.axis(&#39;tight&#39;)
</code></pre><br/>
<p><em>R√©sultat:</em></p>
<p><img src="https://leandeep.com/images/scatter-plot.png" alt="image"></p>
<br/>
<h2 id="32-r√©gression">3.2. R√©gression</h2>
<p>La r√©gression la plus simple est la r√©gression lin√©aire. Voici un exemple:</p>
<p>On cr√©e des donn√©es al√©atoires:</p>
<pre tabindex="0"><code>import numpy as np
np.random.seed(0)
X = np.random.random(size=(20, 1))
y = 3 * X[:, 0] + 2 + np.random.normal(size=20)
print(X)
print(X.shape)
print(y)
print(y.shape)
</code></pre><p><em>R√©sultat:</em></p>
<pre tabindex="0"><code>[[0.5488135 ]
 [0.71518937]
 [0.60276338]
 [0.54488318]
 [0.4236548 ]
 [0.64589411]
 [0.43758721]
 [0.891773  ]
 [0.96366276]
 [0.38344152]
 [0.79172504]
 [0.52889492]
 [0.56804456]
 [0.92559664]
 [0.07103606]
 [0.0871293 ]
 [0.0202184 ]
 [0.83261985]
 [0.77815675]
 [0.87001215]]
(20, 1)
[5.14051958 3.94040984 4.12135783 2.78055381 0.71797458 4.59130093
 4.17719783 3.93315398 7.16074291 1.69595888 4.42093363 3.39950091
 5.2369129  6.24614868 2.3680556  2.63955042 1.17286944 2.51706307
 3.9865581  4.76638541]
(20,)
</code></pre><p>On remplit l&rsquo;<em>estimator</em> avec ces donn√©es:</p>
<pre tabindex="0"><code>from sklearn.linear_model import LinearRegression
model = LinearRegression(fit_intercept=True)
model.fit(X, y)
print(&#34;Model coefficient: %.5f, and intercept: %.5f&#34;
      % (model.coef_, model.intercept_))
</code></pre><br/>
<p><em>R√©sultat:</em></p>
<pre tabindex="0"><code>Model coefficient: 3.93491, and intercept: 1.46229
</code></pre><p>On affiche le graphique et le mod√®le pr√©dictif</p>
<pre tabindex="0"><code># On affiche les donn√©es d&#39;entrainement
import pylab as pl
plt.plot(X[:, 0], y, &#39;o&#39;)

# On pr√©dit les labels pour 100 points allant de 0 √† 1 qu&#39;on ajoute au graphique pr√©c√©dent
X_test = np.linspace(0, 1, 100)[:, np.newaxis]
y_test = model.predict(X_test)
plt.plot(X_test[:, 0], y_test)
</code></pre><br/>
<p><em>R√©sultat:</em></p>
<p><img src="https://leandeep.com/images/regression.png" alt="image"></p>
<br/>
<h1 id="4-r√©gularisation">4. R√©gularisation</h1>
<p>Cela permet de, comme son nom d&rsquo;indique, r√©gulariser les erreurs d&rsquo;apprentissage. Supposez que vous cr√©ez un <em>estimator</em> KNN avec k=1, il est √©vident qu&rsquo;il y aura des erreurs sur vos donn√©es d&rsquo;apprentissage.</p>
<blockquote>
<p>Wikip√©dia
&ldquo;La r√©gularisation fait r√©f√©rence √† un processus consistant √† ajouter de l&rsquo;information √† un probl√®me pour √©viter le surapprentissage&rdquo;</p>
</blockquote>
<p>L&rsquo;id√©e principale de la r√©gularisation est qu&rsquo;il est pr√©f√©rable de construire des mod√®les plus simples m√™me s&rsquo;ils conduisent √† plus d&rsquo;erreurs sur les donn√©es d&rsquo;apprentissage.</p>
<br/>
<p><strong>Un sch√©ma vaut mieux qu&rsquo;un long discours</strong></p>
<p><img src="https://leandeep.com/images/regularisation.png" alt="image"></p>
<br/>
<p>On part des donn√©es suivantes:</p>
<pre tabindex="0"><code>import numpy as np
rng = np.random.RandomState(0)
x = 2 * rng.rand(100) - 1

f = lambda t: 1.2 * t ** 2 + .1 * t ** 3 - .4 * t ** 5 - .5 * t ** 9
y = f(x) + .4 * rng.normal(size=100)

plt.figure()
plt.scatter(x, y, s=4)
</code></pre><br/>
<p><em>R√©sultat:</em></p>
<p><img src="https://leandeep.com/images/scatter-plot2.png" alt="image"></p>
<p>On remplit 2 estimateurs avec des donn√©es ayant des polyn√¥mes 4 et 9.</p>
<pre tabindex="0"><code>x_test = np.linspace(-1, 1, 100)

plt.figure()
plt.scatter(x, y, s=4)

X = np.array([x**i for i in range(5)]).T
X_test = np.array([x_test**i for i in range(5)]).T
order4 = LinearRegression()
order4.fit(X, y)
plt.plot(x_test, order4.predict(X_test), label=&#39;4th order&#39;)

X = np.array([x**i for i in range(10)]).T
X_test = np.array([x_test**i for i in range(10)]).T
order9 = LinearRegression()
order9.fit(X, y)
plt.plot(x_test, order9.predict(X_test), label=&#39;9th order&#39;)

plt.legend(loc=&#39;best&#39;)
plt.axis(&#39;tight&#39;)
plt.title(&#39;Fitting a 4th and a 9th order polynomial&#39;)
</code></pre><p><em>R√©sultat:</em></p>
<p><img src="https://leandeep.com/images/polynomes.png" alt="image"></p>
<br/>
<p>Quelle courbe pr√©f√©rez-vous ?</p>
<p>Le polyn√¥me de degr√© 9 a tendance √† passer par tous les points du graphique. Il va int√©grer le bruit sp√©cifique √† l‚Äô√©chantillon d‚Äôentra√Ænement; ce qui conduira notre mod√®le √† ne pas avoir une bonne performance sur de nouveaux exemples.</p>
<p>Un des risques majeurs avec ce type de mod√®les est le surapprentissage.
La r√©gularisation donc, est une technique permettant de (r√©gulariser) r√™gler ce ph√©nom√®ne.</p>
<br/>
<h1 id="5-example-de-r√©gularisation-l2">5. Example de R√©gularisation L2</h1>
<p>Example de calcul de la distance Euclidienne entre 2 points de chaque pair X et Y:</p>
<p><img src="https://leandeep.com/images/distance_euclidienne.png" alt="image"></p>
<pre tabindex="0"><code>lower_boundary = 0
upper_boundary = 1
n = 5 # dimension
sample_size = 10000

np.random.seed(9001) # set the seed to yield reproducible results

X = np.random.uniform( low=lower_boundary, high=upper_boundary, size=(sample_size, n) )
Y = np.random.uniform( low=lower_boundary, high=upper_boundary, size=(sample_size, n) )

print( &#39;X: &#39;, X )
print( &#39;Y: &#39;, Y )
</code></pre><p><img src="https://leandeep.com/images/paire_x_y.png" alt="image"></p>
<br/>
<pre tabindex="0"><code>from sklearn.metrics.pairwise import euclidean_distances

euclidean_distances_vector_l = []
for index, x in enumerate(X):
    euclidean_distances_vector_l.append(euclidean_distances(x.reshape(1, -1), Y[index].reshape(1, -1)))
</code></pre><br/>
<blockquote>
<p><code>x.reshape(1, -1)</code> permet d&rsquo;un vecteur √† une matrice de dimension 2 ayant autant de colonnes que d&rsquo;√©l√©ments dans le vecteur</p>
</blockquote>
<br/>
<p>Alternative en utilisant des calculs matriciels:</p>
<pre tabindex="0"><code>euclidean_distances_vector_l_vectorized = np.sqrt(np.sum((X - Y) * (X - Y), axis=1))
</code></pre>
            </div>
        </article>

        <hr />

        <div class="post-info">
                <p>
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://leandeep.com/tags/python">Python</a></span><span class="tag"><a href="https://leandeep.com/tags/machine-learning">Machine Learning</a></span><span class="tag"><a href="https://leandeep.com/tags/sklearn">sklearn</a></span>
                </p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>1229 Mots</p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>15 oct.. 2015</p>
        </div>

        
            <div class="pagination">
                <div class="pagination__title">
                    <span class="pagination__title-h"></span>
                    <hr />
                </div>

                <div class="pagination__buttons">
                    
                        <span class="button previous">
                            <a href="https://leandeep.com/cr%C3%A9er-une-archive-zip-sans-.ds_store/">
                                <span class="button__icon">‚Üê</span>
                                <span class="button__text">Cr√©er une archive zip sans .DS_Store</span>
                            </a>
                        </span>
                    

                    
                        <span class="button next">
                            <a href="https://leandeep.com/comment-lire-une-matrice-de-confusion/">
                                <span class="button__text">Comment lire une Matrice de confusion</span>
                                <span class="button__icon">‚Üí</span>
                            </a>
                        </span>
                    
                </div>
            </div>
        

        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>Built by <a href="https://www.linkedin.com/in/oliviereeckhoutte/">Olivier Eeckhoutte</a>,
                Freelance @ LeanDeep <a href="https://leandeep.com/about/">(üçÉ company)</a></span>
            <span>Siret: 83825337500011</span>
            <span><a href="https://leandeep.com/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss">
                        <path d="M4 11a9 9 0 0 1 9 9"></path>
                        <path d="M4 4a16 16 0 0 1 16 16"></path>
                        <circle cx="5" cy="19" r="1"></circle>
                    </svg></a></span>
        </div>
    </div>
</footer>
            
        </div>

        




<script type="text/javascript" src="https://leandeep.com/bundle.min.c184f8481b5847ad1a7d8aa775944fa063f118cb4df68f4eaa3826a2a2e16b26a1ad798f5160210f265c6fbb9a5f19b953fed066ae1ed1092d1858bcff13ae92.js" integrity="sha512-wYT4SBtYR60afYqndZRPoGPxGMtN9o9OqjgmoqLhayahrXmPUWAhDyZcb7uaXxm5U/7QZq4e0QktGFi8/xOukg=="></script>







    </body>
</html>
