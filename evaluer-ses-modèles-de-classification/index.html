<!DOCTYPE html>
<html lang="fr">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author"
  content="Olivier Eeckhoutte">
<meta name="description"
  content="Introduction Voici les m√©triques √† analyser pour √©valuer la performance de son mod√®le.
Classification Justesse / Accuracy
Justesse, (ou Taux de r√©ussite ou encore taux de pr√©diction; accuracy en anglais). Mais attention, il ne faut pas se fier qu&rsquo;√† cette seule m√©trique.
Pour la calculer, c&rsquo;est simple: accuracy = justesse (%) = nombre de pr√©dictions correctes / (nombre total de pr√©dictions donn√©es * 100)
ou accuracy = justesse = VP &#43; VN / ( VP &#43; VN &#43; FP &#43; FN )
" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#252627" />
<script>
  
  
  if (!(window.location.host.startsWith("127.0.0.1")) && !(window.location.host.startsWith("localhost"))) {
    if (window.location.protocol != "https:") {
      console.log("Redirecting to https...")
      window.location.protocol = "https";
    }
  }
</script>


<link rel="canonical" href="https://leandeep.com/evaluer-ses-mod%C3%A8les-de-classification/" />



<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

<style>
  #app {
    display: none;
    border-radius: 10px;
    box-shadow: 2px 5px 12px -1px rgba(0, 0, 0, 0.56);
    padding: 20px;
    background-color: white;
    max-width: 500px;
    margin: 15px auto;
    text-align: center;
    min-height: 500px;
  }

  #app input {
    margin: 0 auto;
    float: none;
    width: 100%;
    max-width: 300px;
    padding: 5px 10px;
    border: 2px solid black;
  }

  #app ul {
    margin: 0;
    padding: 0;
  }

  #app li {
    text-align: left;
    padding: 5px 10px;
    width: 100%;
    max-width: 280px;
    margin: 1px auto;
    background-color: white;
    border: 1px solid black;
    list-style: none;
  }
</style>




<title>
  
  Evaluer ses mod√®les de classification :: Lean Deep Tech blog 
  
</title>



<link href="//cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
  type="text/css">



<link rel="stylesheet" href="https://leandeep.com/main.min.44eaa49e743eabd51724579f1d2ece0dac6f56215301d6961ca74092199d4a05.css">




    <link rel="apple-touch-icon" sizes="180x180" href="https://leandeep.com/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://leandeep.com/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://leandeep.com/favicon-16x16.png">
    <link rel="manifest" href="https://leandeep.com/site.webmanifest">
    <link rel="mask-icon" href="https://leandeep.com/safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="https://leandeep.com/favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">


  <meta itemprop="name" content="Evaluer ses mod√®les de classification">
  <meta itemprop="description" content="Introduction Voici les m√©triques √† analyser pour √©valuer la performance de son mod√®le.
Classification Justesse / Accuracy
Justesse, (ou Taux de r√©ussite ou encore taux de pr√©diction; accuracy en anglais). Mais attention, il ne faut pas se fier qu‚Äô√† cette seule m√©trique.
Pour la calculer, c‚Äôest simple: accuracy = justesse (%) = nombre de pr√©dictions correctes / (nombre total de pr√©dictions donn√©es * 100)
ou accuracy = justesse = VP &#43; VN / ( VP &#43; VN &#43; FP &#43; FN )">
  <meta itemprop="datePublished" content="2017-03-15T15:27:00+00:00">
  <meta itemprop="dateModified" content="2017-03-15T15:27:00+00:00">
  <meta itemprop="wordCount" content="827">
  <meta itemprop="image" content="https://leandeep.com/">
  <meta itemprop="keywords" content="Machine Learning">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://leandeep.com/">
  <meta name="twitter:title" content="Evaluer ses mod√®les de classification">
  <meta name="twitter:description" content="Introduction Voici les m√©triques √† analyser pour √©valuer la performance de son mod√®le.
Classification Justesse / Accuracy
Justesse, (ou Taux de r√©ussite ou encore taux de pr√©diction; accuracy en anglais). Mais attention, il ne faut pas se fier qu‚Äô√† cette seule m√©trique.
Pour la calculer, c‚Äôest simple: accuracy = justesse (%) = nombre de pr√©dictions correctes / (nombre total de pr√©dictions donn√©es * 100)
ou accuracy = justesse = VP &#43; VN / ( VP &#43; VN &#43; FP &#43; FN )">





<meta property="article:published_time" content="2017-03-15 15:27:00 &#43;0000 UTC" />







    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://leandeep.com/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">$ cd /home/leandeep</span>
            <span class="logo__cursor" style=""></span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://leandeep.com/events/">Featured Articles</a></li><li><a href="https://leandeep.com/posts/">All Articles</a></li><li><a href="https://leandeep.com/about/">About Me</a></li><li><a href="https://leandeep.com/other/">Other</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>

            <div class="content">
                
    <main class="post">

        <div class="post-info">
            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>4 minutes

            

            </p>
        </div>

        <article>
            <h1 class="post-title">
                <a href="https://leandeep.com/evaluer-ses-mod%C3%A8les-de-classification/">Evaluer ses mod√®les de classification</a>
            </h1>

            

            <div class="post-content">
                <h2 id="introduction">Introduction</h2>
<p>Voici les m√©triques √† analyser pour √©valuer la performance de son mod√®le.</p>
<h2 id="classification">Classification</h2>
<p><strong>Justesse / Accuracy</strong></p>
<ul>
<li>
<p><code>Justesse</code>, (ou <code>Taux de r√©ussite</code> ou encore <code>taux de pr√©diction</code>; <code>accuracy</code> en anglais). <strong>Mais attention, il ne faut pas se fier qu&rsquo;√† cette seule m√©trique.</strong></p>
<p>Pour la calculer, c&rsquo;est simple:
accuracy = justesse (%) = nombre de pr√©dictions correctes / (nombre total de pr√©dictions donn√©es * 100)</p>
<p>ou
accuracy = justesse = VP + VN / ( VP + VN + FP + FN )</p>
</li>
</ul>
<p>Exemple (source developer.google.com):</p>
<p><img src="https://leandeep.com/images/exemple-justesse.png" alt="image"></p>
<ul>
<li>CART (Classification And Regression Tree) Voir wikip√©dia: <a href="http://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees">http://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees</a></li>
</ul>
<p><strong>Matrice de confusion</strong></p>
<ul>
<li>
<p>La <code>Matrice de confusion</code> (<code>tableau de contingence</code>; <code>contingency table</code> en anglais) est une mani√®re simple et non ambigue de pr√©senter les r√©sultats d&rsquo;un classifier. (Voici un exemple sur ce notebook: <a href="https://leandeep.com/datalab-own/analyse-donnees-dataset-desequilibre.htm">https://leandeep.com/datalab-own/analyse-donnees-dataset-desequilibre.htm</a>)</p>
<p>Pour un sujet de classification binaire et non multi-classes (comme l&rsquo;example plus haut), la matrice de confusion ressemble √† ceci:</p>
</li>
</ul>
<p><img src="https://leandeep.com/images/matrice-confusion.png" alt="image"></p>
<p><em>En haut, on a ce qui est observ√© et sur le c√¥t√© ce qui est pr√©dit.</em></p>
<p>Parfois et par exemple pour des sujets o√π les classes sont d√©s√©quilibr√©es il vaut mieux ne pas se fier au taux de pr√©cision (<em>accuracy</em>) et plus utiliser une matrice de confusion.</p>
<p>En effet, utiliser le <code>nombre de faux positifs</code> ou <code>faux n√©gatifs</code> pour les sujets li√©s √† la sant√© par exemple a plus de sens que le taux de pr√©cision du mod√®le. <strong>Un mod√®le qui pr√©dit si oui ou non on a le cancer ne doit pas avoir de faux n√©gatif. Le taux de pr√©cision a donc moins d&rsquo;importance dans ce cas. Au contraire, un mod√®le qui pr√©dit qu&rsquo;un patient est en bonne sant√© alors qu&rsquo;il a un cancer c&rsquo;est grave car le patient peut en mourir puisqu&rsquo;il ne sera pas soign√© !</strong>)</p>
<p><strong>Precision</strong></p>
<p><img src="https://leandeep.com/images/precision-rappel.png" alt="image"></p>
<p>La <code>pr√©cision</code> permet de r√©pondre √† la question: &ldquo;Quelle proportion d&rsquo;identifications positives √©tait effectivement correcte ?&rdquo;</p>
<p>La pr√©cision se calcule comme ceci:</p>
<p><img src="https://leandeep.com/images/precision.png" alt="image"></p>
<p>Example (source developer.google.com):</p>
<p><img src="https://leandeep.com/images/exemple-precision.png" alt="image"></p>
<p>**Rappel **</p>
<p>Le <code>rappel</code> (<em><code>recall</code></em> en anglais ou aussi <code>sensibilit√©</code> ou encore <code>taux de vrais positifs (TVP)</code>) permet de r√©pondre √† la question suivante: &ldquo;Quelle proportion de r√©sultats positifs r√©els a √©t√© identifi√©e correctement ?&rdquo;</p>
<p>Le rappel se calcule comme ceci:</p>
<p><img src="https://leandeep.com/images/rappel.png" alt="image"></p>
<p>Example (source developer.google.com):</p>
<p><img src="https://leandeep.com/images/exemple-rappel.png" alt="image"></p>
<p>Pour √©valuer les performances d&rsquo;un mod√®le de fa√ßon compl√®te, vous devez analyser √† la fois la pr√©cision et le rappel. Malheureusement, pr√©cision et rappel sont fr√©quemment en tension. Ceci est d√ª au fait que l&rsquo;am√©lioration de la pr√©cision se fait g√©n√©ralement au d√©triment du rappel et r√©ciproquement.</p>
<p>Dans l&rsquo;exemple du d√©pistage de cancer c&rsquo;est la proportion de vrais positifs parmi les personnes √† d√©pister.</p>
<p>**Sp√©cificit√© **</p>
<p>La <code>sp√©cificit√©</code> se calcule comme ceci:</p>
<p><img src="https://leandeep.com/images/specificite.png" alt="image"></p>
<p>Dans l&rsquo;exemple du d√©pistage du cancer c&rsquo;est proportion de vrais n√©gatifs chez les non-malades.</p>
<p><strong>Diff√©rence avec la sensibilit√©:</strong></p>
<p>La <code>sensibilit√©</code> est l&rsquo;indice qui √©value la capacit√© d&rsquo;une mesure √† bien classer les malades (ou les expos√©s), et la <code>sp√©cificit√©</code> celui qui √©value la capacit√© √† bien classer les non-malades (ou les non-expos√©s).</p>
<p>**Score F1 **</p>
<p>Aussi appel√© <em>F Score</em> ou <em>F Measure</em>, le <code>score F1</code> permet de traduire l&rsquo;√©quilibre entre la pr√©cision et le rappel. Attention, le probl√®me de cette m√©trique est qu&rsquo;elle ne tient pas compte de l&rsquo;√©ventuel d√©s√©quilibre entre les classes.</p>
<p>Il se calcule comme ceci:</p>
<p><img src="https://leandeep.com/images/f1-score.png" alt="image"></p>
<p><strong>Courbe ROC</strong></p>
<p>La <code>courbe ROC</code> (Receiver Operating Characteristic) trace le taux de vrais positifs en fonction du taux de faux positifs.</p>
<p>Le taux de vrais positifs (TVP) est l&rsquo;√©quivalent du rappel.</p>
<p>Le taux de faux positifs (TFP) se calcule comme ceci:</p>
<p><img src="https://leandeep.com/images/taux-faux-positifs-TFP.png" alt="image"></p>
<p><img src="https://leandeep.com/images/courbe-roc.png" alt="image"></p>
<p>Elle r√©sume le trade-off entre le taux de vrais positifs et le taux de faux n√©gatifs pour un mod√®le pr√©dictif en utilisant diff√©rent seuils de probabilit√©.</p>
<p>Cette courbe sert √©galement √† comparer diff√©rents classifieurs. <strong>Plus une courbe a des valeurs √©lev√©es, plus l‚Äôaire sous la courbe est grande, moins le classifieur fait d‚Äôerreur.</strong></p>
<blockquote>
<p>Il existe aussi la Precision-Recall curves.
The latter summarizes the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.</p></blockquote>
<p><strong>ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.</strong> En savoir plus sur cet article: <a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/">https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/</a></p>
<p><strong>AUC</strong></p>
<p>En savoir plus sur l&rsquo;aire sous la courbe ROC (<code>AUC</code> pour Area Under the Curve ROC) sur le m√™me site qu&rsquo;au dessus: <a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/">https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/</a></p>
<p>&ldquo;An excellent model has AUC near to the 1 which means it has good measure of separability. A poor model has AUC near to the 0 which means it has worst measure of separability.
And when AUC is 0.5, it means model has no class separation capacity whatsoever. It would be a naive model.&rdquo;</p>
<p>En gros l&rsquo;AUC correspond √† l‚Äôint√©grale de la fonction ROC.</p>
<p>Voici une vid√©o explicative: <a href="https://www.dataschool.io/roc-curves-and-auc-explained/">https://www.dataschool.io/roc-curves-and-auc-explained/</a></p>
<h2 id="conclusion">Conclusion</h2>
<p>Un &ldquo;bon&rdquo; classifieur doit pr√©senter d‚Äôune part un rappel √©lev√© et, d‚Äôautre part, une pr√©cision et une sp√©cificit√© √©lev√©e (et un taux de faux positifs faible).</p>
<p>Scikit Learn fournit un tas de m√©triques par d√©faut: <a href="https://scikit-learn.org/stable/modules/model_evaluation.html">https://scikit-learn.org/stable/modules/model_evaluation.html</a></p>
<p>Voici enfin un article int√©ressant sur les m√©triques en g√©n√©ral pour des sujets de classification, de recommandation et de r√©gression.
<a href="https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/3/evaluation-metrics">https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/3/evaluation-metrics</a></p>

            </div>
        </article>

        <hr />

        <div class="post-info">
                <p>
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://leandeep.com/tags/machine-learning">Machine Learning</a></span>
                </p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>827 Mots</p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>15 mars. 2017</p>
        </div>

        
            <div class="pagination">
                <div class="pagination__title">
                    <span class="pagination__title-h"></span>
                    <hr />
                </div>

                <div class="pagination__buttons">
                    
                        <span class="button previous">
                            <a href="https://leandeep.com/pourquoi-il-faut-utiliser-object.is-pour-comparer-des-%C3%A9l%C3%A9ments/">
                                <span class="button__icon">‚Üê</span>
                                <span class="button__text">Pourquoi il faut utiliser Object.is() pour comparer des √©l√©ments</span>
                            </a>
                        </span>
                    

                    
                        <span class="button next">
                            <a href="https://leandeep.com/tradeoff-biais-variance/">
                                <span class="button__text">Tradeoff biais variance</span>
                                <span class="button__icon">‚Üí</span>
                            </a>
                        </span>
                    
                </div>
            </div>
        

        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>Built by <a href="https://www.linkedin.com/in/oliviereeckhoutte/">Olivier Eeckhoutte</a>,
                Freelance @ LeanDeep <a href="https://leandeep.com/about/">(üçÉ company)</a></span>
            <span>Siret: 83825337500011</span>
            <span><a href="https://leandeep.com/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss">
                        <path d="M4 11a9 9 0 0 1 9 9"></path>
                        <path d="M4 4a16 16 0 0 1 16 16"></path>
                        <circle cx="5" cy="19" r="1"></circle>
                    </svg></a></span>
        </div>
    </div>
</footer>
            
        </div>

        




<script type="text/javascript" src="https://leandeep.com/bundle.min.1b40b3081e8e87bdad099bee55bd6a98514afc1e30a059c463b59602eec9735d70bd6e4d3186c853b9b790984744c67a34d6e5844a992166bcea0d2acca86547.js" integrity="sha512-G0CzCB6Oh72tCZvuVb1qmFFK/B4woFnEY7WWAu7Jc11wvW5NMYbIU7m3kJhHRMZ6NNblhEqZIWa86g0qzKhlRw=="></script>







    </body>
</html>
