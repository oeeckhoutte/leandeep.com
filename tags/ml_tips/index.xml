<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ml_tips on Lean Deep Tech blog</title>
    <link>https://leandeep.com/tags/ml_tips/</link>
    <description>Recent content in ml_tips on Lean Deep Tech blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Mon, 04 Feb 2019 21:23:04 -0700</lastBuildDate><atom:link href="https://leandeep.com/tags/ml_tips/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Détecter les données aberrantes (outliers)</title>
      <link>https://leandeep.com/d%C3%A9tecter-les-donn%C3%A9es-aberrantes-outliers/</link>
      <pubDate>Mon, 04 Feb 2019 21:23:04 -0700</pubDate>
      
      <guid>https://leandeep.com/d%C3%A9tecter-les-donn%C3%A9es-aberrantes-outliers/</guid>
      <description>Pré-requis pip install numpy sklearn # va installer numpy 1.19.1 et sklearn 0.0 Charger les librairies import numpy as np from sklearn.covariance import EllipticEnvelope from sklearn.datasets import make_blobs Créer un faux dataset # Create simulated data X, _ = make_blobs(n_samples = 10, n_features = 2, centers = 1, random_state = 1) # Remplace les valeurs de la première observation avec des données extrèmes X[0,0] = 10000 X[0,1] = 10000 Voici à quoi ressemble notre dataset composé de 10 observations:</description>
    </item>
    
    <item>
      <title>Convertir les données catégorielles en integer pour sklearn</title>
      <link>https://leandeep.com/convertir-les-donn%C3%A9es-cat%C3%A9gorielles-en-integer-pour-sklearn/</link>
      <pubDate>Sat, 02 Feb 2019 22:13:18 -0700</pubDate>
      
      <guid>https://leandeep.com/convertir-les-donn%C3%A9es-cat%C3%A9gorielles-en-integer-pour-sklearn/</guid>
      <description>Pré-requis pip install pandas sklearn # va installer pandas 1.1.0 et sklearn 0.0 Charger les librairies from sklearn import preprocessing import pandas as pd Création d&amp;rsquo;un faux dataset raw_data = { &amp;#39;patient&amp;#39;: [1, 1, 1, 2, 2], &amp;#39;observation&amp;#39;: [1, 2, 3, 1, 2], &amp;#39;traitement&amp;#39;: [0, 1, 0, 1, 0], &amp;#39;etat&amp;#39;: [&amp;#39;vivant&amp;#39;, &amp;#39;mort&amp;#39;, &amp;#39;zombie&amp;#39;, &amp;#39;vivant&amp;#39;, &amp;#39;mort&amp;#39;] } df = pd.DataFrame(raw_data, columns = [&amp;#39;patient&amp;#39;, &amp;#39;observation&amp;#39;, &amp;#39;traitement&amp;#39;, &amp;#39;etat&amp;#39;]) Fit the Label Encoder # Créer un objet label (catégorie) encoder le = preprocessing.</description>
    </item>
    
    <item>
      <title>Effacer les données manquantes</title>
      <link>https://leandeep.com/effacer-les-donn%C3%A9es-manquantes/</link>
      <pubDate>Sun, 30 Dec 2018 22:13:18 -0700</pubDate>
      
      <guid>https://leandeep.com/effacer-les-donn%C3%A9es-manquantes/</guid>
      <description>Pré-requis pip install numpy pandas # va installer numpy 1.19.1 et pandas 1.1.0 Charger les librairies import numpy as np import pandas as pd Création d&amp;rsquo;une matrice de données # Création de la feature matrice X = np.array([[1, 2], [6, 3], [8, 4], [9, 5], [np.nan, 4]]) Effacer les données manquantes Avec Numpy
X[~np.isnan(X).any(axis=1)] Résultat:
array([[1., 2.], [6., 3.], [8., 4.], [9., 5.]]) Avec Pandas
# On transforme les données en dataframe Pandas df = pd.</description>
    </item>
    
  </channel>
</rss>
