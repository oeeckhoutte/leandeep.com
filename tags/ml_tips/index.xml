<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ml_tips on Bienvenue sur le site de Lean Deep</title>
    <link>https://leandeep.com/tags/ml_tips/</link>
    <description>Recent content in ml_tips on Bienvenue sur le site de Lean Deep</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Mon, 04 Feb 2019 21:23:04 -0700</lastBuildDate>
    
	<atom:link href="https://leandeep.com/tags/ml_tips/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Détecter les données aberrantes</title>
      <link>https://leandeep.com/tips/sklearn/detecter-les-donnees-aberrantes/</link>
      <pubDate>Mon, 04 Feb 2019 21:23:04 -0700</pubDate>
      
      <guid>https://leandeep.com/tips/sklearn/detecter-les-donnees-aberrantes/</guid>
      <description>Pré-requis pip install numpy sklearn # va installer numpy 1.19.1 et sklearn 0.0  Charger les librairies import numpy as np from sklearn.covariance import EllipticEnvelope from sklearn.datasets import make_blobs  Créer un faux dataset # Create simulated data X, _ = make_blobs(n_samples = 10, n_features = 2, centers = 1, random_state = 1) # Remplace les valeurs de la première observation avec des données extrèmes X[0,0] = 10000 X[0,1] = 10000 Voici à quoi ressemble notre dataset composé de 10 observations:</description>
    </item>
    
    <item>
      <title>Convertir les données catégorielles en integer pour sklearn</title>
      <link>https://leandeep.com/tips/pandas/convertir-donnees-categorielles-en-integer-pour-sklearn/</link>
      <pubDate>Sat, 02 Feb 2019 22:13:18 -0700</pubDate>
      
      <guid>https://leandeep.com/tips/pandas/convertir-donnees-categorielles-en-integer-pour-sklearn/</guid>
      <description>Pré-requis pip install pandas sklearn # va installer pandas 1.1.0 et sklearn 0.0  Charger les librairies from sklearn import preprocessing import pandas as pd  Création d&#39;un faux dataset raw_data = { &#39;patient&#39;: [1, 1, 1, 2, 2], &#39;observation&#39;: [1, 2, 3, 1, 2], &#39;traitement&#39;: [0, 1, 0, 1, 0], &#39;etat&#39;: [&#39;vivant&#39;, &#39;mort&#39;, &#39;zombie&#39;, &#39;vivant&#39;, &#39;mort&#39;] } df = pd.DataFrame(raw_data, columns = [&#39;patient&#39;, &#39;observation&#39;, &#39;traitement&#39;, &#39;etat&#39;])  Fit the Label Encoder # Créer un objet label (catégorie) encoder le = preprocessing.</description>
    </item>
    
    <item>
      <title>Effacer les données manquantes</title>
      <link>https://leandeep.com/tips/pandas/effacer-les-donnees-manquantes/</link>
      <pubDate>Fri, 01 Feb 2019 22:13:18 -0700</pubDate>
      
      <guid>https://leandeep.com/tips/pandas/effacer-les-donnees-manquantes/</guid>
      <description>Pré-requis pip install numpy pandas # va installer numpy 1.19.1 et pandas 1.1.0  Charger les librairies import numpy as np import pandas as pd  Création d&#39;une matrice de données # Création de la feature matrice X = np.array([[1, 2], [6, 3], [8, 4], [9, 5], [np.nan, 4]])  Effacer les données manquantes Avec Numpy
X[~np.isnan(X).any(axis=1)] Résultat:
array([[1., 2.], [6., 3.], [8., 4.], [9., 5.]])  Avec Pandas
# On transforme les données en dataframe Pandas df = pd.</description>
    </item>
    
  </channel>
</rss>