<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on Bienvenue sur le site de Lean Deep</title>
    <link>https://leandeep.com/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Bienvenue sur le site de Lean Deep</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Tue, 03 Sep 2019 07:48:00 +0000</lastBuildDate>
    
	<atom:link href="https://leandeep.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>[NLP] 2 manières de générer des N-grams en Python </title>
      <link>https://leandeep.com/nlp-2-mani%C3%A8res-de-g%C3%A9n%C3%A9rer-des-n-grams-en-python/</link>
      <pubDate>Tue, 03 Sep 2019 07:48:00 +0000</pubDate>
      
      <guid>https://leandeep.com/nlp-2-mani%C3%A8res-de-g%C3%A9n%C3%A9rer-des-n-grams-en-python/</guid>
      <description>Introduction Dans une phrase, les N-grams sont des séquences de N-mots adjacents. N peut être 1 ou 2 ou toute autre entier positif. En général N n&#39;est pas très grand car ces N-grams apparaissent rarement plusieurs fois.
On utilise ces N-grams en Machine Learning dans les sujets qui traitent du Natural Language Processing. Plus précisément, on les retrouve dans les sujets de classification de textes. On peut utiliser des bi-grams ou tri-grams comme features pour représenter nos documents en plus d&#39;utiliser des tokens individuels trouvés dans le corpus.</description>
    </item>
    
    <item>
      <title>Installer XGBoost, LightGBM et CatBoost sur Ubuntu 18.04</title>
      <link>https://leandeep.com/installer-xgboost-lightgbm-et-catboost-sur-ubuntu-18.04/</link>
      <pubDate>Fri, 19 Jul 2019 11:14:00 +0000</pubDate>
      
      <guid>https://leandeep.com/installer-xgboost-lightgbm-et-catboost-sur-ubuntu-18.04/</guid>
      <description>Installation de XGBoost Installation simple Exécuter la commande suivante:
pip install xgboost  &amp;ldquo;The default open-source XGBoost packages already include GPU support.&amp;rdquo;
 Build from source Si cela ne fonctionne pas, compiler et installer XGBoost depuis les sources.
Installer cmake pour builder xgboost. La version CMake 3.12 ou plus est requise.
sudo apt-get update sudo apt install -y cmake cmake --version Si ce n&#39;est pas la bonne version désinstallez le avant de le réinstaller manuellement:</description>
    </item>
    
    <item>
      <title>Mastering Pandas</title>
      <link>https://leandeep.com/mastering-pandas/</link>
      <pubDate>Sat, 16 Feb 2019 13:47:00 +0000</pubDate>
      
      <guid>https://leandeep.com/mastering-pandas/</guid>
      <description>Cela fait pas mal de temps que j&#39;utilise Pandas. Dans cet article je vais essayer de réunir et synthétiser tous les tips &amp;amp; tricks à savoir (comme si j&#39;utilisais Jupyter Notebook).
Voici la liste des tips:
 Introduction à Pandas Lire des données tabulaires Sélectionner une série Pandas Parenthèses Pandas Renommer des colonnes Effacer une colonne Effacer toutes les colonnes sauf Trier Filtrer Filtres multi-critères Examiner un dataset Numéro, index et contenu de la ligne lors d&#39;une itération  A compléter&amp;hellip;</description>
    </item>
    
    <item>
      <title>Comment réduire la durée d&#39;entrainement d&#39;un modèle ?</title>
      <link>https://leandeep.com/comment-r%C3%A9duire-la-dur%C3%A9e-dentrainement-dun-mod%C3%A8le/</link>
      <pubDate>Wed, 13 Feb 2019 20:11:00 +0000</pubDate>
      
      <guid>https://leandeep.com/comment-r%C3%A9duire-la-dur%C3%A9e-dentrainement-dun-mod%C3%A8le/</guid>
      <description>Supposons que nous ayons un dataset composé de 1000 colonnes et comportant 1 million de lignes pour un sujet de classification, comment réduire sa dimension pour réduire les temps d&#39;entrainement ? On suppose également que la machine qui va faire l&#39;entrainement n&#39;a pas énormément de RAM&amp;hellip;
Voici les différentes options:
 Commencer par fermer toutes les applications qui ne servent à rien Echantillonner aléatoirement le dataset. C&#39;est-à-dire créer plusieurs petits datasets de dimension M(300 000, 1 000) et faire plusieurs entrainements On peut séparer les variables numériques et catégorielles et supprimer les variables corrélées.</description>
    </item>
    
    <item>
      <title>Rendre Tensorflow compatible avec plus de cartes graphiques</title>
      <link>https://leandeep.com/rendre-tensorflow-compatible-avec-plus-de-cartes-graphiques/</link>
      <pubDate>Sat, 29 Sep 2018 19:50:00 +0000</pubDate>
      
      <guid>https://leandeep.com/rendre-tensorflow-compatible-avec-plus-de-cartes-graphiques/</guid>
      <description>Installer les dépendances: Installer openjdk 8:
sudo apt-get install openjdk-8-jdk Installer les autres dépendances:
sudo apt-get install pkg-config zip g++ zlib1g-dev unzip Installer Bazel: wget https://github.com/bazelbuild/bazel/releases/download/0.17.2/bazel-0.17.2-installer-linux-x86_64.sh chmod +x bazel-0.17.2-installer-linux-x86_64.sh ./bazel-0.17.2-installer-linux-x86_64.sh --user Pour pouvoir utiliser Bazel, modifier votre .bashrc ou .zshrc et ajouter cette commande:
export PATH=&amp;quot;$PATH:$HOME/bin&amp;quot; Install libcudnn Télécharger le binaire directement depuis le site: https://developer.nvidia.com/cudnn. Cette étape nécessite de créer une compte chez Nvidia.
Pour installer le binaire il suffit d&#39;exécuter la commande suivante:</description>
    </item>
    
    <item>
      <title>Comment j&#39;organise mes projets de data science ?</title>
      <link>https://leandeep.com/comment-jorganise-mes-projets-de-data-science/</link>
      <pubDate>Thu, 27 Sep 2018 13:22:00 +0000</pubDate>
      
      <guid>https://leandeep.com/comment-jorganise-mes-projets-de-data-science/</guid>
      <description>J&#39;ai travaillé sur multiples projets de développement et clairement ceux qui fonctionnent le mieux sont ceux qui sont les plus structurés que ce soit en terme de:
 Méthodologie et d&#39;organisation d&#39;équipe (Agile) Mindset Pratiques de développement (TDD, refactoring, pair programing) une bonne usine logiciel (CircleCI, Gitlab CI, tests unitaires et e2e auto, monitoring&amp;hellip;) bon staffing  A chaque fois qu&#39;il y avait ces 5 composantes, le projet était couronné de succès.</description>
    </item>
    
    <item>
      <title>Datalab made portable on any server or laptop to work from anywhere with or without internet</title>
      <link>https://leandeep.com/datalab-made-portable-on-any-server-or-laptop-to-work-from-anywhere-with-or-without-internet/</link>
      <pubDate>Fri, 31 Aug 2018 10:46:30 +0000</pubDate>
      
      <guid>https://leandeep.com/datalab-made-portable-on-any-server-or-laptop-to-work-from-anywhere-with-or-without-internet/</guid>
      <description>Introduction Cet article n&#39;est pas vraiment détaillé et structuré. Il s&#39;agit plus de notes personnelles pour avoir toujours à disposition mon datalab avec toutes les données (max 1 To for now) nécessaires pour travailler. Il s&#39;agit d&#39;une installation très rapide à usage personnel. Ici je ne parle pas du tout d&#39;industrialisation ou de setup pour une grande entreprise&amp;hellip; L&#39;idée ici est de pouvoir travailler de partout que ce soit avec ou sans internet.</description>
    </item>
    
    <item>
      <title>Lancer un Datalab en quelques minutes</title>
      <link>https://leandeep.com/lancer-un-datalab-en-quelques-minutes/</link>
      <pubDate>Fri, 19 Jan 2018 23:39:00 +0000</pubDate>
      
      <guid>https://leandeep.com/lancer-un-datalab-en-quelques-minutes/</guid>
      <description>Il m’arrive assez régulièrement de devoir switcher de machine de développement lorsque je travaille sur du Machine ou Deep Learning. C’est d’autant plus vrai lorsque je travaille avec Tensorflow avec support GPU et que je manipule des datasets de plusieurs Go. Pour accélérer la phase d’apprentissage de mes algorithmes, il m’arrive de louer, durant plusieurs heures, des VM survitaminées chez Amazon Web Services.
Pour éviter de devoir reconfigurer à chaque fois mon environnement de datascience, j’utilise 2 images Docker.</description>
    </item>
    
    <item>
      <title>Algorithmes de Marchine Learning organisés par famille</title>
      <link>https://leandeep.com/algorithmes-de-marchine-learning-organis%C3%A9s-par-famille/</link>
      <pubDate>Sat, 06 Jan 2018 19:22:00 +0000</pubDate>
      
      <guid>https://leandeep.com/algorithmes-de-marchine-learning-organis%C3%A9s-par-famille/</guid>
      <description>Mindmap source machinelearningmastery; site internet que je recommande vraiment. Tout n&#39;est pas présent mais il y a quoi faire pour s&#39;amuser.</description>
    </item>
    
    <item>
      <title>Installer (Mini)Conda sur OSX</title>
      <link>https://leandeep.com/installer-miniconda-sur-osx/</link>
      <pubDate>Sun, 04 Jun 2017 20:57:00 +0000</pubDate>
      
      <guid>https://leandeep.com/installer-miniconda-sur-osx/</guid>
      <description>Qu&#39;est-ce que Conda ? Conda est un outil permettant de gérer les packages scientifiques utiles notamment pour faire du Machine Learning. Il gère aussi les dépendances de ces packages; même celles en dehors de Python (Librairies C, Paquets R&amp;hellip;). Il permet également de gérer des environnements virtuels comme virtualenv. C&#39;est un outil très répandu que vous retrouverez dans beaucoup de cours ou tutoriels. Il est donc intéressant de l&#39;installer sur votre poste.</description>
    </item>
    
  </channel>
</rss>