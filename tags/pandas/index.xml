<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pandas on Lean Deep Tech blog</title>
    <link>https://leandeep.com/tags/pandas/</link>
    <description>Recent content in Pandas on Lean Deep Tech blog</description>
    <generator>Hugo</generator>
    <language>fr</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Fri, 27 Jan 2023 10:49:00 +0200</lastBuildDate>
    <atom:link href="https://leandeep.com/tags/pandas/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Créer un dataset avec les données Binance OHLCV pour réaliser des backtests</title>
      <link>https://leandeep.com/cr%C3%A9er-un-dataset-avec-les-donn%C3%A9es-binance-ohlcv-pour-r%C3%A9aliser-des-backtests/</link>
      <pubDate>Fri, 27 Jan 2023 10:49:00 +0200</pubDate>
      <guid>https://leandeep.com/cr%C3%A9er-un-dataset-avec-les-donn%C3%A9es-binance-ohlcv-pour-r%C3%A9aliser-des-backtests/</guid>
      <description>&lt;p&gt;Sans utiliser la librairie CCTX dont j&amp;rsquo;ai parlé &lt;a href=&#34;https://leandeep.com/retourner-un-dataframe-ohlcv-des-tickers-binance-%C3%A0-partir-de-cctx/&#34;&gt;dans l&amp;rsquo;article&lt;/a&gt;, voici comment récupérer directement les données OHLCV depuis l&amp;rsquo;API de Binance:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import requests&#xA;import datetime&#xA;import pandas as pd&#xA;import numpy as np&#xA;&#xA;start_date = &amp;#34;2022-01-01&amp;#34;&#xA;end_date = &amp;#34;2022-01-31&amp;#34;&#xA;interval = &amp;#34;1m&amp;#34;&#xA;symbol = &amp;#34;BTCUSDT&amp;#34;&#xA;&#xA;&#xA;def get_binance_data(&#xA;    ticker: str,&#xA;    interval: str = &amp;#34;4h&amp;#34;,&#xA;    limit: int = 500,&#xA;    start: str = &amp;#34;2018-01-01 00:00:00&amp;#34;,&#xA;) -&amp;gt; pd.DataFrame:&#xA;    &amp;#34;&amp;#34;&amp;#34;Get X (limit) OHLCV entries from Binance&amp;#34;&amp;#34;&amp;#34;&#xA;    columns = [&#xA;        &amp;#34;open_time&amp;#34;,&#xA;        &amp;#34;open&amp;#34;,&#xA;        &amp;#34;high&amp;#34;,&#xA;        &amp;#34;low&amp;#34;,&#xA;        &amp;#34;close&amp;#34;,&#xA;        &amp;#34;volume&amp;#34;,&#xA;        &amp;#34;close_time&amp;#34;,&#xA;        &amp;#34;qav&amp;#34;,&#xA;        &amp;#34;num_trades&amp;#34;,&#xA;        &amp;#34;taker_base_vol&amp;#34;,&#xA;        &amp;#34;taker_quote_vol&amp;#34;,&#xA;        &amp;#34;ignore&amp;#34;,&#xA;    ]&#xA;    start = int(datetime.datetime.timestamp(pd.to_datetime(start)) * 1000)&#xA;    base_url = &amp;#34;https://www.binance.com/api/v3/klines&amp;#34;&#xA;    query_params = (&#xA;        f&amp;#34;?symbol={ticker}&amp;amp;interval={interval}&amp;amp;limit={limit}&amp;amp;startTime={start}&amp;#34;&#xA;    )&#xA;    url = base_url + query_params&#xA;    data = pd.DataFrame(&#xA;        requests.get(url).json(), columns=columns, dtype=np.float&#xA;    )&#xA;    data.index = [&#xA;        pd.to_datetime(x, unit=&amp;#34;ms&amp;#34;).strftime(&amp;#34;%Y-%m-%d %H:%M:%S&amp;#34;)&#xA;        for x in data.open_time&#xA;    ]&#xA;    use_cols = [&#xA;        &amp;#34;open&amp;#34;,&#xA;        &amp;#34;high&amp;#34;,&#xA;        &amp;#34;low&amp;#34;,&#xA;        &amp;#34;close&amp;#34;,&#xA;        &amp;#34;volume&amp;#34;,&#xA;        &amp;#34;qav&amp;#34;,&#xA;        &amp;#34;num_trades&amp;#34;,&#xA;        &amp;#34;taker_base_vol&amp;#34;,&#xA;        &amp;#34;taker_quote_vol&amp;#34;,&#xA;    ]&#xA;    data = data[use_cols]&#xA;    return data&#xA;&#xA;&#xA;if __name__ == &amp;#34;__main__&amp;#34;:&#xA;    df = get_binance_data(&amp;#34;BTCUSDT&amp;#34;, &amp;#34;1m&amp;#34;)&#xA;    print(df.head())&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;br/&gt;&#xA;Résultat:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mastering Pandas</title>
      <link>https://leandeep.com/mastering-pandas/</link>
      <pubDate>Sat, 16 Feb 2019 13:47:00 +0000</pubDate>
      <guid>https://leandeep.com/mastering-pandas/</guid>
      <description>&lt;p&gt;Cela fait pas mal de temps que j&amp;rsquo;utilise Pandas. Dans cet article je vais essayer de réunir et synthétiser tous les tips &amp;amp; tricks à savoir (comme si j&amp;rsquo;utilisais Jupyter Notebook).&lt;/p&gt;&#xA;&lt;p&gt;Voici la liste des tips:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Introduction à Pandas&lt;/li&gt;&#xA;&lt;li&gt;Lire des données tabulaires&lt;/li&gt;&#xA;&lt;li&gt;Sélectionner une série Pandas&lt;/li&gt;&#xA;&lt;li&gt;Parenthèses Pandas&lt;/li&gt;&#xA;&lt;li&gt;Renommer des colonnes&lt;/li&gt;&#xA;&lt;li&gt;Effacer une colonne&lt;/li&gt;&#xA;&lt;li&gt;Effacer toutes les colonnes sauf&lt;/li&gt;&#xA;&lt;li&gt;Trier&lt;/li&gt;&#xA;&lt;li&gt;Filtrer&lt;/li&gt;&#xA;&lt;li&gt;Filtres multi-critères&lt;/li&gt;&#xA;&lt;li&gt;Examiner un dataset&lt;/li&gt;&#xA;&lt;li&gt;Numéro, index et contenu de la ligne lors d&amp;rsquo;une itération&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;introduction-à-pandas&#34;&gt;Introduction à Pandas&lt;/h2&gt;&#xA;&lt;p&gt;C&amp;rsquo;est une librairie opensource d&amp;rsquo;analyse de données qui fourni des structures de données ainsi que des outils d&amp;rsquo;analyse faciles à utiliser.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Convertir les données catégorielles en integer pour sklearn</title>
      <link>https://leandeep.com/convertir-les-donn%C3%A9es-cat%C3%A9gorielles-en-integer-pour-sklearn/</link>
      <pubDate>Sat, 02 Feb 2019 22:13:18 -0700</pubDate>
      <guid>https://leandeep.com/convertir-les-donn%C3%A9es-cat%C3%A9gorielles-en-integer-pour-sklearn/</guid>
      <description>&lt;h2 id=&#34;pré-requis&#34;&gt;Pré-requis&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;pip install pandas sklearn&#xA;# va installer pandas 1.1.0 et sklearn 0.0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;charger-les-librairies&#34;&gt;Charger les librairies&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;from sklearn import preprocessing&#xA;import pandas as pd&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;création-dun-faux-dataset&#34;&gt;Création d&amp;rsquo;un faux dataset&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;raw_data = {&#xA;   &amp;#39;patient&amp;#39;: [1, 1, 1, 2, 2],&#xA;   &amp;#39;observation&amp;#39;: [1, 2, 3, 1, 2],&#xA;   &amp;#39;traitement&amp;#39;: [0, 1, 0, 1, 0],&#xA;   &amp;#39;etat&amp;#39;: [&amp;#39;vivant&amp;#39;, &amp;#39;mort&amp;#39;, &amp;#39;zombie&amp;#39;, &amp;#39;vivant&amp;#39;, &amp;#39;mort&amp;#39;]&#xA;}&#xA;&#xA;df = pd.DataFrame(raw_data, columns = [&amp;#39;patient&amp;#39;, &amp;#39;observation&amp;#39;, &amp;#39;traitement&amp;#39;, &amp;#39;etat&amp;#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;fit-the-label-encoder&#34;&gt;Fit the Label Encoder&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Créer un objet label (catégorie) encoder&#xA;le = preprocessing.LabelEncoder()&#xA;&#xA;# Remplir l&amp;#39;encoder avec la colonne pandas&#xA;le.fit(df[&amp;#39;state&amp;#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;voir-les-labels-debug&#34;&gt;Voir les labels (debug)&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;list(le.classes_)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;transformer-les-catégories-en-integers&#34;&gt;Transformer les catégories en integers&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Appliquer l&amp;#39;objet encoder rempli à la colonne Pandas&#xA;le.transform(df[&amp;#39;state&amp;#39;])&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Inverse: Transformer les integers en catégories: &lt;br/&gt;&#xA;&lt;code&gt;list(le.inverse_transform([2, 2, 1]))&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Effacer les données manquantes</title>
      <link>https://leandeep.com/effacer-les-donn%C3%A9es-manquantes/</link>
      <pubDate>Sun, 30 Dec 2018 22:13:18 -0700</pubDate>
      <guid>https://leandeep.com/effacer-les-donn%C3%A9es-manquantes/</guid>
      <description>&lt;h2 id=&#34;pré-requis&#34;&gt;Pré-requis&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;pip install numpy pandas&#xA;# va installer numpy 1.19.1 et pandas 1.1.0&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;charger-les-librairies&#34;&gt;Charger les librairies&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;import numpy as np&#xA;import pandas as pd&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;création-dune-matrice-de-données&#34;&gt;Création d&amp;rsquo;une matrice de données&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Création de la feature matrice&#xA;X = np.array([[1, 2], &#xA;              [6, 3], &#xA;              [8, 4], &#xA;              [9, 5], &#xA;              [np.nan, 4]])&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;effacer-les-données-manquantes&#34;&gt;Effacer les données manquantes&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Avec Numpy&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;X[~np.isnan(X).any(axis=1)]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Résultat:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;array([[1., 2.],&#xA;       [6., 3.],&#xA;       [8., 4.],&#xA;       [9., 5.]])&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Avec Pandas&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# On transforme les données en dataframe Pandas&#xA;df = pd.DataFrame(X, columns=[&amp;#39;feature_1&amp;#39;, &amp;#39;feature_2&amp;#39;])&#xA;&#xA;# On efface les observations avec des données manquantes&#xA;df.dropna()&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Résultat:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Importer des données depuis Numpy et Pandas dans Tensorflow</title>
      <link>https://leandeep.com/importer-des-donn%C3%A9es-depuis-numpy-et-pandas-dans-tensorflow/</link>
      <pubDate>Fri, 26 Feb 2016 07:31:00 +0000</pubDate>
      <guid>https://leandeep.com/importer-des-donn%C3%A9es-depuis-numpy-et-pandas-dans-tensorflow/</guid>
      <description>&lt;p&gt;Exemple avec le jeu de données Iris:&lt;/p&gt;&#xA;&lt;p&gt;On importe le dataset:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;!mkdir /content/data&#xA;!ls&#xA;!wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -P /content/data&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;p&gt;Output:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;data  sample_data&#xA;--2018-11-16 09:37:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data&#xA;Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249&#xA;Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.&#xA;HTTP request sent, awaiting response... 200 OK&#xA;Length: 4551 (4.4K) [text/plain]&#xA;Saving to: ‘/content/data/iris.data’&#xA;&#xA;iris.data           100%[===================&amp;gt;]   4.44K  --.-KB/s    in 0s      &#xA;&#xA;2018-11-16 09:37:27 (102 MB/s) - ‘/content/data/iris.data’ saved [4551/4551]&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;On crée le modèle Tensorflow en réutilisant les données que l&amp;rsquo;on vient de télécharger:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basics Python commands pour Matplotlib, Numpy, Pandas et debugging misc</title>
      <link>https://leandeep.com/basics-python-commands-pour-matplotlib-numpy-pandas-et-debugging-misc/</link>
      <pubDate>Mon, 14 Sep 2015 19:24:00 +0000</pubDate>
      <guid>https://leandeep.com/basics-python-commands-pour-matplotlib-numpy-pandas-et-debugging-misc/</guid>
      <description>&lt;p&gt;Voici une liste des commandes de base pour commencer à travailler avec Matplotlib et Pandas et Numpy.&#xA;&lt;br/&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-charger-un-dataset&#34;&gt;1. Charger un dataset&lt;/h2&gt;&#xA;&lt;p&gt;On charge un dataset basic (fleurs Iris très connu). On s&amp;rsquo;en sert ensuite dans l&amp;rsquo;affichage d&amp;rsquo;un nuage de points avec Matplotlib.&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;from sklearn.datasets import load_iris&#xA;iris = load_iris()&#xA;&#xA;n_samples, n_features = iris.data.shape&#xA;print(n_samples)&#xA;print(n_features)&#xA;&#xA;# 150&#xA;# 4&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;2-afficher-un-nuage-de-points-scatter-plot&#34;&gt;2. Afficher un nuage de points (scatter plot)&lt;/h2&gt;&#xA;&lt;p&gt;On considère travailler avec un array (150,4). Voir point 1.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
