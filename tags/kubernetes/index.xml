<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Kubernetes on Lean Deep Tech blog</title>
    <link>https://leandeep.com/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on Lean Deep Tech blog</description>
    <generator>Hugo</generator>
    <language>fr</language>
    <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
    <lastBuildDate>Mon, 03 Apr 2023 22:13:00 +0000</lastBuildDate>
    <atom:link href="https://leandeep.com/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Installer Kafka sur Kubernetes</title>
      <link>https://leandeep.com/installer-kafka-sur-kubernetes/</link>
      <pubDate>Mon, 03 Apr 2023 22:13:00 +0000</pubDate>
      <guid>https://leandeep.com/installer-kafka-sur-kubernetes/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Dans cet article très rapide, nous allons voir comment installer Kafka (et Zookeeper) sur Kubernetes (ou avoir une version pour développer en local)&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;installation-de-lopérateur-strimzi&#34;&gt;Installation de l&amp;rsquo;opérateur Strimzi&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl create namespace kafka&#xA;kubectl create -f &amp;#39;https://strimzi.io/install/latest?namespace=kafka&amp;#39; -n kafka&#xA;kubectl get pod -n kafka --watch&#xA;kubectl logs deployment/strimzi-cluster-operator -n kafka -f&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;création-du-cluster&#34;&gt;Création du cluster&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl apply -f https://strimzi.io/examples/latest/kafka/kafka-persistent-single.yaml -n kafka&#xA;kubectl wait kafka/my-cluster --for=condition=Ready --timeout=300s -n kafka&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;envoyer-et-recevoir-des-messages&#34;&gt;Envoyer et recevoir des messages&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Envoyer&#xA;kubectl -n kafka run kafka-producer -ti --image=quay.io/strimzi/kafka:0.34.0-kafka-3.4.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic&#xA;&#xA;# Recevoir&#xA;kubectl -n kafka run kafka-consumer -ti --image=quay.io/strimzi/kafka:0.34.0-kafka-3.4.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server my-cluster-kafka-bootstrap:9092 --topic my-topic --from-beginning&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;effacer-le-cluster&#34;&gt;Effacer le cluster&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl -n kafka delete $(kubectl get strimzi -o name -n kafka)&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;effacer-lopérateur&#34;&gt;Effacer l&amp;rsquo;opérateur&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl -n kafka delete -f &amp;#39;https://strimzi.io/install/latest?namespace=kafka&amp;#39;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;autres&#34;&gt;Autres&lt;/h2&gt;&#xA;&lt;h3 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h3&gt;&#xA;&lt;p&gt;Dans le cas ou vous souhaitez récupérer des YAML distants en local (pour les backuper dans git par exemple) et les appliquer ensuite, on peut aussi utiliser la commande suivante:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Installer Argo workflow sur OSX</title>
      <link>https://leandeep.com/installer-argo-workflow-sur-osx/</link>
      <pubDate>Tue, 26 Jul 2022 22:13:00 +0000</pubDate>
      <guid>https://leandeep.com/installer-argo-workflow-sur-osx/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Dans cet article, nous allons voir comment installer Argo workflow localement sur OSX. Il s&amp;rsquo;agit d&amp;rsquo;une installation très simple utilisant Docker-desktop et Kubernetes. Cette installation n&amp;rsquo;est pas recommandée pour de la production. Elle permet de tester et d&amp;rsquo;évaluer l&amp;rsquo;outil ou de simplement créer/développer des workflows depuis votre poste local.&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;installer-argo-cli&#34;&gt;Installer Argo Cli&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;curl -sLO https://github.com/argoproj/argo-workflows/releases/download/v3.2.6/argo-darwin-amd64.gz&#xA;gunzip argo-darwin-amd64.gz&#xA;chmod +x argo-darwin-amd64&#xA;mv ./argo-darwin-amd64 /usr/local/bin/argo&#xA;argo version&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;déploiement-dargo-sur-k8s&#34;&gt;Déploiement d&amp;rsquo;Argo sur k8s&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl create ns argo&#xA;kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo/stable/manifests/quick-start-postgres.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;accès-linterface&#34;&gt;Accès l&amp;rsquo;interface&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl -n argo port-forward deployment/argo-server 2746:2746&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;déploiement-dun-worklow-de-test&#34;&gt;Déploiement d&amp;rsquo;un worklow de test&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;argo submit -n argo --watch https://raw.githubusercontent.com/argoproj/argo/master/examples/hello-world.yaml&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;debugging&#34;&gt;Debugging&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;argo list -n argo&#xA;argo get -n argo @latest&#xA;argo logs -n argo @latest&#xA;&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    <item>
      <title>Vérifier les ouvertures réseau depuis un pod Kubernetes</title>
      <link>https://leandeep.com/v%C3%A9rifier-les-ouvertures-r%C3%A9seau-depuis-un-pod-kubernetes/</link>
      <pubDate>Tue, 08 Feb 2022 06:59:00 +0000</pubDate>
      <guid>https://leandeep.com/v%C3%A9rifier-les-ouvertures-r%C3%A9seau-depuis-un-pod-kubernetes/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Dans cet article rapide, nous allons voir comment vérifier qu&amp;rsquo;un pod peut accéder à un serveur distant. Dans l&amp;rsquo;image Docker utiliséz dans le pod, aucun outil n&amp;rsquo;est installé (&lt;code&gt;ping command not found&lt;/code&gt;&amp;hellip;).&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;icmp&#34;&gt;ICMP&lt;/h2&gt;&#xA;&lt;p&gt;Ping, c&amp;rsquo;est &lt;a href=&#34;https://fr.wikipedia.org/wiki/Internet_Control_Message_Protocol&#34;&gt;ICMP&lt;/a&gt;, donc si ICMP est bloqué vous ne pourrez pas pinger votre serveur.&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;connexion-tcpudp-via-device&#34;&gt;Connexion tcp/udp via device&lt;/h2&gt;&#xA;&lt;p&gt;Depuis le pod, &lt;code&gt;kubectl exec...&lt;/code&gt;, exécuter les commandes suivantes:&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;export host=le_host_de_votre_serveur_distant&#xA;export port=le_port_de_votre_serveur_distant&#xA;(echo &amp;gt;/dev/tcp/${host}/${port}) &amp;amp;&amp;gt;/dev/null &amp;amp;&amp;amp; echo &amp;#34;open&amp;#34; || echo &amp;#34;closed&amp;#34;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;rappel-autres-outils&#34;&gt;Rappel autres outils&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;telnet:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Installer un cluster Kubernetes sur baremetal avec metalLB et Rancher 2</title>
      <link>https://leandeep.com/installer-un-cluster-kubernetes-sur-baremetal-avec-metallb-et-rancher-2/</link>
      <pubDate>Thu, 19 Nov 2020 23:12:00 +0200</pubDate>
      <guid>https://leandeep.com/installer-un-cluster-kubernetes-sur-baremetal-avec-metallb-et-rancher-2/</guid>
      <description>&lt;p&gt;Dans cet article, nous allons voir comment installer un cluster Kubernetes sur un ou plusieurs noeuds &amp;ldquo;physiques&amp;rdquo;. On est sur de l&amp;rsquo;auto-hébergement. MetalLB sera utilisé pour remplacer les load balancers des &amp;ldquo;clouders&amp;rdquo;. MetalLB est une implémentation de Load Balancer pour les clusters Kubernetes Bare Metal, utilisant des protocoles de routage standard.&#xA;Rancher 2 sera également utilisé. On aurait pu utiliser kubeadm mais cette solution nous simplifie clairement la vie.&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;pré-requis&#34;&gt;Pré-requis&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Docker&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;lancer-rancher-2-via-docker&#34;&gt;Lancer Rancher 2 via Docker&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo docker run -d --privileged --restart=unless-stopped -p 8443:443 rancher/rancher&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;h2 id=&#34;provisionner-un-cluster-k8s&#34;&gt;Provisionner un cluster k8s&lt;/h2&gt;&#xA;&lt;p&gt;Une fois le serveur Rancher démarré, connectez-vous en créant un compte admin puis créez un cluster Kubernetes. Pour faire simple dans cet article, cochez les cases &lt;code&gt;etcd&lt;/code&gt;, &lt;code&gt;controle-plane&lt;/code&gt;, &lt;code&gt;worker&lt;/code&gt;. Cela va générer une commande Docker qu&amp;rsquo;il suffira d&amp;rsquo;exécuter sur le noeud que vous avez à disposition pour installer votre cluster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Forcer l&#39;effacement d&#39;un namespace Kubernetes</title>
      <link>https://leandeep.com/forcer-leffacement-dun-namespace-kubernetes/</link>
      <pubDate>Mon, 05 Oct 2020 19:49:00 +0200</pubDate>
      <guid>https://leandeep.com/forcer-leffacement-dun-namespace-kubernetes/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Parfois lorsqu&amp;rsquo;on tente d&amp;rsquo;effacer un namespace, il ne s&amp;rsquo;efface pas vraiment et reste dans l&amp;rsquo;état &lt;strong&gt;terminated&lt;/strong&gt;.&lt;br/&gt;&#xA;Si vous essayez d&amp;rsquo;exécuter la commande &lt;code&gt;kubectl delete ns mon_namespace&lt;/code&gt; et que vous recevez un message comme ci-dessous, ce tutoriel est fait pour vous:&lt;br/&gt;&#xA;&lt;code&gt;Error from server (Conflict): Operation cannot be fulfilled on namespaces &amp;quot;mon_namespace&amp;quot;: The system is ensuring all content is removed from this namespace.  Upon completion, this namespace will automatically be purged by the system.&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Lister les process Linux dans une image redhat ubi-minimal</title>
      <link>https://leandeep.com/lister-les-process-linux-dans-une-image-redhat-ubi-minimal/</link>
      <pubDate>Fri, 10 Jan 2020 19:49:00 +0200</pubDate>
      <guid>https://leandeep.com/lister-les-process-linux-dans-une-image-redhat-ubi-minimal/</guid>
      <description>&lt;p&gt;&lt;code&gt;ps&lt;/code&gt; n&amp;rsquo;est pas disponible dans les nouvelles images minimales Redhat &lt;code&gt;ubi8-minimal&lt;/code&gt;. Voici un article de RedHat expliquant ce que sont ces images &lt;a href=&#34;https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image&#34;&gt;https://www.redhat.com/en/blog/introducing-red-hat-universal-base-image&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Pour réaliser un &lt;code&gt;ps aux&lt;/code&gt;, cela va être compliqué&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;2 options s&amp;rsquo;offrent à nous:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Option 1: Soit On veut ajouter &lt;em&gt;at vitam eternam&lt;/em&gt; le binaire &lt;code&gt;ps&lt;/code&gt; dans son container/ ou pod.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Option 2: Ou soit on veut ajouter &lt;code&gt;ps&lt;/code&gt; une fois que le container ou pod a démarré (juste une fois).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Installer Rancher 2 sur Centos 7 (Dev setup)</title>
      <link>https://leandeep.com/installer-rancher-2-sur-centos-7-dev-setup/</link>
      <pubDate>Sun, 05 May 2019 19:00:00 +0000</pubDate>
      <guid>https://leandeep.com/installer-rancher-2-sur-centos-7-dev-setup/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Please note that I do not recommend this setup for production. It is convenient for development/demo purposes.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;docker-installation&#34;&gt;Docker installation&lt;/h2&gt;&#xA;&lt;p&gt;&lt;em&gt;Install needed packages:&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo yum install -y yum-utils device-mapper-persistent-data lvm2&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Configure the docker-ce repo:&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Install docker-ce:&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo yum install docker-ce&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Create Docker group:&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;sudo groupadd docker&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;It appeared that docker.sock was owned by root and in the group root:&lt;/em&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ls -l /var/run/docker.sock&#xA;&#xA;srw-rw---- 1 root root 0 May 6 15:42 /var/run/docker.sock&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;Changing the group ownership:&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Commandes utiles Kubernetes</title>
      <link>https://leandeep.com/commandes-utiles-kubernetes/</link>
      <pubDate>Fri, 08 Mar 2019 17:08:00 +0000</pubDate>
      <guid>https://leandeep.com/commandes-utiles-kubernetes/</guid>
      <description>&lt;h2 id=&#34;commandes-propres-à-kubernetes&#34;&gt;Commandes propres à Kubernetes&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Créer un namespace&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl create ns &amp;lt;new-namespace&amp;gt;&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Lister tous les types de ressources disponibles sur le cluster&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl api-resources&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Savoir si une ressource appartient à un namespace&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl api-resources --namespaced=true&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Savoir si une ressource appartient PAS à un namespace&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;kubectl api-resources --namespaced=false&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Switcher de namespace&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;# Install kubens with the following command: &#xA;# Sur Mac: brew install kubectx&#xA;# Sur Linux (les 3 commandes qui suivent): &#xA;# sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx&#xA;# sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx&#xA;# sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens&#xA;&#xA;kubens &amp;lt;namespace&amp;gt;&#xA;&#xA;# Enregistre de manière permanente le namespace pour toutes les commandes kubectl suivantes dans ce contexte&#xA;kubectl config set-context --current --namespace=NOM_DU_NAMESPACE&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Connaître le cluster dans lequel on se situe&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Provisionner un cluster Kubernetes avec AWS EKS</title>
      <link>https://leandeep.com/provisionner-un-cluster-kubernetes-avec-aws-eks/</link>
      <pubDate>Thu, 07 Mar 2019 21:28:00 +0000</pubDate>
      <guid>https://leandeep.com/provisionner-un-cluster-kubernetes-avec-aws-eks/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Dans cet article nous allons voir comment provisionner un cluster simple Kubernetes via AWS EKS.&#xA;Nous verrons dans un prochain article comment mettre en place l&amp;rsquo;autoscaling et comment faire pour que les nouvelles instances automatiquement crées soient des instances Spot.&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;pré-requis&#34;&gt;Pré-requis&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Compte AWS&lt;/li&gt;&#xA;&lt;li&gt;Utilisateur Admin (Policy AdministratorAccess dans IAM)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;br/&gt;&#xA;&lt;h2 id=&#34;installation-via-cloud9&#34;&gt;Installation via Cloud9&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Créer un nouveau workspace dans Cloud9 &amp;lt;nom_de_votre_projet&amp;gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;br/&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;Depuis Cloud9, via le terminal générer une clé SSH&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;ssh-keygen&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;ol start=&#34;3&#34;&gt;&#xA;&lt;li&gt;Uploader sa clé dans la région EC2&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;aws ec2 import-key-pair --key-name &amp;#34;&amp;lt;nom_de_votre_clé&amp;gt;&amp;#34; --public-key-material file://~/.ssh/id_rsa.pub&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;br/&gt;&#xA;&lt;ol start=&#34;4&#34;&gt;&#xA;&lt;li&gt;Installer les outils Kubernetes&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Créer le répertoire ~/.kube par défaut pour stocker la configuration kubectl&lt;/p&gt;</description>
    </item>
    <item>
      <title>Comparaison des services de conteneurisation AWS (ECS, Fargate et EKS) </title>
      <link>https://leandeep.com/comparaison-des-services-de-conteneurisation-aws-ecs-fargate-et-eks/</link>
      <pubDate>Wed, 16 Jan 2019 19:33:00 +0000</pubDate>
      <guid>https://leandeep.com/comparaison-des-services-de-conteneurisation-aws-ecs-fargate-et-eks/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://leandeep.com/images/ecs-fargate-eks.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Il n&amp;rsquo;est pas évident de comprendre les différentes entre AWS ECS, Fargate et EKS. Au premier abord ces outils peuvent sembler similaire. Je me suis personnellement vraiment questionné sur la différence entre AWS Fargate et AWS EKS.&lt;/p&gt;&#xA;&lt;p&gt;Dans cet article je vais essayer de résumer les différences qu&amp;rsquo;il peut y avoir entre ces 3 services.&lt;/p&gt;&#xA;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Avantages&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;ECS&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;EKS&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: right&#34;&gt;Fargate&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Service gratuit (on ne paye que pour le compute sous jacent)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;Offre toutes les features d’ECS + VPC pour le réseau entre pods et isolation au niveau du cluster Kubernetes&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;Possible d’utiliser l’API de Fargate comme celle d’ECS&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Service historique d’AWS d’orchestration de containers Docker&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;Offre tous les avantages de Kubernetes (cloud agnostic)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;Permet de faire tourner des clusters hétérogènes constitués d’instance EC2 ou Fargate. Idéal pour scaler rapidement horizontalement&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Possibilité de dupliquer ses environnements via API&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;Réplication des masters Kubernetes dans 3 zones de disponibilités différentes&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;Permet de ne pas avoir à manager l’infrastructure&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Intégration sans couture avec la registry Docker AWS ECR (pas besoin de gérer sa propre registry + workflow simple pour gérer ses images)&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;Possibilité de répliquer l’environnement dans un autre déjà existant avec assez peu de modifications&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;Support AWS VPC network mode; ce qui signifie que les tâches qui tournent sur une même instance partage l’interface réseau (Elastic Network Interface)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Auto-healing des containers Docker&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;Coût assez faible par cluster: $0.20 par heure&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;Coût à l&amp;rsquo;usage du compute et non pas à l’instance EC2 sous-jacente. Cela peut permettre de faire des économies&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;Toutes les communications entre pods se font via IP dans le VPC&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: right&#34;&gt;Scalabilité horizontale très rapide (machines provisionées à l’avance)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;br/&gt;&#xA;&lt;p&gt;&lt;strong&gt;Inconvénients&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
