<!DOCTYPE html>
<html lang="fr">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author"
  content="Olivier Eeckhoutte">
<meta name="description"
  content="Introduction Le biais conduit √† du sous-apprentissage (underfitting) et la variance am√®ne du sur-apprentissage (overfitting) et donc √† de hautes erreurs de tests.
Example pour un jeu de donn√©es compos√© de 8 points:
Polynomials of various degrees. d = 1 under-fits the data, while d = 6 over-fits the data.
On peut √©viter cela en:
ajoutant de la r√©gularisation √† notre mod√®le; ce qui va r√©duire la capacit√© de notre mod√®le Si la data est under-fit le mod√®le est trop simple." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#252627" />
<script>
  
  
  if (!(window.location.host.startsWith("127.0.0.1")) && !(window.location.host.startsWith("localhost"))) {
    if (window.location.protocol != "https:") {
      console.log("Redirecting to https...")
      window.location.protocol = "https";
    }
  }
</script>


<link rel="canonical" href="https://leandeep.com/tradeoff-biais-variance/" />




<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">



<script src="https://fb.me/react-15.1.0.min.js"></script>
<script src="https://fb.me/react-dom-15.1.0.min.js"></script>
<style>
  .nav-search {
    display: none;
    -webkit-flex-grow: 1;
    -ms-flex-positive: 1;
    position: relative;
    width: 90%;
    height: 47px;
    margin-top: 20px;
    background-color: white;
    z-index: 1000;
  }

  .nav-search.active {
    box-shadow: 0 4px 4px rgba(79, 79, 79, 0.21);
  }

  .nav-search.active .search-dropdown {
    display: block;
  }

  .nav-search.active .search-input {
    -webkit-animation: expand-search-box-animation 0.5s forwards;
    animation: expand-search-box-animation 0.5s forwards;
  }

  .nav-search.active .search-input input {
    border-width: 2px;
  }

  .nav-search.active .search-input .close-search {
    display: inline-block;
  }

  .nav-search.active .search-input .search-dropdown {
    display: block;
  }

  .nav-search .search-input {
    transition: left 0.2s ease-in-out;
    transition: width 0s ease-in-out;
  }

  .nav-search .search-input .search-icon {
    position: absolute;
    left: 15px;
    top: 13px;
    z-index: 999;
    color: black;
  }

  .nav-search .search-input input {
    font: 16px/1.875 "Avenir Next W01", "Avenir Next", "Helvetica Neue", Helvetica, sans-serif;
    height: 50px;
    border: 1px solid #1b98f4;
    border-radius: 4px;
    min-width: 200px;
    width: 100%;
    padding-left: 50px;
    background-color: white;
  }

  .nav-search .search-input input:focus {
    outline: none;
  }

  .nav-search .search-input i.close-search {
    color: #1b98f4;
    display: none;
    position: absolute;
    right: 15px;
    top: 13px;
    cursor: pointer;
  }

  .search-dropdown {
    box-sizing: border-box;
    color: #B3B3B3;
    font: 14px/1.875 "Avenir Next W01", "Avenir Next", "Helvetica Neue", Helvetica, sans-serif;
    opacity: 1.00;
    padding: 20px;
    width: 100%;
    -webkit-animation: expand-search-dropdown-animation 0.5s forwards;
    animation: expand-search-dropdown-animation 0.5s forwards;
    overflow-y: scroll;
    max-height: 400px;
    border-radius: 0 0 4px 4px;
    background-color: #FCFCFC;
    border: 1px solid #E0E0E0;
    box-shadow: 1px 3px 4px rgba(0, 0, 0, 0.09);
    display: none;
    background-color: white;
  }

  .search-dropdown .small {
    -webkit-flex-basis: 35%;
    -ms-flex-preferred-size: 35%;
    flex-basis: 35%;
  }

  .search-dropdown .search-section .hits-blank {
    color: #666;
    text-align: center;
    padding-top: 20px;
  }

  .search-dropdown a {
    text-decoration: none;
    color: inherit;
    z-index: 2000;
  }

  .hit {
    border-bottom: 1px solid #E6E6E6;
    margin-bottom: 20px;
  }

  .hit .hit-title {
    color: #1b98f4;
    font-family: 'bt_mono', monospace;
    font-weight: 500;
    margin-bottom: 0;
    margin-top: 0;
    display: inline-block;
    font-size: 14px;
  }

  .hit .hit-description {
    text-decoration: none;
    color: black;
    font-size: 14px;
    display: block;
    margin-top: 3px;
  }

  .hit .hit-anchor {
    font-size: 13px;
    color: #666;
  }

  .hit .algolia-docsearch-suggestion--highlight {
    background-color: #FFE9A4;
  }

  .hit:last-child {
     
  }

  .ais-hits--item:last-child .hit {
    border: 0;
  }
</style>

<style>
  #app {
    display: none;
     
    border-radius: 10px;
    box-shadow: 2px 5px 12px -1px rgba(0, 0, 0, 0.56);
    padding: 20px;
    background-color: white;
    max-width: 500px;
    margin: 15px auto;
    text-align: center;
    min-height: 500px;
  }

  #app input {
    margin: 0 auto;
    float: none;
    width: 100%;
    max-width: 300px;
    padding: 5px 10px;
    border: 2px solid black;
  }

  #app ul {
    margin: 0;
    padding: 0;
  }

  #app li {
    text-align: left;
    padding: 5px 10px;
    width: 100%;
    max-width: 280px;
    margin: 1px auto;
    background-color: white;
    border: 1px solid black;
    list-style: none;
  }
</style>




<title>
  
  Tradeoff biais variance :: Lean Deep Tech blog 
  
</title>



<link href="//cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
  type="text/css">



<link rel="stylesheet" href="https://leandeep.com/main.min.75f4fccf704dff01fea880bd845a14a4f05d9c04ee40d8b8563f1a6ab98fe848.css">




    <link rel="apple-touch-icon" sizes="180x180" href="https://leandeep.com/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://leandeep.com/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://leandeep.com/favicon-16x16.png">
    <link rel="manifest" href="https://leandeep.com/site.webmanifest">
    <link rel="mask-icon" href="https://leandeep.com/safari-pinned-tab.svg" color="#252627">
    <link rel="shortcut icon" href="https://leandeep.com/favicon.ico">
    <meta name="msapplication-TileColor" content="#252627">
    <meta name="theme-color" content="#252627">

<meta itemprop="name" content="Tradeoff biais variance">
<meta itemprop="description" content="Introduction Le biais conduit √† du sous-apprentissage (underfitting) et la variance am√®ne du sur-apprentissage (overfitting) et donc √† de hautes erreurs de tests.
Example pour un jeu de donn√©es compos√© de 8 points:
Polynomials of various degrees. d = 1 under-fits the data, while d = 6 over-fits the data.
On peut √©viter cela en:
ajoutant de la r√©gularisation √† notre mod√®le; ce qui va r√©duire la capacit√© de notre mod√®le Si la data est under-fit le mod√®le est trop simple."><meta itemprop="datePublished" content="2017-03-01T13:34:00+00:00" />
<meta itemprop="dateModified" content="2017-03-01T13:34:00+00:00" />
<meta itemprop="wordCount" content="1108"><meta itemprop="image" content="https://leandeep.com"/>
<meta itemprop="keywords" content="Machine Learning," /><meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://leandeep.com"/>

<meta name="twitter:title" content="Tradeoff biais variance"/>
<meta name="twitter:description" content="Introduction Le biais conduit √† du sous-apprentissage (underfitting) et la variance am√®ne du sur-apprentissage (overfitting) et donc √† de hautes erreurs de tests.
Example pour un jeu de donn√©es compos√© de 8 points:
Polynomials of various degrees. d = 1 under-fits the data, while d = 6 over-fits the data.
On peut √©viter cela en:
ajoutant de la r√©gularisation √† notre mod√®le; ce qui va r√©duire la capacit√© de notre mod√®le Si la data est under-fit le mod√®le est trop simple."/>





<meta property="article:published_time" content="2017-03-01 13:34:00 &#43;0000 UTC" />







    </head>

    <body class="">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://leandeep.com/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">$ cd /home/leandeep</span>
            <span class="logo__cursor" style=""></span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://leandeep.com/events/">Featured Articles</a></li><li><a href="https://leandeep.com/posts/">All Articles</a></li><li><a href="https://leandeep.com/about/">About</a></li><li><a href="https://leandeep.com/finance/">Finance</a></li><li><a href="https://leandeep.com/notebooks/">ML Notebooks</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>

            <div class="content">
                
    <main class="post">

        <div class="post-info">
            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg>6 minutes

            

            </p>
        </div>

        <article>
            <h1 class="post-title">
                <a href="https://leandeep.com/tradeoff-biais-variance/">Tradeoff biais variance</a>
            </h1>

            

            <div class="post-content">
                <h2 id="introduction">Introduction</h2>
<p>Le biais conduit √† du sous-apprentissage (<em>underfitting</em>) et la variance am√®ne du sur-apprentissage (<em>overfitting</em>) et donc √† de hautes erreurs de tests.</p>
<p>Example pour un jeu de donn√©es compos√© de 8 points:</p>
<p><img src="https://leandeep.com/images/plot_bias_variance_examples.png" alt="image"></p>
<p><em>Polynomials of various degrees. d = 1 under-fits the data, while d = 6 over-fits the data.</em></p>
<p>On peut √©viter cela en:</p>
<ul>
<li>ajoutant de la r√©gularisation √† notre mod√®le; ce qui va r√©duire la capacit√© de notre mod√®le</li>
<li>Si la data est <em>under-fit</em> le mod√®le est trop simple. On dit qu&rsquo;il souffre de <em>High-bias</em>. Le mod√®le est biais√© et cela se traduit par le fait que les data sont <em>poorly fit</em>. On pourrait trouver un autre mod√®le plus complexe.</li>
<li>Attention au contraire √† ne pas avoir un mod√®le trop complexe qui ferait que les donn√©es <em>&ldquo;over-fitterait&rdquo;</em> car il pourrait s&rsquo;ajuster parfaitement aux donn√©es d&rsquo;entrainement gr√¢ce √† tous ses degr√©s de libert√©.</li>
<li>Si le mod√®le over-fit on peut aussi ajouter des donn√©es au dataset&hellip;</li>
</ul>
<p><img src="https://leandeep.com/images/over-under-fitted.png" alt="image"></p>
<blockquote>
<p>Pour d√©terminer le bon algorithme √† utiliser par rapport √† notre jeu de donn√©es, il faut pouvoir identifier quantitativement le bias et la variance pour pouvoir optimiser les metaparam√®tres.</p>
</blockquote>
<p><em>C&rsquo;est faisable gr√¢ce au process de <code>cross-validation</code>.</em></p>
<br/>
<h2 id="d√©tecter-loverfitting-gr√¢ce-√†-la-cross-validation">D√©tecter l&rsquo;overfitting gr√¢ce √† la cross-validation</h2>
<p>Pour quantifier les effets du biais et de la variance et construire le meilleur estimateur possible, on va d√©couper notre dataset en 3 parties:</p>
<ul>
<li>training set (60% du dataset)</li>
<li>cross-validation set (20%)</li>
<li>test set (20%)</li>
</ul>
<p>L&rsquo;id√©e g√©n√©rale est la suivante:</p>
<ol>
<li>Les param√®tres du mod√®les (dans notre cas, les coefficients du polyn√¥me) sont appris en utilisant le training set.</li>
<li>L&rsquo;erreur est √©valu√©e sur le cross-validation set et les meta-param√®tres  (dans notre cas les degr√©s du polyn√¥me) sont ajust√©s pour que l&rsquo;erreur de cross-validation soit minimis√©e.</li>
<li>Finalement les labels sont pr√©dits pour le test set. Ces labels sont utilis√©s pour √©valuer la performance de l&rsquo;algorithme √† labeliser des nouvelles donn√©es.</li>
</ol>
<blockquote>
<p>Pourquoi a-t-on besoin √† la fois d&rsquo;un cross-validation set et d&rsquo;un test set ?</p>
</blockquote>
<blockquote>
<p>Certains data scientists utilisent les m√™mes set de donn√©es pour le cross-validation set et le test set. Ce n&rsquo;est pas la meilleure approche car les meta-param√®tres peuvent &ldquo;<em>over-fitt√©s</em>&rdquo; le cross-validation set tout comme les param√®tres peuvent &ldquo;<em>over-fitt√©s</em>&rdquo; le training set.</p>
</blockquote>
<p>L&rsquo;erreur de cross-validation de notre classifieur polynomial peut √™tre visualis√©e en affichant l&rsquo;erreur comme une fonction du polyn√¥me de degr√© d. (Ici exemple avec 100 points)</p>
<p><img src="https://leandeep.com/images/plot_bias_variance_examples_cross_validation_error.png" alt="image"></p>
<blockquote>
<p>De mani√®re g√©n√©rale, plus on a donn√©es d&rsquo;entra√Ænement et plus on peut utiliser un mod√®le complexe. <em><code>The learning curve</code></em>&hellip;</p>
</blockquote>
<br/>
<h2 id="la-courbe-dapprentissage">La courbe d&rsquo;apprentissage</h2>
<p>La courbe d&rsquo;apprentissage est l&rsquo;affichage des erreurs de training et de cross-validation en fonction du nombre de <em>training points</em>.</p>
<p><img src="https://leandeep.com/images/plot_bias_variance_examples_learning_curve.png" alt="image"></p>
<p><em>Learning Curves for a case of high bias (left, d = 2) and high variance (right, d = 20)</em></p>
<ul>
<li>
<p>Sur la gauche, le polyn√¥me de degr√© 1 est un estimateur hautement biais√© qui sous-apprend les donn√©es. C&rsquo;est indiqu√© par le fait qu&rsquo;√† la fois les erreurs d&rsquo;entrainement et les erreurs de cross-validation sont √©lev√©es.</p>
</li>
<li>
<p>Sur la droite, le polyn√¥me est de degr√© 20. L&rsquo;erreur d&rsquo;entrainement est beaucoup plus faible que l&rsquo;erreur de cross-validation. Plus on ajoute de donn√©es dans le training set et plus l&rsquo;erreur d&rsquo;entrainement augmente alors que l&rsquo;erreur de cross-validation diminue.</p>
</li>
</ul>
<br/>
<h2 id="conclusion">Conclusion</h2>
<p><img src="https://leandeep.com/images/tradeoff-biais-variance-sketch.png" alt="image"></p>
<br/>
<p><strong>Fort biais</strong></p>
<p>Si notre algorithme montre un fort biais, il faut:</p>
<ul>
<li>Ajouter plus de features</li>
<li>Utiliser un mod√®le plus sophistiqu√©</li>
<li>Diminuer le training set pour booster la dur√©e d&rsquo;entrainement. On arrivera √† la m√™me erreur plus rapidement; avec moins de donn√©es d&rsquo;entrainement. Par contre, cela ne va pas am√©liorer la classification.</li>
<li>Diminuer la r√©gularisation: la r√©gularisation est une technique utilis√©e pour simplifier certains mod√®les de Machine Learning en ajoutant des termes de p√©nalit√© qui d√©pendent des caract√©ristiques des param√®tres.</li>
</ul>
<br/>
<p><strong>Forte variance</strong></p>
<ul>
<li>Utiliser moins de features</li>
<li>Augmenter le training set. Ajouter des donn√©es dans le training set peut r√©duire l&rsquo;effet d&rsquo;over-fitting et conduire √† diminuer la variance de l&rsquo;estimateur.</li>
<li>Augmenter la r√©gularisation qui est faite justement pour √©viter l&rsquo;over-fitting.</li>
</ul>
<br/>
<h2 id="code-des-graphs">Code des graphs</h2>
<pre tabindex="0"><code>import pylab as pl
from matplotlib import ticker
from matplotlib.patches import FancyArrow

np.random.seed(42)

def test_func(x, err=0.5):
    return np.random.normal(10 - 1. / (x + 0.1), err)


def compute_error(x, y, p):
    yfit = np.polyval(p, x)
    return np.sqrt(np.mean((y - yfit) ** 2))


#------------------------------------------------------------
# Plot linear regression example
np.random.seed(42)
x = np.random.random(20)
y = np.sin(2 * x)
p = np.polyfit(x, y, 1)  # fit a 1st-degree polynomial to the data

xfit = np.linspace(-0.2, 1.2, 10)
yfit = np.polyval(p, xfit)

pl.scatter(x, y, c=&#39;k&#39;)
pl.plot(xfit, yfit)
pl.xlabel(&#39;x&#39;)
pl.ylabel(&#39;y&#39;)
pl.title(&#39;Linear Regression Example&#39;)

#------------------------------------------------------------
# Plot example of over-fitting and under-fitting

N = 8
np.random.seed(42)
x = 10 ** np.linspace(-2, 0, N)
y = test_func(x)

xfit = np.linspace(-0.2, 1.2, 1000)

titles = [&#39;d = 1 (under-fit)&#39;, &#39;d = 2&#39;, &#39;d = 6 (over-fit)&#39;]
degrees = [1, 2, 6]

pl.figure(figsize = (9, 3.5))
for i, d in enumerate(degrees):
    pl.subplot(131 + i, xticks=[], yticks=[])
    pl.scatter(x, y, marker=&#39;x&#39;, c=&#39;k&#39;, s=50)

    p = np.polyfit(x, y, d)
    yfit = np.polyval(p, xfit)
    pl.plot(xfit, yfit, &#39;-b&#39;)
    
    pl.xlim(-0.2, 1.2)
    pl.ylim(0, 12)
    pl.xlabel(&#39;house size&#39;)
    if i == 0:
        pl.ylabel(&#39;price&#39;)

    pl.title(titles[i])

pl.subplots_adjust(left = 0.06, right=0.98,
                   bottom=0.15, top=0.85,
                   wspace=0.05)

#------------------------------------------------------------
# Plot training error and cross-val error
#   as a function of polynomial degree

Ntrain = 100
Ncrossval = 100
error = 1.0

np.random.seed(0)
x = np.random.random(Ntrain + Ncrossval)
y = test_func(x, error)

xtrain = x[:Ntrain]
ytrain = y[:Ntrain]

xcrossval = x[Ntrain:]
ycrossval = y[Ntrain:]

degrees = np.arange(1, 21)
train_err = np.zeros(len(degrees))
crossval_err = np.zeros(len(degrees))

for i, d in enumerate(degrees):
    p = np.polyfit(xtrain, ytrain, d)

    train_err[i] = compute_error(xtrain, ytrain, p)
    crossval_err[i] = compute_error(xcrossval, ycrossval, p)

pl.figure()
pl.title(&#39;Error for 100 Training Points&#39;)
pl.plot(degrees, crossval_err, lw=2, label = &#39;cross-validation error&#39;)
pl.plot(degrees, train_err, lw=2, label = &#39;training error&#39;)
pl.plot([0, 20], [error, error], &#39;--k&#39;, label=&#39;intrinsic error&#39;)
pl.legend()
pl.xlabel(&#39;degree of fit&#39;)
pl.ylabel(&#39;rms error&#39;)

pl.gca().add_patch(FancyArrow(5, 1.35, -3, 0, width = 0.01,
                              head_width=0.04, head_length=1.0,
                              length_includes_head=True))
pl.text(5.3, 1.35, &#34;High Bias&#34;, fontsize=18, va=&#39;center&#39;)

pl.gca().add_patch(FancyArrow(19, 1.22, 0, -0.1, width = 0.25,
                              head_width=1.0, head_length=0.05,
                              length_includes_head=True))
pl.text(19.8, 1.23, &#34;High Variance&#34;, ha=&#39;right&#39;, fontsize=18)

#------------------------------------------------------------
# Plot training error and cross-val error
#   as a function of training set size

Ntrain = 100
Ncrossval = 100
error = 1.0

np.random.seed(0)
x = np.random.random(Ntrain + Ncrossval)
y = test_func(x, error)

xtrain = x[:Ntrain]
ytrain = y[:Ntrain]

xcrossval = x[Ntrain:]
ycrossval = y[Ntrain:]

sizes = np.linspace(2, Ntrain, 50).astype(int)
train_err = np.zeros(sizes.shape)
crossval_err = np.zeros(sizes.shape)

pl.figure(figsize=(10, 5))

for j,d in enumerate((1, 20)):
    for i, size in enumerate(sizes):
        p = np.polyfit(xtrain[:size], ytrain[:size], d)
        crossval_err[i] = compute_error(xcrossval, ycrossval, p)
        train_err[i] = compute_error(xtrain[:size], ytrain[:size], p)

    ax = pl.subplot(121 + j)
    pl.plot(sizes, crossval_err, lw=2, label=&#39;cross-val error&#39;)
    pl.plot(sizes, train_err, lw=2, label=&#39;training error&#39;)
    pl.plot([0, Ntrain], [error, error], &#39;--k&#39;, label=&#39;intrinsic error&#39;)

    pl.xlabel(&#39;traning set size&#39;)
    if j == 0:
        pl.ylabel(&#39;rms error&#39;)
    else:
        ax.yaxis.set_major_formatter(ticker.NullFormatter())
    
    pl.legend(loc = 4)
    
    pl.ylim(0.0, 2.5)
    pl.xlim(0, 99)

    pl.text(98, 2.45, &#39;d = %i&#39; % d, ha=&#39;right&#39;, va=&#39;top&#39;, fontsize=&#39;large&#39;)

pl.subplots_adjust(wspace = 0.02, left=0.07, right=0.95)
pl.suptitle(&#39;Learning Curves&#39;, fontsize=18)


pl.show()
</code></pre>
            </div>
        </article>

        <hr />

        <div class="post-info">
                <p>
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="https://leandeep.com/tags/machine-learning">Machine Learning</a></span>
                </p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>1108 Mots</p>

            <p><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar"><rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line></svg>01 mars. 2017</p>
        </div>

        
            <div class="pagination">
                <div class="pagination__title">
                    <span class="pagination__title-h"></span>
                    <hr />
                </div>

                <div class="pagination__buttons">
                    
                        <span class="button previous">
                            <a href="https://leandeep.com/evaluer-ses-mod%C3%A8les-de-classification/">
                                <span class="button__icon">‚Üê</span>
                                <span class="button__text">Evaluer ses mod√®les de classification</span>
                            </a>
                        </span>
                    

                    
                        <span class="button next">
                            <a href="https://leandeep.com/class-iterator-en-python/">
                                <span class="button__text">Class iterator en Python</span>
                                <span class="button__icon">‚Üí</span>
                            </a>
                        </span>
                    
                </div>
            </div>
        

        
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>Built by <a href="https://www.linkedin.com/in/oliviereeckhoutte/">Olivier Eeckhoutte</a>,
                Freelance @ LeanDeep <a href="https://leandeep.com/about/">(üçÉ company)</a></span>
            <span>Siret: 83825337500011</span>
            <span><a href="https://leandeep.com/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss">
                        <path d="M4 11a9 9 0 0 1 9 9"></path>
                        <path d="M4 4a16 16 0 0 1 16 16"></path>
                        <circle cx="5" cy="19" r="1"></circle>
                    </svg></a></span>
        </div>
    </div>
</footer>
            
        </div>

        




<script type="text/javascript" src="https://leandeep.com/bundle.min.c184f8481b5847ad1a7d8aa775944fa063f118cb4df68f4eaa3826a2a2e16b26a1ad798f5160210f265c6fbb9a5f19b953fed066ae1ed1092d1858bcff13ae92.js" integrity="sha512-wYT4SBtYR60afYqndZRPoGPxGMtN9o9OqjgmoqLhayahrXmPUWAhDyZcb7uaXxm5U/7QZq4e0QktGFi8/xOukg=="></script>







    </body>
</html>
