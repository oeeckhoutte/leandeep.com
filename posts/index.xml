<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Bienvenue sur le site de Lean Deep</title>
        <link>https://leandeep.com/posts/</link>
        <description>Recent content in Posts on Bienvenue sur le site de Lean Deep</description>
        <generator>Hugo -- gohugo.io</generator>
        <copyright>&lt;a href=&#34;https://creativecommons.org/licenses/by-nc/4.0/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CC BY-NC 4.0&lt;/a&gt;</copyright>
        <lastBuildDate>Sat, 12 Sep 2020 19:49:00 +0200</lastBuildDate>
        <atom:link href="https://leandeep.com/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Mettre en place un datahub pour organiser ses datasets</title>
            <link>https://leandeep.com/mettre-en-place-un-datahub-pour-organiser-ses-datasets/</link>
            <pubDate>Sat, 12 Sep 2020 19:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/mettre-en-place-un-datahub-pour-organiser-ses-datasets/</guid>
            <description>Introduction Dans cet article, nous allons créer voir comment créer un datahub pour organiser ses datasets. La solution open source que nous allons utiliser est CKAN. D&#39;après leur site internet, il s&#39;agit de &amp;ldquo;the world’s leading Open Source data portal platform&amp;rdquo;. Je ne sais pas si c&#39;est vrai mais c&#39;est utilisé par pas mal de sites institutionnels comme data.gouv (USA), opendata.swiss, Government of Canada, Berlin open data&amp;hellip; La solution est simple à installer et est très pratique.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article, nous allons créer voir comment créer un datahub pour organiser ses datasets.
La solution open source que nous allons utiliser est <a href="https://ckan.org/">CKAN</a>. D'après leur site internet, il s'agit de &ldquo;the world’s leading Open Source data portal platform&rdquo;. Je ne sais pas si c'est vrai mais c'est utilisé par pas mal de sites institutionnels comme data.gouv (USA), opendata.swiss, Government of Canada, Berlin open data&hellip; La solution est simple à installer et est très pratique. Elle permet d'organiser, d'avoir des stats d'utilisation et de centraliser tous ses datasets au même endroit.</p>
<br/>
<h2 id="installation-sur-ubuntu-18">Installation sur Ubuntu 18+</h2>
<p><strong>Pré-requis</strong></p>
<pre><code>sudo apt update
sudo apt install -y git docker.io docker-compose

# Add your user to the &quot;docker&quot; group
sudo usermod -aG docker &lt;myUser&gt;

# Restart the system
sudo shutdown -rf 0
</code></pre><br/>
<p><strong>Clonage du repo et configuration:</strong></p>
<pre><code>mkdir ./ckan
cd ~/ckan

git clone https://github.com/oeeckhoutte/docker-ckan
cd docker-ckan

# dupliquer le fichier de config
cp .env.example .env
</code></pre><p>Editer le fichier <code>.env</code> et remplacer <code>CKAN_SITE_URL</code> par <code>http://localhost:5000</code>.</p>
<blockquote>
<p>Il y a un bug de permission sur l'image Docker: <br/>
<code>Error - &lt;type 'exceptions.OSError'&gt;: [Errno 13] Permission denied: '/var/lib/ckan/storage/uploads'</code><br/>
Pour corriger ce problème, éditer le fichier <code>./ckan/Dockerfile</code> et ajouter les 2 lignes suivantes avant la dernière commande:</p>
<pre><code>RUN mkdir -p /var/lib/ckan/storage/uploads
RUN chown -R ckan:ckan /var/lib/ckan/storage
</code></pre></blockquote>
<p><strong>Builder l'image docker:</strong></p>
<pre><code>docker-compose build
</code></pre><br/>
<p><strong>Démarrer CKAN:</strong></p>
<pre><code>docker-compose up -d
</code></pre><br/>
<p>Une fois les containers initialisés, rendez-vous sur <a href="http://localhost:5000/">http://localhost:5000/</a></p>
<br/>
<blockquote>
<p>Credentials admin par défault: ckan_admin/test1234
<br/><br/>
Exécuter <a href="https://docs.ckan.org/en/2.8/maintaining/paster.html"><em>paster</em></a> situé dans un container: <code>docker-compose -f docker-compose.yml exec ckan /bin/bash -c &quot;paster ...&quot;</code></p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Créer son premier smart contract pour Ethereum</title>
            <link>https://leandeep.com/cr%C3%A9er-son-premier-smart-contract-pour-ethereum/</link>
            <pubDate>Sun, 06 Sep 2020 09:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-son-premier-smart-contract-pour-ethereum/</guid>
            <description>Installation des pré-requis Truffle npm install -g truffle  Ganache Option 1:
Rendez-vous à l&#39;adresse http://truffleframework.com/ganache et cliquer sur le bouton &amp;ldquo;Download&amp;rdquo;.
Option 2:
Installation via le terminal
npm install ganache-cli -g puis démarrage du server Ganache via la commande:
ganache-cli -p 7545 -i 47 -l 4700000  Initialisation du projet  Il est possible d&#39;initialiser son project avec la commande truffle init mais des boilerplates prêts à l&#39;emploi existent.</description>
            <content type="html"><![CDATA[<h2 id="installation-des-pr-requis">Installation des pré-requis</h2>
<h3 id="truffle">Truffle</h3>
<pre><code>npm install -g truffle
</code></pre><br/>
<h3 id="ganache">Ganache</h3>
<p><strong>Option 1:</strong></p>
<p>Rendez-vous à l'adresse <a href="http://truffleframework.com/ganache">http://truffleframework.com/ganache</a> et cliquer sur le bouton &ldquo;Download&rdquo;.</p>
<p><strong>Option 2:</strong></p>
<p>Installation via le terminal</p>
<pre><code>npm install ganache-cli -g
</code></pre><p>puis démarrage du server Ganache via la commande:</p>
<pre><code>ganache-cli -p 7545 -i 47 -l 4700000
</code></pre><br/>
<h2 id="initialisation-du-projet">Initialisation du projet</h2>
<blockquote>
<p>Il est possible d'initialiser son project avec la commande <code>truffle init</code> mais des <a href="https://www.trufflesuite.com/boxes">boilerplates</a> prêts à l'emploi existent.</p>
</blockquote>
<pre><code>mkdir amiland-shop
cd amiland-shop
truffle unbox pet-shop
</code></pre><br/>
<h2 id="structure-du-projet">Structure du projet</h2>
<pre><code>├── LICENSE
├── box-img-lg.png
├── box-img-sm.png
├── bs-config.json
├── contracts
│   └── Migrations.sol
├── migrations
│   └── 1_initial_migration.js
├── node_modules
├── package-lock.json
├── package.json
├── src
│   ├── css
│   ├── fonts
│   ├── images
│   ├── index.html
│   ├── js
│   │   ├── app.js
│   │   ├── bootstrap.min.js
│   │   ├── truffle-contract.js
│   │   └── web3.min.js
│   └── pets.json
├── test
└── truffle-config.js
</code></pre><br/>
<ul>
<li>
<p><code>contracts/</code> contient le code source Solidity pour un ou plusieurs Smart contracts, ainsi que le fichier de migration <code>Migrations.sol</code>.</p>
</li>
<li>
<p><code>migrations/</code>: truffle possède un système de migration pour déployer des smarts contracts. Une migration est vue comme un smart contract particulier qui permet de suivre tous les changements réalisés.</p>
</li>
<li>
<p><code>test/</code>: contient à la fois les fichiers de tests pour le code JavaScript et Solidity.</p>
</li>
<li>
<p><code>truffle-config.js</code>: Fichier de configuration Truffle.</p>
</li>
</ul>
<blockquote>
<p>D'autres fichiers ont été créés avec le boilerplate. Nous ne les détaillerons pas dans cet article. Il s'agit principalement des fichiers permettant d'afficher un front pour notre dApp.</p>
</blockquote>
<br/>
<h2 id="smart-contract">Smart contract</h2>
<p>Créer un fichier appelé <code>AdoptUnChien.sol</code> et ajouter le code suivant:</p>
<pre><code>pragma solidity ^0.5.0;

contract AdoptUnChien {
    address[16] public nouveauxParents;
    
    function adoptUnChien(uint chienId) public returns (uint) {
        require(chienId &gt;= 0 &amp;&amp; chienId &lt;= 15);
        nouveauxParents[chienId] = msg.sender;
        return chienId;
    }

    function getNouveauxParents() public view returns (address[16] memory) {
        return nouveauxParents;
    }
}
</code></pre><blockquote>
<p>Nous avons défini la variable <code>nouveauxParents</code> qui est un tableau d'adresse Ethereum. Les tableaux contienne un type et ont une taille fixe ou variable. Dans notre cas de notre variable le type est <code>address</code> et la longueur du tableau est <code>16</code>.</p>
</blockquote>
<blockquote>
<p><code>memory</code> dans <code>address[16] memory</code> retourne la location des données d'une variable.</p>
</blockquote>
<blockquote>
<p>Le mot clé <code>view</code> dans la déclaration de la fonction <code>getNouveauxParents</code> signifie que la fonction ne va pas modifier l'état du contrat.</p>
</blockquote>
<blockquote>
<p>La doc pour apprendre le langage Solidity est ici: <a href="https://solidity.readthedocs.io/en/v0.5.3/types.html">https://solidity.readthedocs.io/en/v0.5.3/types.html</a></p>
</blockquote>
<blockquote>
<p>Le style guide est accessible ici: <a href="https://solidity.readthedocs.io/en/v0.5.3/style-guide.html">https://solidity.readthedocs.io/en/v0.5.3/style-guide.html</a> . Il est inspiré de Python: &ldquo;The structure and many of the recommendations within this style guide were taken from python’s pep8 style guide.&rdquo;
<br/></p>
</blockquote>
<h2 id="compilation">Compilation</h2>
<pre><code>truffle compile
</code></pre><p>Si tout se passe bien, vous devriez voir quelque chose de similaire à ceci:</p>
<pre><code>Compiling your contracts...
===========================
&gt; Compiling ./contracts/AdoptUnChien.sol
&gt; Compiling ./contracts/Migrations.sol
&gt; Artifacts written to /Users/olivier/Dev/Leandeep/Ethereum/amiland-shop/build/contracts
&gt; Compiled successfully using:
   - solc: 0.5.16+commit.9c3226ce.Emscripten.clang
</code></pre><br/>
<h2 id="dploiement">Déploiement</h2>
<p>Pour déployer son smart contract sur la blockchain on utilise une migration.</p>
<p>Pour ceux qui connaissent Alembic en Python pour migrer le schéma de sa base de données Postgres c'est un peu le même concept.</p>
<p>Une migration est un script de déploiement qui altère l'état des contrats de son application en le faisant passer d'un état <em>n</em> à un état <em>n+1</em>.</p>
<p>Pour une première migration, il n'y a pas de changement d'état. On déploie simplement du nouveau code mais pour les autres migrations, il faudra peut être déplacer des données et remplacer un smart contrat par un autre.</p>
<p>Configurer le fichier <code>truffle-config.js</code>. Eventuellement changez le network-id. La valeur à entrer se trouve dans les settings de Ganache.</p>
<p>Puis exécuter la commande de migration:</p>
<pre><code>truffle migrate
</code></pre><p>Si tout se passe bien, vous devriez avoir un message comme celui ci:</p>
<pre><code>Compiling your contracts...
===========================
&gt; Everything is up to date, there is nothing to compile.



Starting migrations...
======================
&gt; Network name:    'development'
&gt; Network id:      47
&gt; Block gas limit: 6721975 (0x6691b7)


1_initial_migration.js
======================

   Deploying 'Migrations'
   ----------------------
   &gt; transaction hash:    0x84d8f3bfba6820d3555a9036eaee427d7c74c26ccf8f855163e4e3cc56e52060
   &gt; Blocks: 0            Seconds: 0
   &gt; contract address:    0x99e87F4bF62117ed6C4f330026FA473570792118
   &gt; block number:        3
   &gt; block timestamp:     1599397484
   &gt; account:             0x52F1292acF383eB82DC4c08A966447D642d8294C
   &gt; balance:             99.99554203
   &gt; gas used:            164175 (0x2814f)
   &gt; gas price:           20 gwei
   &gt; value sent:          0 ETH
   &gt; total cost:          0.0032835 ETH


   &gt; Saving migration to chain.
   &gt; Saving artifacts
   -------------------------------------
   &gt; Total cost:           0.0032835 ETH


2_deploy_contracts.js
=====================

   Deploying 'AdoptUnChien'
   ------------------------
   &gt; transaction hash:    0xbdc59be57dc2ff1811aba723905f1f6cfda1bcb86af3f1686934cdb4c8a3803b
   &gt; Blocks: 0            Seconds: 0
   &gt; contract address:    0x2be685a572F1bd7AAFdD6fCc00C5A9B6E04CFCE7
   &gt; block number:        5
   &gt; block timestamp:     1599397485
   &gt; account:             0x52F1292acF383eB82DC4c08A966447D642d8294C
   &gt; balance:             99.99061867
   &gt; gas used:            203827 (0x31c33)
   &gt; gas price:           20 gwei
   &gt; value sent:          0 ETH
   &gt; total cost:          0.00407654 ETH


   &gt; Saving migration to chain.
   &gt; Saving artifacts
   -------------------------------------
   &gt; Total cost:          0.00407654 ETH


Summary
=======
&gt; Total deployments:   2
&gt; Final cost:          0.00736004 ETH

</code></pre><br/>
<h2 id="tests-unitaires">Tests unitaires</h2>
<h3 id="tests-solidity">Tests Solidity</h3>
<p>Créer un fichier <code>TestAdoptUnChien.sol</code> dans le répertoire <code>test</code> et ajouter le contenu ci-dessous.</p>
<p>La liste des assertions disponible pour Solidity est la suivante: <a href="https://github.com/trufflesuite/truffle/blob/master/packages/core/lib/testing/Assert.sol">https://github.com/trufflesuite/truffle/blob/master/packages/core/lib/testing/Assert.sol</a></p>
<pre><code>pragma solidity ^0.5.0;

import &quot;truffle/Assert.sol&quot;;
import &quot;truffle/DeployedAddresses.sol&quot;;
import &quot;../contracts/AdoptUnChien.sol&quot;;

contract TestAdoptUnChien {
    // The address of the AdoptUnChien contract to be tested
    AdoptUnChien adoptUnChien = AdoptUnChien(DeployedAddresses.AdoptUnChien());

    // The id of the pet that will be used for testing
    uint expectedChienId = 8;

    //The expected owner of adopted pet is this contract
    address expectedNouveauParent = address(this);


    function testNouveauParentPeutAdopterUnChien() public {
        uint returnedId = adoptUnChien.adoptUnChien(expectedChienId);
        Assert.equal(returnedId, expectedChienId, &quot;AdoptUnChien of the expected chien should match what is returned.&quot;);
    }

    function testGetNouveauxParentsAddressByChienId() public {
        address nouveauParent = adoptUnChien.nouveauxParents(expectedChienId);
        Assert.equal(nouveauParent, expectedNouveauParent, &quot;Owner of the expected pet should be this contract&quot;);
    }

     function testGetNouveauParentAddressByChienIdInArray() public {
        // Store nouveauxParents in memory rather than contract's storage
        address[16] memory nouveauxParents = adoptUnChien.getNouveauxParents();
        Assert.equal(nouveauxParents[expectedChienId], expectedNouveauParent, &quot;Owner of the expected chien should be this contract&quot;);
    }

}
</code></pre><p>Exécuter les tests via la commande:</p>
<pre><code>truffle test
</code></pre><p>S'il n'y a pas d'erreur, vous devriez voir quelque chose de similaire:</p>
<pre><code>Using network 'development'.


Compiling your contracts...
===========================
&gt; Compiling ./contracts/AdoptUnChien.sol
&gt; Compiling ./test/TestAdoption.sol
&gt; Artifacts written to /var/folders/6n/c4hj8zyn21j9pbxdjz86y0kw0000gn/T/test--54639-JZkSvOpCLaWh
&gt; Compiled successfully using:
   - solc: 0.5.16+commit.9c3226ce.Emscripten.clang



  TestAdoptUnChien
    ✓ testNouveauParentPeutAdopterUnChien (147ms)
    ✓ testGetNouveauxParentsAddressByChienId (113ms)
    ✓ testGetNouveauParentAddressByChienIdInArray (122ms)


  3 passing (8s)
</code></pre><br/>
<h3 id="tests-javascript">Tests JavaScript</h3>
<p>On peut également créer des tests en JavaScript:</p>
<p>Par exemple, créer un fichier <code>testAdoptUnChien.test.js</code> et ajouter le contenu suivant:</p>
<pre><code>const AdoptUnChien = artifacts.require(&quot;AdoptUnChien&quot;);

contract(&quot;AdoptUnChien&quot;, (nouveauxParents) =&gt; {
    let adoptUnChien;
    let expectedChienId;

    before(async () =&gt; {
        adoptUnChien = await AdoptUnChien.deployed();
    });

    describe(&quot;Adopter un chien et recuperer les adresses de son account&quot;, async () =&gt; {
        before(&quot;adopter un chien en utilisant nouveauxParents[0]&quot;, async () =&gt; {
            await adoptUnChien.adoptUnChien(8, { from: nouveauxParents[0] });
            expectedNouveauParent = nouveauxParents[0];
        });
    });

    describe(&quot;Adopter un chien et récupérer les adresses du compte&quot;, async () =&gt; {
        before(&quot;adopter un chien en utilisant nouveauxParents[0]&quot;, async () =&gt; {
            await adoptUnChien.adoptUnChien(8, { from: nouveauxParents[0] });
            expectedAdopter = nouveauxParents[0];
        });

        it(&quot;peut récupérer l'adresse d'un nouveauParent par chien id&quot;, async () =&gt; {
            const adopteUnChien = await adoptUnChien.nouveauxParents(8);
            assert.equal(adopteUnChien, expectedAdopter, &quot;The owner of the adopted pet should be the first account.&quot;);
        });

        it(&quot;peut récupérer la liste des adresses de tous les nouveaux parents&quot;, async () =&gt; {
            const adopters = await adoptUnChien.getNouveauxParents();
            assert.equal(adopters[8], expectedAdopter, &quot;The owner of the adopted pet should be in the collection.&quot;);
        });
    });

});
</code></pre><p>Exécuter la même commande que pour les tests Solidity:</p>
<pre><code>truffle test
</code></pre><p>Résultat si tout est ok:</p>
<pre><code>Using network 'development'.


Compiling your contracts...
===========================
&gt; Compiling ./contracts/AdoptUnChien.sol
&gt; Artifacts written to /var/folders/6n/c4hj8zyn21j9pbxdjz86y0kw0000gn/T/test--56489-VuSW19vJxhf6
&gt; Compiled successfully using:
   - solc: 0.5.16+commit.9c3226ce.Emscripten.clang



  Contract: AdoptUnChien
    Adopter un chien et récupérer les adresses du compte
      ✓ peut récupérer l'adresse d'un nouveauParent par chien id
      ✓ peut récupérer la liste des adresses de tous les nouveaux parents (75ms)


  2 passing (300ms)
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Monter un disque NFS sur Ubuntu</title>
            <link>https://leandeep.com/monter-un-disque-nfs-sur-ubuntu/</link>
            <pubDate>Sat, 15 Aug 2020 19:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/monter-un-disque-nfs-sur-ubuntu/</guid>
            <description>Voici la procédure très simple pour monter automatiquement un disque NFS sur Ubuntu.
 Installation sudo apt install nfs-common  Configuration Créer le répertoire pour le point de montage:
mkdir -p /mnt/smalldiskspool/Musique  Editer le fichier /etc/fstab et ajouter une ligne comme celle ci par exemple:
192.168.0.42:/mnt/smalldiskspool/Musique/ /mnt/smalldiskspool/Musique nfs rw,sync,hard 0 0   0 0 signifie que Linux ne va pas checker les erreurs disque (ce sera géré par le serveur)</description>
            <content type="html"><![CDATA[<br/>
<p>Voici la procédure très simple pour monter automatiquement un disque NFS sur Ubuntu.</p>
<br/>
<h2 id="installation">Installation</h2>
<pre><code>sudo apt install nfs-common
</code></pre><br/>
<h2 id="configuration">Configuration</h2>
<p>Créer le répertoire pour le point de montage:</p>
<pre><code>mkdir -p /mnt/smalldiskspool/Musique
</code></pre><br/>
<p>Editer le fichier <code>/etc/fstab</code> et ajouter une ligne comme celle ci par exemple:</p>
<pre><code>192.168.0.42:/mnt/smalldiskspool/Musique/ /mnt/smalldiskspool/Musique nfs rw,sync,hard 0 0
</code></pre><br/>
<blockquote>
<p>0 0 signifie que Linux ne va pas checker les erreurs disque (ce sera géré par le serveur)</p>
</blockquote>
<p>Rebooter.</p>
]]></content>
        </item>
        
        <item>
            <title>Serveur de musique lossless UPNP</title>
            <link>https://leandeep.com/serveur-de-musique-lossless-upnp/</link>
            <pubDate>Thu, 13 Aug 2020 19:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/serveur-de-musique-lossless-upnp/</guid>
            <description>Introduction Dans cet article nous allons voir comment installer un serveur UPNP sur OSX et Linux pour streamer des musiques FLAC. Cela peut être utile pour certaines enceintes connectées comme les fameuses KEF LSX. Ce genre de serveur peut vous permettre d&#39;éviter de payer des abonnements Tidal, Spotify ou Deezer pour vos titres favoris.
  Installation sur OSX brew tap gerbera/homebrew-gerbera brew install gerbera  Installation sur Linux Option 1 sur Debian et Ubuntu (1.</description>
            <content type="html"><![CDATA[<br/>
<h2 id="introduction">Introduction</h2>
<p>Dans cet article nous allons voir comment installer un serveur UPNP sur OSX et Linux pour streamer des musiques FLAC. Cela peut être utile pour certaines enceintes connectées comme les fameuses KEF LSX. Ce genre de serveur peut vous permettre d'éviter de payer des abonnements Tidal, Spotify ou Deezer pour vos titres favoris.</p>
<br/>
<p><img src="/images/enceintes-kef-lsx.jpg" alt="image"></p>
<br/>
<h2 id="installation-sur-osx">Installation sur OSX</h2>
<pre><code>brew tap gerbera/homebrew-gerbera
brew install gerbera
</code></pre><br/>
<h2 id="installation-sur-linux">Installation sur Linux</h2>
<p><strong>Option 1 sur Debian et Ubuntu (1.0):</strong></p>
<pre><code>sudo apt install gerbera
</code></pre><p>Le fichier de configuration est situé ici:</p>
<pre><code>sudo vi /etc/gerbera/config.xml
</code></pre><p><br/>
<strong>Option 2 sur Debian et Ubuntu (build pour obtenir la dernière version) :</strong></p>
<pre><code>sudo apt install cmake
sudo apt install g++
sudo apt-get install autoconf
sudo apt-get install libtool
sudo apt-get install pkg-config
sudo apt install libavutil-dev libavcodec-dev libavformat-dev libavdevice-dev \
libavfilter-dev libavresample-dev libswscale-dev libswresample-dev libpostproc-dev
sudo apt install uuid-dev libsqlite3-dev libmysqlclient-dev \
libmagic-dev libexif-dev libcurl4-openssl-dev libspdlog-dev libpugixml-dev
git clone https://github.com/gerbera/gerbera.git
cd gerbera
sudo ./scripts/install-taglib111.sh
sudo ./scripts/install-pupnp.sh
mkdir build
cd build
cmake ../gerbera -DWITH_MAGIC=1 -DWITH_MYSQL=1 -DWITH_CURL=1 -DWITH_JS=1 \
-DWITH_TAGLIB=1 -DWITH_AVCODEC=1 -DWITH_FFMPEGTHUMBNAILER=1 -DWITH_EXIF=1 -DWITH_LASTFM=1
make -j4
sudo make install
</code></pre><br/>
<p><strong>Sur Fedora :</strong></p>
<pre><code>sudo dnf install gerbera
</code></pre><br/>
<h2 id="configuration-et-dmarrage-du-serveur-pour-version-14">Configuration et démarrage du serveur (pour version 1.4+)</h2>
<pre><code>mkdir ~/.config/gerbera
gerbera --create-config | sed 's/accounts enabled=&quot;no&quot;/accounts enable=&quot;yes&quot;/' &gt; ~/.config/gerbera/config.xml
gerbera &amp;

# sur OSX
open -a Safari http://0.0.0.0:49152/
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Manipuler les fréquences radio</title>
            <link>https://leandeep.com/manipuler-les-fr%C3%A9quences-radio/</link>
            <pubDate>Sat, 18 Apr 2020 15:20:00 +0200</pubDate>
            
            <guid>https://leandeep.com/manipuler-les-fr%C3%A9quences-radio/</guid>
            <description>Introduction Dans cet article, nous allons comment installer des outils permettant d&#39;analyser des fréquences radio.
L&#39;installation sera faite sur Ubuntu 18.04 avec un user non root. Le hardware permettant de recevoir et émettre des ondes est un HackRF. 
Les outils sont les suivants:
 Kalibrate Qspectrum Inspectrum Spectrum Analyzer GUI URH (Universal Radio Hack) Gnuradio   Pourquoi ces outils sont-ils utiles ?
 Analyser la sécurité de vos objets connectés, ou votre porte de garage, votre portail motorisé&amp;hellip; (malheureusement beaucoup comportent des failles) Comprendre comment fonctionnent les ondes GSM et mieux vous protéger (Attention aux ISMI catchers) Piloter des drones, voitures téléguidées qui n&#39;ont pas d&#39;API et que vous aimez bidouillez.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article, nous allons comment installer des outils permettant d'analyser des fréquences radio.</p>
<p>L'installation sera faite sur Ubuntu 18.04 avec un user non root. Le hardware permettant de recevoir et émettre des ondes est un HackRF.
<br/></p>
<p>Les outils sont les suivants:</p>
<ul>
<li>Kalibrate</li>
<li>Qspectrum</li>
<li>Inspectrum</li>
<li>Spectrum Analyzer GUI</li>
<li>URH (Universal Radio Hack)</li>
<li>Gnuradio</li>
</ul>
<br/>
<p><strong>Pourquoi ces outils sont-ils utiles ?</strong></p>
<ul>
<li>Analyser la sécurité de vos objets connectés, ou votre porte de garage, votre portail motorisé&hellip; (malheureusement beaucoup comportent des failles)</li>
<li>Comprendre comment fonctionnent les ondes GSM et mieux vous protéger (Attention aux ISMI catchers)</li>
<li>Piloter des drones, voitures téléguidées qui n'ont pas d'API et que vous aimez bidouillez. Votre HackRF vous permet de les contrôler très simplement.</li>
<li>Idem avec vos objets connectés propriétaires. Vous pouvez les contrôler même s'ils n'ont pas d'API ou de SDK mis à disposition par les constructeurs.</li>
<li>Réaliser un projet LORA WAN</li>
<li>etc.</li>
</ul>
<br/>
<h2 id="installation-des-drivers-pour-hackrf">Installation des drivers pour HackRF</h2>
<pre><code>sudo apt install build-essential cmake libfftw3-dev libusb-1.0-0-dev pkg-config

sudo apt install hackrf
</code></pre><br/>
<p>Si le paquet <code>hackrf</code> ne s'installe pas sur votre OS Linux vous pouvez utiliser les commandes suivantes:</p>
<pre><code>git clone https://github.com/mossmann/hackrf.git
cd hackrf/
mkdir host/build/
cd host/build/
cmake ..
make -j8
make install
ldconfig
</code></pre><br/>
<p>Pour des raisons de sécurité, un utilisateur normal sur Linux n'a pas les permissions pour accéder à des devices USB arbitraires. Pour accéder au Hackrf sans droit root, on peut créer un fichier <code>/etc/udev/rules.d/52-hackrf.rules</code> et ajouter le contenu suivant:</p>
<pre><code>ATTR{idVendor}==&quot;1d50&quot;, ATTR{idProduct}==&quot;604b&quot;, SYMLINK+=&quot;hackrf-jawbreaker-%k&quot;, MODE=&quot;660&quot;, GROUP=&quot;plugdev&quot;
ATTR{idVendor}==&quot;1d50&quot;, ATTR{idProduct}==&quot;6089&quot;, SYMLINK+=&quot;hackrf-one-%k&quot;, MODE=&quot;660&quot;, GROUP=&quot;plugdev&quot;
ATTR{idVendor}==&quot;1fc9&quot;, ATTR{idProduct}==&quot;000c&quot;, SYMLINK+=&quot;hackrf-dfu-%k&quot;, MODE=&quot;660&quot;, GROUP=&quot;plugdev&quot;
</code></pre><p><em>Le contenu de ce fichier permet de dire à <code>udev</code> de reconnaitre HackRF grâce au Vendor ID et Product ID
Il fixe les permissions UNIX à 660 et au groupe plugdev pour /dev. Enfin, il crée un symlink dans /dev pour le device HackRF.</em></p>
<br/>
<p>Une fois le fichier de règle précédent créé, il faut reloader <code>udevadm</code>:</p>
<pre><code>sudo udevadm control --reload-rules
</code></pre><br/>
<p>Pour vérifier que HackRF est bien détecté, on peut utiliser la commande <code>hackrf_info</code>.</p>
<br/>
<h2 id="kalibrate">Kalibrate</h2>
<p><strong>Analyse d'ondes GSM avec Kalibrate</strong></p>
<pre><code>apt install libtool autoconf automake m4
</code></pre><pre><code>#git clone https://github.com/scateu/kalibrate-hackrf.git
git clone https://github.com/rxseger/kalibrate-hackrf.git
cd kalibrate-hackrf/
./bootstrap
./configure 
make -j8
cd ../
</code></pre><pre><code>kalibrate-hackrf/src/kal -h
kalibrate-hackrf/src/kal -s GSM900 -l 32 -g 20 -p 10 | tee GSM900.kal-hackrf

sort -rh -k7,7 GSM900.kal-hackrf
</code></pre><br/>
<p>Alternative pour analyser des ondes GSM: utiliser LTE-Cell-Scanner</p>
<pre><code>git clone https://github.com/rxseger/LTE-Cell-Scanner.git
cd LTE-Cell-Scanner/build/src/
./CellSearch -h
./CellSearch --freq-start 1842.5e6 --freq-end 1842.5e6 --gain 20
./CellSearch --freq-start 1842.5e6 --freq-end 1842.5e6 --gain 20 --correction 1.000010337027486429
#1.0000089694805360807

python

&gt;&gt;&gt; 1e6 * (1 - 1.0000101601567139564)
-10.160156713956425

&gt;&gt;&gt; 1e6 * (1 - 1.0000089694805360807)
-8.96948053608071
However - don’t ask me why - it works best without any correction nor PPM

./LTE-Tracker -h
#./LTE-Tracker --gain 20 --freq 1842.5e6 --correction 1.0000089694805360807 --ppm 20
./LTE-Tracker --gain 20 --freq 1842.5e6
</code></pre><br/>
<h2 id="qspectrum">Qspectrum</h2>
<pre><code>git clone https://github.com/xmikos/qspectrumanalyzer.git
#less README.rst #--&gt; Ubuntu
#apt install python3-pyqt5 python3-pyqtgraph

apt install python3-pip
pip3 install qspectrumanalyzer

which hackrf_sweep
qspectrumanalyzer 
</code></pre><br/>
<p><strong>Configurer Qspectrum:</strong></p>
<p>File &gt; Settings</p>
<p>settings/Backend: hackrf_sweep</p>
<p>settings/Sample rate: 20 Mhz</p>
<br/>
<p>Frequency: 10 or 450 - 7250 Mhz</p>
<p>Bin size:  1000 kHz</p>
<br/>
<p>-MAIN CURVE</p>
<p>MAX HOLD</p>
<p>AVERAGE</p>
<p>SMOOTHING</p>
<br/>
<h2 id="inspectrum">Inspectrum</h2>
<pre><code>git clone https://github.com/miek/inspectrum.git
cd inspectrum/
mkdir build/
cd build/
cmake ..
make -j8
sudo make install

hackrf_transfer -h
hackrf_transfer -r air.cs8 -f `arfcncalc -a $arfcn -d` -l 32 -g 20 -s 2e6
hackrf_transfer -r air.cs8 -f 1842.5e6 -l 32 -g 20 -s 11e6
#-C &quot;$hppm&quot;

inspectrum -h
inspectrum --rate 2e6 air.cs8
inspectrum --rate 11e6 air.cs8

</code></pre><p>Si vous avez l'erreur suivante &ldquo;Couldn't transfer any bytes for one second&rdquo;, vous pouvez regarder dans la FAQ de HackRF et les issues ouvertes: <a href="https://github.com/mossmann/hackrf/issues/237">https://github.com/mossmann/hackrf/issues/237</a> &amp; <a href="https://github.com/mossmann/hackrf/wiki/FAQ">https://github.com/mossmann/hackrf/wiki/FAQ</a></p>
<br/>
<h2 id="spectrum-analyzer-gui">Spectrum Analyzer GUI</h2>
<pre><code>sudo apt install build-essential ant git libusb-1.0 libfftw3 libfftw3-dev openjdk-8-jdk

git clone --depth=1 --recurse-submodules https://github.com/pavsa/hackrf-spectrum-analyzer.git
cd hackrf-spectrum-analyzer/src/hackrf-sweep/
make -j8
build/hackrf_sweep_spectrum_analyzer.sh
</code></pre><br/>
<h2 id="installation-de-urh">Installation de URH</h2>
<pre><code>sudo apt install gr-osmosdr
sudo apt-get install libhackrf-dev

mkvirtualenv -p /usr/bin/python3 -a . sdr_env
pip install urh
</code></pre><br/>
<h2 id="installation-de-gnu-radio">Installation de GNU Radio</h2>
<pre><code># Pour connaitre le Sample rate d'un WAV pour configurer la transmission 
sudo apt install mplayer
# example: 
# mplayer Jacky-Core-Encore-Plus-Fort-Captain-2015.wav


sudo add-apt-repository ppa:gnuradio/gnuradio-releases-3.7
sudo apt-get update
sudo apt install gnuradio
</code></pre><blockquote>
<p>Note: une fois votre workflow terminé sur Gnuradio, vous pouvez accéder au code Python pour aller plus loin et automatiser son utilisation. Example dans mon cas: <code>/usr/bin/python2 -u /home/olivier/Dev/SDR/top_block.py</code></p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Installer ROS sur Ubuntu 18.04</title>
            <link>https://leandeep.com/installer-ros-sur-ubuntu-18.04/</link>
            <pubDate>Sun, 29 Mar 2020 16:01:00 +0200</pubDate>
            
            <guid>https://leandeep.com/installer-ros-sur-ubuntu-18.04/</guid>
            <description>Introduction Dans cet article nous allons voir comment installer ROS sur Ubuntu 18.04 et créer son workspace de travail.
 Installation sur Ubuntu directement (sans Docker) Installation de ROS Melodic
# Ajouter le repo ROS sudo sh -c &#39;echo &amp;quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&amp;quot; &amp;gt; /etc/apt/sources.list.d/ros-latest.list&#39; # Truster le repo ROS sudo apt-key adv --keyserver &#39;hkp://keyserver.ubuntu.com:80&#39; --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654 sudo apt install ros-melodic-desktop-full  Installation de rosdep
sudo apt install python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential sudo rosdep init rosdep update  Ajout des variables d&#39;environnement au terminal</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article nous allons voir comment installer ROS sur Ubuntu 18.04 et créer son workspace de travail.</p>
<br/>
<h2 id="installation-sur-ubuntu-directement-sans-docker">Installation sur Ubuntu directement (sans Docker)</h2>
<p><strong>Installation de ROS Melodic</strong></p>
<pre><code># Ajouter le repo ROS
sudo sh -c 'echo &quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list'

# Truster le repo ROS
sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654

sudo apt install ros-melodic-desktop-full
</code></pre><br/>
<p><strong>Installation de rosdep</strong></p>
<pre><code>sudo apt install python-rosdep python-rosinstall python-rosinstall-generator python-wstool build-essential
sudo rosdep init
rosdep update
</code></pre><br/>
<p><strong>Ajout des variables d'environnement au terminal</strong></p>
<p>Rendez-vous dans le répertoire <code>/opt/ros/melodic/</code> et recherchez les fichiers setup.QUELQUE_CHOSE. Repérez celui qui correspond à votre shell et executez la commande correspondante:</p>
<pre><code>echo &quot;source /opt/ros/melodic/setup.zsh&quot; &gt;&gt; ~/.zshrc

# Alternative: 
# echo &quot;source /opt/ros/melodic/setup.bash&quot; &gt;&gt; ~/.bashrc
</code></pre><br/>
<p><strong>Installation de rosinstall</strong></p>
<p>Pour gérer les <em>source trees</em> de certains paquets particulier ROS:</p>
<pre><code>sudo apt install python-rosinstall
</code></pre><br/>
<h2 id="vrification-du-bon-fonctionnement">Vérification du bon fonctionnement</h2>
<p>Dans un terminal exécuter la commande suivante:</p>
<pre><code>roscore
</code></pre><p>Dans un second terminal exécuter la commande suivante:</p>
<pre><code>rosrun turtlesim turtlesim_node
</code></pre><p>Si une tortue apparaît dans une nouvelle fenêtre, c'est que l'installation est correcte.</p>
<blockquote>
<p>Même à distance via SSH, vous devriez voir apparaître cette fenêtre. Si vous avez une erreur du genre <code>Could not connect to any X display</code>, ajoutez le flag <code>-X</code> lors de votre connexion <code>SSH</code>.</p>
</blockquote>
<br/>
<h2 id="installation-avec-docker">Installation avec Docker</h2>
<p>Docker est une option intéressante. Je l'ai testé et cela fonctionne très bien.
Je préfère néanmoins l'installation directement sur le système pour éviter de me prendre la tête avec le serveur X.</p>
<br/>
<pre><code>git clone https://github.com/jbnunn/ROSGazeboDesktop
cd ROSGazeboDesktop
# Le Dockerfile contient une erreur. Il faut ajouter l'installation du paquet python-rosdep

docker build -t ros-gazebo-desktop .
mkdir data
docker run -it --rm --name=ros_gazebo_desktop -m=4g -p 6080:80 -p 5900:5900 -v $PWD/data:/home/ubuntu/data -e RESOLUTION=1680x860 -e USER=ubuntu -e PASSWORD=ubuntu ros-gazebo-desktop   
</code></pre><br/>
<p>On peut ensuite se connecter au container via VNC: http://locahost:6080/</p>
<br/>
<p>Démarrer un nouveau monde:</p>
<pre><code>roslaunch gazebo_ros empty_world.launch 
</code></pre><br/>
<p>Importer un modèle:</p>
<pre><code>rosrun gazebo_ros spawn_model -file ~/.gazebo/models/create/model-1_4.sdf -sdf -model Create
</code></pre><br/>
<p>D'autres mondes sont disponibles:</p>
<pre><code>roslaunch gazebo_ros willowgarage_world.launch
roslaunch gazebo_ros mud_world.launch
roslaunch gazebo_ros shapes_world.launch
roslaunch gazebo_ros rubble_world.launch
</code></pre><br/>
<p>Commandes disponibles pour faire bouger le robot:</p>
<pre><code>rostopic list

/clock
/gazebo/link_states
/gazebo/model_states
/gazebo/parameter_descriptions
/gazebo/parameter_updates
/gazebo/set_link_state
/gazebo/set_model_state
/rosout
</code></pre><br/>
<p>Faire bouger le robot:</p>
<pre><code>rostopic pub /gazebo/set_model_state gazebo_msgs/ModelState '{model_name: Create, pose: { position: { x: 0, y: 0, z: 0 }, orientation: {x: 0, y: 0, z: 0} }, twist: { linear: { x: 1, y: 0, z: 0 }, angular: { x: 0, y: 0, z: 0}  }, reference_frame: world }'
</code></pre><br/>
<p>D'autres modèles sont disponibles à <a href="https://bitbucket.org/osrf/gazebo_models">l'adresse suivante</a>.</p>
<br/>
<h2 id="cration-du-workspace">Création du workspace</h2>
<pre><code>mkdir -p ~/catkin_ws/src
cd catkin_ws/src
catkin_init_workspace
cd ~/catkin_ws
catkin_make
</code></pre><br/>
<p>Pour accéder au workspace nouvellement créé:</p>
<pre><code>echo &quot;source ~/catkin_ws/devel/setup.zsh&quot; &gt;&gt; ~/.zshrc
source ~/.zshrc
</code></pre><br/>
<p>Si la commande suivante retourne un path, c'est tout est ok.</p>
<pre><code>echo $ROS_PACKAGE_PATH
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Linux sur Android</title>
            <link>https://leandeep.com/linux-sur-android/</link>
            <pubDate>Sun, 29 Mar 2020 00:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/linux-sur-android/</guid>
            <description>Introduction Ce weekend j&#39;ai découvert qu&#39;il était possible d&#39;installer Linux sur Android. Je pensais qu&#39;il était necessaire de rooter son téléphone mais pas du tout. Avec l&#39;application UserLand, on peut installer directement ses distributions préférées. Mon besoin était de pouvoir directement brancher mon téléphone à ma télé pour regarder des films. Les solutions comme Kodi ou Plex sont intéressantes mais j&#39;ai souvent des coupures car je regarde des films en UHD.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Ce weekend j'ai découvert qu'il était possible d'installer Linux sur Android. Je pensais qu'il était necessaire de rooter son téléphone mais pas du tout. Avec l'application <a href="https://play.google.com/store/apps/details?id=tech.ula">UserLand</a>, on peut installer directement ses distributions préférées. Mon besoin était de pouvoir directement brancher mon téléphone à ma télé pour regarder des films. Les solutions comme Kodi ou Plex sont intéressantes mais j'ai souvent des coupures car je regarde des films en UHD. En plus de cela, cela occupe de la bande passante sur mon réseau local (j'en ai besoin pour d'autres choses).</p>
<p>Avoir un Linux sur mon Android me permet de démarrer quand j'ai en envi et directement de mon téléphone un serveur multimédia maison basé sur Python, JavaScript et NodeJS.</p>
<p>Mon téléphone est un Huawei p30, (Et oui, bye bye Apple !). L'intérêt de ce téléphone, en plus d'être sous Android, c'est d'avoir nativement un mode desktop . En effet, quand je branche mon téléphone ou usb-c (ou via un adaptateur HDMI &lt;-&gt; usb-c) sur une télévision l'affichage passe en mode desktop. Comme ce téléphone est très puissant, on a presque l'impression d'être sur un PC Linux classique.</p>
<p>Il est possible de faire &ldquo;transiter&rdquo; des fichiers entre Ubuntu et Android et d'y accéder directement dans l'application &ldquo;Fichiers&rdquo;. Pour ce faire, il suffit d'écrire les fichiers dans le répertoire <code>/storage/internal</code>.</p>
<br/>
<h2 id="outils-installs-et-remarques">Outils installés et remarques</h2>
<ul>
<li>
<p>Termux</p>
</li>
<li>
<p>bVNC Free</p>
</li>
<li>
<p>Ubuntu dans Userland</p>
<ul>
<li>
<p>J'ai installé les packages suivants:
<code>sudo apt-get install python-dev python3-dev nodejs npm vim openssh-server git curl net-tools rsync</code></p>
</li>
<li>
<p>nvm est &ldquo;installable&rdquo; mais les versions de NodeJS installées ne sont pas compatible avec l'architecture arm64 du téléphone.</p>
</li>
<li>
<p><code>/etc/hosts</code> fonctionne parfaitement</p>
</li>
<li>
<p>Démarrer des serveurs Python et Nodejs et y accéder sur le réseau local: ok</p>
</li>
<li>
<p>SSH vers serveurs distants: ok</p>
</li>
<li>
<p>SSH vers Ubuntu dans téléphone: ok <strong>&ndash;&gt; port 2022</strong></p>
</li>
</ul>
<blockquote>
<p><a href="https://matt.ucc.asn.au/dropbear/dropbear.html">Dropbear</a> est utilisé comme serveur SSH</p>
</blockquote>
<ul>
<li>
<p>&ldquo;Durée de vie&rdquo; d'un serveur démarré: pas de coupure en activant la fonctionnalité <em>Wakelock</em> d'Android.</p>
</li>
<li>
<p>Installation de vscode (même procédure que pour Jetson Nano): ko</p>
</li>
</ul>
</li>
</ul>
<pre><code>git clone https://github.com/JetsonHacksNano/installVSCode.git
cd installVSCode
./installVSCode.sh
sudo apt install --fix-broken
sudo apt-get install libasound2
./installVSCode.sh
</code></pre><p>L'installation semble aller au bout sans erreur mais au démarrage de <code>code-oss</code> l'erreur suivante apparaît: <code>Error: Cannot find module './bootstrap'</code>. Je ne suis pas le seul à rencontrer le problème. Il y a <a href="https://github.com/headmelted/codebuilds/issues/97">ce bug ouvert sur Github</a>&hellip;</p>
<ul>
<li>
<p>Création de hotspot dans Kali: ko &ndash;&gt; <code>/sys/class/net</code> inaccessible</p>
</li>
<li>
<p>USB support: ko</p>
</li>
<li>
<p>Docker: ko</p>
</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Afficher sur Mac l&#39;interface graphique d&#39;une app executée dans Docker</title>
            <link>https://leandeep.com/afficher-sur-mac-linterface-graphique-dune-app-execut%C3%A9e-dans-docker/</link>
            <pubDate>Sat, 28 Mar 2020 16:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/afficher-sur-mac-linterface-graphique-dune-app-execut%C3%A9e-dans-docker/</guid>
            <description>Introduction Depuis quelque temps je travaille sur l&#39;apprentissage de robots dans ROS. Je fais tourner ROS sans un container Docker et accède à l&#39;interface graphique via VNC (dans le browser avec noVNC). Ce n&#39;est clairement pas une solution qui me contient. Le clavier est mal supporté, les performances sont mauvaises. Je cherche donc une solution de remplacement pour piloter à distance l&#39;outil ROS. En faisant des recherches sur internet, je suis parvenu à afficher l&#39;interface graphique d&#39;une app exécutée dans un container Docker sur mon Mac.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Depuis quelque temps je travaille sur l'apprentissage de robots dans ROS.
Je fais tourner ROS sans un container Docker et accède à l'interface graphique via VNC (dans le browser avec noVNC). Ce n'est clairement pas une solution qui me contient. Le clavier est mal supporté, les performances sont mauvaises. Je cherche donc une solution de remplacement pour piloter à distance l'outil ROS. En faisant des recherches sur internet, je suis parvenu à afficher l'interface graphique d'une app exécutée dans un container Docker sur mon Mac. L'application est basique mais cette piste est à explorer. Voici comment afficher une app basique sur Mac.</p>
<br/>
<h2 id="steps">Steps</h2>
<p><strong>Configurer Xquartz</strong>
Ouvrir Xquartz et rendez-vous dans les préférences.</p>
<pre><code>open -a Xquartz
</code></pre><p>Dans l'onglet &ldquo;Sécurité&rdquo; cocher la case &ldquo;Allow connections from network clients&rdquo;.</p>
<br/>
<p><strong>Lancer socat</strong></p>
<p>Si vous ne l'avez pas déjà, installer <code>socat</code> via la commande <code>brew install socat</code> puis dans un terminal exécuter la commande suivante:</p>
<pre><code>socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\&quot;$DISPLAY\&quot;
</code></pre><blockquote>
<p>Socat permet de manipuler des sockets réseau.</p>
</blockquote>
<br/>
<p><strong>Lancer une app dans un container</strong></p>
<pre><code>export macbook_ip=IP_MACBOOK_SUR_LAN
docker run -it --rm -e DISPLAY=$macbook_ip:0 fr3nd/xeyes
</code></pre><br/>
<p>Voici le Dockerfile de cette image:</p>
<pre><code>FROM debian:jessie

RUN apt-get update &amp;&amp; apt-get install -y \
      x11-apps \
      &amp;&amp; rm -rf /usr/share/doc/* &amp;&amp; \
      rm -rf /usr/share/info/* &amp;&amp; \
      rm -rf /tmp/* &amp;&amp; \
      rm -rf /var/tmp/*

RUN useradd -ms /bin/bash user
USER user
CMD xeyes
</code></pre><p>A priori, il n'y a donc pas grand chose à installer pour que cela fonctionne. A voir ce que cela va donner pour ROS desktop&hellip;</p>
<br/>
<p><strong>Résultat</strong></p>
<p><img src="/images/remote_app_eyes.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Synchroniser 2 répertoires ou 2 disques en temps réel</title>
            <link>https://leandeep.com/synchroniser-2-r%C3%A9pertoires-ou-2-disques-en-temps-r%C3%A9el/</link>
            <pubDate>Wed, 18 Mar 2020 19:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/synchroniser-2-r%C3%A9pertoires-ou-2-disques-en-temps-r%C3%A9el/</guid>
            <description>Introduction L&#39;objectif de cet article est de partager comment je backup mon raid /dev/md0 vers /dev/md1 grâce à l&#39;utilitaire lsyncd. Cela peut être pratique si vous avez des données très sensibles que vous ne voulez pas perdre. Je ne sais pas si c&#39;est la meilleure solution mais avec 2 x 2 disques répliquées, je prends peu de risque de voir disparaître mes données. A voir sur le long terme si c&#39;est efficace en terme de stabilité ou performance.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>L'objectif de cet article est de partager comment je backup mon raid <code>/dev/md0</code> vers <code>/dev/md1</code> grâce à l'utilitaire <code>lsyncd</code>. Cela peut être pratique si vous avez des données très sensibles que vous ne voulez pas perdre. Je ne sais pas si c'est la meilleure solution mais avec 2 x 2 disques répliquées, je prends peu de risque de voir disparaître mes données. A voir sur le long terme si c'est efficace en terme de stabilité ou performance.</p>
<br/>
<h2 id="installation">Installation</h2>
<pre><code>apt install lsyncd
</code></pre><br/>
<h2 id="configuration">Configuration</h2>
<p>Créer les répertoires contenants les status et logs de la synchronisation.</p>
<pre><code>mkdir /var/log/lsyncd
touch /var/log/lsyncd/lsyncd.{log,status}
</code></pre><br/>
<p>Modifier le fichier <code>/etc/lsyncd/lsyncd.conf.lua</code> et ajouter les règles décrivant les synchronisations.</p>
<pre><code>settings {
logfile = &quot;/var/log/lsyncd/lsyncd.log&quot;,
statusFile = &quot;/var/log/lsyncd/lsyncd.status&quot;
}

sync{
default.rsync,
source=&quot;/mnt/md0&quot;,
target=&quot;/mnt/md1&quot;,
}
</code></pre><br/>
<h2 id="activation-le-service">Activation le service</h2>
<pre><code>systemctl enable lsyncd
systemctl start lsyncd
# or 'systemctl restart lsyncd' to take into account the last configuration changes if the service was already running.

# Si tout est ok:
systemctl status lsyncd
● lsyncd.service - LSB: lsyncd daemon init script
   Loaded: loaded (/etc/init.d/lsyncd; generated)
   Active: active (running) since Thu 2020-03-19 00:02:27 CET; 5s ago
     Docs: man:systemd-sysv-generator(8)
  Process: 12729 ExecStop=/etc/init.d/lsyncd stop (code=exited, status=0/SUCCESS)
  Process: 12747 ExecStart=/etc/init.d/lsyncd start (code=exited, status=0/SUCCESS)
    Tasks: 4 (limit: 4915)
   CGroup: /system.slice/lsyncd.service
           ├─12765 /usr/bin/lsyncd -pidfile /var/run/lsyncd.pid /etc/lsyncd/lsyncd.conf.lua
           ├─12861 /usr/bin/rsync --delete --ignore-errors -slt -r /mnt/md0/ /mnt/md1/
           ├─12862 /usr/bin/rsync --delete --ignore-errors -slt -r /mnt/md0/ /mnt/md1/
           └─12863 /usr/bin/rsync --delete --ignore-errors -slt -r /mnt/md0/ /mnt/md1/

Mar 19 00:02:27 olivier-NUC7i7BNH systemd[1]: Starting LSB: lsyncd daemon init script...
Mar 19 00:02:27 olivier-NUC7i7BNH lsyncd[12747]:  * Starting synchronization daemon lsyncd
Mar 19 00:02:27 olivier-NUC7i7BNH lsyncd[12747]:    ...done.
Mar 19 00:02:27 olivier-NUC7i7BNH systemd[1]: Started LSB: lsyncd daemon init script.

</code></pre><br/>
<h2 id="warning">Warning</h2>
<p><strong>Attention</strong>, lors d'un redémarrage de serveur toutes mes données ont été effacées sur le serveur de backup. Je synchronise le raid md0 vers md1.
Après un reboot, le raid md1 a été remonté mais pas md0. Ne voyant plus le disque source, <code>lsyncd</code> a effacé le contenu de md1&hellip;</p>
<p>Pour éviter cela, ajouter l'option <code>delete = false,</code> dans le fichier <code>/etc/lsyncd/lsyncd.conf.lua</code> et redémarrer le service <code>systemctl start lsyncd</code>.</p>
<br/>
<h2 id="ressource">Ressource</h2>
<p><a href="https://linoxide.com/tools/setup-lsyncd-sync-directories/">https://linoxide.com/tools/setup-lsyncd-sync-directories/</a></p>
]]></content>
        </item>
        
        <item>
            <title>Reverse Proxy manager Nginx</title>
            <link>https://leandeep.com/reverse-proxy-manager-nginx/</link>
            <pubDate>Mon, 16 Mar 2020 23:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/reverse-proxy-manager-nginx/</guid>
            <description>Introduction Dans cet article nous allons voir comment installer le reverse proxy manager Nginx nginxproxymanager. Ce manager est vraiment très bien. Il permet par exemple de facilement créer des ACLs, définir des proxy hosts, rediretions, page custom 404, d&#39;avoir de l&#39;audit, créer des certificats let&#39;s encrypt, activer l&#39;HTTP/2, l&#39;HSTS. Il est vraiment top gun ce projet. C&#39;est un concurrent de Traefik.
 Installation Dans un répertoire par exemple mkdir ~/nginxproxymanager &amp;amp;&amp;amp; cd ~/nginxproxymanager, créer les 2 dossiers suivants: data et letsencrypt</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article nous allons voir comment installer le reverse proxy manager Nginx <a href="https://nginxproxymanager.com/">nginxproxymanager</a>. Ce manager est vraiment très bien. Il permet par exemple de facilement créer des ACLs, définir des proxy hosts, rediretions, page custom 404, d'avoir de l'audit, créer des certificats let's encrypt, activer l'HTTP/2, l'HSTS. Il est vraiment top gun ce projet. C'est un concurrent de Traefik.</p>
<br/>
<h2 id="installation">Installation</h2>
<p>Dans un répertoire par exemple <code>mkdir ~/nginxproxymanager &amp;&amp; cd ~/nginxproxymanager</code>, créer les 2 dossiers suivants: <code>data</code> et <code>letsencrypt</code></p>
<br/>
<p>Créer ensuite un fichier <code>docker-compose.yml</code>:</p>
<pre><code>version: &quot;3&quot;
services:
  app:
    image: jc21/nginx-proxy-manager:2
    restart: always
    ports:
      # Public HTTP Port:
      - '80:80'
      # Public HTTPS Port:
      - '443:443'
      # Admin Web Port:
      - '81:81'
    volumes:
      # Make sure this config.json file exists as per instructions above:
      - ./config.json:/app/config/production.json
      - ./data:/data
      - ./letsencrypt:/etc/letsencrypt
    depends_on:
      - db
  db:
    image: jc21/mariadb-aria:10.4
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: &quot;npm&quot;
      MYSQL_DATABASE: &quot;npm&quot;
      MYSQL_USER: &quot;npm&quot;
      MYSQL_PASSWORD: &quot;npm&quot;
    volumes:
      - ./data/mysql:/var/lib/mysql
</code></pre><br/>
<p>Enfin créer un fichier <code>config.json</code>:</p>
<pre><code>{
  &quot;name&quot;: &quot;Nginx Proxy Manager&quot;,
  &quot;version&quot;: &quot;6093335&quot;,
  &quot;slug&quot;: &quot;nginxproxymanager&quot;,
  &quot;description&quot;: &quot;Manage Nginx proxy hosts with a simple, powerful interface&quot;,
  &quot;url&quot;: &quot;https://github.com/hassio-addons/addon-nginx-proxy-manager&quot;,
  &quot;webui&quot;: &quot;http://[HOST]:[PORT:81]&quot;,
  &quot;startup&quot;: &quot;application&quot;,
  &quot;arch&quot;: [
    &quot;aarch64&quot;,
    &quot;amd64&quot;,
    &quot;armhf&quot;,
    &quot;armv7&quot;,
    &quot;i386&quot;
  ],
  &quot;services&quot;: [
    &quot;mysql:need&quot;
  ],
  &quot;ports&quot;: {
    &quot;80&quot;: 80,
    &quot;81&quot;: 81,
    &quot;443&quot;: 443
  },
  &quot;ports_description&quot;: {
    &quot;80&quot;: &quot;HTTP Entrance port&quot;,
    &quot;81&quot;: &quot;Proxy management web interface&quot;,
    &quot;443&quot;: &quot;HTTPS/SSL Entrance port&quot;
  },
  &quot;boot&quot;: &quot;auto&quot;,
  &quot;hassio_api&quot;: true,
  &quot;hassio_role&quot;: &quot;default&quot;,
  &quot;map&quot;: [
    &quot;ssl:rw&quot;,
    &quot;backup:rw&quot;
  ],
  &quot;options&quot;: {},
  &quot;schema&quot;: {
    &quot;log_level&quot;: &quot;list(trace|debug|info|notice|warning|error|fatal)?&quot;
  },
  &quot;image&quot;: &quot;hassioaddons/nginxproxymanager-{arch}&quot;
}
</code></pre><br/>
<p>Configurer le port forward pour les ports 80 et 443 sur votre box vers le host sur lequel est installé le reverse proxy.</p>
<br/>
<h2 id="dmarrer-du-proxy">Démarrer du proxy</h2>
<pre><code>docker-compose up -d
</code></pre><br/>
<h2 id="rsultat">Résultat</h2>
<p><img src="/images/reverse-proxy-nginx-gui.png" alt="image"></p>
<br/>
<p>Rendez vous à l'adresse suivante pour accéder à l'interface d'admin: http://DNS_HOST:81/nginx/proxy</p>
]]></content>
        </item>
        
        <item>
            <title>Créer un serveur OpenVPN en 5 minutes</title>
            <link>https://leandeep.com/cr%C3%A9er-un-serveur-openvpn-en-5-minutes/</link>
            <pubDate>Thu, 12 Mar 2020 19:35:00 +0200</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-un-serveur-openvpn-en-5-minutes/</guid>
            <description>Dans cet article, vous trouverez un script permettant de créer une serveur OpenVPN sur Ubuntu 18.04.
En sortie du script, un fichier config.ovpn sera créé. Il suffit de l&#39;ajouter à un client VPN (i.e. tunnelblick sur Mac) et d&#39;établir une connexion.
Vous pourrez vous connecter à la machine sur laquelle est installée le serveur VPN. Il suffit d&#39;exécutez la commande ssh VOTRE_USER@10.8.0.1&amp;hellip;
Voici le fameux script:
#!/bin/bash if grep -qs &amp;quot;Ubuntu 16.</description>
            <content type="html"><![CDATA[<p>Dans cet article, vous trouverez un script permettant de créer une serveur OpenVPN sur Ubuntu 18.04.</p>
<p>En sortie du script, un fichier config.ovpn sera créé. Il suffit de l'ajouter à un client VPN (i.e. tunnelblick sur Mac) et d'établir une connexion.</p>
<p>Vous pourrez vous connecter à la machine sur laquelle est installée le serveur VPN. Il suffit d'exécutez la commande <code>ssh VOTRE_USER@10.8.0.1</code>&hellip;</p>
<p>Voici le fameux script:</p>
<pre><code>#!/bin/bash

if grep -qs &quot;Ubuntu 16.04&quot; &quot;/etc/os-release&quot;; then
	echo 'Ubuntu 16.04 is no longer supported in the current version of openvpn-install
Use an older version if Ubuntu 16.04 support is needed: https://git.io/vpn1604'
	exit
fi

# Detect Debian users running the script with &quot;sh&quot; instead of bash
if readlink /proc/$$/exe | grep -q &quot;dash&quot;; then
	echo &quot;This script needs to be run with bash, not sh&quot;
	exit
fi

if [[ &quot;$EUID&quot; -ne 0 ]]; then
	echo &quot;Sorry, you need to run this as root&quot;
	exit
fi

if [[ ! -e /dev/net/tun ]]; then
	echo &quot;The TUN device is not available
You need to enable TUN before running this script&quot;
	exit
fi

if [[ -e /etc/debian_version ]]; then
	OS=debian
	GROUPNAME=nogroup
elif [[ -e /etc/centos-release || -e /etc/redhat-release ]]; then
	OS=centos
	GROUPNAME=nobody
else
	echo &quot;Looks like you aren't running this installer on Debian, Ubuntu or CentOS&quot;
	exit
fi

newclient () {
	# Generates the custom client.ovpn
	cp /etc/openvpn/server/client-common.txt ~/$1.ovpn
	echo &quot;&lt;ca&gt;&quot; &gt;&gt; ~/$1.ovpn
	cat /etc/openvpn/server/easy-rsa/pki/ca.crt &gt;&gt; ~/$1.ovpn
	echo &quot;&lt;/ca&gt;&quot; &gt;&gt; ~/$1.ovpn
	echo &quot;&lt;cert&gt;&quot; &gt;&gt; ~/$1.ovpn
	sed -ne '/BEGIN CERTIFICATE/,$ p' /etc/openvpn/server/easy-rsa/pki/issued/$1.crt &gt;&gt; ~/$1.ovpn
	echo &quot;&lt;/cert&gt;&quot; &gt;&gt; ~/$1.ovpn
	echo &quot;&lt;key&gt;&quot; &gt;&gt; ~/$1.ovpn
	cat /etc/openvpn/server/easy-rsa/pki/private/$1.key &gt;&gt; ~/$1.ovpn
	echo &quot;&lt;/key&gt;&quot; &gt;&gt; ~/$1.ovpn
	echo &quot;&lt;tls-auth&gt;&quot; &gt;&gt; ~/$1.ovpn
	sed -ne '/BEGIN OpenVPN Static key/,$ p' /etc/openvpn/server/ta.key &gt;&gt; ~/$1.ovpn
	echo &quot;&lt;/tls-auth&gt;&quot; &gt;&gt; ~/$1.ovpn
}

if [[ -e /etc/openvpn/server/server.conf ]]; then
	while :
	do
	clear
		echo &quot;Looks like OpenVPN is already installed.&quot;
		echo
		echo &quot;What do you want to do?&quot;
		echo &quot;   1) Add a new user&quot;
		echo &quot;   2) Revoke an existing user&quot;
		echo &quot;   3) Remove OpenVPN&quot;
		echo &quot;   4) Exit&quot;
		read -p &quot;Select an option [1-4]: &quot; option
		case $option in
			1) 
			echo
			echo &quot;Tell me a name for the client certificate.&quot;
			echo &quot;Please, use one word only, no special characters.&quot;
			read -p &quot;Client name: &quot; -e CLIENT
			cd /etc/openvpn/server/easy-rsa/
			EASYRSA_CERT_EXPIRE=3650 ./easyrsa build-client-full $CLIENT nopass
			# Generates the custom client.ovpn
			newclient &quot;$CLIENT&quot;
			echo
			echo &quot;Client $CLIENT added, configuration is available at:&quot; ~/&quot;$CLIENT.ovpn&quot;
			exit
			;;
			2)
			# This option could be documented a bit better and maybe even be simplified
			# ...but what can I say, I want some sleep too
			NUMBEROFCLIENTS=$(tail -n +2 /etc/openvpn/server/easy-rsa/pki/index.txt | grep -c &quot;^V&quot;)
			if [[ &quot;$NUMBEROFCLIENTS&quot; = '0' ]]; then
				echo
				echo &quot;You have no existing clients!&quot;
				exit
			fi
			echo
			echo &quot;Select the existing client certificate you want to revoke:&quot;
			tail -n +2 /etc/openvpn/server/easy-rsa/pki/index.txt | grep &quot;^V&quot; | cut -d '=' -f 2 | nl -s ') '
			if [[ &quot;$NUMBEROFCLIENTS&quot; = '1' ]]; then
				read -p &quot;Select one client [1]: &quot; CLIENTNUMBER
			else
				read -p &quot;Select one client [1-$NUMBEROFCLIENTS]: &quot; CLIENTNUMBER
			fi
			CLIENT=$(tail -n +2 /etc/openvpn/server/easy-rsa/pki/index.txt | grep &quot;^V&quot; | cut -d '=' -f 2 | sed -n &quot;$CLIENTNUMBER&quot;p)
			echo
			read -p &quot;Do you really want to revoke access for client $CLIENT? [y/N]: &quot; -e REVOKE
			if [[ &quot;$REVOKE&quot; = 'y' || &quot;$REVOKE&quot; = 'Y' ]]; then
				cd /etc/openvpn/server/easy-rsa/
				./easyrsa --batch revoke $CLIENT
				EASYRSA_CRL_DAYS=3650 ./easyrsa gen-crl
				rm -f pki/reqs/$CLIENT.req
				rm -f pki/private/$CLIENT.key
				rm -f pki/issued/$CLIENT.crt
				rm -f /etc/openvpn/server/crl.pem
				cp /etc/openvpn/server/easy-rsa/pki/crl.pem /etc/openvpn/server/crl.pem
				# CRL is read with each client connection, when OpenVPN is dropped to nobody
				chown nobody:$GROUPNAME /etc/openvpn/server/crl.pem
				echo
				echo &quot;Certificate for client $CLIENT revoked!&quot;
			else
				echo
				echo &quot;Certificate revocation for client $CLIENT aborted!&quot;
			fi
			exit
			;;
			3) 
			echo
			read -p &quot;Do you really want to remove OpenVPN? [y/N]: &quot; -e REMOVE
			if [[ &quot;$REMOVE&quot; = 'y' || &quot;$REMOVE&quot; = 'Y' ]]; then
				PORT=$(grep '^port ' /etc/openvpn/server/server.conf | cut -d &quot; &quot; -f 2)
				PROTOCOL=$(grep '^proto ' /etc/openvpn/server/server.conf | cut -d &quot; &quot; -f 2)
				if pgrep firewalld; then
					IP=$(firewall-cmd --direct --get-rules ipv4 nat POSTROUTING | grep '\-s 10.8.0.0/24 '&quot;'&quot;'!'&quot;'&quot;' -d 10.8.0.0/24 -j SNAT --to ' | cut -d &quot; &quot; -f 10)
					# Using both permanent and not permanent rules to avoid a firewalld reload.
					firewall-cmd --remove-port=$PORT/$PROTOCOL
					firewall-cmd --zone=trusted --remove-source=10.8.0.0/24
					firewall-cmd --permanent --remove-port=$PORT/$PROTOCOL
					firewall-cmd --permanent --zone=trusted --remove-source=10.8.0.0/24
					firewall-cmd --direct --remove-rule ipv4 nat POSTROUTING 0 -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j SNAT --to $IP
					firewall-cmd --permanent --direct --remove-rule ipv4 nat POSTROUTING 0 -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j SNAT --to $IP
				else
					systemctl disable --now openvpn-iptables.service
					rm -f /etc/systemd/system/openvpn-iptables.service
				fi
				if sestatus 2&gt;/dev/null | grep &quot;Current mode&quot; | grep -q &quot;enforcing&quot; &amp;&amp; [[ &quot;$PORT&quot; != '1194' ]]; then
					semanage port -d -t openvpn_port_t -p $PROTOCOL $PORT
				fi
				systemctl disable --now openvpn-server@server.service
				rm -rf /etc/openvpn/server
				rm -f /etc/sysctl.d/30-openvpn-forward.conf
				if [[ &quot;$OS&quot; = 'debian' ]]; then
					apt-get remove --purge -y openvpn
				else
					yum remove openvpn -y
				fi
				echo
				echo &quot;OpenVPN removed!&quot;
			else
				echo
				echo &quot;Removal aborted!&quot;
			fi
			exit
			;;
			4) exit;;
		esac
	done
else
	clear
	echo 'Welcome to this OpenVPN &quot;road warrior&quot; installer!'
	echo
	# OpenVPN setup and first user creation
	echo &quot;I need to ask you a few questions before starting the setup.&quot;
	echo &quot;You can leave the default options and just press enter if you are ok with them.&quot;
	echo
	echo &quot;First, provide the IPv4 address of the network interface you want OpenVPN&quot;
	echo &quot;listening to.&quot;
	# Autodetect IP address and pre-fill for the user
	IP=$(ip addr | grep 'inet' | grep -v inet6 | grep -vE '127\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' | grep -oE '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' | head -1)
	read -p &quot;IP address: &quot; -e -i $IP IP
	# If $IP is a private IP address, the server must be behind NAT
	if echo &quot;$IP&quot; | grep -qE '^(10\.|172\.1[6789]\.|172\.2[0-9]\.|172\.3[01]\.|192\.168)'; then
		echo
		echo &quot;This server is behind NAT. What is the public IPv4 address or hostname?&quot;
		read -p &quot;Public IP address / hostname: &quot; -e PUBLICIP
	fi
	echo
	echo &quot;Which protocol do you want for OpenVPN connections?&quot;
	echo &quot;   1) UDP (recommended)&quot;
	echo &quot;   2) TCP&quot;
	read -p &quot;Protocol [1-2]: &quot; -e -i 1 PROTOCOL
	case $PROTOCOL in
		1) 
		PROTOCOL=udp
		;;
		2) 
		PROTOCOL=tcp
		;;
	esac
	echo
	echo &quot;What port do you want OpenVPN listening to?&quot;
	read -p &quot;Port: &quot; -e -i 1194 PORT
	echo
	echo &quot;Which DNS do you want to use with the VPN?&quot;
	echo &quot;   1) Current system resolvers&quot;
	echo &quot;   2) 1.1.1.1&quot;
	echo &quot;   3) Google&quot;
	echo &quot;   4) OpenDNS&quot;
	echo &quot;   5) Verisign&quot;
	read -p &quot;DNS [1-5]: &quot; -e -i 1 DNS
	echo
	echo &quot;Finally, tell me your name for the client certificate.&quot;
	echo &quot;Please, use one word only, no special characters.&quot;
	read -p &quot;Client name: &quot; -e -i client CLIENT
	echo
	echo &quot;Okay, that was all I needed. We are ready to set up your OpenVPN server now.&quot;
	read -n1 -r -p &quot;Press any key to continue...&quot;
	if [[ &quot;$OS&quot; = 'debian' ]]; then
		apt-get update
		apt-get install openvpn iptables openssl ca-certificates -y
	else
		# Else, the distro is CentOS
		yum install epel-release -y
		yum install openvpn iptables openssl ca-certificates -y
	fi
	# Get easy-rsa
	EASYRSAURL='https://github.com/OpenVPN/easy-rsa/releases/download/v3.0.5/EasyRSA-nix-3.0.5.tgz'
	wget -O ~/easyrsa.tgz &quot;$EASYRSAURL&quot; 2&gt;/dev/null || curl -Lo ~/easyrsa.tgz &quot;$EASYRSAURL&quot;
	tar xzf ~/easyrsa.tgz -C ~/
	mv ~/EasyRSA-3.0.5/ /etc/openvpn/server/
	mv /etc/openvpn/server/EasyRSA-3.0.5/ /etc/openvpn/server/easy-rsa/
	chown -R root:root /etc/openvpn/server/easy-rsa/
	rm -f ~/easyrsa.tgz
	cd /etc/openvpn/server/easy-rsa/
	# Create the PKI, set up the CA and the server and client certificates
	./easyrsa init-pki
	./easyrsa --batch build-ca nopass
	EASYRSA_CERT_EXPIRE=3650 ./easyrsa build-server-full server nopass
	EASYRSA_CERT_EXPIRE=3650 ./easyrsa build-client-full $CLIENT nopass
	EASYRSA_CRL_DAYS=3650 ./easyrsa gen-crl
	# Move the stuff we need
	cp pki/ca.crt pki/private/ca.key pki/issued/server.crt pki/private/server.key pki/crl.pem /etc/openvpn/server
	# CRL is read with each client connection, when OpenVPN is dropped to nobody
	chown nobody:$GROUPNAME /etc/openvpn/server/crl.pem
	# Generate key for tls-auth
	openvpn --genkey --secret /etc/openvpn/server/ta.key
	# Create the DH parameters file using the predefined ffdhe2048 group
	echo '-----BEGIN DH PARAMETERS-----
MIIBCAKCAQEA//////////+t+FRYortKmq/cViAnPTzx2LnFg84tNpWp4TZBFGQz
+8yTnc4kmz75fS/jY2MMddj2gbICrsRhetPfHtXV/WVhJDP1H18GbtCFY2VVPe0a
87VXE15/V8k1mE8McODmi3fipona8+/och3xWKE2rec1MKzKT0g6eXq8CrGCsyT7
YdEIqUuyyOP7uWrat2DX9GgdT0Kj3jlN9K5W7edjcrsZCwenyO4KbXCeAvzhzffi
7MA0BM0oNC9hkXL+nOmFg/+OTxIy7vKBg8P+OxtMb61zO7X8vC7CIAXFjvGDfRaD
ssbzSibBsu/6iGtCOGEoXJf//////////wIBAg==
-----END DH PARAMETERS-----' &gt; /etc/openvpn/server/dh.pem
	# Generate server.conf
	echo &quot;port $PORT
proto $PROTOCOL
dev tun
sndbuf 0
rcvbuf 0
ca ca.crt
cert server.crt
key server.key
dh dh.pem
auth SHA512
tls-auth ta.key 0
topology subnet
server 10.8.0.0 255.255.255.0
ifconfig-pool-persist ipp.txt&quot; &gt; /etc/openvpn/server/server.conf
	echo 'push &quot;redirect-gateway def1 bypass-dhcp&quot;' &gt;&gt; /etc/openvpn/server/server.conf
	# DNS
	case $DNS in
		1)
		# Locate the proper resolv.conf
		# Needed for systems running systemd-resolved
		if grep -q &quot;127.0.0.53&quot; &quot;/etc/resolv.conf&quot;; then
			RESOLVCONF='/run/systemd/resolve/resolv.conf'
		else
			RESOLVCONF='/etc/resolv.conf'
		fi
		# Obtain the resolvers from resolv.conf and use them for OpenVPN
		grep -v '#' $RESOLVCONF | grep 'nameserver' | grep -E -o '[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}' | while read line; do
			echo &quot;push \&quot;dhcp-option DNS $line\&quot;&quot; &gt;&gt; /etc/openvpn/server/server.conf
		done
		;;
		2)
		echo 'push &quot;dhcp-option DNS 1.1.1.1&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		echo 'push &quot;dhcp-option DNS 1.0.0.1&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		;;
		3)
		echo 'push &quot;dhcp-option DNS 8.8.8.8&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		echo 'push &quot;dhcp-option DNS 8.8.4.4&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		;;
		4)
		echo 'push &quot;dhcp-option DNS 208.67.222.222&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		echo 'push &quot;dhcp-option DNS 208.67.220.220&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		;;
		5)
		echo 'push &quot;dhcp-option DNS 64.6.64.6&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		echo 'push &quot;dhcp-option DNS 64.6.65.6&quot;' &gt;&gt; /etc/openvpn/server/server.conf
		;;
	esac
	echo &quot;keepalive 10 120
cipher AES-256-CBC
user nobody
group $GROUPNAME
persist-key
persist-tun
status openvpn-status.log
verb 3
crl-verify crl.pem&quot; &gt;&gt; /etc/openvpn/server/server.conf
	# Enable net.ipv4.ip_forward for the system
	echo 'net.ipv4.ip_forward=1' &gt; /etc/sysctl.d/30-openvpn-forward.conf
	# Enable without waiting for a reboot or service restart
	echo 1 &gt; /proc/sys/net/ipv4/ip_forward
	if pgrep firewalld; then
		# Using both permanent and not permanent rules to avoid a firewalld
		# reload.
		# We don't use --add-service=openvpn because that would only work with
		# the default port and protocol.
		firewall-cmd --add-port=$PORT/$PROTOCOL
		firewall-cmd --zone=trusted --add-source=10.8.0.0/24
		firewall-cmd --permanent --add-port=$PORT/$PROTOCOL
		firewall-cmd --permanent --zone=trusted --add-source=10.8.0.0/24
		# Set NAT for the VPN subnet
		firewall-cmd --direct --add-rule ipv4 nat POSTROUTING 0 -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j SNAT --to $IP
		firewall-cmd --permanent --direct --add-rule ipv4 nat POSTROUTING 0 -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j SNAT --to $IP
	else
		# Create a service to set up persistent iptables rules
		echo &quot;[Unit]
Before=network.target
[Service]
Type=oneshot
ExecStart=/sbin/iptables -t nat -A POSTROUTING -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j SNAT --to $IP
ExecStart=/sbin/iptables -I INPUT -p $PROTOCOL --dport $PORT -j ACCEPT
ExecStart=/sbin/iptables -I FORWARD -s 10.8.0.0/24 -j ACCEPT
ExecStart=/sbin/iptables -I FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT
ExecStop=/sbin/iptables -t nat -D POSTROUTING -s 10.8.0.0/24 ! -d 10.8.0.0/24 -j SNAT --to $IP
ExecStop=/sbin/iptables -D INPUT -p $PROTOCOL --dport $PORT -j ACCEPT
ExecStop=/sbin/iptables -D FORWARD -s 10.8.0.0/24 -j ACCEPT
ExecStop=/sbin/iptables -D FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT
RemainAfterExit=yes
[Install]
WantedBy=multi-user.target&quot; &gt; /etc/systemd/system/openvpn-iptables.service
		systemctl enable --now openvpn-iptables.service
	fi
	# If SELinux is enabled and a custom port was selected, we need this
	if sestatus 2&gt;/dev/null | grep &quot;Current mode&quot; | grep -q &quot;enforcing&quot; &amp;&amp; [[ &quot;$PORT&quot; != '1194' ]]; then
		# Install semanage if not already present
		if ! hash semanage 2&gt;/dev/null; then
			if grep -qs &quot;CentOS Linux release 7&quot; &quot;/etc/centos-release&quot;; then
				yum install policycoreutils-python -y
			else
				yum install policycoreutils-python-utils -y
			fi
		fi
		semanage port -a -t openvpn_port_t -p $PROTOCOL $PORT
	fi
	# And finally, enable and start the OpenVPN service
	systemctl enable --now openvpn-server@server.service
	# If the server is behind a NAT, use the correct IP address
	if [[ &quot;$PUBLICIP&quot; != &quot;&quot; ]]; then
		IP=$PUBLICIP
	fi
	# client-common.txt is created so we have a template to add further users later
	echo &quot;client
dev tun
proto $PROTOCOL
sndbuf 0
rcvbuf 0
remote $IP $PORT
resolv-retry infinite
nobind
persist-key
persist-tun
remote-cert-tls server
auth SHA512
cipher AES-256-CBC
setenv opt block-outside-dns
key-direction 1
verb 3&quot; &gt; /etc/openvpn/server/client-common.txt
	# Generates the custom client.ovpn
	newclient &quot;$CLIENT&quot;
	echo
	echo &quot;Finished!&quot;
	echo
	echo &quot;Your client configuration is available at:&quot; ~/&quot;$CLIENT.ovpn&quot;
	echo &quot;If you want to add more clients, you simply need to run this script again!&quot;
fi
</code></pre><br/>
<h2 id="configurer-ssh-sur-raspberry-pi-et-ubuntu-mate-facultatif">Configurer SSH sur raspberry pi et Ubuntu Mate (facultatif)</h2>
<pre><code>sudo systemctl enable ssh
sudo service ssh restart

sudo dpkg-reconfigure openssh-server
</code></pre><br/>
<h2 id="configurer-un-client-openvpn">Configurer un client OpenVPN</h2>
<pre><code>sudo apt-get install openvpn
sudo openvpn --config /path/to/config.ovpn
</code></pre><p>Pour rendre la connexion permanente, éditer le fichier <code>/etc/default/openvpn</code> et décommenter la ligne <code>AUTOSTART=&quot;all&quot;</code> et copier le fichier <code>.ovpn</code> comme ceci (attention à bien renommer l'extension): <code>/etc/openvpn/config.conf</code></p>
]]></content>
        </item>
        
        <item>
            <title>Combiner plusieurs connexions internet pour booster son débit</title>
            <link>https://leandeep.com/combiner-plusieurs-connexions-internet-pour-booster-son-d%C3%A9bit/</link>
            <pubDate>Sun, 08 Mar 2020 17:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/combiner-plusieurs-connexions-internet-pour-booster-son-d%C3%A9bit/</guid>
            <description>Introduction Dans cet article nous allons voir comment booster son débit internet entrant et sortant en combinant son forfait internet et son forfait mobile.
 Analyse des réseaux Box ADSL
Voici un speed test réalisé en connectant mon ordinateur à ma box internet via Wifi.
 4G
Voici un speed test réalisé en connectant mon ordinateur à mon smartphone via USB.
 Configuration Pour combiner le réseau de votre box et le réseau de votre Smartphone sur votre ordinateur, il vous faut créer un proxy socks local.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article nous allons voir comment booster son débit internet entrant et sortant en combinant son forfait internet et son forfait mobile.</p>
<br/>
<h2 id="analyse-des-rseaux">Analyse des réseaux</h2>
<p><strong>Box ADSL</strong></p>
<p>Voici un speed test réalisé en connectant mon ordinateur à ma box internet via Wifi.</p>
<p><img src="/images/speedtest-box.png" alt="image"></p>
<br/>
<p><strong>4G</strong></p>
<p>Voici un speed test réalisé en connectant mon ordinateur à mon smartphone via USB.</p>
<p><img src="/images/speedtest-4g.png" alt="image"></p>
<br/>
<h2 id="configuration">Configuration</h2>
<p>Pour combiner le réseau de votre box et le réseau de votre Smartphone sur votre ordinateur, il vous faut créer un proxy socks local.</p>
<p>Pour ce faire, vous pouvez utiliser un utilitaire comme <a href="https://github.com/extremecoders-re/go-dispatch-proxy">go-dispatch-proxy</a> qui agira comme proxy entre vos 2 connexions.</p>
<pre><code># Lister les connexions disponibles
./go-dispatch-proxy -list

# Combiner 2 connexions
./go-dispatch-proxy ip1 ip2

# Combiner 2 connexions avec un ratio de contention
./go-dispatch-proxy ip1@2 ip2@3
</code></pre><p>Sur OSX rendez vous dans la section réseau &ndash;&gt; Avancé &ndash;&gt; Proxy et ajoutez 127.0.0.1:8080 comme proxy SOCKS.</p>
<br/>
<h2 id="rsultat-box--4g">Résultat Box + 4g</h2>
<p>En plus de pouvoir observer toutes les URLs externes appelées par votre système, vous pouvez observer que votre débit internet sera plus important car il combinera vos 2 connexions.</p>
<pre><code>...

[DEBUG] spclient.wg.spotify.com:443 -&gt; 192.168.42.70:0
[DEBUG] clients4.google.com:443 -&gt; 192.168.0.24:0
[DEBUG] github.com:443 -&gt; 192.168.0.24:0
[DEBUG] github.githubassets.com:443 -&gt; 192.168.42.70:0
[DEBUG] github.com:443 -&gt; 192.168.42.70:0
[DEBUG] avatars1.githubusercontent.com:443 -&gt; 192.168.0.24:0
[DEBUG] camo.githubusercontent.com:443 -&gt; 192.168.42.70:0
[DEBUG] clients1.google.com:443 -&gt; 192.168.0.24:0
[DEBUG] github.com:443 -&gt; 192.168.42.70:0
[DEBUG] github.com:443 -&gt; 192.168.42.70:0
[DEBUG] www.google-analytics.com:443 -&gt; 192.168.0.24:0
[DEBUG] github.com:443 -&gt; 192.168.42.70:0
[DEBUG] live.github.com:443 -&gt; 192.168.0.24:0
[DEBUG] collector.githubapp.com:443 -&gt; 192.168.42.70:0
[DEBUG] api.github.com:443 -&gt; 192.168.42.70:0
[DEBUG] secure-us.imrworldwide.com:443 -&gt; 192.168.42.70:0
[DEBUG] aax.amazon-adsystem.com:443 -&gt; 192.168.0.24:0
...

</code></pre><p><img src="/images/speedtest-box-4g.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Installer une barre de recherche Algolia sur son blog</title>
            <link>https://leandeep.com/installer-une-barre-de-recherche-algolia-sur-son-blog/</link>
            <pubDate>Sun, 01 Mar 2020 19:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/installer-une-barre-de-recherche-algolia-sur-son-blog/</guid>
            <description>Introduction L&#39;objectif de cet article est de voir comment installer un moteur de recherche Algolia sur son blog Hugo pour pouvoir rechercher n&#39;importe quel contenu.
Le résultat final sur mon blog:
 Création de compte Algolia La première chose à faire est de créer un compte Algolia.
Vous pouvez souscrire à un plan community. Cela vous permettra de créer une barre de recherche gratuitement.
Créer une application.
Créer ensuite un indice.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>L'objectif de cet article est de voir comment installer un moteur de recherche <a href="https://www.algolia.com/">Algolia</a> sur son blog Hugo pour pouvoir rechercher n'importe quel contenu.</p>
<p>Le résultat final sur mon blog:</p>
<p><img src="/images/algolia1.png" alt="image"></p>
<p><img src="/images/algolia2.png" alt="image"></p>
<br/>
<h2 id="cration-de-compte-algolia">Création de compte Algolia</h2>
<p>La première chose à faire est de créer un compte Algolia.</p>
<p>Vous pouvez souscrire à un plan community. Cela vous permettra de créer une barre de recherche gratuitement.</p>
<p>Créer une application.</p>
<p>Créer ensuite un indice. Un indice peut contenir un ou plusieurs indexes.</p>
<p>Enfin créer un index.</p>
<p>Dans l'onglet API Keys, récupérez l'<code>Application ID</code> et l'<code>Admin API Key</code>.</p>
<br/>
<h2 id="indexation-du-contenu-du-blog">Indexation du contenu du blog</h2>
<p>Nous allons utiliser une librairie NodeJS appelée <code>atomic-algolia</code> permettant de générer et d'envoyer des indices Hugo sur Algolia.</p>
<p>Voici donc les commandes à exécuter dans le dossier racine de votre blog Hugo:</p>
<pre><code>npm install atomic-algolia --save
npm init
</code></pre><p>Ajouter la ligne suivante dans la section <code>scripts</code> du fichier <code>package.json</code>:</p>
<pre><code>&quot;algolia&quot;: &quot;atomic-algolia&quot;
</code></pre><p>Créer un fichier <code>.env</code> et renseigner les variables d'environnement suivantes:</p>
<pre><code>ALGOLIA_APP_ID=YOUR_APPLICATION_ID
ALGOLIA_ADMIN_KEY=YOUR_ADMIN_API_KEY
ALGOLIA_INDEX_NAME=YOUR_INDEX_NAME
ALGOLIA_INDEX_FILE=public/algolia.json
</code></pre><p>Générer le fichier json d'indexation de contenu de votre blog et envoyer le sur Algolia:</p>
<pre><code>npm run algolia
</code></pre><br/>
<h2 id="cration-de-la-barre-de-recherche">Création de la barre de recherche</h2>
<p>Nous allons maintenant voir comment ajouter une barre de recherche sur son site.</p>
<p>Voici le code source de la barre de recherche sur mon site:</p>
<pre><code>&lt;link href=&quot;https://fonts.googleapis.com/icon?family=Material+Icons&quot; rel=&quot;stylesheet&quot;&gt;
&lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.0/jquery.min.js&quot;&gt;&lt;/script&gt;
&lt;script src=&quot;https://cdn.jsdelivr.net/instantsearch.js/1/instantsearch.min.js&quot;&gt;&lt;/script&gt;

&lt;style&gt;

.nav-search {
  -webkit-flex-grow: 1;
  -ms-flex-positive: 1;
  position: relative;
  width: 90%;
  height: 47px;
  margin-top: 20px; 
  background-color: white;
  z-index: 1000;
}

.nav-search.active {
  box-shadow: 0 4px 4px rgba(79, 79, 79, 0.21);
}
.nav-search.active .search-dropdown {
  display: block;
}

.nav-search.active .search-input {
  -webkit-animation: expand-search-box-animation 0.5s forwards;
  animation: expand-search-box-animation 0.5s forwards;
}

.nav-search.active .search-input input {
  border-width: 2px;
}

.nav-search.active .search-input .close-search {
  display: inline-block;
}

.nav-search.active .search-input .search-dropdown {
  display: block;
}

.nav-search .search-input {
  transition: left 0.2s ease-in-out;
  transition: width 0s ease-in-out;
}

.nav-search .search-input .search-icon {
  position: absolute;
  left: 15px;
  top: 13px;
  z-index: 999;
  color: black;
}

.nav-search .search-input input {
  font: 16px/1.875 &quot;Avenir Next W01&quot;, &quot;Avenir Next&quot;, &quot;Helvetica Neue&quot;, Helvetica, sans-serif;
  height: 50px;
  border: 1px solid #1b98f4;
  border-radius: 4px;
  min-width: 200px;
  width: 100%;
  padding-left: 50px;
  background-color: white;
}

.nav-search .search-input input:focus {
  outline: none;
}

.nav-search .search-input i.close-search {
  color: #1b98f4;
  display: none;
  position: absolute;
  right: 15px;
  top: 13px;
  cursor: pointer;
}

.search-dropdown {
  box-sizing: border-box;
  color: #B3B3B3;
  font: 14px/1.875 &quot;Avenir Next W01&quot;, &quot;Avenir Next&quot;, &quot;Helvetica Neue&quot;, Helvetica, sans-serif;
  opacity: 1.00;
  padding: 20px;
  width: 100%;
  -webkit-animation: expand-search-dropdown-animation 0.5s forwards;
  animation: expand-search-dropdown-animation 0.5s forwards;
  overflow-y: scroll;
  max-height: 400px;
  border-radius: 0 0 4px 4px;
  background-color: #FCFCFC;
  border: 1px solid #E0E0E0;
  box-shadow: 1px 3px 4px rgba(0, 0, 0, 0.09);
  display: none;
  background-color: white;
}

.search-dropdown .small {
  -webkit-flex-basis: 35%;
  -ms-flex-preferred-size: 35%;
  flex-basis: 35%;
}

.search-dropdown .search-section .hits-blank {
  color: #666;
  text-align: center;
  padding-top: 20px;
}

.search-dropdown a {
  text-decoration: none;
  color: inherit;
  z-index: 2000;
}

.hit {
  border-bottom: 1px solid #E6E6E6;
  margin-bottom: 20px;
}

.hit .hit-title {
  color: #1b98f4;
  font-family: 'bt_mono', monospace;
  font-weight: 500;
  margin-bottom: 0;
  margin-top: 0;
  display: inline-block;
  font-size: 14px;
}
.hit .hit-description {
  text-decoration: none;
  color: black;
  font-size: 14px;
  display: block;
  margin-top: 3px;
}
.hit .hit-anchor {
  font-size: 13px;
  color: #666;
}
.hit .algolia-docsearch-suggestion--highlight {
  background-color: #FFE9A4;
}

.ais-hits--item:last-child .hit {
  border: 0;
}

&lt;/style&gt;

&lt;script&gt;

    $(function() {

        $('#search-input').on('keyup', function() {
            $('.nav-search').addClass('active');
            $('#hits-container').scrollTop(0);
        })

        $('.close-search').on('click', function(evt) {
            evt.preventDefault();
            $('#search-input').val('');
            $('.nav-search').removeClass('active');
        })

        $('#search-input').on('blur', function(evt) {
            if(!evt.isDefaultPrevented) {
                $('.nav-search').removeClass('active');
            }
        })

        
        let search = instantsearch({
            appId: 'YOUR_APPLICATION_ID',
            apiKey: 'YOUR_READONLY_API_KEY',
            indexName: 'YOUR_SEARCH_INDEX',
            searchParameters: {replaceSynonymsInHighlight: false},
            searchFunction: function(helper) {
                var searchResults = $('.search-results');
                if (helper.state.query === '') {
                    searchResults.hide();
                    return;
                }
                helper.search();
                searchResults.show();
            }
        });

        // add a searchBox widget
        search.addWidget(
            instantsearch.widgets.searchBox({
                container: '#search-input',
                placeholder: 'Search for libraries in France...'
            })
        );

        // add a hits widget
            search.addWidget(
                instantsearch.widgets.hits({
                    container: '#hits-container',
                    hitsPerPage: 10,
                    debug: true,
                    templates: {
                    item: '&lt;a href=&quot;\{\{url\}\}&quot; target=&quot;_blank&quot;&gt;&lt;div class=&quot;hit&quot;&gt;&lt;div class=&quot;hit-content&quot;&gt;&lt;h2 class=&quot;hit-title&quot;&gt;\{\{\{_highlightResult.title.value\}\}\}&lt;/h2&gt;&lt;br&gt;&lt;small&gt;\{\{lvl0\}\} \{\{#lvl1\}\}&gt; \{\{\{_highlightResult.lvl1.value\}\}\} \{\{/lvl1\}\}\{\{#lvl2\}\}&gt; \{\{\{_highlightResult.lvl1.value\}\}\} \{\{/lvl2\}\}\{\{#lvl3\}\}&gt; \{\{\{_highlightResult.lvl3.value\}\}\} \{\{/lvl3\}\} \{\{#lvl4\}\}&gt; \{\{\{_highlightResult.lvl4.value\}\}\}\{\{/lvl4\}\}&lt;/small&gt;&lt;p class=&quot;hit-description&quot;&gt;\{\{\{_snippetResult.content.value\}\}\}&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/a&gt;',
                    empty: '&lt;div id=&quot;no-results-message&quot;&gt; &lt;p&gt;We didn`t find any results for the search &lt;em&gt;&quot;\{\{query\}\}&quot;&lt;/em&gt;.&lt;/p&gt;&lt;/div&gt;'
                    }
                })
            );

        // start
        search.start();
    
    });

&lt;/script&gt;
</code></pre><p>Pour que votre index soit utilisé, il suffit de remplacer la valeur des variables <code>appId: 'YOUR_APPLICATION_ID'</code>, <code>apiKey: 'YOUR_READONLY_API_KEY'</code> et <code>indexName: 'YOUR_SEARCH_INDEX'</code> dans le code ci-dessous par les votres.</p>
<p>Algolia est un très bon service SAAS que je recommande. Il est excessivement intuitif et vraiment très performant.</p>
]]></content>
        </item>
        
        <item>
            <title>Convertir des images dmg ou img en iso sur OSX</title>
            <link>https://leandeep.com/convertir-des-images-dmg-ou-img-en-iso-sur-osx/</link>
            <pubDate>Thu, 23 Jan 2020 20:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/convertir-des-images-dmg-ou-img-en-iso-sur-osx/</guid>
            <description>Convertir une image img en iso
hdiutil convert input.img -format UDTO -o output.iso  Convertir une image dmg en iso
hdiutil convert input.dmg -format UDTO -o output.iso </description>
            <content type="html"><![CDATA[<p><strong>Convertir une image img en iso</strong></p>
<pre><code>hdiutil convert input.img -format UDTO -o output.iso
</code></pre><br/>
<p><strong>Convertir une image dmg en iso</strong></p>
<pre><code>hdiutil convert input.dmg -format UDTO -o output.iso
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Mettre en place du monitoring simple sur Ubuntu et recevoir des alertes Slack</title>
            <link>https://leandeep.com/mettre-en-place-du-monitoring-simple-sur-ubuntu-et-recevoir-des-alertes-slack/</link>
            <pubDate>Sun, 19 Jan 2020 22:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/mettre-en-place-du-monitoring-simple-sur-ubuntu-et-recevoir-des-alertes-slack/</guid>
            <description>Introduction L&#39;objectif de cet article est de voir comment mettre en place du monitoring simple sur son serveur Ubuntu avec des alertes Slack et des rapports hebdomadaires.
 Installation de monit sudo apt install monit -y  Commandes utiles Vérifier qu&#39;il n&#39;y a pas d&#39;erreur dans la configuration.
sudo monit -t Si tout est bon, on peut reloader la monit et prendre en compte les changements de configuration avec la commande:</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>L'objectif de cet article est de voir comment mettre en place du monitoring simple sur son serveur Ubuntu avec des alertes Slack et des rapports hebdomadaires.</p>
<br/>
<h3 id="installation-de-monit">Installation de monit</h3>
<pre><code>sudo apt install monit -y
</code></pre><br/>
<h3 id="commandes-utiles">Commandes utiles</h3>
<p>Vérifier qu'il n'y a pas d'erreur dans la configuration.</p>
<pre><code>sudo monit -t
</code></pre><p>Si tout est bon, on peut reloader la monit et prendre en compte les changements de configuration avec la commande:</p>
<pre><code>sudo monit reload
</code></pre><br/>
<h3 id="envoi-dalertes-sur-slack">Envoi d'alertes sur Slack</h3>
<p><strong>Configuration de l'URL du webhook sur le site de Slack</strong></p>
<ul>
<li>
<p>Go to https://<!-- raw HTML omitted -->.slack.com/apps/manage/custom-integrations</p>
</li>
<li>
<p>Click Incoming WebHooks</p>
</li>
<li>
<p>Click Add Configuration</p>
</li>
<li>
<p>Select an existing channel or create a new one (e.g. #monit) - you can change it later</p>
</li>
<li>
<p>Click Add Incoming WebHooks integration</p>
</li>
<li>
<p>Copy the Webhook URL</p>
</li>
</ul>
<br/>
<p><strong>Création du script permettant d'envoyer des messages sur Slack</strong></p>
<p>Créer un fichier <code>/usr/local/bin/slack.sh</code> et ajoutez ce contenu:</p>
<pre><code>#!/bin/bash

URL=$(cat /etc/monit/slack-url)

COLOR=${MONIT_COLOR:-$([[ $MONIT_EVENT == *&quot;succeeded&quot;* ]] &amp;&amp; echo good || echo danger)}
TEXT=$(echo -e &quot;$MONIT_EVENT: $MONIT_DESCRIPTION&quot; | python3 -c &quot;import json,sys;print(json.dumps(sys.stdin.read()))&quot;)

PAYLOAD=&quot;{
  \&quot;attachments\&quot;: [
    {
      \&quot;text\&quot;: $TEXT,
      \&quot;color\&quot;: \&quot;$COLOR\&quot;,
      \&quot;mrkdwn_in\&quot;: [\&quot;text\&quot;],
      \&quot;fields\&quot;: [
        { \&quot;title\&quot;: \&quot;Date\&quot;, \&quot;value\&quot;: \&quot;$MONIT_DATE\&quot;, \&quot;short\&quot;: true },
        { \&quot;title\&quot;: \&quot;Host\&quot;, \&quot;value\&quot;: \&quot;$MONIT_HOST\&quot;, \&quot;short\&quot;: true }
      ]
    }
  ]
}&quot;

curl -s -X POST --data-urlencode &quot;payload=$PAYLOAD&quot; $URL
</code></pre><blockquote>
<p>Ne pas oublier de donner les droits d'exécution sur ce fichier <code>sudo chmod +x /usr/local/bin/slack.sh</code>.</p>
</blockquote>
<br/>
<p><strong>Configuration de l'URL du webhook dans un fichier</strong></p>
<p>Créer un second fichier pour Slack <code>/etc/monit/slack-url</code> et ajouter l'URL du webhook. Ce fichier contiendra uniquement une URL du type <code>https://hooks.slack.com/services/XXXXXX/YYYYYY/XyXyY123xxxZ</code>.</p>
<br/>
<p><strong>Test du bon fonctionnement du script Slack:</strong></p>
<pre><code>MONIT_EVENT=&quot;Oops il y a une erreur&quot; MONIT_DESCRIPTION=&quot;Ceci est un test&quot; MONIT_HOST=`hostname` MONIT_DATE=`date -R` \
  /usr/local/bin/slack.sh
</code></pre><br/>
<h3 id="cration-dalertes">Création d'alertes</h3>
<p><strong>Running out of disk space</strong></p>
<p>Créer un fichier <code>/etc/monit/conf.d/diskspace</code> et ajouter le contenu suivant:</p>
<pre><code>check filesystem rootfs with path /
  if space usage &gt; 80% then exec &quot;/usr/local/bin/slack.sh&quot; else if succeeded then exec &quot;/usr/local/bin/slack.sh&quot;
</code></pre><br/>
<p><strong>High load</strong></p>
<p>Créer le fichier suivant <code>/etc/monit/conf.d/system</code>:</p>
<pre><code>check system $HOSTNAME
  if memory &gt; 80% for 2 cycles then exec &quot;/usr/local/bin/slack.sh&quot; else if succeeded then exec &quot;/usr/local/bin/slack.sh&quot;
  if swap &gt; 10% for 2 cycles then exec &quot;/usr/local/bin/slack.sh&quot; else if succeeded then exec &quot;/usr/local/bin/slack.sh&quot;
  if cpu &gt; 80% for 2 cycles then exec &quot;/usr/local/bin/slack.sh&quot; else if succeeded then exec &quot;/usr/local/bin/slack.sh&quot;
  if loadavg (5min) &gt; 1 for 2 cycles then exec &quot;/usr/local/bin/slack.sh&quot; else if succeeded then exec &quot;/usr/local/bin/slack.sh&quot;
</code></pre><br/>
<p><strong>Open ports</strong></p>
<p>Créer le fichier suivant <code>/etc/monit/conf.d/ports</code>:</p>
<pre><code>check program port21 with path &quot;/bin/sh -c 'echo Port 21 is open ; nc -z $BLOGHOST 21 -w1'&quot; every &quot;5 * * * *&quot;
  if status != 1 then exec &quot;/usr/local/bin/slack.sh&quot;

check program port25 with path &quot;/bin/sh -c 'echo Port 25 is open ; nc -z $BLOGHOST 25 -w1'&quot; every &quot;5 * * * *&quot;
  if status != 1 then exec &quot;/usr/local/bin/slack.sh&quot;

check program port3306 with path &quot;/bin/sh -c 'echo Port 3306 is open ; nc -z $BLOGHOST 3306 -w1'&quot; every &quot;5 * * * *&quot;
  if status != 1 then exec &quot;/usr/local/bin/slack.sh&quot;
</code></pre><p>Vérifier la bonne syntaxe du fichier:</p>
<pre><code>sudo monit -t
</code></pre><p>Reload monit:</p>
<pre><code>sudo monit reload
</code></pre><br/>
<h3 id="rapports-hebdo">Rapports hebdo</h3>
<p>Créer le fichier suivant <code>/usr/local/bin/report.sh</code>:</p>
<pre><code>#!/bin/bash

echo Uptime
echo '```'
w
echo '```'

echo Network
echo '```'
sudo netstat -nlput
echo '```'

echo Disk
echo '```'
df -h
echo '```'

echo Memory
echo '```'
free -h
echo '```'

echo Processes
echo '```'
ps auxf | egrep -v '\[.+\]'
echo '```'
</code></pre><p>Vérifier le bon fonctionnement du rapport en recevant une alerte Slack:</p>
<pre><code>MONIT_EVENT=Report MONIT_DESCRIPTION=`/usr/local/bin/report.sh` \
MONIT_HOST=`hostname` MONIT_DATE=`date -R` MONIT_COLOR=&quot;#808080&quot; \
  /usr/local/bin/slack.sh
</code></pre><br/>
<p><strong>Pour recevoir ce rapport chaque semaine</strong></p>
<p>Créer un fichier <code>/etc/cron.weekly/slack-report</code> et ajouter ce contenu suivant:</p>
<pre><code>MONIT_EVENT=Report MONIT_DESCRIPTION=`/usr/local/bin/report.sh` \
MONIT_HOST=`hostname` MONIT_DATE=`date -R` MONIT_COLOR=&quot;#808080&quot; \
  /usr/local/bin/slack.sh
</code></pre><p>Ne pas oublier de donner à ce fichier les droits d'exécution:</p>
<pre><code>sudo chmod +x /etc/cron.weekly/slack-report
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer Go</title>
            <link>https://leandeep.com/installer-go/</link>
            <pubDate>Wed, 01 Jan 2020 10:59:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-go/</guid>
            <description>Installation sur OSX Rien de plus simple avec Homebrew mais avant d&#39;utiliser cet utilitaire, il est utile d&#39;ajouter les variables d&#39;environnement suivantes dans votre ~/.zshrc.
export GOPATH=&amp;quot;${HOME}/.go&amp;quot; export GOROOT=&amp;quot;$(brew --prefix golang)/libexec&amp;quot; export PATH=&amp;quot;$PATH:${GOPATH}/bin:${GOROOT}/bin&amp;quot; Recharger son terminal:
source ~/.zshrc Installer go:
brew install go Vérifier que l&#39;installation a bien fonctionné:
go get golang.org/x/tools/cmd/godoc go get golang.org/x/lint/golint Pensez à installer l&#39;extension suivante pour VSCode.
Installation sur Ubuntu 18.04 Télécharger le binaire go:</description>
            <content type="html"><![CDATA[<h2 id="installation-sur-osx">Installation sur OSX</h2>
<p>Rien de plus simple avec Homebrew mais avant d'utiliser cet utilitaire, il est utile d'ajouter les variables d'environnement suivantes dans votre <code>~/.zshrc</code>.</p>
<pre><code>export GOPATH=&quot;${HOME}/.go&quot;
export GOROOT=&quot;$(brew --prefix golang)/libexec&quot;
export PATH=&quot;$PATH:${GOPATH}/bin:${GOROOT}/bin&quot;
</code></pre><p>Recharger son terminal:</p>
<pre><code>source ~/.zshrc
</code></pre><p>Installer go:</p>
<pre><code>brew install go
</code></pre><p>Vérifier que l'installation a bien fonctionné:</p>
<pre><code>go get golang.org/x/tools/cmd/godoc
go get golang.org/x/lint/golint
</code></pre><p>Pensez à installer <a href="https://marketplace.visualstudio.com/items/lukehoban.Go">l'extension suivante pour VSCode</a>.</p>
<h2 id="installation-sur-ubuntu-1804">Installation sur Ubuntu 18.04</h2>
<p>Télécharger le binaire go:</p>
<pre><code>wget https://dl.google.com/go/go1.13.linux-amd64.tar.gz
</code></pre><p>Décompresser le binaire go dans <code>/usr/local</code>:</p>
<pre><code>sudo tar -C /usr/local -xzf go1.13.linux-amd64.tar.gz
</code></pre><p>Ajouter les lignes suivantes dans le fichier <code>~/.profile</code>:</p>
<pre><code>export PATH=$PATH:/usr/local/go/bin
export GOPATH=&quot;${HOME}/.go/bin&quot;
export PATH=$GOPATH:$PATH
</code></pre><p>Recharger le fichier <code>~/.profile</code>:</p>
<pre><code>source ~/.profile
</code></pre><p>Vérifier que Go est bien installé:</p>
<pre><code>go version
</code></pre><blockquote>
<p>Installer au moins les packages suivants: <code>apt-get install build-essential git</code> pour avoir <code>gcc</code> et <code>g++</code>.</p>
</blockquote>
<blockquote>
<p>Vérifier le bon fonctionnement de <code>go get</code>. Par exemple: <code>go get github.com/anacrolix/torrent/cmd/torrent</code></p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>NodeJS OSX Catalina fix No receipt for &#39;com.apple.pkg...&#39;</title>
            <link>https://leandeep.com/nodejs-osx-catalina-fix-no-receipt-for-com.apple.pkg.../</link>
            <pubDate>Mon, 30 Dec 2019 14:02:00 +0000</pubDate>
            
            <guid>https://leandeep.com/nodejs-osx-catalina-fix-no-receipt-for-com.apple.pkg.../</guid>
            <description>Lors de l&#39;installation de paquets NPM nécessitant de compiler du code vous pouvez rencontrer l&#39;erreur suivante après avoir installé OSX Catalina.
&amp;gt; node-gyp rebuild No receipt for &#39;com.apple.pkg.CLTools_Executables&#39; found at &#39;/&#39;. No receipt for &#39;com.apple.pkg.DeveloperToolsCLILeo&#39; found at &#39;/&#39;. No receipt for &#39;com.apple.pkg.DeveloperToolsCLI&#39; found at &#39;/&#39;. gyp: No Xcode or CLT version detected! gyp ERR! configure error  Pour solutionner le problème exécutez la commande suivante:
sudo xcode-select -s /Applications/Xcode.app/Contents/Developer </description>
            <content type="html"><![CDATA[<p>Lors de l'installation de paquets NPM nécessitant de compiler du code vous pouvez rencontrer l'erreur suivante après avoir installé OSX Catalina.</p>
<pre><code>&gt; node-gyp rebuild

No receipt for 'com.apple.pkg.CLTools_Executables' found at '/'.

No receipt for 'com.apple.pkg.DeveloperToolsCLILeo' found at '/'.

No receipt for 'com.apple.pkg.DeveloperToolsCLI' found at '/'.

gyp: No Xcode or CLT version detected!
gyp ERR! configure error

</code></pre><br/>
<p>Pour solutionner le problème exécutez la commande suivante:</p>
<pre><code>sudo xcode-select -s /Applications/Xcode.app/Contents/Developer
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Rust to Webassembly</title>
            <link>https://leandeep.com/rust-to-webassembly/</link>
            <pubDate>Sun, 22 Dec 2019 18:28:03 +0000</pubDate>
            
            <guid>https://leandeep.com/rust-to-webassembly/</guid>
            <description>Introduction L&#39;objectif de cet article est de voir comment compiler un tout petit programme en Rust et de l&#39;appeler soit dans un navigateur, soit dans un programme NodeJS ou soit dans un programme Python.
 Installation Installer rustup
 Rustup is an installer for the systems programming language Rust
 curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh source $HOME/.cargo/env  Installer wasm-pack
curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh  Création d&#39;une librairie Rust cargo new --lib days-count Remplacer le contenu du fichier days-count/src/lib.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>L'objectif de cet article est de voir comment compiler un tout petit programme en Rust et de l'appeler soit dans un navigateur, soit dans un programme NodeJS ou soit dans un programme Python.</p>
<br/>
<h2 id="installation">Installation</h2>
<p><strong>Installer rustup</strong></p>
<blockquote>
<p>Rustup is an installer for the systems programming language Rust</p>
</blockquote>
<pre><code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
</code></pre><br/>
<p><strong>Installer wasm-pack</strong></p>
<pre><code>curl https://rustwasm.github.io/wasm-pack/installer/init.sh -sSf | sh
</code></pre><br/>
<h2 id="cration-dune-librairie-rust">Création d'une librairie Rust</h2>
<pre><code>cargo new --lib days-count
</code></pre><p>Remplacer le contenu du fichier <code>days-count/src/lib.rs</code> par celui-ci:</p>
<pre><code>/// Count the number of calendar days between two dates given as
/// timestamps in milliseconds. Make the assumption that One day is
/// 86_400_000 milliseconds (leap seconds are ignored).
use wasm_bindgen::prelude::*;

#[wasm_bindgen]
pub fn count_days_between(timestamp_ms_a: u64, timestamp_ms_b: u64) -&gt; u64 {
    let days_count_a = timestamp_ms_a / 1000 / 3600 / 24;
    let days_count_b = timestamp_ms_b / 1000 / 3600 / 24;
    let days_count_between = match days_count_a.checked_sub(days_count_b) {
        Some(difference) =&gt; difference,
        None =&gt; days_count_b - days_count_a,
    };

    return days_count_between;
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn it_returns_365_between_xmas_2018_and_xmas_2019() {
        assert_eq!(count_days_between(1545696000000, 1577232000000), 365);
    }

    #[test]
    fn it_returns_365_between_xmas_2019_and_xmas_2018() {
        assert_eq!(count_days_between(1577232000000, 1545696000000), 365);
    }

    #[test]
    fn it_returns_0_for_two_timestamps_in_the_same_day() {
        // 2019/11/14 at 00:00, and later in the day
        assert_eq!(count_days_between(1573689600000, 1573750188321), 0);
    }

    #[test]
    fn it_returns_29_in_february_of_a_leap_year() {
        // 2012/03/01 &amp; 2012/02/01
        assert_eq!(count_days_between(1330560000000, 1328054400000), 29);
    }
}
</code></pre><br/>
<p><strong>Ajouter la cible permettant de compiler du Rust en WebAssembly</strong></p>
<pre><code>rustup target add wasm32-unknown-unknown
</code></pre><p>Modifier le fichier <code>Cargo.toml</code> et ajouter le contenu suivant:</p>
<pre><code>[dependencies]
wasm-bindgen = &quot;0.2&quot;

[lib]
crate-type = [&quot;cdylib&quot;]
</code></pre><br/>
<h2 id="accder-au-wasm-depuis-nodejs">Accéder au wasm depuis NodeJS</h2>
<p>On compile la librairie grâce à la commande suivante:</p>
<pre><code>wasm-pack build --release --target nodejs
</code></pre><pre><code>mkdir nodejs &amp;&amp; cd nodejs
yarn init -y # ou : npm init -y
yarn add --dev ../pkg # ou : npm i -D ../pkg
touch index.js
</code></pre><p>On importe le module days-count généré par wasm-pack et on exécute la fonction count_days_between dans notre fichier NodeJS:</p>
<p>Pour ce faire, on modifie donc le fichier <code>nodejs/index.js</code> avec le qui suit:</p>
<pre><code>const daysCount = require('days-count');

console.log(
  daysCount.count_days_between(
    // 01/02/2012
    BigInt(1330560000000),
    // 01/03/2012
    BigInt(1328054400000)
  )
);

</code></pre><p>En exécutant node nodejs/index.js on obtient bien <code>29</code> en output.</p>
<br/>
<h2 id="accder-au-wasm-depuis-le-navigateur">Accéder au wasm depuis le Navigateur</h2>
<p>On compile le project Rust:</p>
<pre><code>wasm-pack build --release --target bundler
</code></pre><p>On crée un projet basé sur la template NPM wasm-app:</p>
<pre><code>mkdir browser &amp;&amp; cd browser
npm init wasm-app
yarn add --dev ../pkg # ou : npm i -D ../pkg
yarn &amp;&amp; yarn build # ou npm install &amp;&amp; npm run build
</code></pre><p>On modifie le fichier <code>browser/index.js</code> et on lui donne le contenu suivant:</p>
<pre><code>import * as daysCount from 'days-count';

// pour changer du console.log
document.body.append(
  daysCount.count_days_between(
    // 01/02/2012
    BigInt(1330560000000),
    // 01/03/2012
    BigInt(1328054400000)
  )
);
</code></pre><p>On lance le projet avec <code>yarn start</code> et on se rend à l'adresse suivante <code>http://localhost:8080</code> pour voir le résultat de la fonction Rust exécutée.</p>
<br/>
<h2 id="bonus---accder--un-wasm-depuis-python">Bonus - Accéder à un wasm depuis Python</h2>
<p>Créer une nouvelle librairie:</p>
<pre><code>cargo new --lib simple
</code></pre><p>Modifier le fichier <code>simple/src/lib.rs</code> et ajouter la fonction Rust suivante:</p>
<pre><code>#[no_mangle]
pub extern fn simple_add(a: i32, b: i32) -&gt; i32 { a + b}
</code></pre><p>Ajouter la target suivante en exécutant cette commande dans votre terminal:</p>
<pre><code>rustup target add wasm32-unknown-unknown
</code></pre><p>Modifier le fichier <code>Cargo.toml</code> et ajouter le contenu suivant:</p>
<pre><code>[dependencies]
wasm-bindgen = &quot;0.2&quot;

[lib]
crate-type = [&quot;cdylib&quot;]
</code></pre><p>Créer un fichier simple.py qui va appeler notre binaire wasm:</p>
<pre><code>from wasmer import Instance
path = './target/wasm32-unknown-unknown/release/simple.wasm'
with open(path, ‘rb’) as bytecode:
    wasm_bytes = bytecode.read()
    instance = Instance(wasm_bytes)
    result = instance.exports.simple_add(12, 12)
    print('Modules exported from Rust: ')
    print(instance.exports)  # this will print function's name
    print('call simple_add(12, 12): ')
    print(result)  # 24
</code></pre><p>Exécuter le fichier python: <code>python simple.py</code> et observer le résultat.</p>
<pre><code>Modules exported from Rust:
[&quot;simple_add&quot;]
call simple_add(12, 12):
24
</code></pre><p>Et voilà.</p>
]]></content>
        </item>
        
        <item>
            <title>Jetson Nano</title>
            <link>https://leandeep.com/jetson-nano/</link>
            <pubDate>Sun, 22 Dec 2019 16:35:00 +0000</pubDate>
            
            <guid>https://leandeep.com/jetson-nano/</guid>
            <description>Découverte du Nvidia Jetson Nano J&#39;ai eu la chance de recevoir par Nvidia (encore un grand merci!) une board Jetson Nano pour la construction de mon robot autonome. Cette carte est un peu comme un Raspberry Pi en plus puissant avec une carte graphique intégrée. Et elle est vraiment très abordable. Elle coûte environ 140 €. Selon moi ses caractéristiques techniques en font une carte parfaitement adaptée à ceux qui veulent s&#39;initier au Edge Deep Learning.</description>
            <content type="html"><![CDATA[<h2 id="dcouverte-du-nvidia-jetson-nano">Découverte du Nvidia Jetson Nano</h2>
<p>J'ai eu la chance de recevoir par Nvidia (encore un grand merci!) une board Jetson Nano pour la construction de mon robot autonome. Cette carte est un peu comme un Raspberry Pi en plus puissant avec une carte graphique intégrée. Et elle est vraiment très abordable. Elle coûte environ 140 €. Selon moi ses caractéristiques techniques en font une carte parfaitement adaptée à ceux qui veulent s'initier au <strong>Edge Deep Learning</strong>. Avec ce genre de carte, on n'a plus besoin du Cloud pour faire l'inférence de modèle de Machine Learinig utilisant des librairies GPU. Cette carte est parfaite pour les sujets IoT. <em>On aura besoin du Cloud juste au moment où il faudra upgrader ses modèles de Machine/ Deep Learning.</em></p>
<p>Voici une première review de cette carte. D'autres articles viendront le compléter&hellip;</p>
<br/>
<h2 id="caractristiques-techniques">Caractéristiques techniques</h2>
<table>
<thead>
<tr>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>CPU</td>
<td align="right">Quad-core ARM® Cortex®-A57 MPCore processor</td>
</tr>
<tr>
<td>GPU</td>
<td align="right">NVIDIA Maxwell™ architecture with 128 NVIDIA CUDA® cores</td>
</tr>
<tr>
<td>RAM</td>
<td align="right">4 GB 64-bit LPDDR4</td>
</tr>
<tr>
<td>Storage</td>
<td align="right">16 GB eMMC 5.1 Flash</td>
</tr>
<tr>
<td>Camera</td>
<td align="right">12 lanes (3×4 or 4×2) MIPI CSI-2 DPHY 1.1 (1.5 Gbps)</td>
</tr>
<tr>
<td>Connectivity</td>
<td align="right">Gigabit Ethernet</td>
</tr>
<tr>
<td>Display Ports</td>
<td align="right">HDMI 2.0 and DP 1.2</td>
</tr>
<tr>
<td>USB Ports</td>
<td align="right">1 USB 3.0 and 3 USB 2.0</td>
</tr>
<tr>
<td>Other</td>
<td align="right">1 x1/2/4 PCIE, 1x SDIO / 2x SPI / 6x I2C / 2x I2S / GPIOs</td>
</tr>
<tr>
<td>Size</td>
<td align="right">69.6 mm x 45 mm</td>
</tr>
</tbody>
</table>
<br/>
<p><img src="/images/jetson-nano.png" alt="image"></p>
<br/>
<h2 id="alimentation-lectrique">Alimentation électrique</h2>
<p>Il y a 3 manières d'alimenter le Jetson Nano Developer Kit.</p>
<p>Premièrement, on peut le faire avec un cable micro-USB qui va fournir 5V et 2A.</p>
<p>Deuxièmement, on peut utiliser une ou deux pins du GPIO qui peuvent recevoir 5V et 3A chacune. On arrive donc à une intensité totale de 6A.</p>
<p>La troisième méthode consiste à utiliser le connecteur <em>Barrel Jack</em> qui reçoit du 5V et 4A. Personnellement, c'est la méthode que j'utilise. Pour que cela fonctionne, il faut relier entre elles les broches du jumper j48. Si vous branchez beaucoup de périphériques à votre Nano privilégiez cette option. Lorsque le Jumper est positionné sur la carte, le micro-USB passe en mode transfert de données.</p>
<blockquote>
<p>Pour info, l'alimentation PoE (Power Over Ethernet) n'est pas supportée&hellip; Par contre les broches sont disponibles sur le connecteur j38</p>
</blockquote>
<p>Deux modes d'alimentation sont disponibles: le mode 5W et le mode 10W.</p>
<p>Pour passer en mode 5W:</p>
<pre><code>sudo nvpmodel -m 1
</code></pre><p>Pour passer en mode 10W:</p>
<pre><code>sudo nvpmodel -m 0
</code></pre><br/>
<h2 id="installation-des-softs">Installation des Softs</h2>
<p><strong>Création de la carte micro SD</strong></p>
<p>Des images Linux <a href="https://developer.nvidia.com/embedded/dlc/jetson-nano-dev-kit-sd-card-image">Linux4Tegra</a> (Ubuntu 18.04 optimisé pour le hardware Nvidia) sont disponibles sur le site de Nvidia pour démarrer très vite.
Avec un utilitaire comme <a href="https://unetbootin.github.io/">Unetbootin</a> sur Mac (ou Win32 Disk Imager sur Windows), on peut créer une carte MicroSD bootable pour démarrer Linux sur son Jetson Nano.</p>
<br/>
<p><strong>Installation d'un virtualenv</strong></p>
<pre><code>sudo apt-get install virtualenv -y
mkdir ~/envs
cd ~/envs
virtualenv --python python3 ai_env
source ~/envs/ai_env/bin/activate
echo 'source ~/envs/ai_env/bin/activate' &gt;&gt; ~/.bashrc
</code></pre><br/>
<p><strong>OpenCV</strong></p>
<p>OpenCV est déjà installé sur cette distribution. Pour l'utiliser dans son projet Python à l'intérieur d'un environnement virtuel, il suffit d'exécuter les commandes suivantes:</p>
<pre><code>sudo find / -name &quot;cv2*&quot;

[sudo] password for olivier:

find: '/run/user/1000/gvfs': Permission denied

/usr/lib/python2.7/dist-packages/cv2.so
/usr/lib/python3.6/dist-packages/cv2.cpython-36m-aarch64-linux-gnu.so

cd ~/envs/ai_env/lib/python3.6/site-packages/

ln -s /usr/lib/python3.6/dist-packages/cv2.cpython-36m-aarch64-linux-gnu.so
</code></pre><p>Pour vérfier que le symlink a bien fonctionné et qu'OpenCV est fonctionnel, vous pouvez exécuter les commandes suivantes:</p>
<pre><code>python
&gt;&gt;&gt; import cv2
&gt;&gt;&gt; print(cv2.__version__)
3.3.1
</code></pre><br/>
<p>Sinon il peut être intéressant de réinstaller la librairie globalement pour ne plus perdre de temps:</p>
<pre><code>sudo apt-get install python3-opencv

python3
Python 3.6.8
[GCC 8.3.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import cv2
&gt;&gt;&gt; cv2._version
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
AttributeError: module 'cv2' has no attribute '_version'
&gt;&gt;&gt; cv2.__version__
'3.2.0'
</code></pre><br/>
<p><strong>Installation de modules de base</strong></p>
<pre><code>sudo apt-get update
sudo apt-get upgrade
# Installer le moteur de polices FreeType 2
sudo apt-get install libfreetype6-dev -y
# Installer le gestionnaire de flags de compilation et d'édition de lien pour les libs
sudo apt-get install pkg-config -y
sudo apt-get install zlib1g-dev zip libjpeg8-dev libhdf5-dev -y
sudo apt-get install libssl-dev libffi-dev python3-dev -y
sudo apt-get install libhdf5-serial-dev hdf5-tools -y
# For numpy install https://packages.debian.org/jessie/liblapack-dev &amp; https://packages.debian.org/jessie/libblas-dev &amp; https://packages.debian.org/jessie/libatlas-base-dev (see below)
sudo apt-get install libblas-dev liblapack-dev libatlas-base-dev -y
# Installation d'un compilateur fortran 
sudo apt-get install gfortran
sudo apt-get install build-essential cmake libgtk-3-dev libboost-all-dev -y
sudo apt-get install nano vim tmux -y
pip install matplotlib
pip install scikit-build
# To do basic image processing functions
pip install imutils
# The Python Imaging Library pillow
pip install pillow
sudo apt-get install python3-setuptools -y
# Librairie d'algèbre linéaire
sudo apt-get install python3-pip libopenblas-base -y
</code></pre><br/>
<p><strong>Installation de Scipy, Scikit-learn, Keras, Jupyter notebook, opencv-python</strong></p>
<pre><code>pip install scipy
pip install keras
pip install scikit-learn
pip install jupyter notebook	
pip install numpy # and wait forever... 
</code></pre><br/>
<p><strong>Installation de Tensorflow</strong></p>
<pre><code>pip install --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v42/tensorflow-gpu version_de_tensorflow 

# Les dernières versions de Tensorflow sont disponibles:
tensorflow_gpu-1.15.0+nv19.11-cp36-cp36m-linux_aarch64.whl 217MB 2019-12-12 16:58:00
tensorflow_gpu-2.0.0+nv19.11-cp36-cp36m-linux_aarch64.whl 198MB 2019-12-12 16:58:00
</code></pre><br/>
<p><strong>Configuration du SWAP</strong></p>
<p>Par défaut, le SWAP n'est pas activé, ce qui provoque des <code>OOM Kills</code> (Out Of Memory kills).</p>
<p>Il faut donc l'activer. Pour ce faire, exécutez les commandes suivantes:</p>
<pre><code>sudo swapon --show

# La taille idéale devrait être de deux fois celle de la RAM. Si vous avez une carte de 64 Go, fixez la taille du Swap à 8G.

sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
ls -lh /swapfile

# Création et activation du SWAP
sudo mkswap /swapfile
sudo swapon /swapfile

# Vérification
sudo swapon --show
free -h

# Rendre l'activation persistente après reboot
sudo cp /etc/fstab /etc/fstab.bak
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
</code></pre><br/>
<p><strong>Installation de Pytorch</strong></p>
<pre><code>wget https://nvidia.box.com/shared/static/ncgzus5o23uck9i5oth2n8n06k340l6k.whl -O torch-1.4.0-cp36-cp36m-linux_aarch64.whl
sudo pip3 install Cython
sudo pip3 install numpy
sudo pip3 install torch-1.4.0-cp36-cp36m-linux_aarch64.whl
</code></pre><br/>
<p><strong>Installation de torchvision</strong></p>
<pre><code>sudo apt-get install libjpeg-dev zlib1g-dev
git clone --branch v0.5.0 https://github.com/pytorch/vision torchvision
cd torchvision
sudo python setup.py install
cd ../   # attempting to load torchvision from build dir will result in import error
</code></pre><br/>
<p><strong>Installation du driver GPIO</strong></p>
<pre><code>pip install Jetson.GPIO
sudo groupadd -f -r gpio
sudo usermod -a -G gpio pi
sudo cp /opt/nvidia/jetson-gpio/etc/99-gpio.rules /etc/udev/rules.d/

Rebooter ou exécuter

sudo udevadm control --reload-rules &amp;&amp; sudo udevadm trigger
</code></pre><br/>
<p><strong>Installation du modèle Yolo</strong></p>
<pre><code>export GPU = 1
pip install yolo34py-gpu
</code></pre><br/>
<h2 id="forum-nvidia-officiel">Forum Nvidia officiel</h2>
<p><a href="https://devtalk.nvidia.com/default/board/371/">Accès au forum Nvidia</a></p>
<br/>
<h2 id="commandes-utiles">Commandes utiles</h2>
<p><strong>Taux d'utilisation et température</strong></p>
<pre><code>tegrastats
</code></pre><br/>
<p><strong>Power mode activé</strong></p>
<pre><code>sudo /usr/sbin/nvpmodel -q
</code></pre><br/>
<p><strong>Booster le ventilateur</strong></p>
<pre><code># Le faire tourner au maximum
sudo sh -c 'echo 255 &gt; /sys/devices/pwm-fan/target_pwm'
# L'arrêter
sudo sh -c 'echo 0 &gt; /sys/devices/pwm-fan/target_pwm'
</code></pre><br/>
<p><strong>Jetson stats</strong></p>
<pre><code>git clone https://github.com/rbonghi/jetson_stats.git
cd jetson_stats/
sudo ./install_jetson_stats.sh --s
ntop
jetson_release
</code></pre><br/>
<h2 id="conclusion">Conclusion</h2>
<p>A part quels petits soucis rencontrés au niveau de l'alimentation de la carte, je ne lui trouve que des avantages.
Les soucis au niveau de l'alimentation était dûs à un manque de connaissance de ma part sur le fonctionnement de cette carte. Une fois qu'on a compris comment bien aliementer sa carte, tout fonctionne parfaitement.</p>
<p>Un GPIO composé de 40 pins est compatible avec celui du Raspberry Pi. Pour moi cela représente un énorme avantage. Si vous avez déjà construit des projets avec des Raspberry Pi vous pouvez reprendre vos montages existants et les porter sur le Nano.</p>
<p>Et avec le GPU présent, vous pourrez sans doute construire de très beaux projets en y apportant des réseaux de neurones. Et la cela devient vraiment fun.</p>
<p>Je pense que c'est assez clair, je recommande très fortement cette carte.</p>
]]></content>
        </item>
        
        <item>
            <title>Autonomous 3D printed car using Nvidia Jetson Nano and Torch</title>
            <link>https://leandeep.com/autonomous-3d-printed-car-using-nvidia-jetson-nano-and-torch/</link>
            <pubDate>Sun, 22 Dec 2019 11:16:00 +0000</pubDate>
            
            <guid>https://leandeep.com/autonomous-3d-printed-car-using-nvidia-jetson-nano-and-torch/</guid>
            <description>&lt;p&gt;Voici une de mes dernières réalisations.&lt;/p&gt;
&lt;p&gt;
    &lt;iframe 
        width=&#34;100%&#34; 
        height=&#34;400px&#34;
        src=&#34;//www.youtube.com/embed/yqyUBr11y00?autoplay=1&amp;mute=1&#34; 
        frameborder=&#34;0&#34; 
        allow=&#34;autoplay; encrypted-media&#34; 
        allowfullscreen&gt;
    &lt;/iframe&gt;


&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>Voici une de mes dernières réalisations.</p>
<p>
    <iframe 
        width="100%" 
        height="400px"
        src="//www.youtube.com/embed/yqyUBr11y00?autoplay=1&mute=1" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>


<!-- raw HTML omitted --></p>
<br/>
<p>Je travaille maintenant sur un modèle à 4 roues omnidirectionnelles homemade.
<img src="/images/omni_wheel.png" alt="image"></p>
<br/>
<p>Work in progress&hellip;</p>]]></content>
        </item>
        
        <item>
            <title>Diffuser une vidéo VLC sur Chromecast</title>
            <link>https://leandeep.com/diffuser-une-vid%C3%A9o-vlc-sur-chromecast/</link>
            <pubDate>Sat, 21 Dec 2019 21:22:17 +0000</pubDate>
            
            <guid>https://leandeep.com/diffuser-une-vid%C3%A9o-vlc-sur-chromecast/</guid>
            <description>Petit tip qui explique comment diffuser le contenu d&#39;une vidéo lancée à partir de VLC vers une Chromecast:
  Lancez VLC 3.0+ sur votre ordinateur ou double-cliquez sur une vidéo associée à VLC.
  Lancer la lecture de la vidéo puis la diffusion sur le Chromecast en cliquant sur le menu Lecture -&amp;gt; Rendu puis sélectionner votre Chromecast.
   Et voilà, rien de plus simple.</description>
            <content type="html"><![CDATA[<p>Petit <em>tip</em> qui explique comment diffuser le contenu d'une vidéo lancée à partir de VLC vers une Chromecast:</p>
<ul>
<li>
<p>Lancez VLC 3.0+ sur votre ordinateur ou double-cliquez sur une vidéo associée à VLC.</p>
</li>
<li>
<p>Lancer la lecture de la vidéo puis la diffusion sur le Chromecast en cliquant sur le menu Lecture -&gt; Rendu puis sélectionner votre Chromecast.</p>
</li>
</ul>
<br/>
<p>Et voilà, rien de plus simple.</p>
]]></content>
        </item>
        
        <item>
            <title>Premier modèle VAE avec Tensorflow 2</title>
            <link>https://leandeep.com/premier-mod%C3%A8le-vae-avec-tensorflow-2/</link>
            <pubDate>Fri, 20 Dec 2019 19:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/premier-mod%C3%A8le-vae-avec-tensorflow-2/</guid>
            <description>Introduction Dans cet article, nous allons créer un modèle VAE qui va nous aider à générer des nouveaux digits. Nous partirons du dataset MNIST. Chaque image de ce dataset est normalisée dans un cadre faisant 28x28 pixels.
 Variational Autoencoders (VAE) Chargement des modules
from __future__ import absolute_import, division, print_function, unicode_literals import tensorflow as tf import os import time import numpy as np import glob import matplotlib.pyplot as plt import PIL import imageio from IPython import display  Chargement du dataset MNIST:</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article, nous allons créer un modèle VAE qui va nous aider à générer des nouveaux digits. Nous partirons du dataset MNIST.
Chaque image de ce dataset est normalisée dans un cadre faisant 28x28 pixels.</p>
<br/>
<h2 id="variational-autoencoders-vae">Variational Autoencoders (VAE)</h2>
<p><strong>Chargement des modules</strong></p>
<pre><code>from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import os
import time
import numpy as np
import glob
import matplotlib.pyplot as plt
import PIL
import imageio
from IPython import display
</code></pre><br/>
<p><strong>Chargement du dataset MNIST:</strong></p>
<pre><code>(train_data, _), (test_data, _) = tf.keras.datasets.mnist.load_data()
train_data = train_data.reshape(train_data.shape[0], 28, 28, 1).astype('float32')
test_data = test_data.reshape(test_data.shape[0], 28, 28, 1).astype('float32')
</code></pre><br/>
<p><strong>Normalisation des images d'entrée entre [0,1]:</strong></p>
<pre><code>train_data /= 255.
test_data /= 255.
</code></pre><br/>
<p><strong>Binarisation des données normalisées:</strong></p>
<pre><code>train_data[train_data &gt;= .5] = 1.
train_data[train_data &lt; .5] = 0.
test_data[test_data &gt;= .5] = 1.
test_data[test_data &lt; .5] = 0.
</code></pre><br/>
<p><strong>Batching et Shuffling du dataset:</strong></p>
<pre><code>TRAIN_SIZE = 60000
BATCH_SIZE = 50
TEST_SIZE = 10000
train_batch = tf.data.Dataset.from_tensor_slices(train_data).shuffle(TRAIN_SIZE).batch(BATCH_SIZE)
test_batch = tf.data.Dataset.from_tensor_slices(test_data).shuffle(TEST_SIZE).batch(BATCH_SIZE)
</code></pre><br/>
<p><strong>Construction des CNN:</strong>
<br/>
On va construire 2 réseaux neuronals convolutionnels pour l'Encoder et le Decoder.
<br/>
Ces deux réseaux seront envoloppés dans tf.keras.Sequential</p>
<pre><code>class CONV_VAE(tf.keras.Model):
  def __init__(self, latent_dim):
    super(CONV_VAE, self).__init__()
    self.latent_vec = latent_vec
    self.encoder_model = tf.keras.Sequential(
      [
          tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),
          tf.keras.layers.Conv2D(
              filters=25, kernel_size=3, strides=(2, 2), activation='relu'),
          tf.keras.layers.Conv2D(
              filters=50, kernel_size=3, strides=(2, 2), activation='relu'),
          tf.keras.layers.Flatten(),
          tf.keras.layers.Dense(latent_vec + latent_vec),
      ]
    )
    self.decoder_model = tf.keras.Sequential(
        [
          tf.keras.layers.InputLayer(input_shape=(latent_vec,)),
          tf.keras.layers.Dense(units=7*7*25, activation=tf.nn.relu),
          tf.keras.layers.Reshape(target_shape=(7, 7, 25)),
          tf.keras.layers.Conv2DTranspose(
              filters=50,
              kernel_size=3,
              strides=(2, 2),
              padding=&quot;SAME&quot;,
              activation='relu'),
          tf.keras.layers.Conv2DTranspose(
              filters=25,
              kernel_size=3,
              strides=(2, 2),
              padding=&quot;SAME&quot;,
              activation='relu'),
          tf.keras.layers.Conv2DTranspose(
              filters=1, kernel_size=3, strides=(1, 1), padding=&quot;SAME&quot;),
        ]
    )

  @tf.function
  def sampling(self, sam=None):
    if sam is None:
      sam = tf.random.normal(shape=(50, self.latent_vec))
    return self.decoder(sam, apply_sigmoid=True)

  def encoder(self, inp):
    mean, logd = tf.split(self.encoder_model(inp), num_or_size_splits=2, axis=1)
    return mean, logd

  def reparameterization(self, mean, logd):
    sam = tf.random.normal(shape=mean.shape)
    return sam * tf.exp(logd * .5) + mean

  def decoder(self, out, apply_sigmoid=False):
    logout = self.decoder_model(out)
    if apply_sigmoid:
      probabs = tf.sigmoid(logout)
      return probabs

    return logout

</code></pre><br/>
<p><strong>Construire la fonction d'optimisation:</strong></p>
<pre><code>optimizer_func = tf.keras.optimizers.Adam(1e-4)

def log_normal_prob_dist_func(sample, mean, logd, raxis=1):
  log2pi = tf.math.log(2. * np.pi)
  return tf.reduce_sum(-.5 * ((sample - mean) ** 2. * tf.exp(-logd) + logd + log2pi), axis=raxis)

@tf.function
def loss_func(model, inp):
  mean, logd = model.encoder(inp)
  out = model.reparameterization(mean, logd)
  log_inp = model.decoder(out)
  cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=log_inp, labels=inp)
  logp_inp_out = -tf.reduce_sum(cross_entropy, axis=[1, 2, 3])
  logp_out = log_normal_prob_dist_func(out, 0., 0.)
  logq_out_inp = log_normal_prob_dist_func(out, mean, logd)
  return -tf.reduce_mean(logp_inp_out + logp_out - logq_out_inp)

@tf.function
def gradient_func(model, inp, optimizer_func):
  with tf.GradientTape() as tape:
    loss = loss_func(model, inp)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer_func.apply_gradients(zip(gradients, model.trainable_variables))

</code></pre><br/>
<p><strong>Entrainement:</strong></p>
<pre><code>epochs = 100
latent_vec = 8
examples = 8

rand_vec = tf.random.normal(
    shape=[examples, latent_vec])
model = CONV_VAE(latent_vec)
</code></pre><br/>
<p><strong>Génération des images à partir du modèle entrainé:</strong></p>
<pre><code>def generate_and_save_images(model, epochs, input_data):
  preds = model.sampling(input_data)
  fig = plt.figure(figsize=(4,4))

  for i in range(preds.shape[0]):
      plt.subplot(4, 4, i+1)
      plt.imshow(preds[i, :, :, 0], cmap='gray')
      plt.axis('off')

  plt.savefig('img_at_epoch{:04d}.png'.format(epochs))
  plt.show()

generate_and_save_images(model, 0, rand_vec)

for epoch in range(1, epochs + 1):
  start_time = time.time()
  for x in train_batch:
    gradient_func(model, x, optimizer_func)
  end_time = time.time()

  if epoch % 1 == 0:
    loss = tf.keras.metrics.Mean()
    for y in test_batch:
      loss(loss_func(model, y))
    elbo = -loss.result()
    display.clear_output(wait=False)
    print('Epoch no.: {}, Test batch ELBO: {}, '
          'elapsed time for current epoch {}'.format(epochs, elbo, end_time - start_time))
    generate_and_save_images(model, epochs, rand_vec)
</code></pre><br/>
<p><strong>Afficher une image générée:</strong></p>
<pre><code>def display_image(epoch_no):
  return PIL.Image.open('img_at_epoch{:04d}.png'.format(epoch_no))

plt.imshow(display_image(epochs))
plt.axis('off')
</code></pre><p><img src="/images/digit_5.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Premier ConvNet avec Tensorflow 2</title>
            <link>https://leandeep.com/premier-convnet-avec-tensorflow-2/</link>
            <pubDate>Tue, 10 Dec 2019 19:49:00 +0200</pubDate>
            
            <guid>https://leandeep.com/premier-convnet-avec-tensorflow-2/</guid>
            <description>Introduction Tensorflow 2 beta est récemment sorti. Beaucoup de choses ont changé et il est maintenant beaucoup plus simple à utiliser. Keras a aussi été pleinement intégré. On peut l&#39;utiliser pour des applications large-scale. Le graphe d&#39;exécution est maintenant automatiquement créé par le framework. Le Python est converti est graphe. Dans cet article, nous allons créer un simple Convnet avec 3 couches en quelques lignes de codes pour se rendre compte à quel point l&#39;utilisation de Tensorflow a été simplifiée.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Tensorflow 2 beta est récemment sorti.
Beaucoup de choses ont changé et il est maintenant beaucoup plus simple à utiliser.
Keras a aussi été pleinement intégré. On peut l'utiliser pour des applications large-scale.
Le graphe d'exécution est maintenant automatiquement créé par le framework. Le Python est converti est graphe. Dans cet article, nous allons créer un simple Convnet avec 3 couches en quelques lignes de codes pour se rendre compte à quel point l'utilisation de Tensorflow a été simplifiée.</p>
<br/>
<h2 id="convnet">ConvNet</h2>
<p><strong>Chargement des modules:</strong></p>
<pre><code>from __future__ import absolute_import, division, print_function, unicode_literals
import numpy as np
import tensorflow as tf
from tensorflow import keras as ks
print(tf.__version__)
</code></pre><p><br/>
<strong>Chargement du dataset opensource Zalando Fashion-MNIST:</strong></p>
<pre><code>mnist_fashion = ks.datasets.fashion_mnist
(training_images, training_labels), (test_images, test_labels) = mnist_fashion.load_data()
print('Training Dataset Shape: {}'.format(training_images.shape))
print('No. of Training Dataset Labels: {}'. format(len(training_labels)))
print('Test Dataset Shape: {}'.format(test_images.shape)) 
print('No. of Test Dataset Labels: {}'.format(len(test_labels)))
</code></pre><p><br/>
<strong>Normalisation des valeurs:</strong>
<br/>
Comme la valeur des pixels varie entre 0 et 255, on va normaliser ces valeurs entre 0 et 1 avant de les pousser dans le modèle. On normalise ces valeurs (training and test data) en les divisant par 255.</p>
<pre><code>training_images = training_images / 255.0
test_images = test_images / 255.0
</code></pre><p><br/>
<strong>Remaniement des training et tests data</strong>
<br/>
On modifie la forme des training et tests matrices en 28x28x1</p>
<pre><code>training_images = training_images.reshape((60000, 28, 28, 1))
test_images = test_images.reshape((10000, 28, 28, 1))
print('Training Dataset Shape: {}'.format(training_images.shape))
print('No. of Training Dataset Labels: {}'.format(len(training_labels)))
print('Test Dataset Shape: {}'.format(test_images.shape))
print('No. of Test Dataset Labels: {}'.format(len(test_labels)))
</code></pre><br/>
<p><strong>Construction des couches du modèle</strong>
<br/>
Keras est utiliser pour construire les différentes couches de notre CNN. <br/>Pour faire simple, on va créer seulement 3 couches.
<br/><br/>
Première couche: couche convolutionnelle avec une fonction d'activation ReLU:</p>
<ul>
<li>Cette couche prend un tableau en 2D (28 × 28 pixels) comme input.</li>
<li>Elle prend 50 kernels (filtres) convolutionnels de forme 3 × 3 pixels.</li>
<li>La sortie de cette couche qui va passer par une fonction d'activation ReLU avant de passer à la prochaine couche</li>
</ul>
<pre><code>cnn_model = ks.models.Sequential()
cnn_model.add(ks.layers.Conv2D(50, (3, 3), activation='relu', input_shape=(28, 28, 1), name='Conv2D_layer'))
</code></pre><p><br/>
Deuxième couche:
<br/>
Cette couche prend 50 26x26 tableaux à 2D comme input et les transforme comme 50 tableaux qui ont des dimensions divisés par 2 (c'est-à-dire: de 26×26 à 13×13 pixels).</p>
<pre><code>cnn_model.add(ks.layers.MaxPooling2D((2, 2), name='Maxpooling_2D'))
</code></pre><p><br/>
Troisième couche &ldquo;fully connected layer&rdquo;:
<br/>
Cette couche prend 50 13x13 tableaux de 2D comme input et les transform en un tableau à 1D comprenant 8450 élements (50×13×13). Ces 8450 élements d'input sont passés à travers un réseau de neuronne &ldquo;fully connected&rdquo; qui donne des scores de probabilité pour chacune des 10 outputs.</p>
<pre><code>cnn_model.add(ks.layers.Flatten(name='Flatten'))
cnn_model.add(ks.layers.Dense(50, activation='relu', name='Hidden_layer'))
cnn_model.add(ks.layers.Dense(10, activation='softmax', name='Output_layer'))
</code></pre><br/>
<p><strong>Synthèse des couches:</strong>
<br/>
On observe le détail des différentes couches grâce à la commande suivante:</p>
<pre><code>cnn_model.summary()
</code></pre><br/>
<p><strong>Création de la fonction d'optimisation:</strong>
<br/>
Maintenant on utiliser une fonction d'optimisation grâce à la méthode compile. On utiliser un optimiseur Adam avec la fonction d'objectif sparse_categorical_crossentropy pour optimiser la métrique accuracy.</p>
<pre><code>cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
</code></pre><br/>
<p><strong>Entraintement du modèle:</strong></p>
<pre><code>cnn_model.fit(training_images, training_labels, epochs=10)
</code></pre><br/>
<p><strong>Modèle évaluation:</strong></p>
<pre><code># 1. Training évaluation
training_loss, training_accuracy = cnn_model.evaluate(training_images, training_labels)
print('Training Accuracy {}'. format(round(float(training_accuracy), 2)))

# 2. Test évaluation
test_loss, test_accuracy = cnn_model.evaluate(test_images, test_labels)
print('Test Accuracy {}'.format(round(float (test_accuracy), 2)))
</code></pre><br/>
<p><strong>Output:</strong>
<br/>
Training Accuracy 0.97<br/>
Test Accuracy 0.91</p>
]]></content>
        </item>
        
        <item>
            <title>Utilitaires utiles OSX Catalina</title>
            <link>https://leandeep.com/utilitaires-utiles-osx-catalina/</link>
            <pubDate>Mon, 18 Nov 2019 11:08:00 +0000</pubDate>
            
            <guid>https://leandeep.com/utilitaires-utiles-osx-catalina/</guid>
            <description>Voici certains (le minimum vital) utilitaires de développement que j&#39;utilise sur Mac.
Oh-my-zsh
sh -c &amp;quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&amp;quot;  Installer Node version manager (NVM)
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.1/install.sh | bash Puis au moins les paquets suivants:
nvm install v12.13.0 nvm use v12.13.0 nvm use default v12.13.0 npm i -g hexo http-server  Homebrew
/usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;  Packages Mac (.dmp, .pkg, &amp;hellip;)
 Onyx (Optimiser le Finder OSX) Docker - Puis activer Kubernetes dans les settings Iterm 2 Xcode via l&#39;App Store et l&#39;utilitaire command line via la commande suivante xcode-select --install Vuze pour télécharger des Torrents.</description>
            <content type="html"><![CDATA[<p>Voici certains (le minimum vital) utilitaires de développement que j'utilise sur Mac.</p>
<p><strong><a href="https://ohmyz.sh/">Oh-my-zsh</a></strong></p>
<pre><code>sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot;
</code></pre><br/>
<p><strong>Installer <a href="https://github.com/nvm-sh/nvm#installation-and-update">Node version manager</a> (NVM)</strong></p>
<pre><code>curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.1/install.sh | bash
</code></pre><p>Puis au moins les paquets suivants:</p>
<pre><code>nvm install v12.13.0
nvm use v12.13.0
nvm use default v12.13.0
npm i -g hexo http-server
</code></pre><br/>
<p><strong><a href="https://brew.sh/">Homebrew</a></strong></p>
<pre><code>/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;
</code></pre><br/>
<p><strong>Packages Mac (.dmp, .pkg, &hellip;)</strong></p>
<ul>
<li><a href="https://www.titanium-software.fr/fr/onyx.html">Onyx</a> (Optimiser le Finder OSX)</li>
<li><a href="https://docs.docker.com/docker-for-mac/install/">Docker</a> - Puis activer Kubernetes dans les settings</li>
<li><a href="https://www.iterm2.com/downloads.html">Iterm 2</a></li>
<li>Xcode via l'App Store et l'utilitaire command line via la commande suivante <code>xcode-select --install</code></li>
<li>Vuze pour télécharger des Torrents. Installation via cette commande <code>sudo ./Vuze\ Installer.app/Contents/MacOS/JavaApplicationStub</code>
car les droits root sont nécessaires</li>
<li><a href="https://code.visualstudio.com/download">Visual Studio Code</a> (Mon IDE)</li>
<li><a href="https://gitup.co/">GitUp</a> (GUI git)</li>
<li>Google Keep (Prise de notes synchronisées avec tous mes devices)</li>
<li>Final Cut pro (Faire des montages vidéo)</li>
<li>Audacity (Enregistrer via microphone)</li>
<li>Sublime Text (En dépannage. Il reste toujours excessivement rapide)</li>
<li><a href="https://aws.amazon.com/fr/workspaces/">AWS Workspaces</a></li>
<li>Google Chrome</li>
<li>Office (Word, Excel, Powerpoint)</li>
<li>Slack</li>
<li><a href="https://www.mongodb.com/products/compass">MongoDB Compass</a></li>
<li>Skype for business</li>
<li>Ultimaker Cura (Pour slicer des modèles 3D)</li>
<li><a href="https://www.pgadmin.org/download/">PG Admin 4</a> (GUI admin postgres)</li>
<li><a href="https://www.mysql.com/fr/products/workbench/">MySQLWorkbench</a> (GUI admin MySQL)</li>
<li>Tunnelblick (Pour accéder à des réseaux VPN)</li>
<li>The Unarchiver (Pour extraire des Rar)</li>
<li>AutoDesk (Pour modifier des modèles 3D)</li>
<li>Screenflow (Pour enregistrer un screencast)</li>
<li>VirtualBox (Pour créer des VMs)</li>
<li><a href="https://cyberduck.io/">Cyberduck</a></li>
<li><a href="https://pasteapp.me/">Paste</a> (Gestionnaire avancé copier coller)</li>
<li><a href="https://github.com/objective-see/LuLu">LuLu</a> (Firewall opensource)</li>
<li><a href="https://apps.apple.com/fr/app/inet-network-scanner/id403304796?mt=12">iNet</a> (GUI de scan réseau)</li>
<li><a href="https://pilotmoon.com/scrollreverser/">Scroll Reverser</a> (Inverser mon scroll de souris quand je travaille en double écran avec souris déportée)</li>
<li><a href="https://unetbootin.github.io/">unetbootin</a> (Créer des clés USB bootables)</li>
<li><a href="https://www.getpostman.com/downloads/">Postman</a> (Communiquer avec des REST APIs)</li>
<li><a href="https://unetbootin.github.io/">Unetbootin</a> (Pour créer des USB bootables)</li>
<li>Divvy (Disponible sur l'Apple Store pour spliter facilement son écran)</li>
<li><a href="https://directory.apache.org/studio/download/download-macosx.html">LDAP Client</a></li>
<li><a href="https://apps.apple.com/fr/app/app-language-chooser/id451732904?mt=12">App Language Chooser</a> (Disponible sur l'Apple Store pour changer la langue d'une seule application)</li>
<li>Code Notes (Pour gérer ses snippets Github (gists) ou en local)</li>
<li>Lepton (Pour gérer ses snippets Github (gists) uniquement)</li>
<li><a href="https://github.com/jwise/HoRNDIS">HoRNDIS</a> Android USB tethering driver for Mac OS X</li>
<li><a href="https://dev.mysql.com/doc/mysql-osx-excerpt/5.7/en/osx-installation-pkg.html">MySQL Server</a> Je préfère installer MySQL server via le .dmg plutôt que via brew pour avoir le bouton &ldquo;Start MySQL Server&rdquo; dans System Preferences.</li>
<li>TimescaleDB (DB timeseries basée sur Postgres): <code>docker run -d --name timescaledb -p 5432:5432 -e POSTGRES_PASSWORD=password timescale/timescaledb:latest</code></li>
</ul>
<br/>
<p><strong>Packages Homebrew</strong></p>
<pre><code>brew install wget tree python@2 pkg-config poppler kubernetes-helm tmux socat
brew cask update
brew cask install ip-in-menu-bar betterzipql
brew cask install qlcolorcode
brew cask install qlmarkdown qlstephen quicklook-json qlimagesize suspicious-package 
brew cask install keepassxc
brew cask install db-browser-for-sqlite

brew install hadolint # Dockerfile linter

# Installation de MongoDB 
# https://docs.mongodb.com/manual/tutorial/install-mongodb-on-os-x/
brew tap mongodb/brew
brew install mongodb-community@4.2
brew services start mongodb-community

# Notifications Github
brew install sargsyan/github-notifier/github-notifier
github-notifier-install
# Puis éventuellement
# github-notifier-configure

# Installation de Redis
Voir cet article https://leandeep.com/Installer-redis-sur-OSX/

# Installation de Mysql client (si MySQL server pas installé)
brew install mysql-client
echo 'export PATH=&quot;/usr/local/opt/mysql-client/bin:$PATH&quot;' &gt;&gt; ~/.zshrc
</code></pre><br/>
<p><strong>Installer virtualenvwrapper</strong></p>
<p>Puis au minimum <code>pip install awscli ansible</code></p>
<br/>
<p><strong>Configurer Git</strong></p>
<p>Ajouter le fichier <code>~/.gitconfig</code> avec le contenu suivant:</p>
<pre><code>[push]
        default = current
[user]
        name = votre_nom
        email = votre_adresse_email

</code></pre><br/>
<p><strong>Configurer iTerm2</strong></p>
<p>Go to iTerm Preferences → Profiles, select your profile, then the Keys tab. Click Load Preset&hellip; and choose Natural Text Editing.</p>
<p><strong>Extensions VSCode</strong></p>
<ul>
<li>Back &amp; Forth</li>
<li>Better TOML</li>
<li>C/C++</li>
<li>Cloud Code</li>
<li>Code Runner</li>
<li>Dart</li>
<li>Docker</li>
<li>Flutter</li>
<li>Formatting Toggle</li>
<li>Git Blame</li>
<li>Git History</li>
<li>Git Tree Compare</li>
<li>GitLens</li>
<li>Go</li>
<li>Hashicorp Terraform</li>
<li>Hugofy</li>
<li>Language-Cython</li>
<li>OpenAPI (Swagger) Editor</li>
<li>Prophet Debugger</li>
<li>Python</li>
<li>Service Bus Explorer</li>
<li>Visual Studio Intellicode</li>
<li>YAML</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Monter un raid existant sur une nouvelle installation d&#39;Ubuntu</title>
            <link>https://leandeep.com/monter-un-raid-existant-sur-une-nouvelle-installation-dubuntu/</link>
            <pubDate>Fri, 15 Nov 2019 13:31:00 +0000</pubDate>
            
            <guid>https://leandeep.com/monter-un-raid-existant-sur-une-nouvelle-installation-dubuntu/</guid>
            <description>Si vous aviez créé votre raid avec l&#39;utilitaire mdadm (comme expliqué dans l&#39;article suivant https://leandeep.com/creer-un-raid-pour-stocker-ses-precieux-datasets/ ), les commandes pour le remonter ou réassembler sur un Ubuntu tout neuf sont les suivantes:
# Installation de mdadm sudo apt-get update sudo apt-get install -y mdadm # On détecte le raid sudo mdadm --assemble --scan # On monte le raid en local sudo mkdir /mnt/md0 sudo mount /dev/md0 /mnt/md0 # Vérifier qu&#39;il est bien monté df -h  Troubleshooting Avoir des informations (type et disques utilisés) sur les raids existants</description>
            <content type="html"><![CDATA[<p>Si vous aviez créé votre raid avec l'utilitaire <code>mdadm</code> (comme expliqué dans l'article suivant <a href="https://leandeep.com/creer-un-raid-pour-stocker-ses-precieux-datasets/">https://leandeep.com/creer-un-raid-pour-stocker-ses-precieux-datasets/</a> ), les commandes pour le remonter ou réassembler sur un Ubuntu tout neuf sont les suivantes:</p>
<pre><code># Installation de mdadm
sudo apt-get update
sudo apt-get install -y mdadm

# On détecte le raid 
sudo mdadm --assemble --scan

# On monte le raid en local
sudo mkdir /mnt/md0
sudo mount /dev/md0 /mnt/md0

# Vérifier qu'il est bien monté
df -h
</code></pre><br/>
<h2 id="troubleshooting">Troubleshooting</h2>
<p><strong>Avoir des informations (type et disques utilisés) sur les raids existants</strong></p>
<ul>
<li>Option 1:</li>
</ul>
<pre><code>cat /proc/mdstat

Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10]
md0 : active raid1 sdb1[0] sdc1[1]
      976761472 blocks [2/2] [UU]
      bitmap: 0/8 pages [0KB], 65536KB chunk

</code></pre><br/>
<ul>
<li>Option 2:</li>
</ul>
<pre><code>grep 'md' /proc/mdstat | tr ' ' '\n' | sed -n 's/\[.*//p'
</code></pre><br/>
<p><strong>Lister les disques</strong></p>
<pre><code>fdisk -l
</code></pre><br/>
<p><strong>Obtenir le serial number d'un disque</strong></p>
<pre><code>sudo hdparm -I /dev/sdb1 | grep 'Serial\ Number'

Serial Number:      S246J9FC405870
</code></pre><p>Cela peut être pratique si vous avez plein de disques dans une tour et que vous voulez identifier les disques HS.</p>
<p><img src="/images/serial-disque-dur.png" alt="image"></p>
<br/>
<p><strong>Error: &ldquo;mdadm: Duplicate MD device names in conf file were found&rdquo;</strong></p>
<p>Editer le fichier <code>/etc/mdadm/mdadm.conf</code> et vérifier qu'un raid n'est pas référencé 2 fois.</p>
<p>Puis exécuter la commande suivante pour prendre en compte la modification:</p>
<pre><code>update-initramfs  -u -k all
</code></pre><p>Vous pouvez ensuite rebooter pour vérifier que cela fonctionne toujours&hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Installer pyenv sur Linux deepin 15 (debian like Linux)</title>
            <link>https://leandeep.com/installer-pyenv-sur-linux-deepin-15-debian-like-linux/</link>
            <pubDate>Mon, 04 Nov 2019 18:21:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-pyenv-sur-linux-deepin-15-debian-like-linux/</guid>
            <description>Introduction Je suis tombé en admiration pour Linux Deepin. Il est basée sur Debian. Son interface graphique est vraiment très agréable; aussi belle qu&#39;OSX. Elle est certes un peu gourmande en ressources mais quand on a 64 Go de RAM ce n&#39;est pas vraiment un problème :D. J&#39;ai découvert cette distribution grâce à Huawei l&#39;embarque maintenant dans ses matebook pro.
Je n&#39;ai pas encore vérifié s&#39;il y avait des spywares dans tous les sens mais je vais m&#39;en occuper d&#39;ici peu.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Je suis tombé en admiration pour Linux Deepin. Il est basée sur Debian. Son interface graphique est vraiment très agréable; aussi belle qu'OSX. Elle est certes un peu gourmande en ressources mais quand on a 64 Go de RAM ce n'est pas vraiment un problème :D. J'ai découvert cette distribution grâce à Huawei l'embarque maintenant dans ses matebook pro.</p>
<p><em>Je n'ai pas encore vérifié s'il y avait des spywares dans tous les sens mais je vais m'en occuper d'ici peu. J'ai un super proxy transparent pour voir tout ce qui transite sur le réseau. En attendant je ne me connecte à aucun site sensible.</em></p>
<p>**Bref dans cet article nous allons voir comment installer pyenv sur cet Linux pour gérer plusieurs environnements Python pour ses environnements virtuels.</p>
<br/>
<h2 id="steps">Steps</h2>
<p>Mise à jour des paquets:</p>
<pre><code>sudo apt-get update &amp;&amp; sudo apt-get upgrade
</code></pre><pre><code># Après un upgrade de système, j'ai pris l'habitude de rebooter mon système pour voir si tout s'est bien passé. Je vous invite à faire la même chose. Cela ne prend que quelques secondes et cela permet de ne pas chercher midi à quatorze heures si votre système ne fonctionne plus avant de passer à la suite.

sudo reboot
</code></pre><p>On installe les dépendances:</p>
<pre><code>sudo apt-get install -y make build-essential libssl-dev zlib1g-dev libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm libncurses5-dev git
</code></pre><p>Installation de Pyenv:</p>
<pre><code>curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash
</code></pre><p>On ajoute les lignes suivantes dans son <code>~/.zshrc</code> avant d'exécuter un <code>source ~/.zshrc</code>:</p>
<pre><code>export PATH=&quot;~/.pyenv/bin:$PATH&quot;
eval &quot;$(pyenv init -)&quot;
eval &quot;$(pyenv virtualenv-init -)&quot;
</code></pre><p>Vérifier le bon fonctionnement de pyenv:</p>
<pre><code>pyenv versions 
</code></pre><p>Lister les versions de Python disponibles:</p>
<pre><code>pyenv install --list
</code></pre><p>Installer une version spécifique:</p>
<pre><code>pyenv install 3.7.5
</code></pre><p>Afficher la version actuellement utilisée:</p>
<pre><code>pyenv version
</code></pre><p>Utiliser une version de Python globalement sur son système:</p>
<pre><code>pyenv global 3.7.5
# Ou localement dans un répertoire
pyenv local 3.7.5
# Ou setter une versoin dans le shell actuel
pyenv shell 3.7.5
</code></pre><p>Après si vous voulez créer un virtualenv avec une version de Python spécifique c'est très simple. Il suffit si vous avez virtualenvwrapper d'exécuter la commande suivante:</p>
<pre><code># Récupérer le path du Python que l'on souhaite utiliser
which python
/home/olivier/.pyenv/shims/python

# Créer le virtualenv
mkvirtualenv -p /home/olivier/.pyenv/shims/python -a . ai_env
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Créer un raid pour stocker ses précieux datasets</title>
            <link>https://leandeep.com/cr%C3%A9er-un-raid-pour-stocker-ses-pr%C3%A9cieux-datasets/</link>
            <pubDate>Sat, 28 Sep 2019 09:51:00 +0000</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-un-raid-pour-stocker-ses-pr%C3%A9cieux-datasets/</guid>
            <description>Introduction Dans cet article nous allons voir comment créer un raid de type 1 pour répliquer nos données sur 2 disques. Si un disque venait à crasher, un second est présent pour éviter de perdre nos précieuses données. J&#39;ai plusieurs fois perdu mes datasets de Machine Learning et cela ma coûté cher en temps pour les retrouver et les recréer. Je me suis armé d&#39;un système raid.
Voici donc la procédure d&#39;installation.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article nous allons voir comment créer un raid de type 1 pour répliquer nos données sur 2 disques. Si un disque venait à crasher, un second  est présent pour éviter de perdre nos précieuses données. J'ai plusieurs fois perdu mes datasets de Machine Learning et cela ma coûté cher en temps pour les retrouver et les recréer. Je me suis armé d'un système raid.</p>
<p>Voici donc la procédure d'installation. Dans un prochain article que j'intitulerai &ldquo;Gérer ses datasets comme un pro&rdquo; je parlerai de la manière dont j'organise mes données au sein de mon serveur. J'en ferais peut-être un autre sur le CICD du Data Scientist (différent de celui des développeurs).</p>
<br/>
<h2 id="vrification-des-disques">Vérification des disques</h2>
<p>Avant de commencer on va vérifier l'état des disques durs:</p>
<pre><code>sudo apt-get install smartmontools
</code></pre><p>Lancer le test avec la commande suivante.</p>
<pre><code>sudo smartctl -t short /dev/sdb
</code></pre><p>Voir le résultat (après l'heure indiquée par la commande précédente):</p>
<pre><code>sudo smartctl -l selftest /dev/sdb
</code></pre><br/>
<h2 id="installation">Installation</h2>
<p><strong>Préparation des disques</strong></p>
<p>Identifier les disques sur lesquels vous voulez créer votre Raid:</p>
<pre><code>sudo fdisk -l
sudo fdisk /dev/sdX
</code></pre><p>Formater ses disques puis créer une partition sur chacun d'eux:</p>
<pre><code># Exemple de création de partitions avec /dev/sdb et /dev/sdc
sudo gdisk /dev/sdb

# voir le menu &quot;m&quot; (vous trouverez ce qu'il faut si vous devez effacer une partition)
# p pour afficher les partitions
o # pour effacer toutes les partitions et créer une nouvelle &quot;protective MBR&quot;.
y # valide
n # pour créer une nouvelle partition
1 # pour le numéro de la partition
Entrée # pour le début des blocks
Entrée # pour la fin des blocks
fd00 # pour le type de partition (Linux Raid)
w # save
y # confirm

# Recommander cette procédure avec /dev/sdc
</code></pre><br/>
<p><strong>Création du raid</strong></p>
<p>Installation de <code>mdadm</code>:</p>
<pre><code>sudo apt install -y mdadm
</code></pre><p>Création du raid:</p>
<pre><code>sudo mdadm --create /dev/md0 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1
</code></pre><p><strong>Attention, l'étape précédente va prendre du temps&hellip;</strong> Vous pouvez voir sa progression avec la commande <code>cat /proc/mdstat</code>.</p>
<p>Créer un filesystem sur le nouvel Array :</p>
<pre><code>sudo mkfs.ext4 -F /dev/md0
</code></pre><p>Créer un point de montage pour le nouveau filesystem:</p>
<pre><code>sudo mkdir -p /mnt/md0
</code></pre><p>Monter le nouveau filesystem:</p>
<pre><code>sudo mount /dev/md0 /mnt/md0
</code></pre><p>Vérifier qu'il est bien accessible:</p>
<pre><code>df -h -x devtmpfs -x tmpfs
</code></pre><p>Pour que le Array soit automatiquement ré-assemblé à chaque reboot, on peut modifier le fichier de configuration de mdadm:</p>
<pre><code>sudo mdadm --detail --scan | sudo tee -a /etc/mdadm/mdadm.conf
</code></pre><p>Rendre le Array accessible durant la phases de early boot en mettant <code>initramfs</code> (initial RAM file system) à jour:</p>
<pre><code>sudo update-initramfs -u
</code></pre><p>Ajouter le disque raid dans fstab:</p>
<pre><code>echo '/dev/md0 /mnt/md0 ext4 defaults,nofail,discard 0 0' | sudo tee -a /etc/fstab
</code></pre><br/>
<h2 id="troubleshooting">Troubleshooting</h2>
<p>Voir le(s) raid(s) existant(s):</p>
<pre><code>cat /proc/mdstat
</code></pre><p>Supprimer un raid:</p>
<pre><code>sudo umount /dev/md0
mdadm -S /dev/md0
mdadm --remove /dev/md0
# Vérifier qu'il n'est pas présent dans /etc/fstab
</code></pre><p>Examiner les superblocks:</p>
<pre><code>sudo mdadm -E /dev/sdd
</code></pre><p>Effacer les superblocks:</p>
<pre><code>sudo mdadm --zero-superblock /dev/sdd
</code></pre><p>Lister les disques:</p>
<pre><code>lsblk -o NAME,SIZE,FSTYPE,TYPE,MOUNTPOINT
</code></pre><p>Wiping the entire disk:</p>
<pre><code>dd if=/dev/zero of=/dev/sdX bs=1M
</code></pre><br/>
<p>Bonus 1: Wiping the entire disk for security reasons (plus long):</p>
<pre><code>dd if=/dev/urandom of=/dev/sdX bs=1M
</code></pre><blockquote>
<p>When you delete a file or format a hard drive you are basically just telling the computer that it can use this portion of the disk again if it is needed. If that portion of the disk is not every written over again. The data will remain indefinitely. So, in order to make deleted data unrecoverable we must write over it.</p>
</blockquote>
<blockquote>
<p>If you are really paranoid or just want to be ultra secure you could write over the drive 7 times with random data. This is the same procedure the US Government uses to secure its own data.</p>
</blockquote>
<p>Cadeau, le script associé:</p>
<pre><code>#!/bin/bash 
for n in `seq 7`; do dd if=/dev/urandom of=/dev/sda bs=8b conv=notrunc; done
# chmod a+x wipeIt
</code></pre><br/>
<p>Bonus 2: Voir la progression de dd</p>
<pre><code>Option 1:
sudo dd if=/dev/zero of=/dev/sdX bs=1M status=progress

Option 2:
# Dans un 1er terminal
sudo dd if=/dev/zero of=/dev/sdX bs=1M
 
# Dans un second terminal on récupère le pid du process dd et on le kill toutes les 10s
while sudo kill -USR1 `pidof dd` ; do sleep 10 ; done
 
# Retourner dans le 1er terminal pour voir la progression
# On voir que formater plusieurs tera de cette façon peut prendre pas mal de temps... 
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer Tensorflow 2 sur Ubuntu 18.04 et un GPU Nvidia GTX 1080</title>
            <link>https://leandeep.com/installer-tensorflow-2-sur-ubuntu-18.04-et-un-gpu-nvidia-gtx-1080/</link>
            <pubDate>Wed, 25 Sep 2019 22:39:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-tensorflow-2-sur-ubuntu-18.04-et-un-gpu-nvidia-gtx-1080/</guid>
            <description>Introduction Voici la procédure permettant d&#39;installer Tensorflow 2 (RC2) sur Ubuntu 18.04 avec une carte graphique Nvidia GTX 1080 dans un eGPU Razer.
 Installation  Avant de démarrer je conseille de faire un backup de votre machine. On n&#39;est jamais trop prudent avec l&#39;installation des Drivers. Cela prend 1 minutes et en cas de problème, vous pourrez faire un rollback en 2 minutes.
  Créer un snapshot:
# Installation de Timeshift sudo apt-add-repository -y ppa:teejee2008/ppa &amp;amp;&amp;amp; sudo apt-get update &amp;amp;&amp;amp; sudo apt-get install timeshift # Créer un snapshot # sudo timeshift --create --comments &amp;quot;before cuda installation&amp;quot; --tags D # Voir les snapshots sudo timeshift --list # Restaurer un snapshot # sudo timeshift --restore  Pour démarrer Timeshift en mode graphique, il suffit d&#39;exécuter la commande sudo timeshift-gtk.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Voici la procédure permettant d'installer Tensorflow 2 (RC2) sur Ubuntu 18.04 avec une carte graphique Nvidia GTX 1080 dans un eGPU Razer.</p>
<br/>
<h2 id="installation">Installation</h2>
<blockquote>
<p>Avant de démarrer je conseille de faire un backup de votre machine. On n'est jamais trop prudent avec l'installation des Drivers. Cela prend 1 minutes et en cas de problème, vous pourrez faire un rollback en 2 minutes.</p>
</blockquote>
<br/>
<p>Créer un snapshot:</p>
<pre><code># Installation de Timeshift
sudo apt-add-repository -y ppa:teejee2008/ppa &amp;&amp; sudo apt-get update &amp;&amp; sudo apt-get install timeshift
# Créer un snapshot 
# sudo timeshift --create --comments &quot;before cuda installation&quot; --tags D
# Voir les snapshots
sudo timeshift --list
# Restaurer un snapshot 
# sudo timeshift --restore
</code></pre><blockquote>
<p>Pour démarrer Timeshift en mode graphique, il suffit d'exécuter la commande <code>sudo timeshift-gtk</code>. Timeshift est un bon outil mais ne permet pas les raids en backup destination. Je vais donc personnellement en recherche d'une alternative&hellip;</p>
</blockquote>
<br/>
<p>Installer le Driver Nvidia:</p>
<pre><code># Ajouter le repository Nvidia
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb
# Ajouter le repository Cuda
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub
# Ajouter le repository Nvidia Machine-Learning
wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
sudo apt install ./nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb
# Mise à jour de la liste des paquets avec les nouveaux repo
sudo apt-get update

# Installation du driver NVIDIA
sudo apt-get install --no-install-recommends nvidia-driver-418
</code></pre><p>Redémarrer votre machine.</p>
<br/>
<p>Activer le boitier eGPU branché au câble thunderbolt sur Ubuntu:</p>
<pre><code>lspci | grep -i nvidia
# Si rien ne s'affiche alors que votre boitier eGPU est bien branché à votre PC, c'est sans doute que le port Thunderbolt n'est pas autorisé à être utilisé. Pour ce faire:
sudo sh -c 'echo 1 &gt; /sys/bus/thunderbolt/devices/0-3/authorized'
# Dans mon cas j'ai exécuté les commandes suivantes:
# sudo sh -c 'echo 1 &gt; /sys/bus/thunderbolt/devices/0-0/authorized'
# sudo sh -c 'echo 1 &gt; /sys/bus/thunderbolt/devices/0-1/authorized'

lspci | grep -i nvidia
# Si le thunderbolt est bien activé et que les drivers sont bien pris en compte, vous devriez voir ceci:

06:00.0 VGA compatible controller: NVIDIA Corporation GP104 [GeForce GTX 1080] (rev a1)
06:00.1 Audio device: NVIDIA Corporation GP104 High Definition Audio Controller (rev a1)
</code></pre><p>Vérifier maintenant que le GPU est bien visible via la commande <code>nvidia-smi</code>.</p>
<br/>
<p>Installer les librairies de développement et d'exécution de cuda (~4GB)</p>
<pre><code>sudo apt-get install --no-install-recommends \
    cuda-10-0 \
    libcudnn7=7.6.2.24-1+cuda10.0  \
    libcudnn7-dev=7.6.2.24-1+cuda10.0
</code></pre><br/>
<p>Installer TensorRT. (libcudnn7 au-dessus doit être installé)</p>
<pre><code>sudo apt-get install -y --no-install-recommends libnvinfer5=5.1.5-1+cuda10.0 \
    libnvinfer-dev=5.1.5-1+cuda10.0
</code></pre><br/>
<p>Installer virtualenvwrapper:</p>
<pre><code>sudo apt install python python-pip python3
sudo pip uninstall virtualenvwrapper
</code></pre><br/>
<p>Ajouter les lignes suivantes dans votre <code>~/.zshrc</code>:</p>
<pre><code>export WORKON_HOME=~/.virtualenvs
source /usr/local/bin/virtualenvwrapper.sh
</code></pre><br/>
<p>Reloader votre shell:</p>
<pre><code>source ~/.zshrc
</code></pre><br/>
<p>Créer un virtualenv:</p>
<pre><code>mkvirtualenv -p /usr/bin/python3 -a . test_env
</code></pre><br/>
<p>Installation de Tensorflow GPU</p>
<pre><code>pip install tensorflow-gpu==2.0.0rc2
</code></pre><br/>
<p>Vérifier le bon fonctionnement de Tensorflow 2 en entrant le code suivant de votre Terminal ou dans Jupyter lab:</p>
<pre><code>python
&gt;&gt;&gt; import tensorflow
&gt;&gt;&gt; from tensorflow.python.client import device_lib
&gt;&gt;&gt; print(device_lib.list_local_devices())

[name: &quot;/device:CPU:0&quot;
device_type: &quot;CPU&quot;
memory_limit: 268435456
locality {
}
incarnation: 9076345463573208199
, name: &quot;/device:XLA_CPU:0&quot;
device_type: &quot;XLA_CPU&quot;
memory_limit: 17179869184
locality {
}
incarnation: 5504146488139860193
physical_device_desc: &quot;device: XLA_CPU device&quot;
, name: &quot;/device:XLA_GPU:0&quot;
device_type: &quot;XLA_GPU&quot;
memory_limit: 17179869184
locality {
}
incarnation: 18444695170601526018
physical_device_desc: &quot;device: XLA_GPU device&quot;
, name: &quot;/device:GPU:0&quot;
device_type: &quot;GPU&quot;
memory_limit: 7975714816
locality {
  bus_id: 1
  links {
  }
}
incarnation: 3513023963840157056
physical_device_desc: &quot;device: 0, name: GeForce GTX 1080, pci bus id: 0000:06:00.0, compute capability: 6.1&quot;
]
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Synchroniser votre DNS avec des IP dynamiques</title>
            <link>https://leandeep.com/synchroniser-votre-dns-avec-des-ip-dynamiques/</link>
            <pubDate>Tue, 17 Sep 2019 17:39:19 +0000</pubDate>
            
            <guid>https://leandeep.com/synchroniser-votre-dns-avec-des-ip-dynamiques/</guid>
            <description>J&#39;ai créé une petite image Docker permettant de mettre à jour l&#39;IP publique de son instance sur Cloudflare. Même s&#39;il existe des Elastic IP (EIP), cela peut parfois être utile de ne pas les utiliser si votre instance est presque tout le temps éteinte. Comme on ne paye les EIP que lorsqu&#39;elles ne sont pas attachées à des instances qui tournent cela peut faire grimper la facture inutilement; surtout quand on a pas mal d&#39;instances dans cet état.</description>
            <content type="html"><![CDATA[<p>J'ai créé une petite image Docker permettant de mettre à jour l'IP publique de son instance sur Cloudflare.
Même s'il existe des Elastic IP (EIP), cela peut parfois être utile de ne pas les utiliser si votre instance est presque tout le temps éteinte. Comme on ne paye les EIP que lorsqu'elles ne sont pas attachées à des instances qui tournent cela peut faire grimper la facture inutilement; surtout quand on a pas mal d'instances dans cet état.</p>
<p>Bref avec l'image Docker suivante <code>docker pull oeeckhoutte/cloudflare-dns</code> vous pouvez si vous avez un startup script toujours avoir accès à votre instance via votre DNS chez cloudflare.</p>
<p>Le code source est accessible sur Github à <a href="https://github.com/oeeckhoutte/cloudflare-dns-update-server-startup">l'adresse suivante</a>.</p>
<p>Si éventuellement vous avez besoin d'un startup script je vous renvoie <a href="https://leandeep.com/cr%C3%A9er-un-script-qui-se-lance-au-d%C3%A9marrage-de-centos-7/">sur un précédent article que j'avais écrit</a>.</p>
<p>Pour utiliser cette image il suffit d'exécuter la commande suivante:</p>
<pre><code>docker run --rm -e CF_API_KEY='0000000000000000000000000000000000000' -e CF_API_EMAIL='your.email@domain.com' -e DNS_TO_UPDATE='your_dns_or_subdns' -it cloudflare-dns
</code></pre><p>Have fun.</p>
]]></content>
        </item>
        
        <item>
            <title>Créer une VM de dev Windows avec Vagrant</title>
            <link>https://leandeep.com/cr%C3%A9er-une-vm-de-dev-windows-avec-vagrant/</link>
            <pubDate>Mon, 16 Sep 2019 12:56:00 +0000</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-une-vm-de-dev-windows-avec-vagrant/</guid>
            <description>Introduction Dans cet article nous allons voir comment installer en quelques secondes une VM Windows 10 de développement. Cet article fait suite à un premier que j&#39;avais écrit mais pour Windows: https://leandeep.com/creer-une-vm-de-dev-pour-ansible-avec-vagrant/ . L&#39;idée est d&#39;avoir une VM de test pour réaliser 2 ou 3 tâches de dev et de la détruire une fois que c&#39;est terminé.
 Marketplace Chercher une box Windows sur la marketplace de Vagrant.
https://app.vagrantup.com/boxes/search?utf8=%E2%9C%93&amp;amp;sort=downloads&amp;amp;provider=&amp;amp;q=windows
 Attention à ce que vous trouvez sur la Marketplace.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article nous allons voir comment installer en quelques secondes une VM Windows 10 de développement. Cet article fait suite à un premier que j'avais écrit mais pour Windows: <a href="https://leandeep.com/creer-une-vm-de-dev-pour-ansible-avec-vagrant/">https://leandeep.com/creer-une-vm-de-dev-pour-ansible-avec-vagrant/</a> . L'idée est d'avoir une VM de test pour réaliser 2 ou 3 tâches de dev et de la détruire une fois que c'est terminé.</p>
<br/>
<h2 id="marketplace">Marketplace</h2>
<p>Chercher une box Windows sur la marketplace de Vagrant.</p>
<p><a href="https://app.vagrantup.com/boxes/search?utf8=%E2%9C%93&amp;sort=downloads&amp;provider=&amp;q=windows">https://app.vagrantup.com/boxes/search?utf8=%E2%9C%93&amp;sort=downloads&amp;provider=&amp;q=windows</a></p>
<blockquote>
<p>Attention à ce que vous trouvez sur la Marketplace. Les box que vous téléchargez peuvent contenir des virus ou autres codes malveillants. Idem pour les images Docker que vous trouvez sur le net ou sur Dockerhub&hellip;</p>
</blockquote>
<br/>
<h2 id="pr-requis">Pré-requis:</h2>
<ul>
<li>Vagrant installé</li>
<li>Virtualbox installé</li>
</ul>
<br/>
<h2 id="cration-de-la-vm">Création de la VM</h2>
<p>Dans un répertoire de développement, créer un fichier appelé <code>Vagrantfile</code> et insérer le contenu suivant:</p>
<pre><code>Vagrant.configure(&quot;2&quot;) do |config|
  config.vm.box = &quot;vdelarosa/windows-10&quot;
end
</code></pre><p>Executez la commande <code>vagrant up</code> et voilà la VM que vous avez trouvé sur la Marketplace va se provisioner et se lancer automatiquement. Il vous faudra une bonne connexion internet car les VMs Windows sont tout sauf légères.</p>
<blockquote>
<p>Pour vous connecter à la VM Windows les crédentials par défaut sont les suivants: <code>vagrant / vagrant</code>. <strong>Attention au clavier en qwerty ;)</strong></p>
</blockquote>
<br/>
<h2 id="clean-boxes">Clean boxes</h2>
<p>Cela peut être utile d'effacer les boxes téléchargées pour faire de l'espace sur votre poste.</p>
<pre><code>vagrant box list
vagrant box remove -f [name]
</code></pre><p>Si cela ne fonctionne pas, tout ce qui est téléchargé lors du provisioning va dans ce répertoire: <code>~/.vagrant.d/boxes</code> (sur Mac)&hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Démarrer simplement des services systemd sur Docker et Centos 7</title>
            <link>https://leandeep.com/d%C3%A9marrer-simplement-des-services-systemd-sur-docker-et-centos-7/</link>
            <pubDate>Sun, 15 Sep 2019 19:33:17 +0000</pubDate>
            
            <guid>https://leandeep.com/d%C3%A9marrer-simplement-des-services-systemd-sur-docker-et-centos-7/</guid>
            <description>Cet article rapide explique comment faire un workaround lorsqu&#39;on essaye de faire un systemctl status un_service dans un container Docker sur Centos (ou Ubuntu) avec Docker 19.03. Sans ce workaround on obtient l&#39;erreur suivante Failed to get D-Bus connection: Operation not permitted.
Créer une image docker basée sur Centos 7:
# This shows systemd services (nginx and named) running in a centos7 container. # There have been lots of problems and workarounds for this, see: # https://hub.</description>
            <content type="html"><![CDATA[<p>Cet article rapide explique comment faire un <em>workaround</em> lorsqu'on essaye de faire un <code>systemctl status un_service</code> dans un container Docker sur Centos (ou Ubuntu) avec Docker 19.03. Sans ce <em>workaround</em> on obtient l'erreur suivante <code>Failed to get D-Bus connection: Operation not permitted</code>.</p>
<p>Créer une image docker basée sur Centos 7:</p>
<pre><code># This shows systemd services (nginx and named) running in a centos7 container.
# There have been lots of problems and workarounds for this, see:
# https://hub.docker.com/_/centos/
# https://github.com/docker/docker/issues/7459

FROM centos:centos7

RUN yum install -y epel-release # for nginx
RUN yum install -y initscripts  # for old &quot;service&quot;

ENV container=docker

RUN (cd /lib/systemd/system/sysinit.target.wants/; for i in *; do [ $i == systemd-tmpfiles-setup.service ] || rm -f $i; done); \
rm -f /lib/systemd/system/multi-user.target.wants/*;\
rm -f /etc/systemd/system/*.wants/*;\
rm -f /lib/systemd/system/local-fs.target.wants/*; \
rm -f /lib/systemd/system/sockets.target.wants/*udev*; \
rm -f /lib/systemd/system/sockets.target.wants/*initctl*; \
rm -f /lib/systemd/system/basic.target.wants/*;\
rm -f /lib/systemd/system/anaconda.target.wants/*;

# named (dns server) service
RUN yum install -y bind bind-utils
RUN systemctl enable named.service 

# Unrelated to systemd, but Apacehe httpd install fails at least if docker uses
# (default) aufs.
#   Error unpacking rpm package httpd-2.4.6-40.el7.centos.x86_64
#   error: unpacking of archive failed on file /usr/sbin/suexec: cpio: cap_set_file
#RUN yum install -y httpd

# webserver service
RUN yum install -y nginx
RUN systemctl enable nginx.service

# Without this, init won't start the enabled services and exec'ing and starting
# them reports &quot;Failed to get D-Bus connection: Operation not permitted&quot;.
VOLUME /run /tmp

# Don't know if it's possible to run services without starting this
CMD /usr/sbin/init
</code></pre><p>Maintenant on crée un docker-compose.yml:</p>
<pre><code>version: '3'
services:
  test:
    build:
      context: .
    cap_add:
      - SYS_ADMIN
    security_opt:
      - seccomp:unconfined
    volumes:
      - /sys/fs/cgroup:/sys/fs/cgroup:ro
    ports:
      - &quot;80:80&quot;
      # The DNS server works within container (dig @localhost example.com), but
      # *not* via published port. Not sure this is related to systemd.
      #- &quot;53:53/tcp&quot;
      #- &quot;53:53/udp&quot;
      
</code></pre><p>Et voilà. Buildez et démarrez votre container :</p>
<pre><code>docker-compose build &amp;&amp; docker-compose down &amp;&amp; docker-compose up -d
</code></pre><p>Connectez vous à votre container et essayez de voir le status d'un service:</p>
<pre><code>docker ps # pour récupérer son id
# Puis 
docker exec -it ID_DU_CONTAINER /bin/bash
systemctl status nginx
</code></pre><p>Cela va fonctionner ;) &hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Créer un script qui se lance au démarrage de Centos 7</title>
            <link>https://leandeep.com/cr%C3%A9er-un-script-qui-se-lance-au-d%C3%A9marrage-de-centos-7/</link>
            <pubDate>Tue, 10 Sep 2019 18:10:11 +0000</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-un-script-qui-se-lance-au-d%C3%A9marrage-de-centos-7/</guid>
            <description>Introduction Dans cet article, nous allons voir comment créer un service systemd qui va s&#39;exécuter automatiquement au démarrage d&#39;une machine. L&#39;IP de ma machine étant renouvelée à chaque redémarrage, je me sers de ce type de service pour mettre à jour automatiquement l&#39;IP publique sur un de mes DNS.
Steps Créer un fichier /var/tmp/boot_script.sh qui contient le code suivant:
#!/bin/bash echo &amp;quot;Boot script sample&amp;quot; &amp;gt; /var/log/boot_script.log echo &amp;quot;Started at `date`&amp;quot; &amp;gt;&amp;gt; /var/log/boot_script.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article, nous allons voir comment créer un service systemd qui va s'exécuter automatiquement au démarrage d'une machine. L'IP de ma machine étant renouvelée à chaque redémarrage, je me sers de ce type de service pour mettre à jour automatiquement l'IP publique sur un de mes DNS.</p>
<h2 id="steps">Steps</h2>
<p>Créer un fichier <code>/var/tmp/boot_script.sh</code> qui contient le code suivant:</p>
<pre><code>#!/bin/bash
echo &quot;Boot script sample&quot; &gt; /var/log/boot_script.log
echo &quot;Started at `date`&quot; &gt;&gt; /var/log/boot_script.log
</code></pre><p>Donner au script des droits d'exécution:</p>
<pre><code>chmod +x /var/tmp/boot_script.sh
</code></pre><p>Créer une nouveau service systemd. Pour ce faire créer un fichier dans le répertoire <code>/etc/systemd/system/</code> et appelé le <code>boot_script.service</code> par exemple. Insérer le contenu suivant dans votre nouveau fichier:</p>
<pre><code>[Unit]
Description=Description de ce que fait le script ici
After=network.target

[Service]
Type=simple
ExecStart=/var/tmp/boot_script.sh
TimeoutStartSec=0

[Install]
WantedBy=default.target
</code></pre><p>Reloader le process systemd pour que notre nouveau service soit pris en compte:</p>
<pre><code>systemctl daemon-reload
</code></pre><blockquote>
<p>Si vous modifiez ce service, il vous faudra également reloader systemd/</p>
</blockquote>
<p>&ldquo;Activer&rdquo; le service pour qu'il se lance automatiquement au démarrage de la machine:</p>
<pre><code>systemctl enable boot_script.service
</code></pre><p>Démarrer le service:</p>
<pre><code>systemctl start boot_script.service
</code></pre><p>Redémarrer votre machine pour vérifier que tout fonctionne bien.</p>
<pre><code>systemctl reboot
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Get rid of .pem file to SSH on your AWS EC2 instance</title>
            <link>https://leandeep.com/get-rid-of-.pem-file-to-ssh-on-your-aws-ec2-instance/</link>
            <pubDate>Fri, 06 Sep 2019 11:39:00 +0000</pubDate>
            
            <guid>https://leandeep.com/get-rid-of-.pem-file-to-ssh-on-your-aws-ec2-instance/</guid>
            <description>Let&#39;s say you want to setup a Gitlab server on AWS and you need to do a git clone using SSH protocol. You will be annoyed by the .pem file. To get rid of it (or more simply hide it) you can follow this procedure:
The pem file contains a private key. Simply extract it and add it to your system.
Copy the private key to the .ssh folder
cp /path/to/your/cert.</description>
            <content type="html"><![CDATA[<p>Let's say you want to setup a Gitlab server on AWS and you need to do a <code>git clone</code> using <code>SSH</code> protocol. You will be annoyed by the <code>.pem</code> file. To get rid of it (or more simply hide it) you can follow this procedure:</p>
<p>The pem file contains a private key. Simply extract it and add it to your system.</p>
<p><strong>Copy the private key to the .ssh folder</strong></p>
<pre><code>cp /path/to/your/cert.pem ~/.ssh/id_rsa_gitlab_ec2
</code></pre><br/>
<p><strong>Generate a public key from the .pem file</strong></p>
<pre><code>ssh-keygen -y -f /path/to/your/cert.pem &gt; ~/.ssh/id_rsa_gitlab_ec2.pub
</code></pre><br/>
<p><strong>Change private key file rights</strong></p>
<pre><code>chmod 600 ~/.ssh/id_rsa_gitlab_ec2
</code></pre><br/>
<p><strong>Add the private key to ssh-agent</strong></p>
<pre><code># Start ssh-agent
eval &quot;$(ssh-agent -s)&quot;

# Add your newly created key to the agent
ssh-add ~/.ssh/id_rsa_gitlab_ec2
</code></pre><br/>
<p><strong>Now try to connect to you EC2 instance via SSH</strong></p>
<pre><code>ssh your_user@ec2-ip......amazonaws.com
</code></pre><p>Try to <code>git clone ...</code>. All good !</p>
]]></content>
        </item>
        
        <item>
            <title>Installer en 30 secondes un bon vieux FTP sur Ubuntu</title>
            <link>https://leandeep.com/installer-en-30-secondes-un-bon-vieux-ftp-sur-ubuntu/</link>
            <pubDate>Fri, 06 Sep 2019 10:44:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-en-30-secondes-un-bon-vieux-ftp-sur-ubuntu/</guid>
            <description>Introduction Besoin de transférer des fichiers entre un Linux et Windows ? Problème, docker ne peut pas être installé sur Windows (à cause d&#39;un processeur non compatible), cygwin gère mal le rsync, impossible d&#39;écrire un shell script pour reprendre le téléchargement interrompu, le scp de Powershell fini par crasher tellement la quantité de données à transférer est énorme. Rien de tel qu&#39;un bon vieux serveur FTP :D . Voici les commandes pour en installer un en 30s top chrono.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Besoin de transférer des fichiers entre un Linux et Windows ? Problème, docker ne peut pas être installé sur Windows (à cause d'un processeur non compatible), cygwin gère mal le rsync, impossible d'écrire un shell script pour reprendre le téléchargement interrompu, le scp de Powershell fini par crasher tellement la quantité de données à transférer est énorme. Rien de tel qu'un bon vieux serveur FTP :D . Voici les commandes pour en installer un en 30s top chrono.</p>
<br/>
<h2 id="installation">Installation</h2>
<pre><code>sudo aptitude install vsftpd
</code></pre><p>Editer le fichier <code>/etc/vsftpd.conf</code> et modifier la configuration avec les paramètres suivants:</p>
<pre><code>anonymous_enable=NO
local_enable=YES
write_enable=YES
</code></pre><p>Et redémarrer le service pour prendre en compte les modifications.</p>
<pre><code>sudo /etc/init.d/vsftpd restart
</code></pre><br/>
<h2 id="usage">Usage</h2>
<p>Via GUI avec le logiciel Filezilla <a href="https://filezilla-project.org/">https://filezilla-project.org/</a></p>
]]></content>
        </item>
        
        <item>
            <title>[NLP] 2 manières de générer des N-grams en Python </title>
            <link>https://leandeep.com/nlp-2-mani%C3%A8res-de-g%C3%A9n%C3%A9rer-des-n-grams-en-python/</link>
            <pubDate>Tue, 03 Sep 2019 07:48:00 +0000</pubDate>
            
            <guid>https://leandeep.com/nlp-2-mani%C3%A8res-de-g%C3%A9n%C3%A9rer-des-n-grams-en-python/</guid>
            <description>Introduction Dans une phrase, les N-grams sont des séquences de N-mots adjacents. N peut être 1 ou 2 ou toute autre entier positif. En général N n&#39;est pas très grand car ces N-grams apparaissent rarement plusieurs fois.
On utilise ces N-grams en Machine Learning dans les sujets qui traitent du Natural Language Processing. Plus précisément, on les retrouve dans les sujets de classification de textes. On peut utiliser des bi-grams ou tri-grams comme features pour représenter nos documents en plus d&#39;utiliser des tokens individuels trouvés dans le corpus.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans une phrase, les N-grams sont des séquences de N-mots adjacents. N peut être 1 ou 2 ou toute autre entier positif. En général N n'est pas très grand car ces N-grams apparaissent rarement plusieurs fois.</p>
<p>On utilise ces N-grams en Machine Learning dans les sujets qui traitent du Natural Language Processing. Plus précisément, on les retrouve dans les sujets de classification de textes. On peut utiliser des bi-grams ou tri-grams comme <em>features</em> pour représenter nos documents en plus d'utiliser des tokens individuels trouvés dans le corpus.</p>
<p>Dans cet article, nous allons voir comment générer en Python des N-grams à partir de phrases en entrée.</p>
<br/>
<h2 id="n-grams-en-pur-python">N-grams en pur Python</h2>
<p>Partons de la phrase suivante et transformons la en N-grams:</p>
<pre><code>s = &quot;On utilise ces N-grams en Machine Learning dans les sujets qui traitent du Natural Language &quot; \ 
    &quot;Processing et en particulier dans les sujets de classification de textes.&quot;
</code></pre><p>Si on transforme cette phrase en bi-grams on va obtenir l'output suivant:</p>
<pre><code>[
    &quot;On utilise&quot;,
    &quot;utilise ces&quot;,
    &quot;ces n&quot;,
    &quot;n grams&quot;,
    &quot;grams en&quot;,
	...
]
</code></pre><p>Pour obtenir le résultat précédent, on peut utiliser le code Python suivant:</p>
<pre><code>import re

def generate_ngrams(s, n):
    # Convert to lowercases
    s = s.lower()
    
    # Replace all non-alphanumeric characters with spaces
    s = re.sub(r'[^a-zA-Z0-9\s]', ' ', s)
    
    # Break sentence in the token, remove empty tokens
    tokens = [token for token in s.split(&quot; &quot;) if token != &quot;&quot;]
    
    # Use the zip function to help us generate n-grams
    # Concatentate the tokens into ngrams and return
    ngrams = zip(*[token[i:] for i in range(n)])
    return [&quot; &quot;.join(ngram) for ngram in ngrams]
</code></pre><p>Si on applique la fonction suivante sur notre phrase d'entrée avec N=4, on obtient le résultat suivant:</p>
<pre><code>&gt;&gt;&gt; generate_ngrams(s, n=4)
['on utilise ces n', 'utilise ces n grams', 'ces n grams en', 'n grams en machine', 'grams en machine learning', 'en machine learning dans', 'machine learning dans les', 'learning dans les sujets', 'dans les sujets qui', 'les sujets qui traitent', 'sujets qui traitent du', 'qui traitent du natural', 'traitent du natural language', 'du natural language processing', 'natural language processing et', 'language processing et en', 'processing et en particulier', 'et en particulier dans', 'en particulier dans les', 'particulier dans les sujets', 'dans les sujets de', 'les sujets de classification', 'sujets de classification de', 'de classification de textes']
</code></pre><p>La fonction précédente utilise la fonction <code>zip</code> qui crée un <em>generator</em> qui aggrége les éléments de plusieurs listes.</p>
<p>Plus de détails dans la section de code commentée:</p>
<pre><code># phrase d'entrée
s = &quot;un deux trois quatre cinq&quot;

tokens = s.split(&quot; &quot;)
# tokens = [&quot;un&quot;, &quot;deux&quot;, &quot;trois&quot;, &quot;quatre&quot;, &quot;cinq&quot;]

sequences = [tokens[i:] for i in range(3)]
# Cette ligne génère des séquences depuis différents éléments de la liste tokens
range(x) définit combien de séquences on veut générer
#
# sequences = [
#   ['un', 'deux', 'trois', 'quatre', 'cinq'],
#   ['deux', 'trois', 'quatre', 'cinq'],
#   ['trois', 'quatre', 'cinq']]

bigrams = zip(*sequences)
# La fonction zip prend les 3 séquences comme une liste d'input grâce à l'opérateur *. 
# Pour info, cette syntaxe revient au même que zip(sequences[0], sequences[1], sequences[2]).
# Chaquee tuple que cette fonction zip retourne contient un élément de chaque séquence.
# Comme il n'y a que 3 éléments dans la dernières séquence, il n'y a que 3 tuples retournés par la fonction zip
</code></pre><br/>
<h2 id="n-grams-avec-nltk">N-grams avec NLTK</h2>
<p>Au lieu d'utiliser la méthode précédente pour générer des N-grams, on peut se simplifier la vie en utilisant la librairie <code>NLTK (Natural Language Toolkit)</code> spécialisée comme son nom l'indique dans le NLP.</p>
<p>Avec le code suivant, on peut générer des N-grams, tout comme on l'a fait avec la méthode <code>generate_ngrams()</code>.</p>
<pre><code>import re
from nltk.util import ngrams

s = s.lower()
s = re.sub(r'[^a-zA-Z0-9\s]', ' ', s)
tokens = [token for token in s.split(&quot; &quot;) if token != &quot;&quot;]
output = list(ngrams(tokens, 5))
</code></pre><blockquote>
<p>Si vous rencontrez l'erreur suivante avec NLTK <code>CERTIFICATE_VERIFY_FAILED] certificate verify failed:</code>, voici les commandes Python à exécuter comme workaround:</p>
</blockquote>
<pre><code>import nltk
import ssl

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    ssl._create_default_https_context = _create_unverified_https_context

# nltk.download('stopwords')
nltk.download('...')
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer Gitlab CE avec un runner sur Centos 7 sur AWS</title>
            <link>https://leandeep.com/installer-gitlab-ce-avec-un-runner-sur-centos-7-sur-aws/</link>
            <pubDate>Mon, 02 Sep 2019 21:21:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-gitlab-ce-avec-un-runner-sur-centos-7-sur-aws/</guid>
            <description>Dans cet article nous allons voir comment installer et configurer Gitlab CE pour construire des pipelines automatiques CICD.
 Installation de Gitlab CE yum update yum -y install curl vim policycoreutils openssh-server openssh-clients postfix # Vérifiez que Firewalld n&#39;est pas démarré sans quoi il faudra le configurer ou le désactiver si vous utilisez les *security groups* d&#39;AWS par exemple systemctl status firewalld # Vérifiez que les services sont bien démarrés systemctl status sshd systemctl status postfix # Installer le repository pour Gitlab curl -sS https://packages.</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons voir comment installer et configurer Gitlab CE pour construire des pipelines automatiques CICD.</p>
<br/>
<h2 id="installation-de-gitlab-ce">Installation de Gitlab CE</h2>
<pre><code>yum update

yum -y install curl vim policycoreutils openssh-server openssh-clients postfix

# Vérifiez que Firewalld n'est pas démarré sans quoi il faudra le configurer ou le désactiver si vous utilisez les *security groups* d'AWS par exemple
systemctl status firewalld

# Vérifiez que les services sont bien démarrés
systemctl status sshd
systemctl status postfix

# Installer le repository pour Gitlab
curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.rpm.sh | sudo bash

# Installer Gitlab
yum -y install gitlab-ce

</code></pre><br/>
<h2 id="configuration-du-dns-en-https">Configuration du DNS en HTTPS</h2>
<p>Gitlab est maintenant installé. Pour configurer un DNS et du HTTPS, voici ce qu'il faut modifier dans le fichier <code>/etc/gitlab/gitlab.rb</code>.</p>
<pre><code>external_url 'https://gitlab.votre_domaine.com'

letsencrypt['enable'] = true
letsencrypt['contact_emails'] = ['votre_adresse_email@votre_domaine.com']
letsencrypt['auto_renew'] = true
letsencrypt['auto_renew_hour'] = 0
</code></pre><p>Une fois ce fichire modifié il faut reconfigurer Gitlab pour que les modifications soient prises en compte avec la commande <code>gitlab-ctl reconfigure</code>.</p>
<p>Rendez-vous à l'adresse DNS que vous avez spécifié en HTTPS pour voir le Gitlab up and running.</p>
<p>Redémarrer la machine pour être certain que tout est bien installé et que Gitlab se lance bien au startup.</p>
<br/>
<h2 id="installation-du-ci">Installation du CI</h2>
<pre><code>curl -L --output /usr/local/bin/gitlab-runner https://gitlab-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-runner-linux-amd64

useradd --comment 'GitLab Runner' --create-home gitlab-runner --shell /bin/bash

gitlab-runner install --user=gitlab-runner --working-directory=/home/gitlab-runner

/usr/local/bin/gitlab-runner register
# Suivez les instructions. Elles sont très simples
</code></pre><p>Et voilà. Vous avez maintenant un runner pour votre pipeline CICD.</p>
<p>Rendez-vous maintenant sur le DNS de votre Gitlab, commencez par renseigner un mot de passe superadmin et rendez-vous dans les settings pour voir le nouveau runner enregistré.</p>
<br/>
<h2 id="synchroniser-gitlab-avec-dautre-git-providers">Synchroniser Gitlab avec d'autre Git providers</h2>
<p>J'ai suivi la documentation de cet article et j'ai pu brancher d'autres Git provider (i.e Github ou Bitbucket) à mon Gitlab: <a href="https://docs.gitlab.com/ee/integration/bitbucket.html">https://docs.gitlab.com/ee/integration/bitbucket.html</a></p>
]]></content>
        </item>
        
        <item>
            <title>Installer Docker comme service sur Centos 7 ou Ubuntu 18.04</title>
            <link>https://leandeep.com/installer-docker-comme-service-sur-centos-7-ou-ubuntu-18.04/</link>
            <pubDate>Sat, 31 Aug 2019 12:34:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-docker-comme-service-sur-centos-7-ou-ubuntu-18.04/</guid>
            <description>Voici une procédure simple pour installer et activer le service Docker sur Centos 7 ou Ubuntu 18.04.
Installation Centos 7
Commencer par installer les pré-requis:
yum install -y yum-utils device-mapper-persistent-data lvm2 Ajouter ensuite le repository Docker à yum:
yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo Installer Docker:
yum install -y docker-ce docker-ce-cli containerd.io Démarrer le service Docker
systemctl start docker Activer le service au démarrage du système:
systemctl enable docker  Ubuntu 18.04
sudo apt update sudo apt install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://download.</description>
            <content type="html"><![CDATA[<p>Voici une procédure simple pour installer et activer le service Docker sur Centos 7 ou Ubuntu 18.04.</p>
<h2 id="installation">Installation</h2>
<p><strong>Centos 7</strong></p>
<p>Commencer par installer les pré-requis:</p>
<pre><code>yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre><p>Ajouter ensuite le repository Docker à yum:</p>
<pre><code>yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</code></pre><p>Installer Docker:</p>
<pre><code>yum install -y docker-ce docker-ce-cli containerd.io
</code></pre><p>Démarrer le service Docker</p>
<pre><code>systemctl start docker
</code></pre><p>Activer le service au démarrage du système:</p>
<pre><code>systemctl enable docker
</code></pre><br/>
<p><strong>Ubuntu 18.04</strong></p>
<pre><code>sudo apt update
sudo apt install apt-transport-https ca-certificates curl software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable&quot;
sudo apt update
apt-cache policy docker-ce
sudo apt install docker-ce
sudo systemctl status docker
</code></pre><br/>
<h2 id="configuration-des-droits">Configuration des droits</h2>
<p>Pour éviter de devoir toujours ajouter <code>sudo</code> devant vos commandes <code>docker</code> on peut changer les droits et ajouter votre utilisateur linux au groupe docker.</p>
<pre><code>sudo usermod -aG docker $USER
</code></pre><p>Rechargez votre terminal pour que les droits soient pris en compte.</p>
<blockquote>
<p>Si vous rencontrez ce problème <code>dial unix /var/run/docker.sock: connect: permission denied</code>, vous avez un problème de droit sur la socket docker.</p>
</blockquote>
<blockquote>
<p>Voici le fix: <code>sudo chown root:docker /var/run/docker.sock</code></p>
</blockquote>
<br/>
<h2 id="installation-de-docker-compose">Installation de docker-compose</h2>
<p>Télécharger le binaire et le placer dans <code>/usr/local/bin</code>:</p>
<pre><code>curl -L &quot;https://github.com/docker/compose/releases/download/1.23.1/docker-compose-$(uname -s)-$(uname -m)&quot; -o /usr/local/bin/docker-compose
</code></pre><p>On donne les droits d'exécution:</p>
<pre><code>  chmod +x /usr/local/bin/docker-compose
</code></pre><p>Vérification du bon fonctionnement:</p>
<pre><code>docker-compose --version
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Créer et activer une partition swap sur Centos 7</title>
            <link>https://leandeep.com/cr%C3%A9er-et-activer-une-partition-swap-sur-centos-7/</link>
            <pubDate>Fri, 30 Aug 2019 14:36:36 +0000</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-et-activer-une-partition-swap-sur-centos-7/</guid>
            <description>Dans cet article nous allons voir comment créer et activer une partition SWAP sur Centos 7 / Red Hat 7. Si vous avez oublié d&#39;en créer une lors de l&#39;installation d&#39;une VM sur AWS par exemple vous pouvez suivre cette procédure.
sudo dd if=/dev/zero of=/swapfile count=4096 bs=1MiB sudo chmod 600 /swapfile sudo mkswap /swapfile sudo swapon /swapfile Editer le fichier /etc/fstab et ajouter la ligne suivante pour que la partition soit montée de manière persistente.</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons voir comment créer et activer une partition SWAP sur Centos 7 / Red Hat 7. Si vous avez oublié d'en créer une lors de l'installation d'une VM sur AWS par exemple vous pouvez suivre cette procédure.</p>
<pre><code>sudo dd if=/dev/zero of=/swapfile count=4096 bs=1MiB
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
</code></pre><p>Editer le fichier <code>/etc/fstab</code> et ajouter la ligne suivante pour que la partition soit montée de manière persistente.</p>
<pre><code>/swapfile   swap    swap    sw  0   0
</code></pre><p>Puis exécutez la commande suivante:</p>
<pre><code>sudo sysctl vm.swappiness=10
</code></pre><p>Enfin éditez le fichier suivant <code>/etc/sysctl.conf</code> et ajoutez les lignes qui suivent:</p>
<pre><code>vm.swappiness = 10
vm.vfs_cache_pressure = 50
</code></pre><p>Pour vérifier la taille du swap vous pouvez utiliser les commandes qui suivent:</p>
<pre><code>swapon --summary
free -h
</code></pre><p>Redémarrez votre machine pour vérifier que la machine est bien opérationnelle et que la partition swap est bien toujours présente et active.</p>
]]></content>
        </item>
        
        <item>
            <title>Activer le mode avion sur Android via le terminal</title>
            <link>https://leandeep.com/activer-le-mode-avion-sur-android-via-le-terminal/</link>
            <pubDate>Sun, 25 Aug 2019 14:25:00 +0000</pubDate>
            
            <guid>https://leandeep.com/activer-le-mode-avion-sur-android-via-le-terminal/</guid>
            <description>Cet article très court décrit comment activer le mode avion sur un Smartphone Android via ADB (Android Debug Bridge). Pour ceux qui ne connaissent pas ADB, voici un lien vers le site officiel.
Avec les commandes suivantes on peut activer ou désactiver le mode avion:
# Activer le mode avion adb shell settings put global airplane_mode_on 1 # Désactiver le mode avion adb shell settings put global airplane_mode_on 0  Si vous avez besoin de broadcaster un intent aux applications du téléphone, c&#39;est possible via la commande adb shell am broadcast -a android.</description>
            <content type="html"><![CDATA[<p>Cet article très court décrit comment activer le mode avion sur un Smartphone Android via <code>ADB (Android Debug Bridge)</code>. Pour ceux qui ne connaissent pas ADB, <a href="https://developer.android.com/studio/command-line/adb">voici un lien vers le site officiel</a>.</p>
<p>Avec les commandes suivantes on peut activer ou désactiver le mode avion:</p>
<pre><code># Activer le mode avion
adb shell settings put global airplane_mode_on 1

# Désactiver le mode avion
adb shell settings put global airplane_mode_on 0
</code></pre><blockquote>
<p>Si vous avez besoin de broadcaster un intent aux applications du téléphone, c'est possible via la commande <code>adb shell am broadcast -a android.intent.action.AIRPLANE_MODE</code>.</p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Commandes utiles Kafka</title>
            <link>https://leandeep.com/commandes-utiles-kafka/</link>
            <pubDate>Sun, 18 Aug 2019 17:53:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-utiles-kafka/</guid>
            <description>Voici une liste de commandes utiles pour utiliser Kafka. Il y a pas mal de jargon dans Kafka, je vous renvoie à l&#39;article suivant qui explique pas mal de choses.
 Lister les groupes de consommateurs (Consumer Groups):
docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --list Décrire/ Obtenir des informations sur un Consumer Group:
docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --group id1 --describe Créer un topic:
docker exec -it wurstmeister/kafka sh -c &amp;quot;JMX_PORT=10001 /opt/kafka/bin/kafka-topics.</description>
            <content type="html"><![CDATA[<p>Voici une liste de commandes utiles pour utiliser Kafka.
Il y a pas mal de jargon dans Kafka, je vous renvoie <a href="https://blog.univalence.io/kafka-et-les-groupes-de-consommateurs/">à l'article suivant</a> qui explique pas mal de choses.</p>
<br/>
<p>Lister les groupes de consommateurs (Consumer Groups):</p>
<pre><code>docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --list
</code></pre><p>Décrire/ Obtenir des informations sur un Consumer Group:</p>
<pre><code>docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --group id1 --describe
</code></pre><p>Créer un topic:</p>
<pre><code>docker exec -it wurstmeister/kafka sh -c &quot;JMX_PORT=10001 /opt/kafka/bin/kafka-topics.sh --create --topic topic --replication-factor 1 --partitions 1 --zookeeper zookeeper:2181&quot;
</code></pre><p>Envoyer des messages:</p>
<pre><code>docker exec -it wurstmeister/kafka sh -c &quot;JMX_PORT=10001 /opt/kafka/bin/kafka-verifiable-producer.sh --topic topic --max-messages 200000 --broker-list localhost:9092&quot;
</code></pre><p>Consumer en mode console:</p>
<pre><code>docker exec -it wurstmeister/kafka sh -c &quot;JMX_PORT=10001 /opt/kafka/bin/kafka-console-consumer.sh --topic topic --bootstrap-server host:9092&quot;

docker run -it wurstmeister/kafka -c &quot;JMX_PORT=10001 /opt/kafka/bin/kafka-console-consumer.sh --topic topic --bootstrap-server host:9092&quot;

docker run --entrypoint=/opt/kafka/bin/kafka-console-consumer.sh wurstmeister/kafka --topic topic --bootstrap-server host:9092
</code></pre><p>Consumer en Python:</p>
<pre><code>#!/usr/bin/env python
from kafka import KafkaConsumer
consumer = KafkaConsumer(bootstrap_servers='kafka1:9092',
                         group_id=None,
                         auto_offset_reset='earliest')

consumer.subscribe(['logs-app1'])
for msg in consumer:
    print(msg)

</code></pre><p>Consumer Kafkacat:</p>
<pre><code>docker run -it confluentinc/cp-kafkacat kafkacat -b host:9092 -t topic -o beginning -v
</code></pre><p>Mettre de la rétention sur certains topics:</p>
<pre><code>docker exec -it kafka /opt/kafka/bin/kafka-configs.sh --zookeeper host:2181 --entity-type topics --entity-name topic --describe

docker exec -it kafka /opt/kafka/bin/kafka-topics.sh --zookeeper host:2181 --topic topic --describe

docker exec -it kafka /opt/kafka/bin/kafka-topics.sh --zookeeper host:2181 --topic topic --alter --config retention.ms=1000
</code></pre><p><a href="https://medium.com/walmartlabs/rendezvous-with-kafka-a-simple-guide-to-get-started-48db3b921cc">L'article suivant</a> parle des partitions et des offsets:</p>
<blockquote>
<p>In short:
When you commit an offset, it means that you read all the previous messages. So committing 7 means that next you won't read 6 and 5 but the new incoming message 8 sent by the producer.</p>
</blockquote>
<p>Offset au début:</p>
<pre><code>docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --topic topic --group id1 --reset-offsets --to-earliest --execute
</code></pre><p>Offset à la fin:</p>
<pre><code>docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --topic topic --group id1 --reset-offsets --to-latest --execute
</code></pre><p>Offset à un moment précis:</p>
<pre><code>docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --topic topic --group id1 --reset-offsets --to-datetime &quot;2017-12-22T00:00:00.000&quot; --execute
</code></pre><p>Offset à un moment précis pour les partitions 0, 1 (même datetime pour les 2 partitions)</p>
<pre><code>docker run wurstmeister/kafka /opt/kafka/bin/kafka-consumer-groups.sh --bootstrap-server kafka:9092 --topic topic:0,1 --group id1 --reset-offsets --to-datetime &quot;2017-12-22T00:00:00.000&quot; --execute
</code></pre><p>Offset à un moment précis pour les partitions 0, 1 (datetimes différents):</p>
<pre><code>docker run dddpaul/kafka-rewind --servers=kafka:9092 --group-id=id1 --topic=topic -o 0=2017-12-01 -o 1=2018-01-01
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Serverless sur AWS avec SAM</title>
            <link>https://leandeep.com/serverless-sur-aws-avec-sam/</link>
            <pubDate>Sat, 17 Aug 2019 16:51:00 +0000</pubDate>
            
            <guid>https://leandeep.com/serverless-sur-aws-avec-sam/</guid>
            <description>Si comme moi vous voulez installer AWS SAM pour développer et tester en local vos applications serverless voici la procédure à suivre:
 Prérequis  AWS Cli AWS Cli configuré Docker (dois-je le préciser ?) Python 3   Installation Créer un bucket S3:
aws s3 mb s3://votre-sam-bucket --region eu-west-1 Installer AWS SAM Cli:
 AWS recommande l&#39;utilisation de Homebrew pour l&#39;installation de SAM mais je préfère utiliser pip pour ne pas être contraint à passer de Python 3.</description>
            <content type="html"><![CDATA[<p>Si comme moi vous voulez installer AWS SAM pour développer et tester en local vos applications serverless voici la procédure à suivre:</p>
<br/>
<h2 id="prrequis">Prérequis</h2>
<ul>
<li>AWS Cli</li>
<li>AWS Cli configuré</li>
<li>Docker (dois-je le préciser ?)</li>
<li>Python 3</li>
</ul>
<br/>
<h2 id="installation">Installation</h2>
<p>Créer un bucket S3:</p>
<pre><code>aws s3 mb s3://votre-sam-bucket --region eu-west-1
</code></pre><p>Installer AWS SAM Cli:</p>
<blockquote>
<p>AWS recommande l'utilisation de Homebrew pour l'installation de SAM mais je préfère utiliser pip pour ne pas être contraint à passer de Python 3.6 à 3.7.</p>
</blockquote>
<pre><code>pip install aws-sam-cli
</code></pre><p>Vérifier que SAM est bien installé:</p>
<pre><code>sam --version

SAM CLI, version 0.19.0
</code></pre><br/>
<h2 id="premire-application">Première application</h2>
<p>Créer une application squelette qui aura la structure suivante:</p>
<pre><code>sam init --runtime python3.6

sam-app/
   ├── README.md
   ├── event.json
   ├── hello_world/
   │   ├── __init__.py
   │   ├── app.py            # Contains your AWS Lambda handler logic.
   │   └── requirements.txt  # Contains any Python dependencies the application requires, used for sam build
   ├── template.yaml         # Contains the AWS SAM template defining your application's AWS resources.
   └── tests/
       └── unit/
           ├── __init__.py
           └── test_handler.py

</code></pre><p>Builder l'application:</p>
<pre><code>cd sam-app
sam build
</code></pre><p>Une fois que l'application a été buildée on peut la packager et l'envoyer sur AWS ou la tester en local.</p>
<br/>
<p><strong>Option 1: Exécuter la fonction sur AWS</strong></p>
<p>Packager votre application:</p>
<pre><code>sam package --output-template packaged.yaml --s3-bucket votre-sam-bucket
</code></pre><p>Déployer votre application:</p>
<pre><code>sam deploy --template-file packaged.yaml --region eu-west-1 --capabilities CAPABILITY_IAM --stack-name aws-sam-getting-started
</code></pre><br/>
<p><strong>Option 2: Exécuter la fonction en local</strong></p>
<p>2 options s'offrent à nous pour tester notre fonction lambda en local. On peut simuler une API REST qui appelera notre fonction si le bon endpoint est appelé ou on peut directement invoquer la fonction lambda via le cli.</p>
<br/>
<p><strong>Option 2.1: Simuler une API REST</strong></p>
<p>Dans un premier terminal lancer l'API:</p>
<pre><code>sam local start-api
</code></pre><p>Puis dans un second terminal exécuter la commande suivante:</p>
<pre><code>curl http://127.0.0.1:3000/hello

{&quot;message&quot;: &quot;hello world&quot;}%
</code></pre><br/>
<p><strong>Option 2.2: Invoquer la fonction directement</strong>*</p>
<pre><code>sam local invoke &quot;HelloWorldFunction&quot; -e event.json

{&quot;statusCode&quot;: 200, &quot;body&quot;: &quot;{\&quot;message\&quot;: \&quot;hello world\&quot;}&quot;}
</code></pre><br/>
<h2 id="events">Events</h2>
<p>Il est possible de simuler ses events AWS. <a href="https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-cli-command-reference-sam-local-generate-event.html">L'article suivant</a> décrit comment faire.</p>
<p>Examples:</p>
<ul>
<li>Simuler un event S3:</li>
</ul>
<pre><code>sam local generate-event s3 [put/delete] --bucket &lt;bucket&gt; --key &lt;key&gt; &gt; s3-event.json
</code></pre><ul>
<li>Simuler un event sur AWS API Gateway:</li>
</ul>
<pre><code>sam local generate-event apigateway aws-proxy --body &quot;&quot; --path &quot;hello&quot; --method GET &gt; api-event.json
</code></pre><ul>
<li>Simuler un event SNS:</li>
</ul>
<pre><code>sam local generate-event sns notification --message \&quot;$(cat event.json)\&quot; | sam local invoke MyAwesomeLambda

# contenu de event.json:
{
  &quot;foo&quot;: &quot;bar&quot;
}
</code></pre><ul>
<li>Simuler un event et invoquer directement la lambda:</li>
</ul>
<pre><code>sam local generate-event s3 [put/delete] --bucket &lt;bucket&gt; --key &lt;key&gt; | sam local invoke &lt;function logical id&gt;
</code></pre><br/>
<h2 id="exemples-dapplications-sam">Exemples d'applications SAM</h2>
<p>AWS fourni <a href="https://github.com/awslabs/serverless-application-model/tree/master/examples/apps">un grand nombre d'examples d'applications</a>.</p>
<br/>
<h2 id="debug">Debug</h2>
<p>Avec remote_pdb, puisque SAM est basé sur Docker.
Dans votre code, ajoutez le snippet suivant là où vous voulez debugguer:</p>
<pre><code>__import__(remote_pdb).RemotePdb('0.0.0.0', 5858).set_trace()
</code></pre><p>Puis, une fois votre container lancé soit par invocation d'événement ou soit par la fonctionnalité API lancez le debugger avec la commande <code>telnet localhost 5858</code>.</p>
]]></content>
        </item>
        
        <item>
            <title>Installer Apache Superset avec Docker</title>
            <link>https://leandeep.com/installer-apache-superset-avec-docker/</link>
            <pubDate>Sun, 11 Aug 2019 00:46:43 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-apache-superset-avec-docker/</guid>
            <description>Apache Superset est un super outil Opensource (construit en React et Python) permettant de réaliser des dashboards d&#39;analyse de données. Cet outil est gratuit et parfaitement responsive design. La documentation officielle est ici.
Son installation est aisée avec Docker.
 Voici les commandes permettant de créer une instance avec toutes ses dépendances (Redis et Postgres) avec Docker:
git clone https://github.com/apache/incubator-superset/ cd incubator-superset/contrib/docker docker-compose run -e SUPERSET_LOAD_EXAMPLES=yes --rm superset ./docker-init.sh docker-compose up  Une fois le container principal (superset) lancé, il suffit de se rendre à l&#39;adresse suivante http://localhost:8088 pour accéder à l&#39;outil.</description>
            <content type="html"><![CDATA[<p><code>Apache Superset</code> est un super outil Opensource (construit en React et Python) permettant de réaliser des dashboards d'analyse de données. Cet outil est gratuit et parfaitement responsive design. La documentation officielle est <a href="https://superset.incubator.apache.org">ici</a>.</p>
<p>Son installation est aisée avec Docker.</p>
<br/>
<p>Voici les commandes permettant de créer une instance avec toutes ses dépendances (Redis et Postgres) avec Docker:</p>
<pre><code>git clone https://github.com/apache/incubator-superset/
cd incubator-superset/contrib/docker
docker-compose run -e SUPERSET_LOAD_EXAMPLES=yes --rm superset ./docker-init.sh
docker-compose up
</code></pre><br/>
<p>Une fois le container principal (superset) lancé, il suffit de se rendre à l'adresse suivante http://localhost:8088 pour accéder à l'outil.
Une fois authentifié avec le compte créé durant l'installation, on peut commencer par créer une base de données. Si votre datasource est un CSV, cochez la case permettant d'uploader des CSV lors de la création de la base de données.</p>
<p>Vous pouvez ensuite créer de beaux dashboards avec des charts qui montrent les informations extraites pertinentes dont vous avez besoin.</p>
<p><img src="/images/superset-donnees-filtrees.png" alt="image"></p>
<br/>
<p>Vous pouvez construire des dashboards design:</p>
<p><img src="/images/superset-example.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Installer XGBoost, LightGBM et CatBoost sur Ubuntu 18.04</title>
            <link>https://leandeep.com/installer-xgboost-lightgbm-et-catboost-sur-ubuntu-18.04/</link>
            <pubDate>Fri, 19 Jul 2019 11:14:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-xgboost-lightgbm-et-catboost-sur-ubuntu-18.04/</guid>
            <description>Installation de XGBoost Installation simple
Exécuter la commande suivante:
pip install xgboost  &amp;ldquo;The default open-source XGBoost packages already include GPU support.&amp;rdquo;
  Build from source
Si cela ne fonctionne pas, compiler et installer XGBoost depuis les sources.
Installer cmake pour builder xgboost. La version CMake 3.12 ou plus est requise.
sudo apt-get update sudo apt install -y cmake cmake --version Si ce n&#39;est pas la bonne version désinstallez le avant de le réinstaller manuellement:</description>
            <content type="html"><![CDATA[<h2 id="installation-de-xgboost">Installation de XGBoost</h2>
<p><strong>Installation simple</strong></p>
<p>Exécuter la commande suivante:</p>
<pre><code>pip install xgboost
</code></pre><blockquote>
<p>&ldquo;The default open-source XGBoost packages already include GPU support.&rdquo;</p>
</blockquote>
<br/>
<p><strong>Build from source</strong></p>
<p>Si cela ne fonctionne pas, compiler et installer XGBoost depuis les sources.</p>
<p>Installer cmake pour builder xgboost. La version CMake 3.12 ou plus est requise.</p>
<pre><code>sudo apt-get update
sudo apt install -y cmake
cmake --version
</code></pre><p>Si ce n'est pas la bonne version désinstallez le avant de le réinstaller manuellement:</p>
<pre><code>sudo apt purge cmake

# Download source
version=3.14
build=5
mkdir ~/temp
cd ~/temp
wget https://cmake.org/files/v$version/cmake-$version.$build.tar.gz
tar -xzvf cmake-$version.$build.tar.gz
cd cmake-$version.$build/

# Build et installation
./bootstrap
make -j4 &amp;&amp; sudo make install

# Vérification de la version
cmake --version
</code></pre><p>Déterminer le compute capability de votre carte graphique pour l'indiquer à la prochaine commande dans le flag <code>-DGPU_COMPUTE_VER=</code>:</p>
<pre><code>cd ~/NVIDIA_CUDA-9.0_Samples/1_Utilities/deviceQuery
make 
./deviceQuery

./deviceQuery Starting...

 CUDA Device Query (Runtime API) version (CUDART static linking)

Detected 1 CUDA Capable device(s)

Device 0: &quot;GeForce GTX 660 Ti&quot;
  CUDA Driver Version / Runtime Version          9.1 / 9.0
  CUDA Capability Major/Minor version number:    3.0
  Total amount of global memory:                 2000 MBytes (2097086464 bytes)
  ( 7) Multiprocessors, (192) CUDA Cores/MP:     1344 CUDA Cores
  GPU Max Clock rate:                            980 MHz (0.98 GHz)
  Memory Clock rate:                             3004 Mhz
  Memory Bus Width:                              192-bit
  L2 Cache Size:                                 393216 bytes
  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)
  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers
  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
  Maximum memory pitch:                          2147483647 bytes
  Texture alignment:                             512 bytes
  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)
  Run time limit on kernels:                     Yes
  Integrated GPU sharing Host Memory:            No
  Support host page-locked memory mapping:       Yes
  Alignment requirement for Surfaces:            Yes
  Device has ECC support:                        Disabled
  Device supports Unified Addressing (UVA):      Yes
  Supports Cooperative Kernel Launch:            No
  Supports MultiDevice Co-op Kernel Launch:      No
  Device PCI Domain ID / Bus ID / location ID:   0 / 6 / 0
  Compute Mode:
     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;

deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 9.1, CUDA Runtime Version = 9.0, NumDevs = 1
Result = PASS
</code></pre><p>La ligne qui nous intéresse est la suivante <code>CUDA Capability Major/Minor version number:    3.0</code></p>
<p>Dans le flag <code>-DGPU_COMPUTE_VER=</code> vous pourrez indiquer la valeur <code>30</code>.</p>
<blockquote>
<p><strong>Cette carte graphique n'est plus compatible avec XGBoost. Le minimum requis d'après le site officiel est <code>CUDA 9.0, Compute Capability 3.5 required</code></strong>. <a href="https://xgboost.readthedocs.io/en/latest/gpu/">https://xgboost.readthedocs.io/en/latest/gpu/</a></p>
</blockquote>
<p>Builder XGBoost:</p>
<pre><code>cd ~ &amp;&amp; \
    git clone --recursive https://github.com/dmlc/xgboost &amp;&amp; \
    cd xgboost &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; cmake -DCUDA_HOST_COMPILER=/usr/bin/gcc-6 -DGPU_COMPUTE_VER=35 -DUSE_CUDA=ON .. &amp;&amp; make -j
</code></pre><p>Installer XGBoost:</p>
<pre><code>cd ../python-package
sudo python3 setup.py install
</code></pre><br/>
<p><strong>Vérification du bon fonctionnement d'XGBoost</strong></p>
<pre><code>git clone https://github.com/dmlc/xgboost
cd xgboost

python3 # ou workon votre_environnement_virtuel &amp;&amp; python
Puis exécutez les commandes Python suivantes:

import xgboost as xgb
# read in data
dtrain = xgb.DMatrix('demo/data/agaricus.txt.train')
dtest = xgb.DMatrix('demo/data/agaricus.txt.test')
# specify parameters via map
param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }
num_round = 2
bst = xgb.train(param, dtrain, num_round)
# make prediction
preds = bst.predict(dtest)
print(preds)
</code></pre><br/>
<h2 id="installation-de-lightgbm">Installation de LightGBM</h2>
<p>Installation des dépendances:</p>
<pre><code>sudo apt install -y \
    libboost-dev \
    libboost-system-dev \
    libboost-filesystem-dev
</code></pre><p>Build:</p>
<pre><code>cd ~ &amp;&amp; \
    git clone --recursive https://github.com/Microsoft/LightGBM &amp;&amp; \
    cd LightGBM &amp;&amp; mkdir build &amp;&amp; cd build &amp;&amp; \
    cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda-9.0/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda-9.0/include/ .. &amp;&amp; \
    make -j
    
</code></pre><p>Installation:</p>
<pre><code>cd ../python-package
sudo python setup.py install --precompile
</code></pre><p>Vérifier le bon fonctionnement de LightGBM:</p>
<pre><code>cd ~/LightGBM/examples/python-guide/
pip install scikit-learn pandas matplotlib scipy -U
python3 simple_example.py

Loading data...
Starting training...
[1]	valid_0's l1: 0.492841	valid_0's l2: 0.243898
Training until validation scores don't improve for 5 rounds.
[2]	valid_0's l1: 0.489327	valid_0's l2: 0.240605
[3]	valid_0's l1: 0.484931	valid_0's l2: 0.236472
[4]	valid_0's l1: 0.480567	valid_0's l2: 0.232586
[5]	valid_0's l1: 0.475965	valid_0's l2: 0.22865
[6]	valid_0's l1: 0.472861	valid_0's l2: 0.226187
[7]	valid_0's l1: 0.469847	valid_0's l2: 0.223738
[8]	valid_0's l1: 0.466258	valid_0's l2: 0.221012
[9]	valid_0's l1: 0.462751	valid_0's l2: 0.218429
[10]	valid_0's l1: 0.458755	valid_0's l2: 0.215505
[11]	valid_0's l1: 0.455252	valid_0's l2: 0.213027
[12]	valid_0's l1: 0.452051	valid_0's l2: 0.210809
[13]	valid_0's l1: 0.448764	valid_0's l2: 0.208612
[14]	valid_0's l1: 0.446667	valid_0's l2: 0.207468
[15]	valid_0's l1: 0.444211	valid_0's l2: 0.206009
[16]	valid_0's l1: 0.44186	valid_0's l2: 0.20465
[17]	valid_0's l1: 0.438508	valid_0's l2: 0.202489
[18]	valid_0's l1: 0.435919	valid_0's l2: 0.200668
[19]	valid_0's l1: 0.433348	valid_0's l2: 0.19925
[20]	valid_0's l1: 0.431211	valid_0's l2: 0.198136
Did not meet early stopping. Best iteration is:
[20]	valid_0's l1: 0.431211	valid_0's l2: 0.198136
Saving model...
Starting predicting...
The rmse of prediction is: 0.44512434910807497
</code></pre><br/>
<h2 id="installation-de-catboost">Installation de CatBoost</h2>
<p>Simplement:</p>
<pre><code>pip install catboost
</code></pre><p>Installer l'outil de visualisation:</p>
<pre><code>pip install ipywidgets
</code></pre><pre><code># Turn on the widgets extension:
jupyter nbextension enable --py widgetsnbextension
</code></pre><p>Pour tester le bon fonctionnement vous pouvez créer un fichier <code>test.py</code> et y insérer le code suivant:</p>
<pre><code>from catboost import Pool, CatBoostClassifier

train_data = [[&quot;summer&quot;, 1924, 44],
              [&quot;summer&quot;, 1932, 37],
              [&quot;winter&quot;, 1980, 37],
              [&quot;summer&quot;, 2012, 204]]

eval_data = [[&quot;winter&quot;, 1996, 197],
             [&quot;winter&quot;, 1968, 37],
             [&quot;summer&quot;, 2002, 77],
             [&quot;summer&quot;, 1948, 59]]

cat_features = [0]

train_label = [&quot;France&quot;, &quot;USA&quot;, &quot;USA&quot;, &quot;UK&quot;]
eval_label = [&quot;USA&quot;, &quot;France&quot;, &quot;USA&quot;, &quot;UK&quot;]


train_dataset = Pool(data=train_data,
                     label=train_label,
                     cat_features=cat_features)

eval_dataset = Pool(data=eval_data,
                    label=eval_label,
                    cat_features=cat_features)

# Initialize CatBoostClassifier
model = CatBoostClassifier(iterations=10,
                           learning_rate=1,
                           depth=2,
                           loss_function='MultiClass',
                           task_type=&quot;GPU&quot;)
# Fit model
model.fit(train_dataset)
# Get predicted classes
preds_class = model.predict(eval_dataset)
# Get predicted probabilities for each class
preds_proba = model.predict_proba(eval_dataset)
# Get predicted RawFormulaVal
preds_raw = model.predict(eval_dataset,
                          prediction_type='RawFormulaVal')

</code></pre><p>Après l'avoir exécuté le code précédent un training sera réalisé sur GPU. <a href="https://catboost.ai/docs/features/training-on-gpu.html#training-on-gpu">Le lien suivant</a> décrit comment faire. Si tout est ok vous devriez obtenir le résultat suivant:</p>
<pre><code>0:	learn: -0.9623099	total: 8.48ms	remaining: 76.3ms
1:	learn: -0.7421078	total: 14.6ms	remaining: 58.3ms
2:	learn: -0.5898572	total: 20.2ms	remaining: 47.2ms
3:	learn: -0.4816516	total: 26.3ms	remaining: 39.4ms
4:	learn: -0.4023528	total: 31.8ms	remaining: 31.8ms
5:	learn: -0.3545669	total: 37.2ms	remaining: 24.8ms
6:	learn: -0.3052314	total: 42.1ms	remaining: 18ms
7:	learn: -0.2666318	total: 47.6ms	remaining: 11.9ms
8:	learn: -0.2358041	total: 53ms	remaining: 5.89ms
9:	learn: -0.2107419	total: 57.9ms	remaining: 0us
</code></pre><br/>
<h2 id="comparaison-des-3-algorithmes-de-boosting">Comparaison des 3 algorithmes de Boosting</h2>
<p>Un article très intéressant comparant les 3 algorithmes est disponible <a href="https://towardsdatascience.com/catboost-vs-light-gbm-vs-xgboost-5f93620723db">à l'adresse suivante</a>.</p>
<p>Voici un tableau comparatif extrait de cet article:</p>
<p><img src="/images/lightGBM-vs-CatBoost-vs-XGBoost.png" alt="image"></p>
<p>Au vu de ces résultats, je pencherais soit sur l'utilisation de CatBoost si les délais d'inférence sont un enjeu. Dans le cas contraire, vue les résultats de LightGBM et sa durée d'entrainement nécessaire par rapport à XGBoost je partirais sur LightGBM.</p>
]]></content>
        </item>
        
        <item>
            <title>Installer un eGPU sur un Intel Nuc avec Ubuntu 18.04</title>
            <link>https://leandeep.com/installer-un-egpu-sur-un-intel-nuc-avec-ubuntu-18.04/</link>
            <pubDate>Thu, 18 Jul 2019 12:19:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-un-egpu-sur-un-intel-nuc-avec-ubuntu-18.04/</guid>
            <description>&lt;p&gt;&lt;img src=&#34;https://leandeep.com/images/IMG_35783.JPG&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p><img src="/images/IMG_35783.JPG" alt="image"></p>
<br/>
<h2 id="introduction">Introduction</h2>
<p>J'ai récemment fait l'acquisition d'un Intel Nuc (Core i7 et 32 go de RAM). Franchement je suis vraiment satisfait. Il est petit, leger, sobre, stylé, consomme peu et celui que j'ai choisi a du Thunderbolt 3. C'est d'ailleurs pour cela que je l'ai acheté.</p>
<p>Qui dit Thunderbolt 3 dit eGPU. Et qui dit eGPU dit tensorflow-gpu !..</p>
<p>J'ai recyclé une ancienne carte graphique qui trainaient dans un ancien PC. Il s'agit d'une <code>Geforce GTX 660 Ti</code> achetée en 2012 aux USA. Elle ne vaut sans doute plus grand chose aujourd'hui. Mais pourtant elle va nous être bien utile; soit pour miner (nouveau centre d'intérêt) soit pour entraîner mes modèles de Machine / Deep Learning.<br>
J'ai aussi fait l'acquisition d'un boitier eGPU. J'ai pris un Razer Core X. C'est la première fois que j'achète du Razer. Ce premier achat me satisfait vraiment car il est de très bonne qualité.</p>
<br/>
<p><strong>Dans cet article nous allons voir comment installer les drivers pour que la carte graphique utilisée dans le boitier eGPU soit reconnue et comment installer les outils nécessaires pour que Tensorflow puisse être compilé et fonctionner avec ce dernier. J'ai beaucoup galéré pour faire fonctionner le tout. J'espère que cet article pourra vous faire économiser des heures pour rien.</strong></p>
<br/>
<h2 id="pr-requis">Pré-requis</h2>
<p>Le kernel que j'utilise est le <code>4.18.0</code>. Il y a pleins d'articles sur internet qui disent de mettre à jour le Kernel avant de commencer. Je l'ai fait et cela n'a pas fonctionné. J'ai testé le <code>5.2</code> et j'ai dû faire machine arrière&hellip;</p>
<br/>
<h2 id="questions">Questions!</h2>
<p><strong>Comment connaître la version du kernel ?</strong></p>
<p>Tout simplement avec la commande:</p>
<pre><code>cat /proc/version
</code></pre><br/>
<p><strong>Comment mettre à jour le kernel ?</strong></p>
<p>En ligne de commande ou via une petite interface graphique:</p>
<pre><code># Installer ukuu
sudo apt-add-repository ppa:teejee2008/ppa
sudo apt update
sudo apt-get install ukuu
# Lancer l'interface
sudo ukuu-gtk
</code></pre><br/>
<p><strong>Comment backuper sa machine avant de la bidouiller ?</strong></p>
<p>Très bonne question! Heureusement avant chaque manipulation délicate j'ai snapshoté ma machine. J'ai pris le risque de laisser le snapshot dessus en toute connaissance de cause. Vous pouvez le sortir si vraiment vous craignez de ne pas pouvoir réparer votre machine. Je vous conseille juste d'installer SSH pour pouvoir vous connecter dessus au cas où Gnome ne démarre même plus&hellip;</p>
<p>Je réalise mes snapshots avec Timeshift. Il y a une interface graphique mais apprenez à l'utiliser en lignes de commande. Ce n'est pas le jour où tout est crashé qu'il faut se demander comment faire :D .</p>
<pre><code># Installation de Timeshift
sudo apt-add-repository -y ppa:teejee2008/ppa &amp;&amp; sudo apt-get update &amp;&amp; sudo apt-get install timeshift
# Créer un snapshot 
# sudo timeshift --create --comments &quot;after cuda installation&quot; --tags D
# Voir les snapshots
sudo timeshift --list
# Restaurer un snapshot 
# sudo timeshift --restore
</code></pre><br/>
<p><strong>Est-ce que le GPU installé dans le boitier eGPU est bien détecté ?</strong></p>
<pre><code>lspci | grep -i nvidia

06:00.0 VGA compatible controller: NVIDIA Corporation GK104 [GeForce GTX 660 Ti] (rev a1)
</code></pre><br/>
<h2 id="installation">Installation</h2>
<p><strong>Configurer GCC et G++</strong></p>
<p>Il vous faudra une utiliser la version 6 de <code>GCC</code> et <code>G++</code> pour builder Tensorflow. Si vous avez une version plus récente cela ne fonctionnera pas.</p>
<pre><code>gcc --version
g++ --version
</code></pre><p>Installer gcc et g++ 6:</p>
<pre><code>sudo apt install gcc-6 g++-6
</code></pre><p>Créer les variables d'environnement permettant de sélectionner la bonne version dans le fichier <code>~/.zshrc</code>.</p>
<pre><code>export CC=/usr/bin/gcc-6
export CXX=/usr/bin/g++-6
</code></pre><br/>
<p><strong>Installer les Drivers Nvidia</strong></p>
<p>Enlever les nouveaux drivers qui viennent avec l'installation d'Ubuntu. Identifier les avec la commande:</p>
<pre><code>lsmod | grep nouveau
</code></pre><p>Créer un fichier <code>/etc/modprobe.d/blacklist-nouveau.conf</code> et ajouter lui le contenu suivant:</p>
<pre><code>blacklist nouveau
options nouveau modeset=0
</code></pre><p>Régénérer le Kernel initramfs:</p>
<pre><code>sudo update-initramfs -u
</code></pre><p>On peut maintenant installer le Driver Nvidia nécessaire au bon fonctionnement de mon GPU:</p>
<pre><code>sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt install nvidia-384 nvidia-384-dev
sudo reboot
</code></pre><p>Après le reboot vérifier que tout fonctionne avecc la commande <code>nvidia-smi</code>. Si vous avez un résultat similaire à celui-ci vous êtes sur la bonne voie.</p>
<pre><code>+-----------------------------------------------------------------------------+
| NVIDIA-SMI 390.116                Driver Version: 390.116                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 660 Ti  Off  | 00000000:06:00.0 N/A |                  N/A |
| 30%   26C    P8    N/A /  N/A |    162MiB /  1999MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0                    Not Supported                                       |
+-----------------------------------------------------------------------------+
</code></pre><br/>
<p><strong>Installer Cuda</strong></p>
<p>On peut maintenant passer à l'installation de Cuda.
J'ai beaucoup galéré à cette étape car j'ai essayé d'installer les dernières versione de Cuda. Au moment où j'écris cet article il s'agissait de la version 10.1. Cette dernière n'a pas fonctionné car trop récente pour mon GPU.
J'ai donc installé la <code>cuda version 9.0</code> à partir de ce fichier précisément <code>cuda_9.0.176_384.81_linux-run</code>.</p>
<pre><code>wget https://developer.nvidia.com/compute/cuda/9.0/Prod/local_installers/cuda_9.0.176_384.81_linux-run
chmod +x cuda_9.0.176_384.81_linux.run 
sudo ./cuda_9.0.176_384.81_linux.run --override
</code></pre><ul>
<li>
<p>Pendant l'installation dire yes à &ldquo;You are attempting to install on an unsupported configuration. Do you wish to continue?&rdquo;</p>
</li>
<li>
<p>Dire no à &ldquo;Install NVIDIA Accelerated Graphics Driver for Linux-x86_64 384.81?&rdquo;</p>
</li>
<li>
<p>Dire yes à &ldquo;Install the CUDA 9.0 Toolkit?&rdquo;</p>
</li>
<li>
<p>Dire yes à &ldquo;Create symbolic links?&rdquo;</p>
</li>
<li>
<p>Dire yes à l'installation des examples Cuda et installer les dans le répertoire proposé par défaut.</p>
</li>
</ul>
<p>Vous pouvez vérifier la bonne installation de Cuda avec la commande:</p>
<pre><code>nvcc -V

nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2017 NVIDIA Corporation
Built on Fri_Sep__1_21:08:03_CDT_2017
Cuda compilation tools, release 9.0, V9.0.176
</code></pre><br/>
<p><strong>Installer CudNN</strong></p>
<p>Connectez-vous au site <a href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a> et téléchargez le package suivant <code>cudnn-9.0-linux-x64-v7.3.0.29</code>. Ensuite installez le.</p>
<pre><code>tar -xzvf cudnn-9.0-linux-x64-v7.3.0.29.tgz
sudo cp -P cuda/include/cudnn.h /usr/local/cuda-9.0/include
sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda-9.0/lib64/
sudo chmod a+r /usr/local/cuda-9.0/lib64/libcudnn*
</code></pre><br/>
<p><strong>Installer libcudnn</strong></p>
<p>Connectez-vous au site <a href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a> et téléchargez les 3 packages <code>libcudnn7_7.3.0.29-1+cuda9.0_amd64.deb</code>, <code>libcudnn7-dev_7.3.0.29-1+cuda9.0_amd64.deb</code> et <code>libcudnn7-doc_7.3.0.29-1+cuda9.0_amd64.deb</code>. Attention les numéros de versions sont à respecter. J'ai aussi perdu beaucoup de temps sur cela.</p>
<p>Installez les:</p>
<pre><code>sudo dpkg -i libcudnn7_7.3.0.29-1+cuda9.0_amd64.deb
sudo dpkg -i libcudnn7-dev_7.3.0.29-1+cuda9.0_amd64.deb
sudo dpkg -i libcudnn7-doc_7.3.0.29-1+cuda9.0_amd64.deb
</code></pre><p>Vérifier que cudnn est bien installé:</p>
<pre><code># Copy the cuDNN sample to a writable path.
cp -r /usr/src/cudnn_samples_v7/ $HOME
# Go to the writable path.
cd  $HOME/cudnn_samples_v7/mnistCUDNN
# Compile the mnistCUDNN sample.
make clean &amp;&amp; make
# Run the mnistCUDNN sample.
./mnistCUDNN
# If cuDNN is properly installed and running on your Linux system, you will see a message similar to the following:
$ Test passed!
</code></pre><p>Maintenons les paquets afin qu’ils ne soient pas updatés ou effacés:</p>
<pre><code>sudo apt-mark hold libcudnn7 libcudnn7-dev libcudnn7-doc
</code></pre><br/>
<p><strong>Installer Bazel</strong></p>
<pre><code>wget https://github.com/bazelbuild/bazel/releases/download/0.17.2/bazel-0.17.2-installer-linux-x86_64.sh
chmod +x bazel-0.17.2-installer-linux-x86_64.sh
./bazel-0.17.2-installer-linux-x86_64.sh --user
</code></pre><p>Pour pouvoir utiliser Bazel, modifier votre .bashrc ou .zshrc et ajouter cette commande:</p>
<pre><code>export PATH=&quot;$PATH:$HOME/bin&quot;
</code></pre><br/>
<p><strong>Builder/Installer/Tester Tensorflow GPU</strong></p>
<p>Rendez-vous ensuite sur un précédent article que j'ai écrit sur le sujet. Suivez la section &ldquo;Installer TensorFlow&rdquo;. J'ai suivi mon propre tutorial et cela a fonctionné ! <a href="https://leandeep.com/rendre-tensorflow-compatible-avec-plus-de-cartes-graphiques/#Installer-Tensorflow">https://leandeep.com/rendre-tensorflow-compatible-avec-plus-de-cartes-graphiques/#Installer-Tensorflow</a></p>
<p>Cela fonctionne avec Python 2.7 et Python 3&hellip;</p>
<pre><code>python
Python 3.6.8 (default, Jan 14 2019, 11:02:34)
[GCC 8.0.1 20180414 (experimental) [trunk revision 259383]] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
&gt;&gt;&gt; sess = tf.Session()

2019-07-19 11:08:55.100940: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2019-07-19 11:08:55.170484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-07-19 11:08:55.171894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:
name: GeForce GTX 660 Ti major: 3 minor: 0 memoryClockRate(GHz): 0.98
pciBusID: 0000:06:00.0
totalMemory: 1.95GiB freeMemory: 1.75GiB
2019-07-19 11:08:55.171908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2019-07-19 11:08:55.467370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-19 11:08:55.467397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0
2019-07-19 11:08:55.467409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N
2019-07-19 11:08:55.467629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1523 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 660 Ti, pci bus id: 0000:06:00.0, compute capability: 3.0)
</code></pre><blockquote>
<p>Jupyter Lab fix:
Après avoir installé Tensorflow j'avais un message d'erreur m'indiquant que la librairie <code>libcublas</code> n'existait pas (<code>No such file or directory</code>) alors que les variables d'environnement <code>LD_LIBRARY_PATH=/usr/local/cuda-9.0/lib64</code> et <code>PATH=$PATH:/usr/local/cuda-9.0/bin</code> étaient bien configurées. Cette erreur n'apparaissait que dans Jupyter Lab. Partout ailleurs Tensorflow fonctionnait. J'ai donc modifié la configuration de Jupyter Lab et ajouté l'import manuellement. En haut du fichier <code>~/.jupyter/jupyter_notebook_config.py</code> j'ai ajouté le code suivant:</p>
</blockquote>
<pre><code>import os
c = get_config()
os.environ['LD_LIBRARY_PATH'] = '/usr/local/cuda-9.0/lib64:usr/local/cuda-9.0/lib64/libcudart.so.9.0'
c.Spawner.env.update('LD_LIBRARY_PATH')
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Extract &amp; resolve geographic entities from unstructured text</title>
            <link>https://leandeep.com/extract-resolve-geographic-entities-from-unstructured-text/</link>
            <pubDate>Fri, 12 Jul 2019 12:07:00 +0000</pubDate>
            
            <guid>https://leandeep.com/extract-resolve-geographic-entities-from-unstructured-text/</guid>
            <description>In this article we are going to see how to install a great opensource tool called CLAVIN (Cartographic Location And Vicinity INdexer) that can extract and parse geographic entities from an unstructured text. The installation will be done on Ubuntu 18.04.
Here is an example of what you can do: http://clavin.berico.us/clavin-web/
Here is the description of the tool coming from the official website:
CLAVIN does not simply “look up” location names – it uses intelligent heuristics to identify exactly which “Springfield” (for example) was intended by the author, based on the context of the document.</description>
            <content type="html"><![CDATA[<p>In this article we are going to see how to install a great opensource tool called <code>CLAVIN</code> (Cartographic Location And Vicinity INdexer) that can extract and parse geographic entities from an unstructured text.
The installation will be done on Ubuntu 18.04.</p>
<p>Here is an example of what you can do: <a href="http://clavin.berico.us/clavin-web/">http://clavin.berico.us/clavin-web/</a></p>
<p>Here is the description of the tool coming from the official website:</p>
<p><em>CLAVIN does not simply “look up” location names – it uses intelligent heuristics to identify exactly which “Springfield” (for example) was intended by the author, based on the context of the document. CLAVIN also employs fuzzy search to handle incorrectly-spelled location names, and it recognizes alternative names (e.g., “Ivory Coast” and “Côte d’Ivoire”) as referring to the same geographic entity.</em></p>
<br/>
<h2 id="prerequisites">Prerequisites</h2>
<p><strong>Install Maven</strong></p>
<p>Update your system to the latest stable version:</p>
<pre><code>sudo apt-get update -y
sudo apt-get upgrade -y
</code></pre><p>Install Java if necessary:</p>
<pre><code>sudo apt-get install -y default-jdk
</code></pre><p>Verify it is correctly installed with:</p>
<pre><code>java -version
</code></pre><p>Install Maven:</p>
<pre><code>cd /opt/
sudo wget https://www-us.apache.org/dist/maven/maven-3/3.6.0/binaries/apache-maven-3.6.0-bin.tar.gz
sudo tar -xvzf apache-maven-3.6.0-bin.tar.gz
sudo mv apache-maven-3.6.0 maven 
</code></pre><p>Set environment variables by adding the following lines in the <code>/etc/profile.d/mavenenv.sh</code> file:</p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/default-java
export M2_HOME=/opt/maven
export PATH=${M2_HOME}/bin:${PATH}
</code></pre><p>Give the execution rights on the environment variable file:</p>
<pre><code>sudo chmod +x /etc/profile.d/mavenenv.sh
</code></pre><p>Load the env file:</p>
<pre><code>source /etc/profile.d/mavenenv.sh
</code></pre><p>Add this command at the end of your <code>~/.zshrc</code> file:</p>
<pre><code>source /etc/profile.d/mavenenv.sh
</code></pre><p>Verify it works with:</p>
<pre><code>mvn --version
</code></pre><br/>
<h2 id="install-clavin-api">Install CLAVIN API</h2>
<p>Clone the CLAVIN REST API repo:</p>
<pre><code>git clone https://github.com/Berico-Technologies/CLAVIN-rest
cd CLAVIN-rest 
</code></pre><p>Edit the <code>pom.xml</code> file and add the following lines inside the <code>&lt;properties&gt;</code> tag.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Build the jar executable:</p>
<pre><code>mvn clean install

or $ mvn package
</code></pre><p>Download Geonames:</p>
<pre><code>curl -O http://download.geonames.org/export/dump/allCountries.zip
unzip allCountries.zip
</code></pre><p>Download CLAVIN yaml configuration file:</p>
<pre><code>curl -O https://raw.githubusercontent.com/Berico-Technologies/CLAVIN-rest/master/clavin-rest.yml
</code></pre><p>Create a CLAVIN dictionary or index of geographical names (also called gazetteer):</p>
<pre><code>java -Xmx4096m -jar ./target/clavin-rest-0.3.0-SNAPSHOT.jar index clavin-rest.yml
</code></pre><p>Run the REST server:</p>
<pre><code>java -Xmx2048m -jar clavin-rest.jar server clavin-rest.yml 
</code></pre><p>The API will be available at: http://localhost:9090/api/v0/geotag</p>
]]></content>
        </item>
        
        <item>
            <title>Install Elasticsearch on Ubuntu 18.04 </title>
            <link>https://leandeep.com/install-elasticsearch-on-ubuntu-18.04/</link>
            <pubDate>Sat, 06 Jul 2019 11:01:00 +0000</pubDate>
            
            <guid>https://leandeep.com/install-elasticsearch-on-ubuntu-18.04/</guid>
            <description>In this article we are going to see how to install ElasticSearch as service on Ubuntu 18.04.
 Pré-requis Verify Java is installed:
$ java -version openjdk version &amp;quot;11.0.3&amp;quot; 2019-04-16 OpenJDK Runtime Environment (build 11.0.3+7-Ubuntu-1ubuntu218.04.1) OpenJDK 64-Bit Server VM (build 11.0.3+7-Ubuntu-1ubuntu218.04.1, mixed mode, sharing) Also verify the environment variable JAVA_HOME is set.
echo $JAVA_HOME If the previous command return an empty string you need to set the environment variable in your ~/.</description>
            <content type="html"><![CDATA[<p>In this article we are going to see how to install ElasticSearch as service on Ubuntu 18.04.</p>
<br/>
<h2 id="pr-requis">Pré-requis</h2>
<p>Verify Java is installed:</p>
<pre><code>$ java -version
openjdk version &quot;11.0.3&quot; 2019-04-16
OpenJDK Runtime Environment (build 11.0.3+7-Ubuntu-1ubuntu218.04.1)
OpenJDK 64-Bit Server VM (build 11.0.3+7-Ubuntu-1ubuntu218.04.1, mixed mode, sharing)
</code></pre><p>Also verify the environment variable <code>JAVA_HOME</code> is set.</p>
<pre><code>echo $JAVA_HOME
</code></pre><p>If the previous command return an empty string you need to set the environment variable in your <code>~/.zshrc</code>. Add this line: <code>export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64</code>.</p>
<blockquote>
<p>Please note that it might not be this path <code>/usr/lib/jvm/java-11-openjdk-amd64</code> in your case. Just check what java path you have under <code>/usr/lib/jvm</code>.</p>
</blockquote>
<br/>
<h2 id="install-elasticsearch">Install Elasticsearch</h2>
<pre><code>sudo apt-get install apt-transport-https
# Add gpg key
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
# Add ES repo
add-apt-repository &quot;deb https://artifacts.elastic.co/packages/7.x/apt stable main&quot;
sudo apt-get update
# Install ES
sudo apt-get install elasticsearch
</code></pre><br/>
<h2 id="add-servicce">Add Servicce</h2>
<pre><code>sudo systemctl enable elasticsearch.service
sudo systemctl start elasticsearch.service
# To debug
sudo systemctl status elasticsearch.service
# or 
journalctl -xe
</code></pre><br/>
<h2 id="verify-it-is-working">Verify it is working</h2>
<pre><code>curl -X GET http://localhost:9200
</code></pre><blockquote>
<p>To customize ES settings you can edit the well documented configuration file located in this path <code>/etc/elasticsearch/elasticsearch.yml</code>.</p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Install Apache Guacamole for SSH and VNC over HTML5</title>
            <link>https://leandeep.com/install-apache-guacamole-for-ssh-and-vnc-over-html5/</link>
            <pubDate>Fri, 05 Jul 2019 15:07:21 +0000</pubDate>
            
            <guid>https://leandeep.com/install-apache-guacamole-for-ssh-and-vnc-over-html5/</guid>
            <description>I struggled a little bit with the installation on Apache Guacamole. I think this tutorial will help some people. I installed it on Ubuntu 18.04.
 Install VNC Install the following packages:
sudo apt-get install -y ubuntu-desktop gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal tightvncserver We are going to create a VNC startup script:
cd mkdir ~/.vnc Create a VNC startup script at this location ~/.vnc/xstartup and enter this content:
 Option 1: Pour Ubuntu 18.</description>
            <content type="html"><![CDATA[<p>I struggled a little bit with the installation on Apache Guacamole. I think this tutorial will help some people. I installed it on Ubuntu 18.04.</p>
<br/>
<h2 id="install-vnc">Install VNC</h2>
<p>Install the following packages:</p>
<pre><code>sudo apt-get install -y ubuntu-desktop gnome-panel gnome-settings-daemon metacity nautilus gnome-terminal tightvncserver
</code></pre><p>We are going to create a VNC startup script:</p>
<pre><code>cd
mkdir ~/.vnc
</code></pre><p>Create a VNC startup script at this location <code>~/.vnc/xstartup</code> and enter this content:</p>
<br/>
<p><strong>Option 1: Pour Ubuntu 18.04 &ldquo;classique&rdquo; avec le desktop environment Gnome</strong></p>
<pre><code>#!/bin/sh

xrdb $HOME/.Xresources
xsetroot -solid grey
#x-terminal-emulator -geometry 80x24+10+10 -ls -title &quot;$VNCDESKTOP Desktop&quot; &amp;
#x-window-manager &amp;
# Fix to make GNOME work
export XKL_XMODMAP_DISABLE=1
/etc/X11/Xsession

unset SESSION_MANAGER
vncconfig -iconic &amp;
x-terminal-emulator -geometry 80x24+10+10 -ls -title &quot;$VNCDESKTOP Desktop&quot; &amp;
x-window-manager &amp;
gnome-panel &amp;
gnome-settings-daemon &amp;
nautilus &amp;
metacity &amp;
gnome-session-flashback &amp;
</code></pre><br/>
<p><strong>Option 2: Pour Ubuntu Mate</strong></p>
<pre><code>#!/bin/sh
unset DBUS_SESSION_BUS_ADDRESS
[ -x /etc/vnc/xstartup ] &amp;&amp; exec /etc/vnc/xstartup
[ -r $HOME/.Xresources ] &amp;&amp; xrdb $HOME/.Xresources
xsetroot -solid grey
vncconfig -iconic &amp;
x-terminal-emulator -geometry 80x24+10+10 -ls -title &quot;$VNCDESKTOP Desktop&quot; &amp;
x-window-manager &amp;
mate-session &amp;
</code></pre><p>Donner les droits d'exécution sur le fichier <code>~/.vnc/xstartup</code>:</p>
<pre><code>sudo chmod +x ~/.vnc/xstartup
</code></pre><p>Reconfigure the session manager:</p>
<pre><code>sudo update-alternatives --config x-session-manager
</code></pre><p>Select: <code>/usr/lib/gnome-flashback/gnome-flashback-metacity</code></p>
<blockquote>
<p>Fix rights issue:
<code>sudo chown -R olivier:olivier /home/olivier/.cache/dconf</code></p>
</blockquote>
<br/>
<h2 id="create-vnc-service">Create VNC service</h2>
<pre><code>sudo vi /etc/systemd/system/vncserver@.service
</code></pre><p>Enter the following content. Replace <code>olivier</code> by your username.</p>
<pre><code>[Unit]
Description=Start TightVNC server at startup
After=syslog.target network.target

[Service]
Type=forking
User=olivier
Group=olivier
WorkingDirectory=/home/olivier

PIDFile=/home/olivier/.vnc/%H:%i.pid
ExecStartPre=-/usr/bin/vncserver -kill :%i &gt; /dev/null 2&gt;&amp;1
ExecStart=/usr/bin/vncserver -depth 24 -geometry 1280x800 :%i
ExecStop=/usr/bin/vncserver -kill :%i

[Install]
WantedBy=multi-user.target
</code></pre><p>Configure vncserver. To do so execute <code>vncserver</code> and enter a vnc password. Do not create a readonly password. When you are done kill the running server.</p>
<pre><code>vncserver -kill :1
</code></pre><p>Start the service:</p>
<pre><code>sudo systemctl daemon-reload
sudo systemctl enable vncserver@1.service
sudo systemctl start vncserver@1
</code></pre><br/>
<h2 id="install-guacamole">Install Guacamole</h2>
<p>Create a install script and enter the following content:</p>
<pre><code>#!/bin/bash

# Check if user is root or sudo
if ! [ $(id -u) = 0 ]; then echo &quot;Please run this script as sudo or root&quot;; exit 1 ; fi

# Version number of Guacamole to install
GUACVERSION=&quot;1.0.0&quot;

# Colors to use for output
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
RED='\033[0;31m'
GREEN='\033[0;32m'
NC='\033[0m' # No Color

# Log Location
LOG=&quot;/tmp/guacamole_${GUACVERSION}_build.log&quot;

# Get script arguments for non-interactive mode
while [ &quot;$1&quot; != &quot;&quot; ]; do
    case $1 in
        -m | --mysqlpwd )
            shift
            mysqlpwd=&quot;$1&quot;
            ;;
        -g | --guacpwd )
            shift
            guacpwd=&quot;$1&quot;
            ;;
        -u | --mysqluser )
            shift
            mysqluser=&quot;$1&quot;
            ;;
        -d | --database )
            shift
            DB=&quot;$1&quot;
            ;;
    esac
    shift
done

# Checking if mysql user given
if [ -z &quot;$mysqluser&quot; ]; then
    mysqluser=&quot;guacamole_user&quot;
fi

# Checking if database name given
if [ -z &quot;$DB&quot; ]; then
    DB=&quot;guacamole_db&quot;
fi

# Get MySQL root password and Guacamole User password
if [ -n &quot;$mysqlpwd&quot; ] &amp;&amp; [ -n &quot;$guacpwd&quot; ]; then
        mysqlrootpassword=$mysqlpwd
        guacdbuserpassword=$guacpwd
else
    echo
    while true
    do
        read -s -p &quot;Enter a MySQL ROOT Password: &quot; mysqlrootpassword
        echo
        read -s -p &quot;Confirm MySQL ROOT Password: &quot; password2
        echo
        [ &quot;$mysqlrootpassword&quot; = &quot;$password2&quot; ] &amp;&amp; break
        echo &quot;Passwords don't match. Please try again.&quot;
        echo
    done
    echo
    while true
    do
        read -s -p &quot;Enter a Guacamole User Database Password: &quot; guacdbuserpassword
        echo
        read -s -p &quot;Confirm Guacamole User Database Password: &quot; password2
        echo
        [ &quot;$guacdbuserpassword&quot; = &quot;$password2&quot; ] &amp;&amp; break
        echo &quot;Passwords don't match. Please try again.&quot;
        echo
    done
    echo
fi

debconf-set-selections &lt;&lt;&lt; &quot;mysql-server mysql-server/root_password password $mysqlrootpassword&quot;
debconf-set-selections &lt;&lt;&lt; &quot;mysql-server mysql-server/root_password_again password $mysqlrootpassword&quot;

# Ubuntu and Debian have different package names for libjpeg
# Ubuntu and Debian versions have differnet package names for libpng-dev
# Ubuntu 18.04 does not include universe repo by default
source /etc/os-release
if [[ &quot;${NAME}&quot; == &quot;Ubuntu&quot; ]]
then
    JPEGTURBO=&quot;libjpeg-turbo8-dev&quot;
    if [[ &quot;${VERSION_ID}&quot; == &quot;18.04&quot; ]]
    then
        sed -i 's/bionic main$/bionic main universe/' /etc/apt/sources.list
    fi
    if [[ &quot;${VERSION_ID}&quot; == &quot;16.04&quot; ]]
    then
        LIBPNG=&quot;libpng12-dev&quot;
    else
        LIBPNG=&quot;libpng-dev&quot;
    fi
elif [[ &quot;${NAME}&quot; == *&quot;Debian&quot;* ]]
then
    JPEGTURBO=&quot;libjpeg62-turbo-dev&quot;
    if [[ &quot;${PRETTY_NAME}&quot; == *&quot;stretch&quot;* ]]
    then
        LIBPNG=&quot;libpng-dev&quot;
    else
        LIBPNG=&quot;libpng12-dev&quot;
    fi
else
    echo &quot;Unsupported Distro - Ubuntu or Debian Only&quot;
    exit 1
fi

# Update apt so we can search apt-cache for newest tomcat version supported
apt-get -qq update

# Tomcat 8.0.x is End of Life, however Tomcat 7.x is not...
# If Tomcat 8.5.x or newer is available install it, otherwise install Tomcat 7
# I have not testing with Tomcat9...
if [[ $(apt-cache show tomcat8 | egrep &quot;Version: 8.[5-9]&quot; | wc -l) -gt 0 ]]
then
    TOMCAT=&quot;tomcat8&quot;
else
    TOMCAT=&quot;tomcat7&quot;
fi

if [ -z $(command -v mysql) ]
then
    MYSQL=&quot;mysql-server mysql-client mysql-common mysql-utilities&quot;
else
    MYSQL=&quot;&quot;
fi

# Uncomment to manually force a tomcat version
#TOMCAT=&quot;&quot;

# Install features
echo -e &quot;${BLUE}Installing dependencies. This might take a few minutes...${NC}&quot;

export DEBIAN_FRONTEND=noninteractive

apt-get -y install build-essential libcairo2-dev ${JPEGTURBO} ${LIBPNG} libossp-uuid-dev libavcodec-dev libavutil-dev \
libswscale-dev libfreerdp-dev libpango1.0-dev libssh2-1-dev libtelnet-dev libvncserver-dev libpulse-dev libssl-dev \
libvorbis-dev libwebp-dev ${MYSQL} libmysql-java ${TOMCAT} freerdp-x11 \
ghostscript wget dpkg-dev &amp;&gt;&gt; ${LOG}

if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed. See ${LOG}${NC}&quot;
    exit 1
else
    echo -e &quot;${GREEN}OK${NC}&quot;
fi

# Set SERVER to be the preferred download server from the Apache CDN
SERVER=&quot;http://apache.org/dyn/closer.cgi?action=download&amp;filename=guacamole/${GUACVERSION}&quot;
echo -e &quot;${BLUE}Downloading Files...${NC}&quot;

# Download Guacamole Server
wget -q --show-progress -O guacamole-server-${GUACVERSION}.tar.gz ${SERVER}/source/guacamole-server-${GUACVERSION}.tar.gz
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed to download guacamole-server-${GUACVERSION}.tar.gz&quot;
    echo -e &quot;${SERVER}/source/guacamole-server-${GUACVERSION}.tar.gz${NC}&quot;
    exit 1
fi
echo -e &quot;${GREEN}Downloaded guacamole-server-${GUACVERSION}.tar.gz${NC}&quot;

# Download Guacamole Client
wget -q --show-progress -O guacamole-${GUACVERSION}.war ${SERVER}/binary/guacamole-${GUACVERSION}.war
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed to download guacamole-${GUACVERSION}.war&quot;
    echo -e &quot;${SERVER}/binary/guacamole-${GUACVERSION}.war${NC}&quot;
    exit 1
fi
echo -e &quot;${GREEN}Downloaded guacamole-${GUACVERSION}.war${NC}&quot;

# Download Guacamole authentication extensions (Database)
wget -q --show-progress -O guacamole-auth-jdbc-${GUACVERSION}.tar.gz ${SERVER}/binary/guacamole-auth-jdbc-${GUACVERSION}.tar.gz
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed to download guacamole-auth-jdbc-${GUACVERSION}.tar.gz&quot;
    echo -e &quot;${SERVER}/binary/guacamole-auth-jdbc-${GUACVERSION}.tar.gz&quot;
    exit 1
fi
echo -e &quot;${GREEN}Downloaded guacamole-auth-jdbc-${GUACVERSION}.tar.gz${NC}&quot;

# Download Guacamole authentication extensions (TOTP)
wget -q --show-progress -O guacamole-auth-totp-${GUACVERSION}.tar.gz ${SERVER}/binary/guacamole-auth-totp-${GUACVERSION}.tar.gz
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed to download guacamole-auth-totp-${GUACVERSION}.tar.gz&quot;
    echo -e &quot;${SERVER}/binary/guacamole-auth-totp-${GUACVERSION}.tar.gz&quot;
    exit 1
fi
echo -e &quot;${GREEN}Downloaded guacamole-auth-totp-${GUACVERSION}.tar.gz${NC}&quot;

echo -e &quot;${GREEN}Downloading complete.${NC}&quot;

# Extract Guacamole files
tar -xzf guacamole-server-${GUACVERSION}.tar.gz
tar -xzf guacamole-auth-jdbc-${GUACVERSION}.tar.gz
tar -xzf guacamole-auth-totp-${GUACVERSION}.tar.gz

# Make directories
mkdir -p /etc/guacamole/lib
mkdir -p /etc/guacamole/extensions

# Install guacd
cd guacamole-server-${GUACVERSION}

echo -e &quot;${BLUE}Building Guacamole with GCC $(gcc --version | head -n1 | grep -oP '\)\K.*' | awk '{print $1}') ${NC}&quot;

echo -e &quot;${BLUE}Configuring. This might take a minute...${NC}&quot;
./configure --with-init-dir=/etc/init.d  &amp;&gt;&gt; ${LOG}
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed. See ${LOG}${NC}&quot;
    exit 1
else
    echo -e &quot;${GREEN}OK${NC}&quot;
fi

echo -e &quot;${BLUE}Running Make. This might take a few minutes...${NC}&quot;
make &amp;&gt;&gt; ${LOG}
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed. See ${LOG}${NC}&quot;
    exit 1
else
    echo -e &quot;${GREEN}OK${NC}&quot;
fi

echo -e &quot;${BLUE}Running Make Install...${NC}&quot;
make install &amp;&gt;&gt; ${LOG}
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed. See ${LOG}${NC}&quot;
    exit 1
else
    echo -e &quot;${GREEN}OK${NC}&quot;
fi

ldconfig
systemctl enable guacd
cd ..

# Get build-folder
BUILD_FOLDER=$(dpkg-architecture -qDEB_BUILD_GNU_TYPE)

# Move files to correct locations
mv guacamole-${GUACVERSION}.war /etc/guacamole/guacamole.war
ln -s /etc/guacamole/guacamole.war /var/lib/${TOMCAT}/webapps/
ln -s /usr/local/lib/freerdp/guac*.so /usr/lib/${BUILD_FOLDER}/freerdp/
ln -s /usr/share/java/mysql-connector-java.jar /etc/guacamole/lib/
cp guacamole-auth-jdbc-${GUACVERSION}/mysql/guacamole-auth-jdbc-mysql-${GUACVERSION}.jar /etc/guacamole/extensions/
cp guacamole-auth-totp-${GUACVERSION}/guacamole-auth-totp-${GUACVERSION}.jar /etc/guacamole/extensions/

# Configure guacamole.properties
rm -f /etc/guacamole/guacamole.properties
touch /etc/guacamole/guacamole.properties
echo &quot;mysql-hostname: localhost&quot; &gt;&gt; /etc/guacamole/guacamole.properties
echo &quot;mysql-port: 3306&quot; &gt;&gt; /etc/guacamole/guacamole.properties
echo &quot;mysql-database: ${DB}&quot; &gt;&gt; /etc/guacamole/guacamole.properties
echo &quot;mysql-username: ${mysqluser}&quot; &gt;&gt; /etc/guacamole/guacamole.properties
echo &quot;mysql-password: ${guacdbuserpassword}&quot; &gt;&gt; /etc/guacamole/guacamole.properties

# restart tomcat
echo -e &quot;${BLUE}Restarting tomcat...${NC}&quot;

service ${TOMCAT} restart
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed${NC}&quot;
    exit 1
else
    echo -e &quot;${GREEN}OK${NC}&quot;
fi

# Create guacamole_db and grant $mysqluser permissions to it

# SQL code
SQLCODE=&quot;
create database ${DB};
create user if not exists '${mysqluser}'@'localhost' identified by \&quot;${guacdbuserpassword}\&quot;;
GRANT SELECT,INSERT,UPDATE,DELETE ON guacamole_db.* TO '${mysqluser}'@'localhost';
flush privileges;&quot;

# Execute SQL code
echo ${SQLCODE} | mysql -u root -p${mysqlrootpassword}

# Add Guacamole schema to newly created database
echo -e &quot;Adding db tables...&quot;
cat guacamole-auth-jdbc-${GUACVERSION}/mysql/schema/*.sql | mysql -u root -p${mysqlrootpassword} ${DB}
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed${NC}&quot;
    exit 1
else
    echo -e &quot;${GREEN}OK${NC}&quot;
fi

# Ensure guacd is started
service guacd start

# Cleanup
echo -e &quot;${BLUE}Cleanup install files...${NC}&quot;

rm -rf guacamole-*
if [ $? -ne 0 ]; then
    echo -e &quot;${RED}Failed${NC}&quot;
    exit 1
else
    echo -e &quot;${GREEN}OK${NC}&quot;
fi

echo -e &quot;${BLUE}Installation Complete\nhttp://localhost:8080/guacamole/\nDefault login guacadmin:guacadmin\nBe sure to change the password.${NC}&quot;
</code></pre><p>Give that script the execution right:</p>
<pre><code>chmod +x install_guacamole.sh
</code></pre><p>Install Guacamole:</p>
<pre><code>./install_guacamole.sh
</code></pre><br/>
<h2 id="configure-guacamole">Configure Guacamole</h2>
<p>Create a new user and create 2 connections (one for SSH and one for VNC).
This is very easy I do not describe this part.</p>
<p>At the end you will have this:
<img src="/images/guacamole-home.png" alt="image"></p>
<p><img src="/images/guacamole-ssh.png" alt="image"></p>
<p><img src="/images/guacamole-vnc.png" alt="image"></p>
<br/>
<h2 id="configurer-un-reverse-proxy-nginx">Configurer un reverse proxy Nginx</h2>
<p>Installer Nginx:</p>
<pre><code>apt install nginx
</code></pre><p>Activer le service:</p>
<pre><code>systemctl enable nginx
</code></pre><p>Générer un certificat SSL/TLS auto-signé:</p>
<pre><code>openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/guacamole-selfsigned.key -out /etc/ssl/certs/guacamole-selfsigned.crt
</code></pre><p>Configurer Nginx. Créer le fichier <code>/etc/nginx/sites-available/nginx-guacamole-ssl</code> et ajoutez le contenu suivant:</p>
<pre><code>server {
	listen 80;
	server_name guacamole.example.com;
	return 301 https://$host$request_uri;
}
server {
	listen 443 ssl;
	server_name guacamole.example.com;

	root /var/www/html;

	index index.html index.htm index.nginx-debian.html;
    
    	ssl_certificate /etc/ssl/certs/guacamole-selfsigned.crt;
	ssl_certificate_key /etc/ssl/private/guacamole-selfsigned.key;

	ssl_protocols TLSv1.2 TLSv1.3;
	ssl_prefer_server_ciphers on; 
	ssl_dhparam /etc/nginx/dhparam.pem;
	ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384;
	ssl_ecdh_curve secp384r1;
	ssl_session_timeout  10m;
	ssl_session_cache shared:SSL:10m;
	resolver 192.168.42.129 8.8.8.8 valid=300s;
	resolver_timeout 5s; 
	add_header Strict-Transport-Security &quot;max-age=63072000; includeSubDomains; preload&quot;;
	add_header X-Frame-Options DENY;
	add_header X-Content-Type-Options nosniff;
	add_header X-XSS-Protection &quot;1; mode=block&quot;;

	access_log  /var/log/nginx/guac_access.log;
	error_log  /var/log/nginx/guac_error.log;

	location / {
		    proxy_pass http://guacamole.example.com:8080/guacamole/;
		    proxy_buffering off;
		    proxy_http_version 1.1;
		    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		    proxy_set_header Upgrade $http_upgrade;
		    proxy_set_header Connection $http_connection;
		    proxy_cookie_path /guacamole/ /;
	}

}
</code></pre><p>Générer un certificat Deffie-Hellman pour avoir une clé d'échange. Le flag <code>-dsaparam</code> est ajouté pour accélérer la génération:</p>
<pre><code>openssl dhparam -dsaparam -out /etc/nginx/dhparam.pem 4096
</code></pre><p>Activer la configuration Nginx:</p>
<pre><code>ln -s /etc/nginx/sites-available/nginx-guacamole-ssl /etc/nginx/sites-enabled/
</code></pre><p>Vérifier la bonne configuration:</p>
<pre><code>nginx -t
 nginx: the configuration file /etc/nginx/nginx.conf syntax is ok
 nginx: configuration file /etc/nginx/nginx.conf test is successful
</code></pre><p>Restart Nginx:</p>
<pre><code>systemctl restart nginx
</code></pre><br/>
<h2 id="troubleshooting">Troubleshooting</h2>
<p><strong>Accéder à VNC via le réseau local</strong></p>
<p>Editer le fichier <code>/etc/systemd/system/vncserver@.service</code> et ajouter l'option <code>-localhost no</code> au démarrage du service <code>ExecStart=/usr/bin/vncserver -localhost no ...</code>.</p>
<blockquote>
<p>Utiliser le port 5900 ou 5901</p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Install ohmyzsh on Ubuntu 18.04</title>
            <link>https://leandeep.com/install-ohmyzsh-on-ubuntu-18.04/</link>
            <pubDate>Fri, 05 Jul 2019 12:14:00 +0000</pubDate>
            
            <guid>https://leandeep.com/install-ohmyzsh-on-ubuntu-18.04/</guid>
            <description>We are going to assume that nothing is installed on your Ubuntu. When I created this tutorial I installed ohmyzsh on a brand new Intel Nuc.
 Install Zsh sudo apt-get update sudo apt-get install -y zsh  Install the custom fonts sudo apt-get install -y powerline fonts-powerline  Install Git sudo apt-get install -y git  Install ohmyzsh git clone https://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc  Install custom theme Inside the ~/.</description>
            <content type="html"><![CDATA[<p>We are going to assume that nothing is installed on your Ubuntu. When I created this tutorial I installed ohmyzsh on a brand new Intel Nuc.</p>
<br/>
<h2 id="install-zsh">Install Zsh</h2>
<pre><code>sudo apt-get update
sudo apt-get install -y zsh
</code></pre><br/>
<h2 id="install-the-custom-fonts">Install the custom fonts</h2>
<pre><code>sudo apt-get install -y powerline fonts-powerline
</code></pre><br/>
<h2 id="install-git">Install Git</h2>
<pre><code>sudo apt-get install -y git
</code></pre><br/>
<h2 id="install-ohmyzsh">Install ohmyzsh</h2>
<pre><code>git clone https://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh
cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc
</code></pre><br/>
<h2 id="install-custom-theme">Install custom theme</h2>
<p>Inside the ~/.zshrc file comment the line <code>ZSH_THEME=&quot;robbyrussell&quot;</code> and add this new line just below <code>ZSH_THEME=&quot;agnoster&quot;</code>.</p>
<br/>
<h2 id="change-the-default-shell">Change the default shell</h2>
<pre><code>chsh -s /bin/zsh
</code></pre><blockquote>
<p>Note: You can still revert and go back to bash using the command <code>chsh -s /bin/bash</code>.</p>
</blockquote>
<br/>
<h2 id="plugin-installation">Plugin installation</h2>
<p>In case you want syntax highlighting you can install this plugin:</p>
<pre><code>git clone https://github.com/zsh-users/zsh-syntax-highlighting.git &quot;$HOME/.zsh-syntax-highlighting&quot; --depth 1

echo &quot;source $HOME/.zsh-syntax-highlighting/zsh-syntax-highlighting.zsh&quot; &gt;&gt; &quot;$HOME/.zshrc&quot;
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Install Jupyter Lab on Ubuntu 18.04</title>
            <link>https://leandeep.com/install-jupyter-lab-on-ubuntu-18.04/</link>
            <pubDate>Fri, 05 Jul 2019 12:10:32 +0000</pubDate>
            
            <guid>https://leandeep.com/install-jupyter-lab-on-ubuntu-18.04/</guid>
            <description>In this tutorial we are going to see how to install Jupyter lab. More on this tool here: https://jupyterlab.readthedocs.io/en/stable/
 Install NodeJS We are going to install NVM (Node Version Manager) to manage the install NodeJS version.
sudo apt-get update sudo apt-get install -y curl curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash Add the following commands in your ~/.zshrc file:
export NVM_DIR=&amp;quot;$HOME/.nvm&amp;quot; [ -s &amp;quot;$NVM_DIR/nvm.sh&amp;quot; ] &amp;amp;&amp;amp; \. &amp;quot;$NVM_DIR/nvm.sh&amp;quot; # This loads nvm [ -s &amp;quot;$NVM_DIR/bash_completion&amp;quot; ] &amp;amp;&amp;amp; \.</description>
            <content type="html"><![CDATA[<p>In this tutorial we are going to see how to install Jupyter lab.
More on this tool here: <a href="https://jupyterlab.readthedocs.io/en/stable/">https://jupyterlab.readthedocs.io/en/stable/</a></p>
<br/>
<h2 id="install-nodejs">Install NodeJS</h2>
<p>We are going to install NVM (Node Version Manager) to manage the install NodeJS
version.</p>
<pre><code>sudo apt-get update
sudo apt-get install -y curl
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.34.0/install.sh | bash
</code></pre><p>Add the following commands in your <code>~/.zshrc</code> file:</p>
<pre><code>export NVM_DIR=&quot;$HOME/.nvm&quot;
[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; \. &quot;$NVM_DIR/nvm.sh&quot;  # This loads nvm
[ -s &quot;$NVM_DIR/bash_completion&quot; ] &amp;&amp; \. &quot;$NVM_DIR/bash_completion&quot;  # This loads nvm bash_completion
</code></pre><p>Once it is done do not forget to reload your terminal with <code>source ~/.zshrc</code>.</p>
<p>Then install the lastest LTS NodeJS version:</p>
<pre><code>nvm ls-remote
# Determine the latest LTS. For me it is v10.16.0 when I am writing this tutorial
nvm install v10.16.0
nvm use default v10.16.0
</code></pre><br/>
<p><strong>Install python 3</strong></p>
<pre><code>sudo apt-get update
sudo apt-get install python3
sudo apt-get install python3-pip
</code></pre><br/>
<p><strong>Install jupyterlab</strong></p>
<pre><code>pip3 install jupyterlab
</code></pre><p>If you are using ohmyzsh (and you should !) edit your <code>~/.zshrc</code> file and add the line at the end <code>export PATH=$PATH:~/.local/bin/</code>. Then execute <code>source ~/.zshrc</code>.</p>
<br/>
<p><strong>Verify jupyterlab works</strong></p>
<pre><code>jupyter lab --allow-root --ip=0.0.0.0 --no-browser
</code></pre><br/>
<p><strong>Install extensions hub</strong></p>
<blockquote>
<p>Kill the previously launched server with Ctrl-c</p>
</blockquote>
<pre><code>jupyter labextension install @jupyterlab/hub-extension
jupyter lab build
jupyter lab --allow-root --ip=0.0.0.0 --no-browser
</code></pre><p>Go to &ldquo;Settings&rdquo; &ndash;&gt; &ldquo;Enable Extensions manager (Experimental) to enable the extensions manager.
If you click on the extensions icon that appear on the left menu you should see all available extensions to install.</p>
<br/>
<p><strong>Make Jupyterlab a service</strong></p>
<p>Generate a config file:</p>
<pre><code>jupyter-lab --generate-config
</code></pre><p>Create a working directory:</p>
<pre><code>mkdir -p /home/$USER/Dev/jupyterlab
export WorkingDirectory=/home/$USER/Dev/jupyterlab
</code></pre><p>Generate Service file:</p>
<pre><code>cat &lt;&lt; EOF | sudo tee /etc/systemd/system/jupyter-lab.service
[Unit]
Description=Jupyter Lab
[Service]
Type=simple
PIDFile=/run/jupyter.pid
ExecStart=/home/$USER/.local/bin/jupyter-lab --config=/home/$USER/.jupyter/jupyter_notebook_config.py
WorkingDirectory=$WorkingDirectory
User=$USER
Group=$USER
Restart=always
RestartSec=10
#KillMode=mixed
[Install]
WantedBy=multi-user.target
EOF
</code></pre><p>Reload systemctl daemon after creating service entry:</p>
<pre><code>sudo systemctl daemon-reload
</code></pre><p>Enable Jupyter Lab service:</p>
<pre><code>sudo systemctl enable jupyter-lab.service
</code></pre><p>Start the service:</p>
<pre><code>sudo systemctl start jupyter-lab.service
</code></pre><p>Verify jupyterlab service is working and get access token:</p>
<pre><code>sudo systemctl status jupyter-lab.service
</code></pre><br/>
<p><strong>Add custom Password</strong></p>
<p>Start a Python repl and enter the following commands:</p>
<pre><code>from notebook.auth import passwd
passwd()
</code></pre><p>Copy the hashed password, uncomment the line <code>c.NotebookApp.password</code> and add the password as value.</p>
<p>Restart the service (or container).</p>
<br/>
<p><strong>Custom jupyter conf</strong></p>
<p>It is possible to custom jupyter lab conf with the following commands:</p>
<pre><code># Incoming connection whitelist. tried with IP &amp; CIDR. not sure about ranges. should be comma separated if more than one.
sed -i.back &quot;s/#c.NotebookApp.allow_origin = ''/c.NotebookApp.allow_origin = '10.1.0.0\/24'/&quot; ~/.jupyter/jupyter_notebook_config.py

# Jupyter listening IP. Set to localhost if only planning on using locally.
sed -i &quot;s/#c.NotebookApp.ip = 'localhost'/c.NotebookApp.ip = '$ipAddress'/&quot; ~/.jupyter/jupyter_notebook_config.py

# Whether or not to open browser on jupyter launch. If headless, or server, set to False.
sed -i &quot;s/#c.NotebookApp.open_browser = True/c.NotebookApp.open_browser = False/&quot; ~/.jupyter/jupyter_notebook_config.py

# Listening port. Change if necessary
sed -i &quot;s/#c.NotebookApp.port = 8888/c.NotebookApp.port = 8888/&quot; ~/.jupyter/jupyter_notebook_config.py

# Randomly generated token for access without user/pass
sed -i &quot;s/^#c.NotebookApp.token .*/c.NotebookApp.token = '$token'/&quot; ~/.jupyter/jupyter_notebook_config.py

# Trash Cleanup
sed -i &quot;s/#c.NotebookApp.cookie_secret = b''/#c.NotebookApp.cookie_secret = ''/&quot; ~/.jupyter/jupyter_notebook_config.py
sed -i &quot;s/#c.Session.key = b''/#c.Session.key = ''/&quot; ~/.jupyter/jupyter_notebook_config.py
sed -i &quot;s/#c.NotebookNotary.secret = b''/#c.NotebookNotary.secret = ''/&quot; ~/.jupyter/jupyter_notebook_config.py
</code></pre><br/>
<p>Have fun !</p>
]]></content>
        </item>
        
        <item>
            <title>Convertir tous les fichiers epub d&#39;un répertoire en mobi</title>
            <link>https://leandeep.com/convertir-tous-les-fichiers-epub-dun-r%C3%A9pertoire-en-mobi/</link>
            <pubDate>Thu, 27 Jun 2019 23:00:00 +0000</pubDate>
            
            <guid>https://leandeep.com/convertir-tous-les-fichiers-epub-dun-r%C3%A9pertoire-en-mobi/</guid>
            <description>Voici la commande pour convertir tous les fichiers epub d&#39;un répertoire en fichiers mobi.
En pré-requis, il faut installer le logiciel calibre.
# Pour Linux apt-get install calibre # Pour OSX brew cask install calibre Ensuite, on peut utiliser le script suivant:
for book in *.epub; do echo &amp;quot;Converting $book&amp;quot;; ebook-convert &amp;quot;$book&amp;quot; &amp;quot;$(basename &amp;quot;$book&amp;quot; .epub).mobi&amp;quot;; done </description>
            <content type="html"><![CDATA[<p>Voici la commande pour convertir tous les fichiers epub d'un répertoire en fichiers mobi.</p>
<p>En pré-requis, il faut installer le logiciel calibre.</p>
<pre><code># Pour Linux
apt-get install calibre

# Pour OSX
brew cask install calibre
</code></pre><p>Ensuite, on peut utiliser le script suivant:</p>
<pre><code>for book in *.epub; do echo &quot;Converting $book&quot;; ebook-convert &quot;$book&quot; &quot;$(basename &quot;$book&quot; .epub).mobi&quot;; done
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Commandes custom utiles Openshift</title>
            <link>https://leandeep.com/commandes-custom-utiles-openshift/</link>
            <pubDate>Tue, 25 Jun 2019 09:43:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-custom-utiles-openshift/</guid>
            <description>Lister les utilisateurs ayant le rôle cluster-admin A partir de 3.9:
oc get clusterrolebinding -o json | jq &#39;.items[] | select(.metadata.name | startswith(&amp;quot;cluster-admin&amp;quot;)) | .userNames&#39; Ajouter un rôle cluster à un utilisateur oc adm policy add-cluster-role-to-user &amp;lt;cluster-role&amp;gt; &amp;lt;user&amp;gt; Retirer un rôle cluster à un utilisateur oc adm policy remove-cluster-role-from-user &amp;lt;cluster-role&amp;gt; &amp;lt;user&amp;gt; Lister les pods en erreur (ou n&#39;ayant pas le status Running) oc get pods --all-namespaces | awk &#39;!/Running/ {print}&#39; Lister les pods en erreur par namespace oc get pods --all-namespaces | awk &#39;!</description>
            <content type="html"><![CDATA[<h2 id="lister-les-utilisateurs-ayant-le-rle-cluster-admin">Lister les utilisateurs ayant le rôle cluster-admin</h2>
<p><em>A partir de 3.9</em>:</p>
<pre><code>oc get clusterrolebinding -o json | jq '.items[] | select(.metadata.name |  startswith(&quot;cluster-admin&quot;)) | .userNames'
</code></pre><h2 id="ajouter-un-rle-cluster--un-utilisateur">Ajouter un rôle cluster à un utilisateur</h2>
<pre><code>oc adm policy add-cluster-role-to-user &lt;cluster-role&gt; &lt;user&gt;
</code></pre><h2 id="retirer-un-rle-cluster--un-utilisateur">Retirer un rôle cluster à un utilisateur</h2>
<pre><code>oc adm policy remove-cluster-role-from-user &lt;cluster-role&gt; &lt;user&gt;
</code></pre><h2 id="lister-les-pods-en-erreur-ou-nayant-pas-le-status-running">Lister les pods en erreur (ou n'ayant pas le status Running)</h2>
<pre><code>oc get pods --all-namespaces | awk '!/Running/ {print}'
</code></pre><h2 id="lister-les-pods-en-erreur-par-namespace">Lister les pods en erreur par namespace</h2>
<pre><code>oc get pods --all-namespaces | awk '!/Running/ {print}' | awk 'NR&gt;1{arr[$1]++}END{for (a in arr) print a, arr[a]}' | sort -nrk2
</code></pre><h2 id="ne-garder-que-2-dploiements">Ne garder que 2 déploiements</h2>
<pre><code>oc adm prune deployments --orphans --keep-failed=2 --keep-complete=2  --confirm
</code></pre><h2 id="ne-garder-que-2-builds">Ne garder que 2 builds</h2>
<pre><code>oc adm prune builds --orphans --keep-failed=2 --keep-complete=2  --confirm
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Useful Postgres commands</title>
            <link>https://leandeep.com/useful-postgres-commands/</link>
            <pubDate>Fri, 21 Jun 2019 19:43:00 +0000</pubDate>
            
            <guid>https://leandeep.com/useful-postgres-commands/</guid>
            <description>Here is a list of Postgres basic commands:
Basics \? list all the commands \l list databases \conninfo display information about current connection \c [DBNAME] connect to new database, e.g., \c template1 \dt list tables of the public schema \dt &amp;lt;schema-name&amp;gt;.* list tables of certain schema, e.g., \dt public.* \dt *.* list tables of all schemas Then you can run SQL statements, e.g., SELECT * FROM my_table;(Note: a statement must be terminated with semicolon ;) \q quit psql  I recommand the usage of pgadmin4 to manage your Postgres Databases.</description>
            <content type="html"><![CDATA[<p>Here is a list of Postgres basic commands:</p>
<h2 id="basics">Basics</h2>
<pre><code>\? list all the commands
\l list databases
\conninfo display information about current connection
\c [DBNAME] connect to new database, e.g., \c template1
\dt list tables of the public schema
\dt &lt;schema-name&gt;.* list tables of certain schema, e.g., \dt public.*
\dt *.* list tables of all schemas
Then you can run SQL statements, e.g., SELECT * FROM my_table;(Note: a statement must be terminated with semicolon ;)
\q quit psql
</code></pre><blockquote>
<p>I recommand the usage of pgadmin4 to manage your Postgres Databases.</p>
</blockquote>
<br/>
<h2 id="install-psql-client">Install PSQL Client</h2>
<p><strong>On ubuntu</strong></p>
<pre><code>apt-get update
apt-get install -y postgresql-client
</code></pre><br/>
<h2 id="database">Database</h2>
<p><strong>Connect to specific local DB</strong></p>
<pre><code>psql your_db your_username
</code></pre><br/>
<p><strong>Connect to remote DB</strong></p>
<pre><code>psql -h DB_HOST -p DB_PORT DB_NAME DB_USER
</code></pre><br/>
<p><strong>Dump DB</strong></p>
<pre><code>pg_dump -Fc my_db &gt; /tmp/db.dump

# restore
# pg_restore -d new_db /tmp/db.dump
</code></pre><br/>
<p><strong>Restore DB:</strong></p>
<pre><code>pg_restore path_to_backup_file.backup --dbname=your_db --username=your_username --clean

# -d &lt;=&gt; --dbname
# -U &lt;=&gt; --username
# --clean = clean (drop) database objects before recreating
</code></pre><br/>
<p><strong>Create a DB with a particular role:</strong></p>
<pre><code>CREATE DATABASE your_db
    WITH 
    OWNER = postgres
    ENCODING = 'UTF8'
    CONNECTION LIMIT = -1;
</code></pre><br/>
<p><strong>Drop DB:</strong></p>
<pre><code>drop database your_db;
</code></pre><br/>
<p><strong>Close all sessions:</strong></p>
<pre><code>SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'you_db';
</code></pre><br/>
<p><strong>Truncate all tables from DB</strong></p>
<p><em>(It is as if you remove the data but keep the schema.)</em></p>
<pre><code># Create Schema dump of database (schema-only)
pg_dump your_db -s &gt; schema.sql

# Drop database
drop database your_db;

# Create Database
create database your_db;

4) Import Schema
psql your_db &lt; schema.sql
</code></pre><blockquote>
<p>In case you want to create a script can execute SQL commands the Terminal using the -c flag: <code>$ psql -c &quot;YOUR SQL QUERY;&quot;</code></p>
</blockquote>
<br/>
<h2 id="roles-vs-users-vs-groups">Roles vs Users vs Groups</h2>
<blockquote>
<p>&ldquo;CREATE ROLE&rdquo;, &ldquo;CREATE USER&rdquo;, and &ldquo;CREATE GROUP&rdquo; were different couple of years ago. Since group management has changed these 3 commands are (almost) the same. They all still exist for the sake of compatibility.
There is all the same a slight difference between for example &ldquo;CREATE ROLE&rdquo; and &ldquo;CREATE USER&rdquo;. &ldquo;CREATE ROLE&rdquo; will create a default user that cannot login (NOLOGIN), even though &ldquo;CREATE USER&rdquo; will create a user with the LOGIN attribute. .</p>
</blockquote>
<br/>
<h2 id="roles">Roles</h2>
<p><strong>List roles:</strong></p>
<pre><code>\du

# or 

SELECT
   rolname
FROM
   pg_roles;
</code></pre><br/>
<p><strong>Create a role:</strong></p>
<pre><code>create role your_role
</code></pre><br/>
<h2 id="users">Users</h2>
<p><strong>Create user:</strong></p>
<pre><code>create user your_user with encrypted password 'user_password';
</code></pre><br/>
<p><strong>Grant all priviledges to user on database:</strong></p>
<pre><code>grant all privileges on database your_db to your_user;
</code></pre><br/>
<h2 id="installations">Installations</h2>
<h3 id="on-centos-7">On Centos 7</h3>
<pre><code>yum install postgresql-server postgresql-contrib
# Initialize the DB
postgresql-setup initdb
# Start the service
systemctl start postgresql
# Starts with system
systemctl enable postgresql
Change user to postgres and connect to the client to check if it works
su postgres
psql
\l
</code></pre><br/>
<h3 id="on-osx">On OSX</h3>
<pre><code>brew install postgresql
brew services start postgres
</code></pre><br/>
<h2 id="database-modeler">Database modeler</h2>
<p>It can be very useful to generate the database graph to see all relations betweens tables.</p>
<p>There is a great tool that can help. It is opensource and works perfectly with Postgres 11+. It is called pgmodeler and it is available here:  <a href="https://github.com/pgmodeler/pgmodeler.git">https://github.com/pgmodeler/pgmodeler.git</a></p>
<p>Here is the procedure to install it on OSX. (You need Xcode installed)</p>
<pre><code>brew install qt
echo 'export PATH=&quot;/usr/local/opt/qt/bin:$PATH&quot;' &gt;&gt; ~/.zshrc
source ~/.zshrc
git clone https://github.com/pgmodeler/pgmodeler.git
cd pgmodeler
git checkout the_latest_tag
# Edit the file pgmodeler.pri and replace the variables `PGSQL_LIB = /Library/PostgreSQL/11/lib/libpq.dylib` and `PGSQL_INC = /Library/PostgreSQL/11/include` with respectively `PGSQL_LIB = /usr/local/Cellar/postgresql/11.4/lib/libpq.dylib` and `PGSQL_INC = /usr/local/Cellar/postgresql/11.4/include`
qmake -r CONFIG+=release pgmodeler.pro
make &amp;&amp; make install
open /Applications/pgmodeler.app
</code></pre><br/>
<h2 id="great-python-orm">Great Python ORM</h2>
<p><strong>SQLAlchemy</strong> is a great Python ORM.
Here are few useful links to manage to model your Postgres DB using Python and this library:
<a href="https://docs.sqlalchemy.org/en/13/orm/basic_relationships.html">https://docs.sqlalchemy.org/en/13/orm/basic_relationships.html</a></p>
]]></content>
        </item>
        
        <item>
            <title>Custom Python Packages with AWS lambda and CDK</title>
            <link>https://leandeep.com/custom-python-packages-with-aws-lambda-and-cdk/</link>
            <pubDate>Tue, 18 Jun 2019 21:27:00 +0000</pubDate>
            
            <guid>https://leandeep.com/custom-python-packages-with-aws-lambda-and-cdk/</guid>
            <description>Introduction The purpose of this article is to describe how to execute Python code with custom packages on AWS Lambda. Since there is no way to execute a pip install on lambda when you use the inline code feature you cannot use external packages. So you are very limited. Fortunately there is a work around (as usual with AWS). You can package your app with its dependences in a zip file and upload it directly on Lambda.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>The purpose of this article is to describe how to execute Python code with custom packages on <strong>AWS Lambda</strong>. Since there is no way to execute a <code>pip install</code> on lambda when you use the inline code feature you cannot use external packages. So you are very limited.
Fortunately there is a work around (as usual with AWS). You can package your app with its dependences in a zip file and upload it directly on Lambda. If you use a deployment script (.sh or Makefile) and <strong>AWS CDK</strong> like I do it becomes very easy to make Lambda execute any Python code.</p>
<br/>
<h2 id="docker">Docker</h2>
<p>I use Docker and an <code>Amazon AMI Linux</code> base image to build everything. At least I am sure that everything I build fits the target execution environment (AWS Lambda).</p>
<p>Dockerfile example:</p>
<pre><code>FROM amazonlinux:latest

RUN yum update -y 
RUN yum install -y gcc-c++ pkgconfig python3-devel redhat-rpm-config python3-pip

RUN mkdir -p /app
ADD requirements-prod.txt /app/requirements.txt
ADD my_script.py /app

WORKDIR /app
RUN pip3 install -t . -Ur requirements.txt
RUN zip -r zip.zip . 

CMD python3 my_script.py
</code></pre><p>I use this Docker image to deploy on AWS Lambda and also run my Python script locally if neccessary.
As you can see the pip dependences are installed in the current directory /app and everything is zipped to be deployed on AWS Lambda.</p>
<br/>
<h2 id="deployment">Deployment</h2>
<p>With few basic commands and a CDK script it becomes handy to automate the whole deployment of your AWS infrastructure and create a Lambda function that will use your previously generated zip file containing your Python code with custom dependences.</p>
<p>Here is an example of deployment script you can write:</p>
<pre><code># Create the Docker image based on Amazonlinux
docker build -t lambda-function .

# Verify the function works and creates a container to produce a zip file
docker run -it lambda-function

# Get the last container ID
container_id=`docker ps --last 1 --format &quot;{{.ID}}&quot;`

# Print the last container ID
echo $container_id

# Copy the zip.zip file from the Docker container to the host
docker cp $container_id:/app/zip.zip .

# Deploy the AWS infra with AWS Lambda function. The latter will use the zip.zip file located inside the current directory of the host
cdk deploy --require-approval=never 
</code></pre><p>Here is a CDK script example to deploy an AWS Lambda function with a zip file. In the following example the zip file is located locally. It could have been located in AWS S3.</p>
<blockquote>
<p>I use the package version 0.31.0 for aws-cdk.aws-lambda and aws-cdk.cdk</p>
</blockquote>
<pre><code>from aws_cdk import (
    aws_lambda as lambda_,
    cdk,
)

class BonjourExampleLambda(cdk.Stack):
    def __init__(self, scope: cdk.Construct, id: str, **kwargs) -&gt; None:
        super().__init__(scope, id, *kwargs)
        
		lambdaFn = lambda_.Function(
    		self,
		    &quot;exampleLambda&quot;,
		    code=lambda_.Code.asset(&quot;zip.zip&quot;),
		    handler=&quot;my_script.main_function_to_call&quot;,
		    timeout=30,
		    runtime=lambda_.Runtime.PYTHON37,
            tracing=lambda_.Tracing.Active,
		)
  
app = cdk.App()
BonjourExampleLambda(app, &quot;Example-lambda-cdk&quot;)
app.run()

</code></pre><blockquote>
<p>If some of your dependences require shared objects (<code>*.so</code> files) to work you can also create one or few &ldquo;Layer(s)&rdquo; that contain the <code>*.so</code> files. AWS Lambda will use them and your dependences should work.</p>
</blockquote>
<br/>
<h2 id="conclusion">Conclusion</h2>
<p><strong>Firstly use AWS CDK ! Secondly if you need to execute custom packages on Lambda you can ! Docker is great alternative (with AWS Fargate if you want to manage nothing) but it is not always the best solution. It depends on your team, your skills, your budget and above all your use case&hellip;</strong></p>
<p>Obviously this is a simple example but you could build a pretty cool and modern architecture with these tools. This is especially true if you investigate in the AWS CDK (that use AWS Cloud Formation under the hood)&hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Dependency Injection in Python</title>
            <link>https://leandeep.com/dependency-injection-in-python/</link>
            <pubDate>Wed, 12 Jun 2019 19:28:00 +0000</pubDate>
            
            <guid>https://leandeep.com/dependency-injection-in-python/</guid>
            <description>Introduction There are many articles available online that talk about dependency injection (DI) in Python. Most of them suggest complexe methods for something that can be finally very easy to do using the built-in Python mechanisms.
Working with dependency injection is a good thing since it makes your code more testable and decoupled.
To implement dependency injection we are going to use the super method. Super calls the next dependency in the Method Resolution Order.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>There are many articles available online that talk about dependency injection (DI) in Python.
Most of them suggest complexe methods for something that can be finally very easy to do using the built-in Python mechanisms.</p>
<p>Working with dependency injection is a good thing since it makes your code more testable and decoupled.</p>
<p>To implement dependency injection we are going to use the <code>super</code> method. Super calls the next dependency in the <strong><a href="https://en.wikipedia.org/wiki/C3_linearization">Method Resolution Order</a></strong>.</p>
<br/>
<h2 id="example">Example</h2>
<p>Let's say I am developing an (kind of) autonomous surveillance camera composed of a RC car with a camera on top of it.</p>
<p>I have the following class to steer my car:</p>
<p><em>Create a file autonomous_surveillance_car.py</em></p>
<pre><code>class Car(object):
    &quot;&quot;&quot;
    Class that can drive a RCC car
    &quot;&quot;&quot;

    def turn_on(self):
        print(&quot;Starting car...&quot;)

    def move_forward(self):
        print(&quot;Going forward...&quot;)

    def move_backward(self):
        print(&quot;Going backward...&quot;)

    def turn_right(self):
        print(&quot;Turning right...&quot;)

    def turn_left(self):
        print(&quot;Turning left...&quot;)


class AutonomousCar(Car):
    &quot;&quot;&quot;
    Automates the car directions to spy the house
    &quot;&quot;&quot;

    def spy(self, times=10):
        super().turn_on()
        for i in range(times):
            super().move_forward()
            super().turn_right()
            super().move_forward()
            super().turn_right()
            super().move_forward()
            super().turn_right()
            super().move_forward()
            super().turn_right()
            # sleep x minutes


if __name__ == '__main__':
    auto_car = AutonomousCar()
    auto_car.spy()

</code></pre><p>Now I want to write tests for my autonomous car class car but I don't want that my car starts going forward. This can be dangerous. I want to use a Mock. But I don't want to modify the <code>AutonomousCar(Car)</code> line and replace the <code>Car</code> dependency with something like <code>MockCar</code> when I want to execute my tests.</p>
<p>The solution is to use a dependency injection:</p>
<p><em>Create a file called test_autonomous_surveillance_car.py</em></p>
<pre><code>import unittest
from autonomous_surveillance_car import AutonomousCar, Car


class MockCar(Car):
    &quot;&quot;&quot;
    Simulates a read RC car by recording tasks
    &quot;&quot;&quot;

    def __init__(self):
        self.tasks = []

    def turn_on(self):
        self.tasks.append(&quot;Turning on car&quot;)

    def move_forward(self):
        self.tasks.append(&quot;Going forward&quot;)

    def move_backward(self):
        self.tasks.append(&quot;Going backward&quot;)

    def turn_right(self):
        self.tasks.append(&quot;Turning right&quot;)

    def turn_left(self):
        self.tasks.append(&quot;Turning left&quot;)


class MockedAutonomousCar(AutonomousCar, MockCar):
    &quot;&quot;&quot;
    Inject a mock car into the car dependency
    &quot;&quot;&quot;


class TestAutonomousCar(unittest.TestCase):

    def test_spy(self):
        mocked_auto_car = MockedAutonomousCar()
        mocked_auto_car.spy()
        expected = ([&quot;Turning on car&quot;] +
                    [&quot;Going forward&quot;, &quot;Turning right&quot;] * 40)
        self.assertEqual(mocked_auto_car.tasks, expected)


if __name__ == &quot;__main__&quot;:
    unittest.main()

</code></pre><p>Now execute the test:</p>
<pre><code>python -i test_autonomous_surveillance_car.py
</code></pre><p>Result:</p>
<pre><code>.
----------------------------------------------------------------------
Ran 1 test in 0.000s

OK
</code></pre><p>In the prompt type <code>help(MockedAutonomousCar)</code>.</p>
<p>You will see the Method Resolution Order (the dependencies order used when <code>super</code> is called) of the <code>MockedAutonomousCar</code> Class:</p>
<pre><code>Help on class MockedAutonomousCar in module __main__:

class MockedAutonomousCar(autonomous_surveillance_car.AutonomousCar, MockCar)
 |  Inject a mock car into the car dependency
 |
 |  Method resolution order:
 |      MockedAutonomousCar
 |      autonomous_surveillance_car.AutonomousCar
 |      MockCar
 |      autonomous_surveillance_car.Car
 |      builtins.object
 |

...

</code></pre><br/>
<h2 id="conclusion">Conclusion</h2>
<p>We see that our <code>MockedAutonomousCar</code> class uses depends on <code>autonomous_surveillance_car.AutonomousCar</code> class that depends on <code>MockCar</code> class. It does not depends on the <code>Car</code> class and we did not change our codebase. Moreover the implementation was very easy and just took 1 line of code.</p>
]]></content>
        </item>
        
        <item>
            <title>Passer de oh-my-zsh à oh-my-fish</title>
            <link>https://leandeep.com/passer-de-oh-my-zsh-%C3%A0-oh-my-fish/</link>
            <pubDate>Thu, 23 May 2019 15:07:00 +0000</pubDate>
            
            <guid>https://leandeep.com/passer-de-oh-my-zsh-%C3%A0-oh-my-fish/</guid>
            <description>Dans cet article nous allons voir comment configurer le terminal Fish sur Mac.
 Si Homebrew n&#39;est pas déjà installé sur votre poste, faites le via la commande. It&#39;s worth it ! /usr/bin/ruby -e &amp;quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&amp;quot;
 Pourquoi je teste Fish Shell ? Pour ces features:
- Autosuggestions as you type - Syntax highlighting with extensive error checking. - Searchable command history. - 256 terminal colors - Advanced tab completion.</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons voir comment configurer le terminal Fish sur Mac.</p>
<blockquote>
<p>Si Homebrew n'est pas déjà installé sur votre poste, faites le via la commande. It's worth it ! <code>/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;</code></p>
</blockquote>
<h1 id="pourquoi-je-teste-fish-shell-">Pourquoi je teste Fish Shell ?</h1>
<p>Pour ces features:</p>
<pre><code>- Autosuggestions as you type
- Syntax highlighting with extensive error checking.
- Searchable command history.
- 256 terminal colors
- Advanced tab completion.
- Web-based configuration
- A special help command gives access to all the fish documentation in the user’s web browser
- Error messages designed to actually tell the user what went wrong and what can be done about it
- Universal variables
- Support for the X clipboard
- Change fish setting by editing the ~/.config/fish/config.fish file
- Man page completions
- Fully scriptable with syntax that is simple, clean, and consistent
- Features work out of the box without any configuration
</code></pre><h1 id="installation-de-oh-my-fish">Installation de oh-my-fish</h1>
<h2 id="installer-fish">Installer Fish</h2>
<pre><code>brew install fish

# Ajoutez fish shell dans la liste des terminaux sur Mac
echo &quot;/usr/local/bin/fish&quot; | sudo tee -a /etc/shells

# Configurez fish pour qu'il soit utilisé par défaut
chsh -s /usr/local/bin/fish

# Si vous voulez retourner à zsh ou autre 
# $ cat /etc/shells
# $ chsh -s /bin/zsh ## pour retourner à zsh
</code></pre><h2 id="installer-oh-my-fish">Installer oh-my-fish</h2>
<pre><code>curl -L https://get.oh-my.fish | fish
</code></pre><h2 id="installer-bob-the-fish-theme">Installer &ldquo;bob the fish&rdquo; theme</h2>
<pre><code>omf install bobthefish

# Installer les fonts utilisées par le thème
brew tap caskroom/fonts
brew cask install font-firacode-nerd-font

# ou si la dernière commande ne fonctionne pas
# brew install homebrew/cask-fonts/font-firacode-nerd-font
set -U theme_nerd_fonts yes
</code></pre><h2 id="configurer-la-font-pour-le-terminal">Configurer la font pour le Terminal</h2>
<p>Dans l'apparence du terminal sélectionnez la police <code>FuraCode Nerd Font</code> en Regular taille 14.</p>
<h2 id="configurer-la-font-pour-vscode">Configurer la font pour VSCode</h2>
<p>Aller dans les préférences et cliquez sur settings. Cliquez sur le bouton pour éditer directement les settings au format json (on ne perd pas de temps) et ajoutez les lignes suivantes au JSON:</p>
<pre><code>&quot;terminal.integrated.shell.osx&quot;: &quot;/usr/local/bin/fish&quot;,
&quot;terminal.integrated.fontSize&quot;: 14,
&quot;terminal.integrated.fontFamily&quot;: &quot;FuraCode Nerd Font&quot;
</code></pre><p>Cela donne ceci pour le terminal intégré à VSCode :</p>
<p><img src="/images/vscode_terminal.png" alt="image"></p>
<p>Pas mal !</p>
<h1 id="advanced-tips">Advanced Tips</h1>
<h2 id="installer-des-plugins">Installer des plugins</h2>
<p>Avec fisher <a href="https://github.com/jorgebucaran/fisher">https://github.com/jorgebucaran/fisher</a>
Voici une liste de plugins <a href="https://github.com/jorgebucaran/awesome-fish">https://github.com/jorgebucaran/awesome-fish</a></p>
<pre><code>curl https://git.io/fisher --create-dirs -sLo ~/.config/fish/functions/fisher.fish

# Puis 
fisher add jorgebucaran/fish-nvm
fisher add kennethreitz/fish-pipenv

# Uninstall plugin: fisher rm jorgebucaran/fish-nvm
</code></pre><p>Reload la config Fish</p>
<pre><code>source ~/.config/fish/config.fish
</code></pre><h2 id="custom-thme">Custom thème</h2>
<p>Forkez le thème bob the fish et customizez le. Le README est très bien fait.</p>
<pre><code>https://github.com/oh-my-fish/theme-bobthefish
</code></pre><h2 id="dmarrer-des-sessions-tmux-automatiquement-dans-iterm2">Démarrer des sessions tmux automatiquement dans iTerm2</h2>
<blockquote>
<p>Vérifiez que tmux est bien installé <code>brew install tmux</code></p>
</blockquote>
<pre><code>omf install tmux-zen

# to uninstall tmux-zen
# omf uninstall tmux-zen
</code></pre><h2 id="les-autres-utilitaires-indispensables">Les autres utilitaires indispensables</h2>
<p>A mettre dans un fichier bash ceci en haut: <code>#!/usr/bin/env bash</code></p>
<pre><code># Install Xcode Command Line Tools.
xcode-select --install

# Install Homebrew.
/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;


# Install brew basics (auto-updating).
brew install terminal-notifier
brew tap domt4/autoupdate
brew autoupdate --start --upgrade --cleanup --enable-notifications

brew install terraform
brew install caskroom/cask/virtualbox
brew install caskroom/cask/minikube
brew install openshift-cli
brew install kubernetes-cli
brew install kubernetes-helm

# Downloader
brew install youtube-dl
brew install wget

brew install fish
brew install grc
brew install direnv
brew install nnn
brew install thefuck
brew install autojump
brew install googler
brew install mas
brew install htop
brew install neofetch
brew install mosh

brew install pipenv

# Install git utilities.
brew install git-open
brew install gist

# Install fun stuff.
brew install fortune
brew install cowsay
brew install sl
gem install lolcat

# Install network utilities
brew install sshuttle
npm install --global speed-test
brew install tor
brew install torsocks
brew install telnet

# Twitter utilities.
gem install t

# AWS
brew install amazon-ecs-cli
brew install awscli

# Video
brew install ffmpeg

# Blog
brew install hugo
npm install -g hexo

# Dev
npm i -g http-server
brew install mongodb
brew install tree
brew install watch
</code></pre>]]></content>
        </item>
        
        <item>
            <title>VSCode et les pipenv</title>
            <link>https://leandeep.com/vscode-et-les-pipenv/</link>
            <pubDate>Wed, 22 May 2019 18:19:00 +0000</pubDate>
            
            <guid>https://leandeep.com/vscode-et-les-pipenv/</guid>
            <description>Introduction Pipenv est un super utilitaire pour pouvoir gérer facilement les dépendances de ses projets avec des environnements virtuels. C&#39;est l&#39;équivalent de npm en NodeJS. Il est un peu plus avancé que les virtualenv.
Voici comment utiliser pipenv avec Visual Studio Code.
Virtual environment création &amp;amp; pipenv installation Imaginez que vous cloniez un projet qui contient un fichier Pipfile. La première chose à faire est d&#39;excuter la commande pipenv install --dev --python version_installee_par_pyenv.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p><code>Pipenv</code> est un super utilitaire pour pouvoir gérer facilement les dépendances de ses projets avec des environnements virtuels.
C'est l'équivalent de <code>npm</code> en NodeJS. Il est un peu plus avancé que les <code>virtualenv</code>.</p>
<p>Voici comment utiliser pipenv avec Visual Studio Code.</p>
<h2 id="virtual-environment-cration--pipenv-installation">Virtual environment création &amp; pipenv installation</h2>
<p>Imaginez que vous cloniez un projet qui contient un fichier Pipfile. La première chose à faire est d'excuter la commande <code>pipenv install --dev --python version_installee_par_pyenv</code>. Cette commande va créer un environnement virtuel dans le répertoire suivant: <code>~/.local/share/virtualenvs/</code></p>
<blockquote>
<p>Bien sûr pipenv doit être installé sur votre poste. Pour se faire, il suffit d'exécuter la commande suivante: <code>pip3 install --user pipenv</code>.</p>
</blockquote>
<h2 id="pyenv">pyenv</h2>
<p>Pyenv vous permet d'installer des versions de Python très facilement. C'est l'équivalent de <code>nvm</code> en NodeJS.</p>
<p>Par exemple <code>pyenv install 3.7.1</code> permet de télécharger et d'installer Python 3.7.1 sur son poste.</p>
<blockquote>
<p>Note: zlib et sqlite sont nécessaires pour que pyenv fonctionne. Il faut exécuter les commandes suivantes: <code>brew install zlib</code> et <code>brew install sqlite</code></p>
</blockquote>
<blockquote>
<p>Si vous utilisez Fish Shell la config suivante est à ajouter dans votre fichier <code>~/.config/fish/config.fish</code>:</p>
</blockquote>
<pre><code># pyenv
export PYENV_ROOT=&quot;$HOME/.pyenv&quot;
export PATH=&quot;$PYENV_ROOT/bin:$PATH&quot;
#pyenv init - | source ## permet de démarrer un virtualenv au démarrage d'une session d'un terminal
#pyenv rehash &gt;/dev/null ^&amp;1

# Build python

# For compilers to find zlib and sqlite you may need to set:
export LDFLAGS=&quot;$LDFLAGS -L/usr/local/opt/zlib/lib&quot;
export LDFLAGS=&quot;$LDFLAGS -L/usr/local/opt/sqlite/lib&quot;
export CPPFLAGS=&quot;$CPPFLAGS -I/usr/local/opt/zlib/include&quot;
export CPPFLAGS=&quot;$CPPFLAGS -I/usr/local/opt/sqlite/include&quot;

# For pkg-config to find zlib and sqlite you may need to set:
export PKG_CONFIG_PATH=&quot;$PKG_CONFIG_PATH /usr/local/opt/zlib/lib/pkgconfig&quot;
export PKG_CONFIG_PATH=&quot;$PKG_CONFIG_PATH /usr/local/opt/sqlite/lib/pkgconfig&quot;
</code></pre><h2 id="vscode-config">VSCode config</h2>
<p>Exécutez la commande suivante pour configurer VSCode pour votre projet:</p>
<pre><code>mkdir .vscode &amp;&amp; touch .vscode/settings.json
</code></pre><p><strong>Contenu du fichier settings.json</strong>. Je suppose que vos tests sont réalisés avec Pytest:</p>
<pre><code>{
    &quot;python.testing.unittestEnabled&quot;: false,
    &quot;python.testing.nosetestsEnabled&quot;: false,
    &quot;python.testing.pyTestEnabled&quot;: true,
    &quot;files.exclude&quot;: {
        &quot;**/.git&quot;: true,
        &quot;**/.svn&quot;: true,
        &quot;**/.hg&quot;: true,
        &quot;**/CVS&quot;: true,
        &quot;**/.DS_Store&quot;: true,
        &quot;**/*.pyc&quot;: true,
        &quot;**/__pycache__&quot;: true
    },
    &quot;python.pythonPath&quot;: &quot;/Users/olivier/.local/share/virtualenvs/requests-aKdvsJ14/bin/python&quot;
}
</code></pre><p>Remplacez <code>/Users/olivier/.local/share/virtualenvs/requests-aKdvsJ14/bin/python</code> par votre propre virtualenv créé lors de l'exécution de la commande <code>pipenv install --dev --python version_installee_par_pyenv</code>. Pour connaître le path de votre virtualenv vous pouvez utiliser la commande <code>pipenv --py</code>.</p>
<blockquote>
<p>Note: Si un terminal était déjà ouvert dans VSCode et que le virtualenv n'a pas été pris en compte, on peut utiliser la commande <code>pipenv shell</code> pour basculer dessus.</p>
</blockquote>
<p>Et voilà c'est tout, c'est simple !</p>
<blockquote>
<p>Si vous allez dans l'onglet Tests dans VScode et que vos tests sont automatiquement détectés, c'est que tout est bien configuré.</p>
</blockquote>
<h2 id="alternative-virtualenvwrapper">Alternative (virtualenvwrapper)</h2>
<p>Utiliser Virtualenvwrapper <a href="https://virtualenvwrapper.readthedocs.io">https://virtualenvwrapper.readthedocs.io</a>. Cela fonctionne extrèmement bien.</p>
<p>Pour créer un environnement il suffit d'utiliser la commande suivante:</p>
<pre><code>mkvirtualenv -p /usr/local/bin/python3.7 -a . ai_env
</code></pre><p>Pour dire à VSCode de proposer un interprêteur Python créé dans un virtualenv(wrapper) lorsque l'on exécute la commande <code>cmd + shift + p --&gt; Python: Select interpreter</code>, il suffit de lui ajouter la variable globale ci-dessous et de le redémarrer.</p>
<pre><code>&quot;python.venvPath&quot;: &quot;$HOME/.virtualenvs&quot;,

# ou un autre répertoire si vous avez configuré autre chose comme répertoire par défaut pour virtualenvwrapper dans votre ~/.zshrc...
</code></pre><h2 id="quick-tip">Quick tip</h2>
<p>Il est possible de convertir un fichier <code>Pipfile.lock</code> en <code>requirements.txt</code> grâce à la commande suivante:</p>
<pre><code>jq -r '.default
        | to_entries[]
        | .key + .value.version' \
    Pipfile.lock &gt; requirements.txt
    
</code></pre><p>Le petit alias qui va bien pour son <code>~/.zshrc</code>:</p>
<pre><code>alias pipfile_to_requirements='
jq -r &quot;.default
        | to_entries[]
        | .key + .value.version&quot; \
    Pipfile.lock &gt; requirements.txt'

</code></pre>]]></content>
        </item>
        
        <item>
            <title>Deployer une image Docker sur AWS Fargate</title>
            <link>https://leandeep.com/deployer-une-image-docker-sur-aws-fargate/</link>
            <pubDate>Tue, 07 May 2019 21:17:00 +0000</pubDate>
            
            <guid>https://leandeep.com/deployer-une-image-docker-sur-aws-fargate/</guid>
            <description>Voici la procédure pour déployer des containers Docker sur Fargate.
Rôle ecsTaskExecutionRole Vérifier l&#39;existance de ce rôle dans l&#39;IAM. S&#39;il n&#39;existe pas, il faut le créer:
Créer un fichier appelé task-execution-assume-role.json avec ce contenu:
{ &amp;quot;Version&amp;quot;: &amp;quot;2012-10-17&amp;quot;, &amp;quot;Statement&amp;quot;: [ { &amp;quot;Sid&amp;quot;: &amp;quot;&amp;quot;, &amp;quot;Effect&amp;quot;: &amp;quot;Allow&amp;quot;, &amp;quot;Principal&amp;quot;: { &amp;quot;Service&amp;quot;: &amp;quot;ecs-tasks.amazonaws.com&amp;quot; }, &amp;quot;Action&amp;quot;: &amp;quot;sts:AssumeRole&amp;quot; } ] } Créer une tâche d&#39;exécution de rôle:
aws iam --region eu-west-1 create-role --role-name ecsTaskExecutionRole --assume-role-policy-document file://task-execution-assume-role.json Attacher la tâche d&#39;exécution de rôle:</description>
            <content type="html"><![CDATA[<p>Voici la procédure pour déployer des containers Docker sur Fargate.</p>
<h2 id="rle-ecstaskexecutionrole">Rôle ecsTaskExecutionRole</h2>
<p>Vérifier l'existance de ce rôle dans l'IAM.
S'il n'existe pas, il faut le créer:</p>
<p>Créer un fichier appelé <code>task-execution-assume-role.json</code> avec ce contenu:</p>
<pre><code>{
  &quot;Version&quot;: &quot;2012-10-17&quot;,
  &quot;Statement&quot;: [
    {
      &quot;Sid&quot;: &quot;&quot;,
      &quot;Effect&quot;: &quot;Allow&quot;,
      &quot;Principal&quot;: {
        &quot;Service&quot;: &quot;ecs-tasks.amazonaws.com&quot;
      },
      &quot;Action&quot;: &quot;sts:AssumeRole&quot;
    }
  ]
}
</code></pre><p>Créer une tâche d'exécution de rôle:</p>
<pre><code>aws iam --region eu-west-1 create-role --role-name ecsTaskExecutionRole --assume-role-policy-document file://task-execution-assume-role.json
</code></pre><p>Attacher la tâche d'exécution de rôle:</p>
<pre><code>aws iam --region eu-west-1 attach-role-policy --role-name ecsTaskExecutionRole --policy-arn arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy
</code></pre><h2 id="configurer-aws-cli-et-ecs-cli">Configurer AWS cli et ecs cli</h2>
<pre><code># Pour OSX
brew upgrade amazon-ecs-cli
brew upgrade awscli

rm -rf ~/.ecs # ou mv ~/.ecs ...

export PROJECT_NAME=xxxxxxxxxxxxx

# Création d'un profil
ecs-cli configure profile --access-key $AWS_ACCESS_KEY_ID --secret-key $AWS_SECRET_ACCESS_KEY --profile-name $PROJECT_NAME
</code></pre><h2 id="cration-dun-cluster">Création d'un cluster</h2>
<pre><code>ecs-cli configure --cluster $PROJECT_NAME --region eu-west-1 --default-launch-type FARGATE --config-name $PROJECT_NAME

ecs-cli up
</code></pre><p>Output:</p>
<pre><code>...
VPC created: vpc-xxxxxxxxxx
Subnet created: subnet-xxxxxxxxx
Subnet created: subnet-xxxxxxxxx
Cluster creation succeeded.
</code></pre><h2 id="cration-dun-securitygroup">Création d'un securitygroup</h2>
<pre><code>export VPC_ID=&quot;vpc-xxxxxxxxxxxxxxxxxxx&quot;

# securitygroup name
export SG_NAME=&quot;xxxxxxxxxxxxx-sg&quot;

export SG_DESCRIPTION=&quot;xxxxxxxxxx xxxxxx xxx security group&quot;

aws ec2 create-security-group --group-name $SG_NAME --description $SG_DESCRIPTION --vpc-id $VPC_ID
</code></pre><p>Output:</p>
<pre><code>{
    &quot;GroupId&quot;: &quot;sg-xxxxxxxxxxxxxxx&quot;
}
</code></pre><h2 id="cration-rgle-ingress">Création règle Ingress</h2>
<pre><code>export SG_GROUP_ID=&quot;sg-xxxxxxxxxxxxxxxxx&quot;

aws ec2 authorize-security-group-ingress --group-id $SG_GROUP_ID --protocol tcp --port 8080 --cidr 0.0.0.0/0
</code></pre><h2 id="configuration-docker-et-ressources">Configuration Docker et Ressources</h2>
<p>Créer un fichier <code>docker-compose.yml</code></p>
<pre><code>version: '3'
services:
  SERVICE_NAME_IE_WP:
    image: IMAGE_DOCKER
    ports:
      - &quot;8080:8080&quot;
    logging:
      driver: awslogs
      options: 
        awslogs-group: PROJECT_NAME
        awslogs-region: eu-west-1
        awslogs-stream-prefix: SERVICE_NAME_IE_WP

</code></pre><p>Créer un fichier <code>ecs-params.yml</code>:</p>
<pre><code>version: 1
task_definition:
  task_execution_role: ecsTaskExecutionRole
  ecs_network_mode: awsvpc
  task_size:
    mem_limit: 0.5GB
    cpu_limit: 256
run_params:
  network_configuration:
    awsvpc_configuration:
      subnets:
        - &quot;subnet-xxxxxxxxxxxxxxxxx&quot;
        - &quot;subnet-xxxxxxxxxxxxxxxxx&quot;
      security_groups:
        - &quot;sg-xxxxxxxxxxxxxxxxxx&quot;
      assign_public_ip: ENABLED

</code></pre><h2 id="dploiement-sur-fargate">Déploiement sur Fargate:</h2>
<pre><code>ecs-cli compose --project-name $PROJECT_NAME service up --create-log-groups --cluster-config $PROJECT_NAME
</code></pre><p>Pour updater le container, il suffit de réexécuter la commande ci-dessus. Une nouvelle version de la task déployée se créera et l'ancienne sera éteinte.</p>
<blockquote>
<p>Note: Pour ajouter une instance RDS et l'utiliser dans le container, le plus simple est de créer l'instance RDS dans le VPC du container. Puis il faudra créer une rêgle dans le securitygroup créé précédemment et réutilisant la commande suivante: <code> aws ec2 authorize-security-group-ingress --group-id $SG_GROUP_ID --protocol tcp --port 5432 --cidr 0.0.0.0/0</code></p>
</blockquote>
<p>Rien de plus simple et le tarif est intéressant: <a href="https://aws.amazon.com/fr/fargate/pricing/">https://aws.amazon.com/fr/fargate/pricing/</a></p>
<h2 id="troubleshooting">Troubleshooting</h2>
<p><strong>Restart task:</strong></p>
<blockquote>
<p>Attention l'IP publique sera modifiée.</p>
</blockquote>
<pre><code>export SERVICE_NAME=xxxx
export CLUSTER_NAME=xxxx

aws ecs update-service --force-new-deployment --cluster $CLUSTER_NAME --service $SERVICE_NAME
</code></pre><h2 id="tip-useful-bash-functions">Tip: Useful bash functions</h2>
<pre><code>stop_running_tasks() {
    tasks=$(aws ecs list-tasks --cluster $CLUSTER --service $SERVICE | $JQ &quot;.taskArns | . []&quot;);
    tasks=( $tasks )
    for task in &quot;${tasks[@]}&quot;
    do
        [[ ! -z &quot;$task&quot; ]] &amp;&amp; stop_task=$(aws ecs stop-task --cluster $CLUSTER --task &quot;$task&quot;)
    done
}

push_ecr_image(){
    echo &quot;Push built image to ECR&quot;
    eval $(aws ecr get-login --region us-east-1)
    docker push $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/repository:$TAG
}

configure_aws_cli(){
    aws --version
    aws configure set default.region us-east-1
    aws configure set default.output json
}

start_tasks() {
    start_task=$(aws ecs start-task --cluster $CLUSTER --task-definition $DEFINITION --container-instances $EC2_INSTANCE --group $SERVICE_GROUP --started-by $SERVICE_ID)
    echo &quot;$start_task&quot;
}
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer Rancher 2 sur Centos 7 (Dev setup)</title>
            <link>https://leandeep.com/installer-rancher-2-sur-centos-7-dev-setup/</link>
            <pubDate>Sun, 05 May 2019 19:00:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-rancher-2-sur-centos-7-dev-setup/</guid>
            <description>Please note that this setup is not recommended for production use, but can be convenient for development/demo purposes.
Docker installation Install needed packages:
$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2 Configure the docker-ce repo:
$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo Install docker-ce:
$ sudo yum install docker-ce Create Docker group:
$ sudo groupadd docker It appeared that docker.sock was owned by root and in the group root:
$ ls -l /var/run/docker.</description>
            <content type="html"><![CDATA[<p><strong>Please note that this setup is not recommended for production use, but can be convenient for development/demo purposes.</strong></p>
<h2 id="docker-installation">Docker installation</h2>
<p><em>Install needed packages:</em></p>
<pre><code>$ sudo yum install -y yum-utils device-mapper-persistent-data lvm2
</code></pre><p><em>Configure the docker-ce repo:</em></p>
<pre><code>$ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo
</code></pre><p><em>Install docker-ce:</em></p>
<pre><code>$ sudo yum install docker-ce
</code></pre><p><em>Create Docker group:</em></p>
<pre><code>$ sudo groupadd docker
</code></pre><p><em>It appeared that docker.sock was owned by root and in the group root:</em></p>
<pre><code>$ ls -l /var/run/docker.sock

srw-rw---- 1 root root 0 May 6 15:42 /var/run/docker.sock
</code></pre><p><em>Changing the group ownership:</em></p>
<pre><code>$ sudo chown root:docker /var/run/docker.sock

$ ls -l /var/run/docker.sock

srw-rw---- 1 root docker 0 May 6 15:42 /var/run/docker.sock
</code></pre><p><em>Add your user to the docker group with the following command.</em></p>
<pre><code>$ sudo usermod -aG docker $(whoami)
</code></pre><p><em>Set Docker to start automatically at boot time:</em></p>
<pre><code>$ sudo systemctl enable docker.service
</code></pre><p><em>Finally, start the Docker service:</em></p>
<pre><code>$ sudo systemctl start docker.service
</code></pre><p><em>Logging back on, now can run docker commands without sudo.</em></p>
<h2 id="docker-compose-installation">Docker-compose installation</h2>
<p><em>Install Extra Packages for Enterprise Linux</em></p>
<pre><code>$ sudo yum install epel-release
Install python-pip

$ sudo yum install -y python-pip
Then install Docker Compose:

$ sudo pip install docker-compose
</code></pre><p><em>You will also need to upgrade your Python packages on CentOS 7 to get docker-compose to run successfully:</em></p>
<pre><code>$ sudo yum upgrade python*
</code></pre><p><em>To verify a successful Docker Compose installation, run:</em></p>
<pre><code>$ docker-compose version
</code></pre><h2 id="rancher-2-installation">Rancher 2 installation</h2>
<pre><code>$ docker run -d --restart=unless-stopped \
  -p 8080:80 -p 8443:443 \
  -v /opt/rancher:/var/lib/rancher \
  rancher/rancher:latest \
  --acme-domain &lt;DNS_GUI_RANCHER&gt;
</code></pre><blockquote>
<p>In the situation where you want to use a single node to run Rancher and to be able to add the same node to a cluster, you have to adjust the host ports mapped for the rancher/rancher container.</p>
</blockquote>
<blockquote>
<p>If a node is added to a cluster, it deploys the nginx ingress controller which will use port 80 and 443. This will conflict with the default ports we advise to expose for the rancher/rancher container.</p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Mettre en place un Sonarqube et scanner son projet en moins de 5 minutes</title>
            <link>https://leandeep.com/mettre-en-place-un-sonarqube-et-scanner-son-projet-en-moins-de-5-minutes/</link>
            <pubDate>Wed, 24 Apr 2019 21:56:00 +0000</pubDate>
            
            <guid>https://leandeep.com/mettre-en-place-un-sonarqube-et-scanner-son-projet-en-moins-de-5-minutes/</guid>
            <description>Introduction Voici les étapes à suivre pour ajouter un sonar dans son projet. Dans le cas présent, le projet est un projet Python.
Steps Déployer un sonar via Docker $ docker pull sonarqube $ docker run -d --name sonarqube -p 9000:9000 -p 9092:9092 sonarqube # Si nécessaire pour ajouter des plugins $ wget https://binaries.sonarsource.com/Distribution/sonar-python-plugin/sonar-python-plugin-1.13.0.2922.jar $ docker cp ./sonar-python-plugin-1.13.0.2922.jar sonarqube:/opt/sonarqube/extensions/plugins/sonar-python-plugin-1.13.0.2922.jar $ docker restart sonarqube  Note: Mot de passe par défault: admin/admin</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Voici les étapes à suivre pour ajouter un sonar dans son projet.
Dans le cas présent, le projet est un projet Python.</p>
<h1 id="steps">Steps</h1>
<h2 id="dployer-un-sonar-via-docker">Déployer un sonar via Docker</h2>
<pre><code>$ docker pull sonarqube
$ docker run -d --name sonarqube -p 9000:9000 -p 9092:9092 sonarqube

# Si nécessaire pour ajouter des plugins

$ wget https://binaries.sonarsource.com/Distribution/sonar-python-plugin/sonar-python-plugin-1.13.0.2922.jar

$ docker cp ./sonar-python-plugin-1.13.0.2922.jar sonarqube:/opt/sonarqube/extensions/plugins/sonar-python-plugin-1.13.0.2922.jar  

$ docker restart sonarqube
</code></pre><blockquote>
<p>Note: Mot de passe par défault: admin/admin</p>
</blockquote>
<h2 id="configurer-le-projet">Configurer le projet</h2>
<p>Créer un fichier <code>sonar-project.properties</code> à la racine du projet</p>
<pre><code># Required metadata
sonar.projectKey=org.sonarqube:python-sonar-scanner
sonar.projectName=Python :: PYTHON! : SonarQube Scanner
sonar.projectVersion=1.0

# Comma-separated paths to directories with sources (required)
sonar.sources=PATH_DU_REPERTOIRE_A_SCANNER

# Language
sonar.language=py

# Encoding of the source files
sonar.sourceEncoding=UTF-8

sonar.host.url=http://IP_DU_SONAR:9000
</code></pre><h2 id="lancer-le-scan-du-projet">Lancer le scan du projet</h2>
<pre><code>docker run -ti -v $(pwd):/root/src zaquestion/sonarqube-scanner
</code></pre><p>(Docker image <code>zaquestion/sonarqube-scanner</code> source: <a href="https://github.com/oeeckhoutte/docker-sonarqube-scanner">https://github.com/oeeckhoutte/docker-sonarqube-scanner</a>)</p>
<h1 id="rsultat">Résultat</h1>
<p>Voici ce que vous obtiendrez:</p>
<p><img src="/images/sonar-clean.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Faire un Dual-Boot Linux sur Mac</title>
            <link>https://leandeep.com/faire-un-dual-boot-linux-sur-mac/</link>
            <pubDate>Sat, 13 Apr 2019 09:51:00 +0000</pubDate>
            
            <guid>https://leandeep.com/faire-un-dual-boot-linux-sur-mac/</guid>
            <description>Introduction Dans cet article, nous allons voir comment installer refind, un bootloader custom pour Mac qui permet de détecter les disques internes et externes pour booter sur différents OS.
Pré-requis  Disque dur externe ou clé USB ayant suffisamment d&#39;espace disque pour contenir un OS comme Fedora par exemple. Formater votre disque grâce à Disk Utility. Sélectionnez votre disque, cliquez erase et sélectionnez le format MS-DOS, et &amp;ldquo;GUID Partition Map&amp;rdquo;. Via des utilitaires comme Unetbootin, BalenaEtcher (anciennement Etcher), Fedora Media Writer créez une clé USB contenant un Live CD de Linux.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article, nous allons voir comment installer refind, un bootloader custom pour Mac qui permet de détecter les disques internes et externes pour booter sur différents OS.</p>
<h2 id="pr-requis">Pré-requis</h2>
<ul>
<li>Disque dur externe ou clé USB ayant suffisamment d'espace disque pour contenir un OS comme Fedora par exemple.</li>
<li>Formater votre disque grâce à <em>Disk Utility</em>. Sélectionnez votre disque, cliquez erase et sélectionnez le format MS-DOS, et &ldquo;GUID Partition Map&rdquo;.</li>
<li>Via des utilitaires comme <code>Unetbootin</code>, <code>BalenaEtcher</code> (anciennement Etcher), <code>Fedora Media Writer</code> créez une clé USB contenant un Live CD de Linux.</li>
</ul>
<h2 id="installation">Installation</h2>
<ul>
<li>
<p>Redémarrer votre Mac et désactivez le <code>System Integrity Protection (SIP)</code>.</p>
</li>
<li>
<p>Lors du redémarrage, maintenez les touchez <code>Command + R</code> pour passer en mode recovery.</p>
</li>
<li>
<p>Un fois démarré en mode recovery, ouvrez un terminal (Utilities &ndash;&gt; Terminal)</p>
</li>
<li>
<p>Exécutez la commande <code>csrutil disable</code></p>
</li>
<li>
<p>Rebootez</p>
</li>
<li>
<p>Téléchargez <a href="http://sourceforge.net/projects/refind/files/0.11.2/refind-bin-0.11.2.zip/download">Refind</a></p>
</li>
<li>
<p>Unzip le fichier téléchargé.</p>
</li>
<li>
<p>Ouvrir un Terminal et exécutez le fichier &ldquo;refind-installer&rdquo; contenu dans le dossier que vous venez d'extraire.</p>
</li>
<li>
<p>Et voilà. Rebootez pour vérifier que cela fonctionne.</p>
</li>
</ul>
<h2 id="dsinstallation">Désinstallation</h2>
<p>Ouvrez un Terminal et exécutez les commandes suivantes:</p>
<pre><code>sudo mkdir /Volumes/efi
sudo mount -t msdos /dev/disk0s1 /Volumes/efi
sudo rm -rf /Volumes/efi/EFI/refind
</code></pre><p>Et voilà. Rebootez. Vous devriez voir ceci:</p>
<p><img src="/images/dual-boot.JPG" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Mettre en place Traefik en moins de 5 minutes</title>
            <link>https://leandeep.com/mettre-en-place-traefik-en-moins-de-5-minutes/</link>
            <pubDate>Fri, 29 Mar 2019 21:44:00 +0000</pubDate>
            
            <guid>https://leandeep.com/mettre-en-place-traefik-en-moins-de-5-minutes/</guid>
            <description>Introduction Tout est dans le titre ! Dans cet article nous allons voir comment mettre en place le load balancer Traefik devant 2 applications.
Nous allons déployer 2 nginx pour simuler 2 sites statiques et nous allons customiser la page d&#39;accueil de chacun de nos Nginx avec les messages Hello world 1 et Hello world 2. On ne peut pas plus simple !
Installtion Docker-compose Créer un fichier docker-compose.yml:
version: &amp;quot;3.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Tout est dans le titre ! Dans cet article nous allons voir comment mettre en place le load balancer Traefik devant 2 applications.</p>
<p>Nous allons déployer 2 nginx pour simuler 2 sites statiques et nous allons customiser la page d'accueil de chacun de nos Nginx avec les messages <code>Hello world 1</code> et <code>Hello world 2</code>. On ne peut pas plus simple !</p>
<h1 id="installtion">Installtion</h1>
<h2 id="docker-compose">Docker-compose</h2>
<p>Créer un fichier <code>docker-compose.yml</code>:</p>
<pre><code>version: &quot;3.5&quot;

services:

  traefik:d
  	restart: alwaysd
    image: traefik:1.7.10
    command: --api --docker --docker.domain=app.test --logLevel=DEBUG # Enables the web UI and tells Traefik to listen to docker
    depends_on:
    # our setup relies on the 2 apps running. Trying to spin up traefik will bring up those too
    - &quot;app1&quot;
    - &quot;app2&quot;
    ports:
      - &quot;80:80&quot;
      # Management UI
      - &quot;8080:8080&quot;
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./traefik.toml:/etc/traefik/traefik.toml:ro
    networks:
      outside-world:
      internal-network:

  app1:
    image: nginx:alpine
    labels:
    - &quot;traefik.port=80&quot;
    - &quot;traefik.frontend.rule=Host:app1.test&quot;
    volumes:
      - ./app1/:/usr/share/nginx/html:ro
    networks:
      internal-network:
        # the aliases are not required, but are useful if the applications want to internally
        # reference each other by host name
        aliases:
        - &quot;app1.test&quot;

  app2:
    image: nginx:alpine
    labels:
    - &quot;traefik.port=80&quot;
    - &quot;traefik.frontend.rule=Host:app2.test&quot;
    volumes:
      - ./app2/:/usr/share/nginx/html:ro
    networks:
      internal-network:
        aliases:
        - &quot;app2.test&quot;

networks:
  # everything that is *only* on &quot;internal network&quot; cannot talk to WAN
  internal-network:
    internal: true
  # add this network to a container to make it talk to the rest of the world
  outside-world:

</code></pre><h2 id="contenus-html-des-apps">Contenus HTML des apps</h2>
<p>Créer 2 répertoires <code>app1</code> et <code>app2</code> contenant les fichiers index.html customisés.</p>
<p>Vous devriez obtenir l'arborescence suivante:</p>
<pre><code>├── app1
│   └── index.html # Contient le texte: Hello world 1
├── app2
│   └── index.html # Contient le texte: Hello world 2
└── docker-compose.yml
</code></pre><h2 id="etchosts">/etc/hosts</h2>
<p>Si vous êtes en local, il vous faudra configurer votre /etc/hosts avec le nom de domaine permettant d'accéder aux apps et à Traefik.</p>
<p>Pour ce faire editez le fichier (en mode root) <code>/etc/hosts</code>, et ajoutez les 3 entrées suivantes:</p>
<pre><code>127.0.0.1       app.test
127.0.0.1       app1.test
127.0.0.1       app2.test
</code></pre><h2 id="test">Test</h2>
<p>Exécutez la commande:</p>
<pre><code>docker-compose up 
</code></pre><p>Puis rendez-vous sur <code>http://app.test:8080</code> pour accéder à l'admin de Traefik et sur vos apps <code>http://app1.test</code> et <code>http://app2.test</code>.</p>
<p>Et voilà !</p>
<p><img src="/images/traefik.png" alt="image"></p>
<p>Pour aller plus loin, vous pouvez ajouter un fichier <code>acme.json</code> et le monter comme volume dans votre service Traefik pour avoir de l'HTTPS. <code>- ./acme.json:/acme.json</code></p>
<p>Voici la doc officielle (j'en ferais peut-être un article si le temps me le permet :D) <a href="https://docs.traefik.io/configuration/acme/">https://docs.traefik.io/configuration/acme/</a></p>
<h1 id="htpasswd">htpasswd</h1>
<p>Il est également possible d'ajouter un htpasswd:</p>
<pre><code>htpasswd -n username
</code></pre><p>Voici ce que l'on obtient avec admin/admin (à ne pas utiliser):</p>
<pre><code>admin:$apr1$IBj9Hfsd$kf7vXLpY4/9XD365jcp/n1
</code></pre><p>Modifier le fichier <code>docker-compose.yml</code> et ajoutez le label suivant dans le service traefik:</p>
<pre><code>labels:
      - &quot;traefik.frontend.auth.basic=admin:$$apr1$$IBj9Hfsd$$kf7vXLpY

</code></pre>]]></content>
        </item>
        
        <item>
            <title>Commandes utiles Kubernetes</title>
            <link>https://leandeep.com/commandes-utiles-kubernetes/</link>
            <pubDate>Fri, 08 Mar 2019 17:08:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-utiles-kubernetes/</guid>
            <description>Commandes propres à Kubernetes Créer un namespace
kubectl create ns &amp;lt;new-namespace&amp;gt;  Savoir si une ressource appartient à un namespace
kubectl api-resources --namespaced=true  Savoir si une ressource appartient PAS à un namespace
kubectl api-resources --namespaced=false  Switcher de namespace
# Install kubens with the following command: # Sur Mac: brew install kubectx # Sur Linux (les 3 commandes qui suivent): # sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx # sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx # sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens kubens &amp;lt;namespace&amp;gt; # Enregistre de manière permanente le namespace pour toutes les commandes kubectl suivantes dans ce contexte kubectl config set-context --current --namespace=NOM_DU_NAMESPACE  Connaître le cluster dans lequel on se situe</description>
            <content type="html"><![CDATA[<h2 id="commandes-propres--kubernetes">Commandes propres à Kubernetes</h2>
<p><strong>Créer un namespace</strong></p>
<pre><code>kubectl create ns &lt;new-namespace&gt;
</code></pre><br/>
<p><strong>Savoir si une ressource appartient à un namespace</strong></p>
<pre><code>kubectl api-resources --namespaced=true
</code></pre><br/>
<p><strong>Savoir si une ressource appartient PAS à un namespace</strong></p>
<pre><code>kubectl api-resources --namespaced=false
</code></pre><br/>
<p><strong>Switcher de namespace</strong></p>
<pre><code># Install kubens with the following command: 
# Sur Mac: brew install kubectx
# Sur Linux (les 3 commandes qui suivent): 
# sudo git clone https://github.com/ahmetb/kubectx /opt/kubectx
# sudo ln -s /opt/kubectx/kubectx /usr/local/bin/kubectx
# sudo ln -s /opt/kubectx/kubens /usr/local/bin/kubens

kubens &lt;namespace&gt;

# Enregistre de manière permanente le namespace pour toutes les commandes kubectl suivantes dans ce contexte
kubectl config set-context --current --namespace=NOM_DU_NAMESPACE
</code></pre><br/>
<p><strong>Connaître le cluster dans lequel on se situe</strong></p>
<pre><code>kubectl config get-contexts
</code></pre><br/>
<p><strong>Connaître le namespace dans lequel on se situe</strong></p>
<pre><code>kubectl config view | grep namespace

# Alternative: 
# kubectl config view --minify --output 'jsonpath={..namespace}'
</code></pre><br/>
<p><strong>Effacer un namespace</strong></p>
<pre><code>kubectl delete ns &lt;namespace-to-delete&gt;
</code></pre><br/>
<p><strong>Voir les ressources utilisées par les nodes</strong></p>
<pre><code># Nécessite heapster
kubectl top node
</code></pre><br/>
<p><strong>Voir les ressources utilisées par les pods</strong></p>
<pre><code>kubectl top pods
</code></pre><br/>
<p><strong>Voir les logs d'une app particulière dans un namespace particulier</strong></p>
<pre><code>kubectl logs -l app=catalog-catalog-controller-manager -n catalog
</code></pre><br/>
<p><strong>Voir le cluster sur lequel kubectl est connecté</strong></p>
<pre><code>kubectl config current-context
</code></pre><br/>
<p><strong>Lister les clusters configurés dans kubeconfig</strong></p>
<pre><code>kubectl config get-clusters
</code></pre><br/>
<p><strong>Switcher de cluster en cluster</strong></p>
<pre><code>kubectl config use-context cluster_name
</code></pre><br/>
<p><strong>Obtenir quelques informations sur le cluster</strong></p>
<pre><code>kubectl cluster-info
</code></pre><br/>
<p><strong>Voir les noeuds du cluster</strong></p>
<pre><code>kubectl get nodes
</code></pre><br/>
<p><strong>Port forward un service sur k8s chez vous</strong></p>
<pre><code>kubectl -n NAMESPACE_DANS_LEQUEL_SE_TROUVE_LE_SERVICE port-forward svc/NOM_DU_SERVICE_AUQUEL_VOUS_VOULEZ_ACCEDER PORT_CHEZ_VOUS_POUR_ACCEDER_AU_SERVICE:PORT_DU_SERVICE_SUR_K8S
</code></pre><p>Le port sera bindé sur 127.0.0.1. Il est possible d'ajouter le flag <code>--address 0.0.0.0</code>. (Attention à la sécurité)</p>
<br/>
<p><strong>Installer le dashboard k8s et y accéder</strong></p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml

kubectl proxy
</code></pre><p>Maintenant rendez-vous à l'adresse suivante:</p>
<p>http://localhost:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/#!/login</p>
<p>Une mire d'authentification va apparaitre pour se connecter au dashboard. Privilégier l'authentification par token. Pour obtenir ce dernier utiliser les commandes suivantes:</p>
<pre><code>TOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d '\t' | sed -e 's/^[[:space:]]*//')

echo $TOKEN
</code></pre><br/>
<p><strong>Déployer un 1er service</strong></p>
<pre><code>kubectl run hello-nginx --image=nginx --port=80
kubectl get pods
kubectl get deployments
kubectl expose deployment hello-nginx --type=NodePort
kubectl describe service hello-nginx
kubectl get services

NAME          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
hello-nginx   NodePort    10.111.152.236   &lt;none&gt;        80:31256/TCP   58s
kubernetes    ClusterIP   10.96.0.1        &lt;none&gt;        443/TCP        46m
</code></pre><p>Se rendre sur l'URL suivante pour accéder au service Nginx (Nodeport):
http://localhost:31256/</p>
<br/>
<h2 id="troubleshooting">Troubleshooting</h2>
<p><strong>Voir les events et status des noeuds</strong></p>
<pre><code>kubectl get events --sort-by=.metadata.creationTimestamp
kubectl describe nodes
</code></pre><br/>
<p><strong>Voir la consommation cpu et memory des pods les plus gourmands</strong></p>
<pre><code>kubectl top pods
</code></pre><br/>
<p><strong>Lister les containers par pods</strong></p>
<pre><code>kubectl get pods --all-namespaces -o=jsonpath='{range .items[*]}{&quot;\n&quot;}{.metadata.name}{&quot;:\t&quot;}{range .spec.containers[*]}{.image}{&quot;, &quot;}{end}{end}' |\
sort

# Pour un pod particulier, pour avoir les container names dans le pod, on peut aussi exécuter:
kubectl logs POD_NAME 
# S'il y a plusieurs containers un message d'erreur apparaîtra indiquant de selectionner un container --&gt; choose one of: [container-name-1 container-name-2]
</code></pre><br/>
<p><strong>Entrer dans un pod</strong></p>
<pre><code>kubectl exec -it shell-demo -- /bin/bash
</code></pre><br/>
<h2 id="crer-un-single-node-cluster-avec-kubeadm-sur-ubuntu">Créer un Single node cluster avec kubeadm sur Ubuntu</h2>
<p><strong>Installer kubeadm:</strong></p>
<pre><code>apt-get update &amp;&amp; apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
cat &lt;&lt;EOF &gt;/etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
apt-get update
apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl
</code></pre><br/>
<p><strong>Déployer le single node cluster:</strong></p>
<pre><code>kubeadm init
# Puis suivre les informations qui apparaissent
</code></pre><br/>
<h2 id="effacement-du-cluster">Effacement du cluster</h2>
<pre><code># Obtenir le nom du noeud
kubectl get nodes

# Drainer le noeud 
kubectl drain NOM_DU_NOEUD --delete-local-data --force --ignore-daemonsets

# On l'efface
kubectl delete node NOM_DU_NOEUD

# On reset kubeadm
kubeadm reset

# Un reboot permet d'effacer les interfaces réseaux en trop 
sudo reboot
</code></pre><br/>
<h2 id="commandes-propres--eks-kubernetes-aws">Commandes propres à EKS (Kubernetes AWS)</h2>
<p><strong>Se connecter à son cluster EKS nouvellement créé</strong></p>
<pre><code>aws --profile=&lt;profile-name&gt; eks update-kubeconfig --name &lt;cluster-name&gt;
export KUBECONFIG=~/.kube/config-&lt;of-your-cluster&gt;
</code></pre><br/>
<p><strong>Lister les clusters EKS</strong></p>
<pre><code>aws eks list-clusters
</code></pre><br/>
<h2 id="commandes-propres--aks-kubernetes-azure">Commandes propres à AKS (Kubernetes Azure)</h2>
<p><strong>Se connecter à son cluster AKS nouvellement créé</strong></p>
<pre><code>az login

# Ajoute la conf du cluster dans le kube config
az aks get-credentials --resource-group NOM_DU_RESSOURCE_GROUPE --name NOM_DU_CLUSTER_K8S

# Vérification
kubectl config get-contexts
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Provisionner un cluster Kubernetes avec AWS EKS</title>
            <link>https://leandeep.com/provisionner-un-cluster-kubernetes-avec-aws-eks/</link>
            <pubDate>Thu, 07 Mar 2019 21:28:00 +0000</pubDate>
            
            <guid>https://leandeep.com/provisionner-un-cluster-kubernetes-avec-aws-eks/</guid>
            <description>Introduction Dans cet article nous allons voir comment provisionner un cluster simple Kubernetes via AWS EKS. Nous verrons dans un prochain article comment mettre en place l&#39;autoscaling et comment faire pour que les nouvelles instances automatiquement crées soient des instances Spot.
Pré-requis  Compte AWS Utilisateur Admin (Policy AdministratorAccess dans IAM)  Installation via Cloud9  Créer un nouveau workspace dans Cloud9 &amp;lt;nom_de_votre_projet&amp;gt; Depuis Cloud9, via le terminal générer une clé SSH  ssh-keygen Uploader sa clé dans la région EC2  aws ec2 import-key-pair --key-name &amp;quot;&amp;lt;nom_de_votre_clé&amp;gt;&amp;quot; --public-key-material file://~/.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Dans cet article nous allons voir comment provisionner un cluster simple Kubernetes via AWS EKS.
Nous verrons dans un prochain article comment mettre en place l'autoscaling et comment faire pour que les nouvelles instances automatiquement crées soient des instances Spot.</p>
<h2 id="pr-requis">Pré-requis</h2>
<ul>
<li>Compte AWS</li>
<li>Utilisateur Admin (Policy AdministratorAccess dans IAM)</li>
</ul>
<h2 id="installation-via-cloud9">Installation via Cloud9</h2>
<ol>
<li>Créer un nouveau workspace dans Cloud9 &lt;nom_de_votre_projet&gt;</li>
<li>Depuis Cloud9, via le terminal générer une clé SSH</li>
</ol>
<pre><code>ssh-keygen
</code></pre><ol start="3">
<li>Uploader sa clé dans la région EC2</li>
</ol>
<pre><code>aws ec2 import-key-pair --key-name &quot;&lt;nom_de_votre_clé&gt;&quot; --public-key-material file://~/.ssh/id_rsa.pub
</code></pre><ol start="4">
<li>Installer les outils Kubernetes</li>
</ol>
<ul>
<li>
<p>Créer le répertoire ~/.kube par défaut pour stocker la configuration kubectl</p>
</li>
<li>
<p>Installer kubectl</p>
</li>
</ul>
<pre><code>sudo curl --silent --location -o /usr/local/bin/kubectl &quot;https://amazon-eks.s3-us-west-2.amazonaws.com/1.11.5/2018-12-06/bin/linux/amd64/kubectl&quot;
sudo chmod +x /usr/local/bin/kubectl
</code></pre><ul>
<li>Installer AWS IAM Authenticator</li>
</ul>
<pre><code>go get -u -v github.com/kubernetes-sigs/aws-iam-authenticator/cmd/aws-iam-authenticator
sudo mv ~/go/bin/aws-iam-authenticator /usr/local/bin/aws-iam-authenticator
</code></pre><ul>
<li>Vérifier les binaires</li>
</ul>
<pre><code>kubectl version --short --client
aws-iam-authenticator help
</code></pre><ul>
<li>Installer JQ</li>
</ul>
<pre><code>sudo yum -y install jq
</code></pre><ol start="5">
<li>Créer un rôle IAM pour le workspace Cloud9</li>
</ol>
<ul>
<li>
<p>Cliquer sur le lien suivant pour créer un rôle IAM avec accès administator: <a href="https://console.aws.amazon.com/iam/home#/roles$new?step=review&amp;commonUseCase=EC2%2BEC2&amp;selectedUseCase=EC2&amp;policies=arn:aws:iam::aws:policy%2FAdministratorAccess">https://console.aws.amazon.com/iam/home#/roles$new?step=review&amp;commonUseCase=EC2%2BEC2&amp;selectedUseCase=EC2&amp;policies=arn:aws:iam::aws:policy%2FAdministratorAccess</a></p>
</li>
<li>
<p>Vérifier que la police service AWS: ec2.amazonaws.com est bien sélectionnée et cliquer sur Next pour voir les permissions.</p>
</li>
<li>
<p>Vérifier qu'AdministratorAccess est bien coché et cliquer sur Next.</p>
</li>
<li>
<p>Entrer &lt;nom_de_votre_projet&gt;-admin comme exemple de nom et cliquer sur Create Role.</p>
</li>
</ul>
<ol start="6">
<li>Attacher le rôle IAM à votre workspace</li>
</ol>
<ul>
<li>
<p>Cliquer sur le lien suivant pour identifier votre instance Cloud9 EC2: <a href="https://console.aws.amazon.com/ec2/v2/home?#Instances:tag:Name=aws-cloud9-%3Cnom_de_votre_projet%3E">https://console.aws.amazon.com/ec2/v2/home?#Instances:tag:Name=aws-cloud9-&lt;nom_de_votre_projet&gt;</a>*;sort=desc:launchTime</p>
</li>
<li>
<p>Selectionner votre instance et cliquer sur Actions / Instance Settings / Attach/Replace IAM Role</p>
</li>
<li>
<p>Sélectionner &lt;nom_de_votre_projet&gt;-admin dans la drop down IAM Role et cliquer sur Apply.</p>
</li>
</ul>
<ol start="7">
<li>Mettre à jour les préférences IAM du workspace</li>
</ol>
<ul>
<li>
<p>Retourner dans votre workspace Cloud0 et lancer l'onglet préférences en cliquant en haut à droite sur la roue crantée.</p>
</li>
<li>
<p>Sélectionner AWS SETTINGS</p>
</li>
<li>
<p>Décocher AWS managed temporary credentials</p>
</li>
<li>
<p>Fermer l'onglet des préférences</p>
</li>
</ul>
<ol start="8">
<li>Pour être certain que des credentials n'ont pas déjà été mis en place, exécuter la commande suivante:</li>
</ol>
<pre><code>rm -vf ${HOME}/.aws/credentials
</code></pre><ol start="9">
<li>Configurer l'AWS cli avec la région actuelle:</li>
</ol>
<pre><code>export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r '.region')
echo &quot;export AWS_REGION=${AWS_REGION}&quot; &gt;&gt; ~/.bash_profile
aws configure set default.region ${AWS_REGION}
aws configure get default.region
</code></pre><ol start="10">
<li>Valider le rôle IAM</li>
</ol>
<ul>
<li>
<p>On va utiliser la commande CLI GetCallerIdentity <a href="https://docs.aws.amazon.com/cli/latest/reference/sts/get-caller-identity.html">https://docs.aws.amazon.com/cli/latest/reference/sts/get-caller-identity.html</a> pour vérifier que Cloud9 utilise le bon rôle IAM.</p>
</li>
<li>
<p>On commence par récupérer le rôle IAM du CLI AWS.</p>
</li>
</ul>
<pre><code>INSTANCE_PROFILE_NAME=`basename $(aws ec2 describe-instances --filters Name=tag:Name,Values=aws-cloud9-${C9_PROJECT}-${C9_PID} | jq -r '.Reservations[0].Instances[0].IamInstanceProfile.Arn' | awk -F &quot;/&quot; &quot;{print $2}&quot;)`
aws iam get-instance-profile --instance-profile-name $INSTANCE_PROFILE_NAME --query &quot;InstanceProfile.Roles[0].RoleName&quot; --output text
</code></pre><p>En sortie on doit obtenir ceci:</p>
<pre><code>&lt;nom_de_votre_projet&gt;-admin
</code></pre><p>Comparer le résultat de cette commande avec celle-ci:</p>
<pre><code>aws sts get-caller-identity
</code></pre><p>Si l'ARN contient le rôle name comme ci-dessous, tout est bien configuré:</p>
<pre><code>{
    &quot;Account&quot;: &quot;123456789012&quot;, 
    &quot;UserId&quot;: &quot;AROA1SAMPLEAWSIAMROLE:i-01234567890abcdef&quot;, 
    &quot;Arn&quot;: &quot;arn:aws:sts::123456789012:assumed-role/&lt;nom_de_votre_projet&gt;-admin/i-01234567890abcdef&quot;
}
</code></pre><ol start="11">
<li>Installer le binaire <code>eksctl</code>:</li>
</ol>
<pre><code>curl --silent --location &quot;https://github.com/weaveworks/eksctl/releases/download/latest_release/eksctl_$(uname -s)_amd64.tar.gz&quot; | tar xz -C /tmp

sudo mv -v /tmp/eksctl /usr/local/bin
</code></pre><p>Et vérifier que l'installation est bonne via:</p>
<pre><code>eksctl version
</code></pre><ol start="12">
<li>Création du cluster</li>
</ol>
<pre><code>eksctl create cluster --name=&lt;nom_de_votre_projet&gt;-eksctl --nodes=3 --node-ami=auto --region=${AWS_REGION}
</code></pre><h2 id="vrifier-le-bon-fonctionnement-du-cluster">Vérifier le bon fonctionnement du cluster</h2>
<pre><code>kubectl get nodes
</code></pre><h2 id="dployer-le-dashboard-k8s-officiel">Déployer le dashboard k8s officiel</h2>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml
</code></pre><ol start="15">
<li>Accéder au dashboard</li>
</ol>
<pre><code>kubectl proxy --port=8080 --address='0.0.0.0' --disable-filter=true &amp;
</code></pre><ul>
<li>
<p>Dans Cloud9, cliquer sur Tools / Preview / Preview Running Application. Positionnezvous à la fin de l'URL et ajoutez:
/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</p>
</li>
<li>
<p>Ouvrer un nouvel onglet et entrer la commande suivante pour obtenir un token:</p>
</li>
</ul>
<pre><code>aws-iam-authenticator token -i &lt;nom_de_votre_projet&gt;-eksctl --token-only
</code></pre><ul>
<li>Enfin cliquer sur Sign In.</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Mastering Pandas</title>
            <link>https://leandeep.com/mastering-pandas/</link>
            <pubDate>Sat, 16 Feb 2019 13:47:00 +0000</pubDate>
            
            <guid>https://leandeep.com/mastering-pandas/</guid>
            <description>Cela fait pas mal de temps que j&#39;utilise Pandas. Dans cet article je vais essayer de réunir et synthétiser tous les tips &amp;amp; tricks à savoir (comme si j&#39;utilisais Jupyter Notebook).
Voici la liste des tips:
 Introduction à Pandas Lire des données tabulaires Sélectionner une série Pandas Parenthèses Pandas Renommer des colonnes Effacer une colonne Effacer toutes les colonnes sauf Trier Filtrer Filtres multi-critères Examiner un dataset Numéro, index et contenu de la ligne lors d&#39;une itération  A compléter&amp;hellip;</description>
            <content type="html"><![CDATA[<p>Cela fait pas mal de temps que j'utilise Pandas. Dans cet article je vais essayer de réunir et synthétiser tous les tips &amp; tricks à savoir (comme si j'utilisais Jupyter Notebook).</p>
<p>Voici la liste des tips:</p>
<ul>
<li>Introduction à Pandas</li>
<li>Lire des données tabulaires</li>
<li>Sélectionner une série Pandas</li>
<li>Parenthèses Pandas</li>
<li>Renommer des colonnes</li>
<li>Effacer une colonne</li>
<li>Effacer toutes les colonnes sauf</li>
<li>Trier</li>
<li>Filtrer</li>
<li>Filtres multi-critères</li>
<li>Examiner un dataset</li>
<li>Numéro, index et contenu de la ligne lors d'une itération</li>
</ul>
<p>A compléter&hellip;</p>
<ul>
<li>Utiliser le paramètre Axis</li>
<li>Utiliser les méthodes String</li>
<li>Changer le type de donnée</li>
<li>Utiliser groupeby</li>
<li>Explorer les séries</li>
<li>Gérer les données manquantes</li>
<li>Utiliser l'index Pandas</li>
<li>Sélectionner plusieurs lignes et colonnes</li>
<li>Utiliser le paramètre inplace</li>
<li>Réduire le dataset plus petit et plus rapide</li>
<li>Pandas et Scikit-learn</li>
<li>Echantillonner aléatoirement</li>
<li>Créer des dummy variables</li>
<li>Manipuler des dates et heures</li>
<li>Retirer les lignes en doublon</li>
<li>Filtrer et convenir les series NaN</li>
<li>Changer les options d'affichage</li>
</ul>
<h2 id="introduction--pandas">Introduction à Pandas</h2>
<p>C'est une librairie opensource d'analyse de données qui fourni des structures de données ainsi que des outils d'analyse faciles à utiliser.</p>
<p>Ses avantages sont:</p>
<ul>
<li>Un grand nombre de fonctionnalités</li>
<li>Une communauté active</li>
<li>Documentation bien faite</li>
<li>S'associe bien avec d'autres packages connus
<ul>
<li>construit au-dessus de Numpy</li>
<li>s'utilise facilement avec Scikit-learn</li>
</ul>
</li>
</ul>
<p>Lien vers la documentation officielle: <a href="http://pandas.pydata.org/">http://pandas.pydata.org/</a></p>
<h2 id="lire-des-donnes-tabulaires">Lire des données tabulaires</h2>
<p><em>Lire des fichiers de données tabulaires dans Pandas</em></p>
<p><strong>Example de fichiers de données:</strong></p>
<ul>
<li>CSV</li>
<li>Excel</li>
<li>Table-like data format</li>
</ul>
<pre><code># import pandas
import pandas as pd
</code></pre><pre><code># reading a well-formatted .tsv file
url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/chipotle.tsv'
orders = pd.read_table(url)
orders.head()
</code></pre><p><img src="/images/pandas-1.png" alt="image"></p>
<p><strong>Fonctionnement par default de read_table:</strong></p>
<ul>
<li>Le fichier à charger doit contenir des tabs entre les colonnes</li>
<li>Présence d'un header</li>
</ul>
<pre><code>url2 = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/u.user'
users = pd.read_table(url2)
users.head()
</code></pre><p><img src="/images/pandas-2.png" alt="image"></p>
<p><strong>Problème:</strong></p>
<ul>
<li>Le sepérateur entre les colonnes est le caractère <code>&quot;|&quot;</code>. Il faut donc le spécifier à Pandas avec le paramètre <code>sep=</code></li>
<li>Il n'y a pas de header. Il faut donc le spécifier en passant le paramètre <code>header=None</code>. On peut aussi ajouter une ligne pour les noms des colonnes en utilisant le paramètre <code>names=user_cols</code></li>
</ul>
<pre><code>user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']
users = pd.read_table(url2, sep='|', header=None, names=user_cols)
users.head()
</code></pre><p><img src="/images/pandas-3.png" alt="image"></p>
<p><strong>Note:</strong></p>
<p>Si vous avez un fichier contenant du texte en haut ou en bas vous pouvez utiliser les paramètres suivants: <code>skiprows=None</code> ou <code>skipfooter=None</code>.</p>
<p>Lien vers la documentation de read_table: <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html">http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_table.html</a></p>
<h2 id="slectionner-une-srie-pandas">Sélectionner une série Pandas</h2>
<p><em>Sélectionner une série Pandas à partir d'un dataframe</em></p>
<p><strong>Qu'est-ce qu'une série ?</strong></p>
<ul>
<li>c'est un vecteur m x 1
<ul>
<li>m est le nombre de lignes</li>
<li>1 le nombre de colonne</li>
</ul>
</li>
<li>Chaque colonne d'un dataframe Pandas est une série</li>
</ul>
<pre><code>import pandas as pd
</code></pre><pre><code># The csv file is separated by commas
url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv'

# method 1: read_table
ufo = pd.read_table(url, sep=',')

# method 2: read_csv
# this is a short-cut here using read_csv because it uses comma as the default separator
ufo = pd.read_csv(url)
ufo.head()
</code></pre><p><img src="/images/pandas-4.png" alt="image"></p>
<pre><code># Method 1: Selecting City series (this will always work)
ufo['City']

# Method 2: Selecting City series
ufo.City

# 'City' is case-sensitive, you cannot use 'city'
</code></pre><p>Jupyter Output:</p>
<pre><code>0                      Ithaca
1                 Willingboro
2                     Holyoke
3                     Abilene
4        New York Worlds Fair
5                 Valley City
6                 Crater Lake
7                        Alma
8                     Eklutna
9                     Hubbard
10                    Fontana
11                   Waterloo
12                     Belton
13                     Keokuk
14                  Ludington
15                Forest Home
16                Los Angeles
17                  Hapeville
18                     Oneida
19                 Bering Sea
20                   Nebraska
21                        NaN
22                        NaN
23                  Owensboro
24                 Wilderness
25                  San Diego
26                 Wilderness
27                     Clovis
28                 Los Alamos
29               Ft. Duschene
                 ...         
18211                 Holyoke
18212                  Carson
18213                Pasadena
18214                  Austin
18215                El Campo
18216            Garden Grove
18217           Berthoud Pass
18218              Sisterdale
18219            Garden Grove
18220             Shasta Lake
18221                Franklin
18222          Albrightsville
18223              Greenville
18224                 Eufaula
18225             Simi Valley
18226           San Francisco
18227           San Francisco
18228              Kingsville
18229                 Chicago
18230             Pismo Beach
18231             Pismo Beach
18232                    Lodi
18233               Anchorage
18234                Capitola
18235          Fountain Hills
18236              Grant Park
18237             Spirit Lake
18238             Eagle River
18239             Eagle River
18240                    Ybor
Name: City, dtype: object
</code></pre><pre><code># confirm type
type(ufo['City'])
type(ufo.City)
</code></pre><p>Jupyter Output:</p>
<pre><code>pandas.core.series.Series
</code></pre><p><strong>Comment sélectionner une colonne qui contient des espaces ?</strong></p>
<ul>
<li>Il n'est pas possible d'utiliser la méthode 2  <code>ufo.category_name</code></li>
<li>Il faut utiliser la méthode 1 <code>ufo['category name']</code></li>
</ul>
<pre><code>ufo['Colors Reported']
</code></pre><p>Jupyter Output:</p>
<pre><code>0           NaN
1           NaN
2           NaN
3           NaN
4           NaN
5           NaN
6           NaN
7           NaN
8           NaN
9           NaN
10          NaN
11          NaN
12          RED
13          NaN
14          NaN
15          NaN
16          NaN
17          NaN
18          NaN
19          RED
20          NaN
21          NaN
22          NaN
23          NaN
24          NaN
25          NaN
26          NaN
27          NaN
28          NaN
29          NaN
          ...  
18211       NaN
18212       NaN
18213     GREEN
18214       NaN
18215       NaN
18216    ORANGE
18217       NaN
18218       NaN
18219       NaN
18220      BLUE
18221       NaN
18222       NaN
18223       NaN
18224       NaN
18225       NaN
18226       NaN
18227       NaN
18228       NaN
18229       NaN
18230       NaN
18231       NaN
18232       NaN
18233       RED
18234       NaN
18235       NaN
18236       NaN
18237       NaN
18238       NaN
18239       RED
18240       NaN
Name: Colors Reported, dtype: object
</code></pre><p><strong>Comment créer une nouvelle série Pandas dans un dataframe ?</strong></p>
<pre><code># example of concatenating strings
'ab' + 'cd'
</code></pre><pre><code># created a new column called &quot;Location&quot; with a concatenation of &quot;City&quot; and &quot;State&quot;
ufo['Location'] = ufo.City + ', ' + ufo.State
ufo.head()
</code></pre><p><img src="/images/pandas-5.png" alt="image"></p>
<h2 id="parenthses-pandas">Parenthèses Pandas</h2>
<p><em>Commandes Pandas finissant par des parenthèses</em></p>
<pre><code>import pandas as pd
</code></pre><pre><code>url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csv'
movies = pd.read_csv(url)
</code></pre><pre><code># Looking at the first 5 rows of the DataFrame
movies.head()
</code></pre><p><img src="/images/pandas-6.png" alt="image"></p>
<pre><code># This will show descriptive statistics of numeric columns
movies.describe()
</code></pre><p><img src="/images/pandas-7.png" alt="image"></p>
<pre><code>movies.describe(include=['float64'])
</code></pre><p><img src="/images/pandas-8.png" alt="image"></p>
<pre><code># Finding out dimensionality of DataFrame
movies.shape
</code></pre><p>Jupyter Output:</p>
<pre><code>(979, 6)
</code></pre><pre><code># Finding out data types of each columns
movies.dtypes
</code></pre><p>Jupyter Output:</p>
<pre><code>star_rating       float64
title              object
content_rating     object
genre              object
duration            int64
actors_list        object
dtype: object
</code></pre><pre><code>type(movies)
</code></pre><p>Jupyter Output:</p>
<pre><code>pandas.core.frame.DataFrame
</code></pre><p><strong>Les dataframes ont certains attributs et méthodes</strong></p>
<ul>
<li>
<p>Méthodes: avec parenthèses</p>
<ul>
<li>
<p>Orientées action:</p>
<ul>
<li><code>movies.head()</code></li>
<li><code>movies.describe()</code></li>
</ul>
</li>
<li>
<p>Les parenthèses autorisent les arguments optionnels</p>
<ul>
<li><code>movies.describe(include='object')</code></li>
</ul>
</li>
</ul>
</li>
<li>
<p>Attributs: sans parenthèse</p>
<ul>
<li>Orientés description:
<ul>
<li><code>movie.shape</code></li>
<li><code>movie.dtypes</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="renommer-des-colonnes">Renommer des colonnes</h2>
<pre><code>import pandas as pd
</code></pre><pre><code>url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv'
ufo = pd.read_csv(url)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-9.png" alt="image"></p>
<pre><code># To check out only the columns
# It will output a list of columns
ufo.columns
</code></pre><p>Jupyter Output:</p>
<pre><code>Index(['City', 'Colors Reported', 'Shape Reported', 'State', 'Time'], dtype='object')
</code></pre><p><strong>Méthode 1: Renommer une seule colonne:</strong></p>
<pre><code># inplace=True to affect DataFrame
ufo.rename(columns = {'Colors Reported': 'Colors_Reported', 'Shape Reported': 'Shape_Reported'}, inplace=True)
</code></pre><pre><code>ufo.columns
</code></pre><p>Jupyter Output:</p>
<pre><code>Index(['City', 'Colors_Reported', 'Shape_Reported', 'State', 'Time'], dtype='object')
</code></pre><p><strong>Méthode 2: renommer plusieurs colonnes:</strong></p>
<pre><code>ufo_cols = ['city', 'colors reported', 'shape reported', 'state', 'time']
</code></pre><pre><code>ufo.columns = ufo_cols
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-10.png" alt="image"></p>
<p><strong>Méthode 3: Changer les colonnes pendant la lecture:</strong></p>
<pre><code>url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv'
ufo = pd.read_csv(url, names=ufo_cols, header=0)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-11.png" alt="image"></p>
<p><strong>Méthode 4: replacer les espaces avec des underscores pour toutes les colonnes:</strong></p>
<pre><code>ufo.columns = ufo.columns.str.replace(' ', '_')
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-12.png" alt="image"></p>
<h2 id="effacer-une-colonne">Effacer une colonne</h2>
<pre><code>import pandas as pd
</code></pre><pre><code># Creating pandas DataFrame
url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv'
ufo = pd.read_csv(url)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-13.png" alt="image"></p>
<pre><code>ufo.shape
</code></pre><p>Jupyter Output:</p>
<pre><code>(18241, 5)
</code></pre><pre><code># Removing column
# axis=0 row axis
# axis=1 column axis
# inplace=True to effect change
ufo.drop('Colors Reported', axis=1, inplace=True)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-14.png" alt="image"></p>
<pre><code># Removing column
list_drop = ['City', 'State']
ufo.drop(list_drop, axis=1, inplace=True)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-15.png" alt="image"></p>
<pre><code># Removing rows 0 and 1
# axis=0 is the default, so technically, you can leave this out
rows = [0, 1]
ufo.drop(rows, axis=0, inplace=True)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-16.png" alt="image"></p>
<h2 id="effacer-toutes-les-colonnes-sauf-certaine">Effacer toutes les colonnes sauf certaine</h2>
<pre><code># df d'origine
a  b  c  d  e  f  g  
1  2  3  4  5  6  7
4  3  7  1  6  9  4
8  9  0  2  4  2  1

# df attendu
a  b
1  2
4  3
8  9

df = df[['a','b']]
</code></pre><h2 id="trier">Trier</h2>
<pre><code>import pandas as pd
</code></pre><pre><code>url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csv'
movies = pd.read_csv(url)
</code></pre><pre><code>movies.head()
</code></pre><p><img src="/images/pandas-17.png" alt="image"></p>
<pre><code># sort using sort_values
# sort with numbers first then alphabetical order
movies.title.sort_values()

# alternative sorting
movies['title'].sort_values()
</code></pre><p>Jupyter Output:</p>
<pre><code>542                   (500) Days of Summer
5                             12 Angry Men
201                       12 Years a Slave
698                              127 Hours
110                  2001: A Space Odyssey
910                                   2046
596                               21 Grams
624                              25th Hour
708                       28 Days Later...
60                                3 Idiots
225                                 3-Iron
570                                    300
555                           3:10 to Yuma
427           4 Months, 3 Weeks and 2 Days
824                                     42
597                                  50/50
203                                  8 1/2
170                       A Beautiful Mind
941                       A Bridge Too Far
571                           A Bronx Tale
266                      A Christmas Story
86                      A Clockwork Orange
716                         A Few Good Men
750                    A Fish Called Wanda
276                   A Fistful of Dollars
612                     A Hard Day's Night
883                  A History of Violence
869              A Nightmare on Elm Street
865                        A Perfect World
426                              A Prophet
                      ...                 
207       What Ever Happened to Baby Jane?
562            What's Eating Gilbert Grape
719                When Harry Met Sally...
649                      Where Eagles Dare
33                                Whiplash
669                Who Framed Roger Rabbit
219        Who's Afraid of Virginia Woolf?
127                      Wild Strawberries
497    Willy Wonka &amp; the Chocolate Factory
270                        Wings of Desire
483                           Withnail &amp; I
920                                Witness
65             Witness for the Prosecution
970                            Wonder Boys
518                         Wreck-It Ralph
954                                  X-Men
248             X-Men: Days of Future Past
532                     X-Men: First Class
871                                     X2
695                      Y Tu Mama Tambien
403                             Ying xiong
235                                Yip Man
96                                 Yojimbo
280                     Young Frankenstein
535                                  Zelig
955                       Zero Dark Thirty
677                                 Zodiac
615                             Zombieland
526                                   Zulu
864                                  [Rec]
Name: title, dtype: object
</code></pre><pre><code># returns a series
type(movies['title'].sort_values())
</code></pre><p>Jupyter Output:</p>
<pre><code>pandas.core.series.Series
</code></pre><p><strong>Tirer une colonne:</strong></p>
<pre><code># sort in ascending=False
# this does not affect the underlying data
movies.title.sort_values(ascending=False)
</code></pre><p>Jupyter Output:</p>
<pre><code>864                                  [Rec]
526                                   Zulu
615                             Zombieland
677                                 Zodiac
955                       Zero Dark Thirty
535                                  Zelig
280                     Young Frankenstein
96                                 Yojimbo
235                                Yip Man
403                             Ying xiong
695                      Y Tu Mama Tambien
871                                     X2
532                     X-Men: First Class
248             X-Men: Days of Future Past
954                                  X-Men
518                         Wreck-It Ralph
970                            Wonder Boys
65             Witness for the Prosecution
920                                Witness
483                           Withnail &amp; I
270                        Wings of Desire
497    Willy Wonka &amp; the Chocolate Factory
127                      Wild Strawberries
219        Who's Afraid of Virginia Woolf?
669                Who Framed Roger Rabbit
33                                Whiplash
649                      Where Eagles Dare
719                When Harry Met Sally...
562            What's Eating Gilbert Grape
207       What Ever Happened to Baby Jane?
                      ...                 
426                              A Prophet
865                        A Perfect World
869              A Nightmare on Elm Street
883                  A History of Violence
612                     A Hard Day's Night
276                   A Fistful of Dollars
750                    A Fish Called Wanda
716                         A Few Good Men
86                      A Clockwork Orange
266                      A Christmas Story
571                           A Bronx Tale
941                       A Bridge Too Far
170                       A Beautiful Mind
203                                  8 1/2
597                                  50/50
824                                     42
427           4 Months, 3 Weeks and 2 Days
555                           3:10 to Yuma
570                                    300
225                                 3-Iron
60                                3 Idiots
708                       28 Days Later...
624                              25th Hour
596                               21 Grams
910                                   2046
110                  2001: A Space Odyssey
698                              127 Hours
201                       12 Years a Slave
5                             12 Angry Men
542                   (500) Days of Summer
Name: title, dtype: object
</code></pre><p><strong>Trieer un DataFrame en utilisant une colonne particulière:</strong></p>
<pre><code>movies.sort_values('title')
</code></pre><p><img src="/images/pandas-18.png" alt="image"></p>
<pre><code>movies.sort_values('duration', ascending=False)
</code></pre><p><img src="/images/pandas-19.png" alt="image"></p>
<p><strong>Trier un DataFrame en utilisant plusieurs colonnes:</strong></p>
<pre><code># create list of columns
# sort using content_rating
# then within content_rating, sort by duration
columns = ['content_rating', 'duration']

# sort column
movies.sort_values(columns)
</code></pre><p><img src="/images/pandas-20.png" alt="image"></p>
<h2 id="filtrer">Filtrer</h2>
<p><em>Filtrer les lignes d'un dataframe Pandas par rapport aux valeurs d'une colonne</em></p>
<pre><code>import pandas as pd
</code></pre><pre><code># url

url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csv'

# create DataFrame called movies
movies = pd.read_csv(url)
</code></pre><pre><code>movies.head()
</code></pre><p><img src="/images/pandas-21.png" alt="image"></p>
<pre><code>movies.shape
</code></pre><p>Jupyter Output:</p>
<pre><code>(979, 6)
</code></pre><pre><code># booleans
type(True)
type(False)
</code></pre><p>Jupyter Output:</p>
<pre><code>bool
</code></pre><p>On veut créer une liste de boolean avec le même nombre de lignes que le dataframe movies</p>
<ul>
<li>Le boolean vaudra true si la duration &gt; 200</li>
<li>false dans le cas contraire</li>
</ul>
<pre><code># create list
booleans = []

# loop
for length in movies.duration:
    if length &gt;= 200:
        booleans.append(True)
    else:
        booleans.append(False)
</code></pre><pre><code>booleans[0:5]
</code></pre><p>Jupyter Output:</p>
<pre><code>[False, False, True, False, False]
</code></pre><pre><code># len(booleans) is the same as the number of rows in movies' DataFrame
len(booleans)
</code></pre><p>Jupyter Output:</p>
<pre><code>979
</code></pre><pre><code># convert booleans into a Pandas series
is_long = pd.Series(booleans)
</code></pre><pre><code>is_long.head()
</code></pre><p>Jupyter Output:</p>
<pre><code>0    False
1    False
2     True
3    False
4    False
dtype: bool
</code></pre><pre><code># pulls out genre
movies['genre']
</code></pre><p>Jupyter Output:</p>
<pre><code>0          Crime
1          Crime
2          Crime
3         Action
4          Crime
5          Drama
6        Western
7      Adventure
8      Biography
9          Drama
10     Adventure
11        Action
12        Action
13         Drama
14     Adventure
15     Adventure
16         Drama
17         Drama
18     Biography
19        Action
20        Action
21         Crime
22         Drama
23         Crime
24         Drama
25        Comedy
26       Western
27         Drama
28         Crime
29        Comedy
         ...    
949       Comedy
950        Crime
951        Drama
952       Comedy
953    Adventure
954       Action
955        Drama
956       Comedy
957       Comedy
958        Drama
959       Comedy
960       Comedy
961    Biography
962       Comedy
963       Action
964    Biography
965      Mystery
966    Animation
967       Action
968        Drama
969        Crime
970        Drama
971       Comedy
972        Drama
973        Drama
974       Comedy
975    Adventure
976       Action
977       Horror
978        Crime
Name: genre, dtype: object
</code></pre><pre><code># this pulls out duration &gt;= 200mins
movies[is_long]
</code></pre><p><img src="/images/pandas-22.png" alt="image"></p>
<p><strong>Méthode plus rapide sans for loop:</strong></p>
<pre><code># this line of code replaces the for loop
# when you use a series name using pandas and use a comparison operator, it will loop through each row
is_long = movies.duration &gt;= 200
is_long.head()
</code></pre><p>Jupyter Output:</p>
<pre><code>0    False
1    False
2     True
3    False
4    False
Name: duration, dtype: bool
</code></pre><pre><code>movies[is_long]
</code></pre><p><img src="/images/pandas-23.png" alt="image"></p>
<p><strong>Méthode encore meilleure pour simplifier <code>movies[is_long]</code>:</strong></p>
<pre><code>movies[movies.duration &gt;= 200]
</code></pre><p><img src="/images/pandas-24.png" alt="image"></p>
<p><strong>Conseil additionnel: on veut étudier la duration et seulement le genre au lieu de toutes les colonnes</strong></p>
<pre><code># this is a DataFrame, we use dot or bracket notation to get what we want
movies[movies.duration &gt;= 200]['genre']
movies[movies.duration &gt;= 200].genre
</code></pre><p>Jupyter Output:</p>
<pre><code>2          Crime
7      Adventure
17         Drama
78         Crime
85     Adventure
142    Adventure
157        Drama
204    Adventure
445    Adventure
476        Drama
630    Biography
767       Action
Name: genre, dtype: object
</code></pre><pre><code># best practice is to use .loc instead of what we did above by selecting columns
movies.loc[movies.duration &gt;= 200, 'genre']
</code></pre><p>Jupyter Output:</p>
<pre><code>2          Crime
7      Adventure
17         Drama
78         Crime
85     Adventure
142    Adventure
157        Drama
204    Adventure
445    Adventure
476        Drama
630    Biography
767       Action
Name: genre, dtype: object
</code></pre><h2 id="filtres-multi-critres">Filtres multi-critères</h2>
<p><em>Appliquer des filtres multi-critères sur un dataframe Pandas</em></p>
<pre><code>import pandas as pd
</code></pre><pre><code>url = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/imdb_1000.csv'

# Create movies DataFrame
movies = pd.read_csv(url)
</code></pre><pre><code>movies.head()
</code></pre><p><img src="/images/pandas-25.png" alt="image"></p>
<pre><code>movies[movies.duration &gt;= 200]
</code></pre><p><img src="/images/pandas-26.png" alt="image"></p>
<p>2 conditions</p>
<ul>
<li>duration &gt; 200</li>
<li>Seulement genre Drama</li>
</ul>
<pre><code>True or False
Output: True

True or True
Output: True

False or False
Output: False

True and True
Output: True

True and False
Output: False
</code></pre><pre><code># when you wrap conditions in parantheses, you give order
# you do those in brackets first before 'and'
# AND
movies[(movies.duration &gt;= 200) &amp; (movies.genre == 'Drama')]
</code></pre><p><img src="/images/pandas-27.png" alt="image"></p>
<pre><code># OR 
movies[(movies.duration &gt;= 200) | (movies.genre == 'Drama')]
</code></pre><p><img src="/images/pandas-28.png" alt="image"></p>
<pre><code>(movies.duration &gt;= 200) | (movies.genre == 'Drama')
</code></pre><p>Jupyter Output:</p>
<pre><code>0      False
1      False
2       True
3      False
4      False
5       True
6      False
7       True
8      False
9       True
10     False
11     False
12     False
13      True
14     False
15     False
16      True
17      True
18     False
19     False
20     False
21     False
22      True
23     False
24      True
25     False
26     False
27      True
28     False
29     False
       ...  
949    False
950    False
951     True
952    False
953    False
954    False
955     True
956    False
957    False
958     True
959    False
960    False
961    False
962    False
963    False
964    False
965    False
966    False
967    False
968     True
969    False
970     True
971    False
972     True
973     True
974    False
975    False
976    False
977    False
978    False
dtype: bool
</code></pre><pre><code>(movies.duration &gt;= 200) &amp; (movies.genre == 'Drama')
</code></pre><p>Jupyter Output:</p>
<pre><code>0      False
1      False
2      False
3      False
4      False
5      False
6      False
7      False
8      False
9      False
10     False
11     False
12     False
13     False
14     False
15     False
16     False
17      True
18     False
19     False
20     False
21     False
22     False
23     False
24     False
25     False
26     False
27     False
28     False
29     False
       ...  
949    False
950    False
951    False
952    False
953    False
954    False
955    False
956    False
957    False
958    False
959    False
960    False
961    False
962    False
963    False
964    False
965    False
966    False
967    False
968    False
969    False
970    False
971    False
972    False
973    False
974    False
975    False
976    False
977    False
978    False
dtype: bool
</code></pre><p><strong>Et si on veut les genres crime, drama, et action?</strong></p>
<pre><code># slow method
movies[(movies.genre == 'Crime') | (movies.genre == 'Drama') | (movies.genre == 'Action')]
</code></pre><p><img src="/images/pandas-29.png" alt="image"></p>
<pre><code># fast method
filter_list = ['Crime', 'Drama', 'Action']
movies[movies.genre.isin(filter_list)]
</code></pre><p><img src="/images/pandas-30.png" alt="image"></p>
<h2 id="examiner-un-dataset">Examiner un dataset</h2>
<p><em>Lire un sous-ensemble de colonnes ou lignes</em></p>
<pre><code>import pandas as pd
</code></pre><pre><code>link = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/ufo.csv'
ufo = pd.read_csv(link)
</code></pre><pre><code>ufo.columns
</code></pre><p>Jupyter Output:</p>
<pre><code>Index(['City', 'Colors Reported', 'Shape Reported', 'State', 'Time'], dtype='object')
</code></pre><pre><code># reference using String
cols = ['City', 'State']

ufo = pd.read_csv(link, usecols=cols)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-31.png" alt="image"></p>
<pre><code># reference using position (Integer)
cols2 = [0, 4]

ufo = pd.read_csv(link, usecols=cols2)
</code></pre><pre><code>ufo.head()
</code></pre><p><img src="/images/pandas-32.png" alt="image"></p>
<pre><code># if you only want certain number of rows
ufo = pd.read_csv(link, nrows=3)
</code></pre><pre><code>ufo
</code></pre><p><img src="/images/pandas-33.png" alt="image"></p>
<p><em>Itérer dans une série et un dataframe</em></p>
<pre><code># intuitive method
for c in ufo.City:
    print(c)
</code></pre><p>Jupyter Output:</p>
<pre><code>Ithaca
Willingboro
Holyoke
</code></pre><pre><code># pandas method
# you can grab index and row
for index, row in ufo.iterrows():
    print(index, row.City, row.State)
</code></pre><p>Jupyter Output:</p>
<pre><code>0 Ithaca NY
1 Willingboro NJ
2 Holyoke CO
</code></pre><p><em>Retirer les colonnes non-numeriques d'un DataFrame</em></p>
<pre><code>link = 'https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/drinks.csv'
drinks = pd.read_csv(link)
</code></pre><pre><code># you have 2 non-numeric columns
drinks.dtypes
</code></pre><p>Jupyter Output:</p>
<pre><code>country                          object
beer_servings                     int64
spirit_servings                   int64
wine_servings                     int64
total_litres_of_pure_alcohol    float64
continent                        object
dtype: object
</code></pre><pre><code>import numpy as np
drinks.select_dtypes(include=[np.number]).dtypes
</code></pre><p>Jupyter Output:</p>
<pre><code>beer_servings                     int64
spirit_servings                   int64
wine_servings                     int64
total_litres_of_pure_alcohol    float64
dtype: object
</code></pre><h2 id="numro-index-et-contenu-de-la-ligne-lors-dune-itration">Numéro, index et contenu de la ligne lors d'une itération</h2>
<p>Pour obtenir le numéro, l'index et le contenu de la ligne lors d'une itération on peut utiliser le code suivant:</p>
<pre><code>for line_number, (idx, row) in enumerate(df.iterrows()):
	...

</code></pre>]]></content>
        </item>
        
        <item>
            <title>Comment réduire la durée d&#39;entrainement d&#39;un modèle ?</title>
            <link>https://leandeep.com/comment-r%C3%A9duire-la-dur%C3%A9e-dentrainement-dun-mod%C3%A8le/</link>
            <pubDate>Wed, 13 Feb 2019 20:11:00 +0000</pubDate>
            
            <guid>https://leandeep.com/comment-r%C3%A9duire-la-dur%C3%A9e-dentrainement-dun-mod%C3%A8le/</guid>
            <description>Supposons que nous ayons un dataset composé de 1000 colonnes et comportant 1 million de lignes pour un sujet de classification, comment réduire sa dimension pour réduire les temps d&#39;entrainement ? On suppose également que la machine qui va faire l&#39;entrainement n&#39;a pas énormément de RAM&amp;hellip;
Voici les différentes options:
 Commencer par fermer toutes les applications qui ne servent à rien Echantillonner aléatoirement le dataset. C&#39;est-à-dire créer plusieurs petits datasets de dimension M(300 000, 1 000) et faire plusieurs entrainements On peut séparer les variables numériques et catégorielles et supprimer les variables corrélées.</description>
            <content type="html"><![CDATA[<p>Supposons que nous ayons un dataset composé de 1000 colonnes et comportant 1 million de lignes pour un sujet de classification, comment réduire sa dimension pour réduire les temps d'entrainement ? On suppose également que la machine qui va faire l'entrainement n'a pas énormément de RAM&hellip;</p>
<p>Voici les différentes options:</p>
<ul>
<li>Commencer par fermer toutes les applications qui ne servent à rien</li>
<li>Echantillonner aléatoirement le dataset. C'est-à-dire créer plusieurs petits datasets de dimension M(300 000, 1 000) et faire plusieurs entrainements</li>
<li>On peut séparer les variables numériques et catégorielles et supprimer les variables corrélées. Plus précisément, pour les variables numériques on utilise la corrélation et pour les variables catégorielles on utilise le test du chi 2.</li>
<li>On peut utiliser le PCA et sélectionner les composants qui expliquent le maximum de variance dans le dataset</li>
<li>On peut utiliser l'algorithme de Vowpal Wabbit (online learning)</li>
<li>On peut construire un modèle linéaire en utilisant une descente de gradient stochastique</li>
<li>On peut aussi utiliser ses compétences métier pour sélectionner les features qui vont impacter le plus modèle. C'est une approche qui fait appel à l'intuition.</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Commandes utiles Puppeteer </title>
            <link>https://leandeep.com/commandes-utiles-puppeteer/</link>
            <pubDate>Sat, 09 Feb 2019 21:32:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-utiles-puppeteer/</guid>
            <description>Introduction &amp;ldquo;Puppeteer ou le remplaçant de Selenium.&amp;quot; Dans cet article plutôt rapide, on retrouve les commandes de base pour créer un premier petit script qui va piloter un Chrome Headless.
Initialiser un browser non headless try { (async () =&amp;gt; { const browser = await puppeteer.launch({headless: false}) [...] })() } catch (err) { console.error(err) } Naviguer vers une page const page = await browser.newPage() await page.goto(&amp;quot;https://url_du_site&amp;quot;) Ajouter du contenu dans un input type text await page.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p><strong>&ldquo;Puppeteer ou le remplaçant de Selenium.&quot;</strong>
Dans cet article plutôt rapide, on retrouve les commandes de base pour créer un premier petit script qui va piloter un Chrome Headless.</p>
<h2 id="initialiser-un-browser-non-headless">Initialiser un browser non headless</h2>
<pre><code>try {
    (async () =&gt; {
		const browser = await puppeteer.launch({headless: false})
        
        [...]
       
	})()

} catch (err) {
    console.error(err)
} 

</code></pre><h2 id="naviguer-vers-une-page">Naviguer vers une page</h2>
<pre><code>const page = await browser.newPage()
await page.goto(&quot;https://url_du_site&quot;)

</code></pre><h2 id="ajouter-du-contenu-dans-un-input-type-text">Ajouter du contenu dans un input type text</h2>
<pre><code>await page.type('#input_search', 'text_a_ajouter')
</code></pre><h2 id="cliquer-sur-un-bouton">Cliquer sur un bouton</h2>
<pre><code>await page.click('#buttsearch')
</code></pre><h2 id="chercher-dans-tout-le-corps-dune-page-si-un-pattern-existe">Chercher dans tout le corps d'une page si un pattern existe</h2>
<pre><code>const found = (await page.content()).match(/Chiffre d\'affaires/) 
if (found) {
	
    [...]

}

</code></pre><h2 id="slectionner-un-lment-par-href">Sélectionner un élément par href</h2>
<pre><code>const elementHandle = await page.$('a[href=&quot;#chiffrecle&quot;]');
</code></pre><h2 id="obtenir-le-contenu-texte-dun-lment">Obtenir le contenu texte d'un élément</h2>
<pre><code>const text = await (await elementHandle.getProperty('textContent')).jsonValue();
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Manipulation de CSV volumineux en Data Science </title>
            <link>https://leandeep.com/manipulation-de-csv-volumineux-en-data-science/</link>
            <pubDate>Fri, 08 Feb 2019 11:41:00 +0000</pubDate>
            
            <guid>https://leandeep.com/manipulation-de-csv-volumineux-en-data-science/</guid>
            <description>Il existe de nombreuses librairies en Python pour manipuler des fichiers CSV. Je recommande l&#39;usage des langages de haut niveau comme Python le plus possible car cela permet d&#39;automatiser, &amp;ldquo;d&#39;APIser&amp;rdquo; et d&#39;industrialiser au maximum ses use cases. Mais parfois lorsqu&#39;il faut tailler dans la masse sur des fichiers extrèmement volumineux, rien de tel que les bonnes vieilles méthodes de DevOps :) .
AWK à la rescousse pour par exemple extraire toutes les entreprises situées dans le Nord sur un fichier de plusieurs GB.</description>
            <content type="html"><![CDATA[<p>Il existe de nombreuses librairies en Python pour manipuler des fichiers CSV. Je recommande l'usage des langages de haut niveau comme Python le plus possible car cela permet d'automatiser, <em>&ldquo;d'APIser&rdquo;</em> et d'industrialiser au maximum ses use cases. Mais parfois lorsqu'il faut tailler dans la masse sur des fichiers extrèmement volumineux, rien de tel que les bonnes vieilles méthodes de DevOps :) .</p>
<p><code>AWK</code> à la rescousse pour par exemple extraire toutes les entreprises situées dans le Nord sur un fichier de plusieurs GB.</p>
<pre><code>awk -F &quot;;&quot; '$21~/^&quot;(59)([0-9]{3})&quot;$/' mon_fichier_volumineux.csv &gt;&gt; companies_nord.csv
</code></pre><blockquote>
<p>Note: On peut aussi passer par un Dataframe Pandas et lire le fichier CSV par <em>chunks</em> avec ceci <code>pd.read_csv(csv_url,chunksize=500)</code> mais c'est quand même beaucoup plus long et lourd&hellip;
Je dirais que cela dépend du use case dans lequel on se trouve. Dans mon cas, générer ce fichier est du one-shot&hellip;</p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Comparaison des services de conteneurisation AWS (ECS, Fargate et EKS) </title>
            <link>https://leandeep.com/comparaison-des-services-de-conteneurisation-aws-ecs-fargate-et-eks/</link>
            <pubDate>Wed, 16 Jan 2019 19:33:00 +0000</pubDate>
            
            <guid>https://leandeep.com/comparaison-des-services-de-conteneurisation-aws-ecs-fargate-et-eks/</guid>
            <description>Il n&#39;est pas évident de comprendre les différentes entre AWS ECS, Fargate et EKS. Au premier abord ces outils peuvent sembler similaire. Je me suis personnellement vraiment questionné sur la différence entre AWS Fargate et AWS EKS.
Dans cet article je vais essayer de résumer les différences qu&#39;il peut y avoir entre ces 3 services.
Avantages
   ECS EKS Fargate     Service gratuit (on ne paye que pour le compute sous jacent) Offre toutes les features d’ECS + VPC pour le réseau entre pods et isolation au niveau du cluster Kubernetes Possible d’utiliser l’API de Fargate comme celle d’ECS   Service historique d’AWS d’orchestration de containers Docker Offre tous les avantages de Kubernetes (cloud agnostic) Permet de faire tourner des clusters hétérogènes constitués d’instance EC2 ou Fargate.</description>
            <content type="html"><![CDATA[<p><img src="/images/ecs-fargate-eks.png" alt="image"></p>
<p>Il n'est pas évident de comprendre les différentes entre AWS ECS, Fargate et EKS. Au premier abord ces outils peuvent sembler similaire. Je me suis personnellement vraiment questionné sur la différence entre AWS Fargate et AWS EKS.</p>
<p>Dans cet article je vais essayer de résumer les différences qu'il peut y avoir entre ces 3 services.</p>
<p><strong>Avantages</strong></p>
<table>
<thead>
<tr>
<th>ECS</th>
<th align="center">EKS</th>
<th align="right">Fargate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Service gratuit (on ne paye que pour le compute sous jacent)</td>
<td align="center">Offre toutes les features d’ECS + VPC pour le réseau entre pods et isolation au niveau du cluster Kubernetes</td>
<td align="right">Possible d’utiliser l’API de Fargate comme celle d’ECS</td>
</tr>
<tr>
<td>Service historique d’AWS d’orchestration de containers Docker</td>
<td align="center">Offre tous les avantages de Kubernetes (cloud agnostic)</td>
<td align="right">Permet de faire tourner des clusters hétérogènes constitués d’instance EC2 ou Fargate. Idéal pour scaler rapidement horizontalement</td>
</tr>
<tr>
<td>Possibilité de dupliquer ses environnements via API</td>
<td align="center">Réplication des masters Kubernetes dans 3 zones de disponibilités différentes</td>
<td align="right">Permet de ne pas avoir à manager l’infrastructure</td>
</tr>
<tr>
<td>Intégration sans couture avec la registry Docker AWS ECR (pas besoin de gérer sa propre registry + workflow simple pour gérer ses images)</td>
<td align="center">Possibilité de répliquer l’environnement dans un autre déjà existant avec assez peu de modifications</td>
<td align="right">Support AWS VPC network mode; ce qui signifie que les tâches qui tournent sur une même instance partage l’interface réseau (Elastic Network Interface)</td>
</tr>
<tr>
<td>Auto-healing des containers Docker</td>
<td align="center">Coût assez faible par cluster: $0.20 par heure</td>
<td align="right">Coût à l'usage du compute et non pas à l’instance EC2 sous-jacente. Cela peut permettre de faire des économies</td>
</tr>
<tr>
<td></td>
<td align="center">Toutes les communications entre pods se font via IP dans le VPC</td>
<td align="right">Scalabilité horizontale très rapide (machines provisionées à l’avance)</td>
</tr>
</tbody>
</table>
<p><strong>Inconvénients</strong></p>
<table>
<thead>
<tr>
<th>ECS</th>
<th align="center">EKS</th>
<th align="right">Fargate</th>
</tr>
</thead>
<tbody>
<tr>
<td>Service pas simple à utiliser pour les systèmes distribués</td>
<td align="center">Faible intégration avec les autres services AWS</td>
<td align="right">Moins d’options de customisation</td>
</tr>
<tr>
<td>Scalabité horizontale dépendante du démarrage d’instances EC2</td>
<td align="center">Prévoir des charges supplémentaires pour des ressources complémentaires (ex: stockage)</td>
<td align="right">Besoin de démarrer ses propres composants</td>
</tr>
<tr>
<td>Obtenir un cluster On-demand peut prendre du temps</td>
<td align="center">Pas possible d’avoir plus de 3 clusters par région (quota augmenté par ticket)</td>
<td align="right">Démarrage assez long</td>
</tr>
<tr>
<td>Changer le type d’instance n’est pas possible une fois démarrée</td>
<td align="center">IAM au niveau des pod est difficile à mettre en place</td>
<td align="right">Pas d’accès à un filesystem persistent</td>
</tr>
</tbody>
</table>
]]></content>
        </item>
        
        <item>
            <title>Préparation installation Xpenology - Virtualisation sur Deep Learning Station</title>
            <link>https://leandeep.com/pr%C3%A9paration-installation-xpenology-virtualisation-sur-deep-learning-station/</link>
            <pubDate>Fri, 04 Jan 2019 16:11:00 +0000</pubDate>
            
            <guid>https://leandeep.com/pr%C3%A9paration-installation-xpenology-virtualisation-sur-deep-learning-station/</guid>
            <description>Introduction Il y a quelques temps j&#39;ai investi dans du matériel informatique et me suis construit une station pour faire du Deep Learning. Depuis quelques semaines et surtout depuis qu&#39;on m&#39;a parlé du projet Xpenology (Synology maison) je pense à me construire un NAS. Mais débourser environ 800 euros (TTC) sans être certain du résultat ne m&#39;enchante guère&amp;hellip;
Je vais donc expérimenter Xpenology sur ma station de Deep Learning qui possède un grand nombre de disques durs et qui est allumée 24/7.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Il y a quelques temps j'ai investi dans du matériel informatique et me suis construit une station pour faire du Deep Learning. Depuis quelques semaines et surtout depuis qu'on m'a parlé du projet Xpenology (Synology maison) je pense à me construire un NAS. Mais débourser environ 800 euros (TTC) sans être certain du résultat ne m'enchante guère&hellip;</p>
<p>Je vais donc expérimenter Xpenology sur ma station de Deep Learning qui possède un grand nombre de disques durs et qui est allumée 24/7. Initialement, je voulais installer Proxmox (hyperviseur type 1) et réinstaller ma config de Deep Learning mais ce dernier n'est pas compatible avec ma carte graphique pour faire du <code>passthrough GPU</code>. Et finalement, après réflexion, c'est <em>overkill</em> pour réaliser une expérimentation. Bref avec cette installation, je vais pouvoir vérifier si ce nouveau NAS maison est bien stable avant d'investir.</p>
<p>Je vais installer l'hyperviseur type 2 qemu-kvm pour créer une VM sur laquelle j'installerai Xpenology.</p>
<p>J'ai passé tellement de temps à configurer ma station de Deep Learning que je ne veux pas prendre le risque d'installer n'importe quoi sur mon disque dur actuel. Je commence donc par faire un backup de mon SSD et travailler sur le clone pour vérifier qu'il a bien fonctionné.</p>
<p>Voici la photo d'un boitier assez pratique qui me sert pour cloner mes disques&hellip;</p>
<p><img src="/images/IMG_2801.JPG" alt="image"></p>
<p>Dans cet article, nous allons voir comment installer l'hyperviseur et dans un prochain article voir comment installer Xpenology sur une VM.</p>
<h1 id="installation">Installation</h1>
<h2 id="installation-de-lhyperviseur">Installation de l'hyperviseur</h2>
<p>On vérifie que le hardware est compatible.</p>
<pre><code>sudo apt-get install cpu-checker
sudo kvm-ok

INFO: /dev/kvm exists
KVM acceleration can be used

# ou $ egrep '^flags.*(vmx|svm)' /proc/cpuinfo
# Si un résultat s'affiche, c'est good !
</code></pre><p>Installation du paquet <code>qemu-kvm</code></p>
<pre><code>sudo apt-get install qemu-kvm
</code></pre><p>On ajoute l'utilisateur courant au groupe kvm</p>
<pre><code>sudo adduser $USER kvm
</code></pre><p>On télécharge un ISO pour faire nos tests. Par exemple, Ubuntu server 18.04 LTS: <a href="http://releases.ubuntu.com/bionic/">http://releases.ubuntu.com/bionic/</a></p>
<p>Il est possible de créer des VMs via le CLI mais il y a tellement d'options possibles avec qemu-kvm qu'il est quand même plus simple d'utiliser le gui <code>virt-manager</code>.</p>
<blockquote>
<p>Si comme moi vous vous connectez à votre machine en SSH n'oubliez pas le flag <code>-X</code>.</p>
</blockquote>
<p>Voici néanmoins, si vous êtes curieux, les commandes qu'il est possible d'utiliser:</p>
<p>On crée un fichier image:</p>
<pre><code>cd ~
mkdir virtual_images
qemu-img create -f qcow2 /home/olivier/virtual_images/ubuntu_1804.img 10G
</code></pre><p>Et on peut crée une VM:</p>
<pre><code>kvm -m 256 -cdrom ~/ubuntu-18.04.1.0-live-server-amd64.iso -boot d /home/olivier/virtual_images/ubuntu_1804.img
</code></pre><h2 id="installation-du-gui">Installation du GUI</h2>
<pre><code>sudo apt-get install virt-manager
sudo apt-get install libvirt-bin
sudo adduser $USER libvirtd
reboot
sudo service libvirt-bin start
virt-manager
</code></pre><p>Et voilà il est maintenant possible de créer vos VMs&hellip;</p>
<p><img src="/images/virtmanager.png" alt="image"></p>
<p>Pour accéder en SSH à votre nouvelle VM, sélectionner <code>Host device eno1: macvtap</code> comme Network source et <code>Bridge</code> comme Source mode.</p>
<p>Note:
Pour customiser certains paramètres comme la <code>vram</code> par exemple (impossible à faire via virt-manager), il faut le faire via la commande suivante <code>sudo virsh edit &lt;nom-de-la-vm&gt;</code>.</p>
]]></content>
        </item>
        
        <item>
            <title>Créer une clé USB bootable depuis OSX</title>
            <link>https://leandeep.com/cr%C3%A9er-une-cl%C3%A9-usb-bootable-depuis-osx/</link>
            <pubDate>Thu, 03 Jan 2019 22:19:00 +0000</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-une-cl%C3%A9-usb-bootable-depuis-osx/</guid>
            <description>Voici la procédure à suivre pour créer une clé USB bootable depuis un fichier iso.
diskutil list diskutil unmountDisk disk2 sudo dd if=/Users/olivier/Downloads/proxmox-ve_5.3-1.iso of=/dev/disk2 bs=8m diskutil eject disk2 </description>
            <content type="html"><![CDATA[<p>Voici la procédure à suivre pour créer une clé USB bootable depuis un fichier iso.</p>
<pre><code>diskutil list

diskutil unmountDisk disk2

sudo dd if=/Users/olivier/Downloads/proxmox-ve_5.3-1.iso of=/dev/disk2 bs=8m

diskutil eject disk2
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Provisionner un cluster Kubernetes sur HCloud</title>
            <link>https://leandeep.com/provisionner-un-cluster-kubernetes-sur-hcloud/</link>
            <pubDate>Wed, 02 Jan 2019 00:45:00 +0000</pubDate>
            
            <guid>https://leandeep.com/provisionner-un-cluster-kubernetes-sur-hcloud/</guid>
            <description>Introduction Dans cet article nous allons voir comment provisionner un cluster avec ou sans haute disponibilité sur HCloud. Sans haute disponibilité, on va créer un cluster contenant 2 noeuds (1 master et 1 worker). C&#39;est parfait quand on n&#39;est pas en production.
Pré-requis  Installer Go Installer le binaire Go disponible sur le repository https://github.com/xetys/hetzner-kube  Déploiement du cluster Créer un compte sur HCloud (entrez vos informations personnelles et surtout une CB)</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Dans cet article nous allons voir comment provisionner un cluster avec ou sans haute disponibilité sur <a href="https://console.hetzner.cloud">HCloud</a>.
Sans haute disponibilité, on va créer un cluster contenant 2 noeuds (1 master et 1 worker). C'est parfait quand on n'est pas en production.</p>
<h1 id="pr-requis">Pré-requis</h1>
<ul>
<li>Installer Go</li>
<li>Installer le binaire Go disponible sur le repository <a href="https://github.com/xetys/hetzner-kube">https://github.com/xetys/hetzner-kube</a></li>
</ul>
<h1 id="dploiement-du-cluster">Déploiement du cluster</h1>
<p>Créer un compte sur HCloud (entrez vos informations personnelles et surtout une CB)</p>
<p>Ensuite créez un projet sur <a href="https://console.hetzner.cloud">HCloud</a>.</p>
<p>Une fois le projet créé, créer un token API et gardez le précieusement.</p>
<p>Ensuite entrer les commandes suivantes:</p>
<pre><code># Doc: https://github.com/xetys/hetzner-kube/blob/master/docs/cluster-create.md

# Create context
hetzner-kube context add demo
# Create SSH key
hetzner-kube ssh-key add --name macbook
# Create Cluster
hetzner-kube cluster create --name demo --ssh-key macbook --datacenters nbg1-dc3 --worker-server-type cx21 --master-server-type cx11 --worker-count 1
</code></pre><blockquote>
<p>Pour avoir un cluster en HA, il suffit de passer le paramètre <code>--ha-enabled</code> à la commande précédente. Il y aura alors 3 masters nodes.</p>
</blockquote>
<p>La commande suivante va permettre de créer un contexte Kubernetes &ldquo;kubernetes-admin@kubernetes&rdquo; sur votre laptop dans ~/.kube/config</p>
<pre><code>#hetzner-kube cluster kubeconfig &lt;cluster-name&gt; -f
hetzner-kube cluster kubeconfig demo -f
</code></pre><p>Il sera ensuite possible de lister les noeuds du cluster:</p>
<pre><code>kubectl get nodes

NAME             STATUS    ROLES     AGE       VERSION
demo-master-01   Ready     master    1h        v1.9.6
demo-worker-01   Ready     &lt;none&gt;    1h        v1.9.6
</code></pre><h1 id="installation-dopenebs">Installation d'OpenEBS</h1>
<p>Installation de l'operator et de la storageclass:</p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-operator.yaml

kubectl apply -f https://raw.githubusercontent.com/openebs/openebs/master/k8s/openebs-storageclasses.yaml
</code></pre><p>On définit la nouvelle storageclass comme classe par défaut:</p>
<pre><code>kubectl patch storageclass openebs-standard -p '{&quot;metadata&quot;: {&quot;annotations&quot;:{&quot;storageclass.kubernetes.io/is-default-class&quot;:&quot;true&quot;}}}'
</code></pre><h1 id="installation-dun-ingress-controller">Installation d'un Ingress Controller</h1>
<h2 id="traefik-ingress">Traefik Ingress</h2>
<h3 id="1-cration-des-rles-rbac">1. Création des Rôles (RBAC):</h3>
<pre><code>kubectl apply -f   https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-rbac.yaml
</code></pre><p>Contenu du fichier distant <code>traefik-rbac.yaml</code> :</p>
<pre><code>---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
rules:
  - apiGroups:
      - &quot;&quot;
    resources:
      - services
      - endpoints
      - secrets
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - extensions
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: traefik-ingress-controller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: traefik-ingress-controller
subjects:
- kind: ServiceAccount
  name: traefik-ingress-controller
  namespace: kube-system
</code></pre><h3 id="2-dployement-de-traefik-via-deployment-ou-daemonset">2. Déployement de traefik via Deployment ou DaemonSet</h3>
<p><strong>Option 1: via Deployment (permet de créer un nodePort)</strong></p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-deployment.yaml
</code></pre><p>Contenu du fichier distant <code>traefik-deployment.yaml</code>:</p>
<pre><code>---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: traefik-ingress-lb
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      serviceAccountName: traefik-ingress-controller
      terminationGracePeriodSeconds: 60
      containers:
      - image: traefik
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
        - name: admin
          containerPort: 8080
        args:
        - --api
        - --kubernetes
        - --logLevel=INFO
---
kind: Service
apiVersion: v1
metadata:
  name: traefik-ingress-service
  namespace: kube-system
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
    - protocol: TCP
      port: 80
      name: web
    - protocol: TCP
      port: 8080
      name: admin
  type: NodePort
</code></pre><p><strong>Option 2: via DaemonSet (sera indispensable pour la suite du tuto)</strong></p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/traefik-ds.yaml
</code></pre><p>Contenu du fichier distant <code>traefik-ds.yaml</code> :</p>
<pre><code>---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
---
kind: DaemonSet
apiVersion: extensions/v1beta1
metadata:
  name: traefik-ingress-controller
  namespace: kube-system
  labels:
    k8s-app: traefik-ingress-lb
spec:
  template:
    metadata:
      labels:
        k8s-app: traefik-ingress-lb
        name: traefik-ingress-lb
    spec:
      serviceAccountName: traefik-ingress-controller
      terminationGracePeriodSeconds: 60
      containers:
      - image: traefik
        name: traefik-ingress-lb
        ports:
        - name: http
          containerPort: 80
          hostPort: 80
        - name: admin
          containerPort: 8080
          hostPort: 8080
        securityContext:
          capabilities:
            drop:
            - ALL
            add:
            - NET_BIND_SERVICE
        args:
        - --api
        - --kubernetes
        - --logLevel=INFO
---
kind: Service
apiVersion: v1
metadata:
  name: traefik-ingress-service
  namespace: kube-system
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
    - protocol: TCP
      port: 80
      name: web
    - protocol: TCP
      port: 8080
      name: admin
</code></pre><h3 id="3-vrification-du-dploiement">3. Vérification du déploiement</h3>
<pre><code>kubectl --namespace=kube-system get pods
</code></pre><h3 id="4-dploiement-de-linterface-dadmin-de-traefik">4. Déploiement de l'interface d'admin de Traefik</h3>
<p>Via un service:</p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/ui.yaml
</code></pre><p>Contenu du fichier distant <code>ui.yaml</code> :</p>
<pre><code>---
apiVersion: v1
kind: Service
metadata:
  name: traefik-web-ui
  namespace: kube-system
spec:
  selector:
    k8s-app: traefik-ingress-lb
  ports:
  - name: web
    port: 80
    targetPort: 8080
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: traefik-web-ui
  namespace: kube-system
spec:
  rules:
  - host: traefik-ui.minikube
    http:
      paths:
      - path: /
        backend:
          serviceName: traefik-web-ui
          servicePort: web
</code></pre><h3 id="5-accs--linterface-traefik-en-dev">5. Accès à l'interface Traefik en dev</h3>
<pre><code>echo &quot;ip_dun_worker traefik-ui.minikube&quot; | sudo tee -a /etc/hosts
</code></pre><h3 id="6-vrification-du-bon-fonctionnement-de-lingress">6. Vérification du bon fonctionnement de l'ingress</h3>
<p><strong>6.1. Déploiement de 3 apps de test</strong></p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-deployments.yaml
</code></pre><p>Contenu du fichier distant <code>cheese-deployments.yaml</code> :</p>
<pre><code>---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: stilton
  labels:
    app: cheese
    cheese: stilton
spec:
  replicas: 2
  selector:
    matchLabels:
      app: cheese
      task: stilton
  template:
    metadata:
      labels:
        app: cheese
        task: stilton
        version: v0.0.1
    spec:
      containers:
      - name: cheese
        image: errm/cheese:stilton
        resources:
          requests:
            cpu: 100m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 50Mi
        ports:
        - containerPort: 80
---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: cheddar
  labels:
    app: cheese
    cheese: cheddar
spec:
  replicas: 2
  selector:
    matchLabels:
      app: cheese
      task: cheddar
  template:
    metadata:
      labels:
        app: cheese
        task: cheddar
        version: v0.0.1
    spec:
      containers:
      - name: cheese
        image: errm/cheese:cheddar
        resources:
          requests:
            cpu: 100m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 50Mi
        ports:
        - containerPort: 80
---
kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  name: wensleydale
  labels:
    app: cheese
    cheese: wensleydale
spec:
  replicas: 2
  selector:
    matchLabels:
      app: cheese
      task: wensleydale
  template:
    metadata:
      labels:
        app: cheese
        task: wensleydale
        version: v0.0.1
    spec:
      containers:
      - name: cheese
        image: errm/cheese:wensleydale
        resources:
          requests:
            cpu: 100m
            memory: 50Mi
          limits:
            cpu: 100m
            memory: 50Mi
        ports:
        - containerPort: 80
</code></pre><p><strong>6.2. Création des 3 services</strong></p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-services.yaml
</code></pre><p>Contenu du fichier distant <code>cheese-services.yaml</code> :</p>
<pre><code>---
apiVersion: v1
kind: Service
metadata:
  name: stilton
spec:
  ports:
  - name: http
    targetPort: 80
    port: 80
  selector:
    app: cheese
    task: stilton
---
apiVersion: v1
kind: Service
metadata:
  name: cheddar
spec:
  ports:
  - name: http
    targetPort: 80
    port: 80
  selector:
    app: cheese
    task: cheddar
---
apiVersion: v1
kind: Service
metadata:
  name: wensleydale
spec:
  ports:
  - name: http
    targetPort: 80
    port: 80
  selector:
    app: cheese
    task: wensleydale
</code></pre><p><strong>6.3. Création de l'ingress</strong></p>
<pre><code>kubectl apply -f https://raw.githubusercontent.com/containous/traefik/master/examples/k8s/cheese-ingress.yaml
</code></pre><p>Contenu du fichier distant <code>cheese-ingress.yaml</code> :</p>
<pre><code>apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: cheese
spec:
  rules:
  - host: stilton.minikube
    http:
      paths:
      - path: /
        backend:
          serviceName: stilton
          servicePort: http
  - host: cheddar.minikube
    http:
      paths:
      - path: /
        backend:
          serviceName: cheddar
          servicePort: http
  - host: wensleydale.minikube
    http:
      paths:
      - path: /
        backend:
          serviceName: wensleydale
          servicePort: http
</code></pre><h3 id="accs-aux-3-apps-en-dev">Accès aux 3 apps en dev</h3>
<pre><code>echo &quot;116.203.33.4 stilton.minikube cheddar.minikube wensleydale.minikube&quot; | sudo tee -a /etc/hosts
</code></pre><h2 id="ingress-nginx">Ingress Nginx</h2>
<p>Voir le tuto: <a href="https://github.com/kubernetes/ingress-nginx/blob/master/docs/deploy/index.md">https://github.com/kubernetes/ingress-nginx/blob/master/docs/deploy/index.md</a></p>
<h1 id="dploiement-dune-app-via-helm">Déploiement d'une app via helm</h1>
<h2 id="installation-du-tiller">Installation du tiller</h2>
<pre><code>helm init --service-account tiller
</code></pre><h2 id="cration-dun-service-account">Création d'un service account</h2>
<pre><code>kubectl create serviceaccount --namespace kube-system tiller
# Ajout des droits sur l'ensemble du cluster pour pouvoir déployer dans les différents namespaces
kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller
kubectl patch deploy --namespace kube-system tiller-deploy -p '{&quot;spec&quot;:{&quot;template&quot;:{&quot;spec&quot;:{&quot;serviceaccount&quot;:&quot;tiller&quot;}}}}'
</code></pre><h2 id="dploiement">Déploiement</h2>
<p>Pour accéder à une application il y a différente possibilités.</p>
<p><strong>Accès via Nodeport</strong></p>
<p>Déploiement d'un nodeport:
<img src="/images/nodeport.png" alt="image"></p>
<pre><code>kubectl expose deployment hello-world --type=NodePort --name=example-service
kubectl get svc
NAME              TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)          AGE
example-service   NodePort    10.97.67.9   &lt;none&gt;        8080:30485/TCP   2s
kubernetes        ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP          1h

curl http://&lt;ip_cluster&gt;:30485
Hello Kubernetes!
</code></pre><p><code>NodePort</code> est une option que l'on configure directement dans le service. Kubernetes va allouer un port specifique sur chaque noeud du cluster pour accéder au service. Une requête arrivant sur n'importe quel noeud sera routée vers le service.</p>
<p>C'est cool car c'est très simple à mettre en place mais ce n'est pas robuste. De plus on ne peut pas savoir quel port sera alloué au service et pas garantir qu'il sera toujours le même&hellip;</p>
<p>Il y a d'autres solutions:</p>
<ul>
<li>LoadBalancer</li>
<li>Ingress</li>
</ul>
<p><strong>Accès via LoadBalancer</strong> (si votre IAAS est capable de vous fournir un Load Balancer à la demande)</p>
<p><img src="/images/loadbalancer.png" alt="image"></p>
<p>Egalement assez simple à mettre en place, il est possible de spécifier dans le YAML qu'un service est de type LoadBalancer.
Par contre, la fonctionnalité de load balancing doit être implémentée à l'extérieur par le cloud provider. Attention donc aux coûts (i.e. GKE) car à chaque fois que vous aurez à exposer un service au monde extérieur vous devrez créer un nouveau load balancer et obtenir une adresse IP.</p>
<p><strong>Accès via Ingress</strong></p>
<p><img src="/images/ingress.png" alt="image"></p>
<p>Contrairement au <code>NodePort</code> and au <code>LoadBalancer</code>, l'<code>Ingress</code> est une ressource complètement indépendante du service. On déclare, crée et détruit l'ingress indépendament des services.</p>
<p>C'est donc découplé et isolé des services que l'on veut exposer. Cela permet, entre autres, de mieux gérer les rêgles de routage.</p>
<hr>
<p>Dans notre cas, nous allons utiliser un ingress.
On commence par déployer l'application en spécifiant <code>ClusterIP</code> comme <code>serviceType</code>:</p>
<pre><code>helm install --set service.type=ClusterIP stable/ghost
</code></pre><p>A présent on peut créer notre ingress:</p>
<p>Note du 02/01/2018 - Procédure suivante à vérifier (validation d'ici peu&hellip; Si cela ne fonctionne pas, voir le contenu du fichier <code>cheese-ingress.yaml</code> plus haut)</p>
<pre><code>cat ingress.yaml
</code></pre><p>Output:</p>
<pre><code>apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  name: iron-hyena-ghost
spec:
  backend:
    serviceName: iron-hyena-ghost
    servicePort: 80
</code></pre><p>Puis on applique:</p>
<pre><code>kubectl apply -f ingress.yaml
</code></pre><h1 id="etendre-le-cluster">Etendre le cluster</h1>
<p>Pour ajouter des workers au cluster existant:</p>
<pre><code>hetzner-kube cluster add-worker --worker-server-type cx21 --datacenters nbg1-dc3 --name demo --nodes 1

#hetzner-kube cluster add-worker --worker-server-type cx21 --datacenters nbg1-dc3 --name &lt;cluster-name&gt; --nodes 1
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Monter un dossier distant avec SSHFS</title>
            <link>https://leandeep.com/monter-un-dossier-distant-avec-sshfs/</link>
            <pubDate>Sat, 29 Dec 2018 21:24:00 +0000</pubDate>
            
            <guid>https://leandeep.com/monter-un-dossier-distant-avec-sshfs/</guid>
            <description>SSHFS sert à monter sur son système de fichier, un autre système de fichier distant, à travers une connexion SSH, le tout avec des droits utilisateur.
C&#39;est plutôt pratique. Voici la commande:
sshfs -p &amp;lt;votre_port_ssh&amp;gt; -o allow_other,defer_permissions olivier@ip_server:path_dossier_a_monter repertoire_en_local  Installer sshfs sur Ubuntu: sudo apt install -y sshfs
  Installer sshfs sur OSX: brew cask install osxfuse &amp;amp;&amp;amp; brew install sshfs
 </description>
            <content type="html"><![CDATA[<p><code>SSHFS</code> sert à monter sur son système de fichier, un autre système de fichier distant, à travers une connexion SSH, le tout avec des droits utilisateur.</p>
<p>C'est plutôt pratique. Voici la commande:</p>
<pre><code>sshfs -p &lt;votre_port_ssh&gt; -o allow_other,defer_permissions olivier@ip_server:path_dossier_a_monter repertoire_en_local
</code></pre><blockquote>
<p>Installer sshfs sur Ubuntu: <code>sudo apt install -y sshfs</code></p>
</blockquote>
<blockquote>
<p>Installer sshfs sur OSX: <code>brew cask install osxfuse &amp;&amp; brew install sshfs</code></p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Construire une voiture téléguidée autonome - part 1</title>
            <link>https://leandeep.com/construire-une-voiture-t%C3%A9l%C3%A9guid%C3%A9e-autonome-part-1/</link>
            <pubDate>Fri, 21 Dec 2018 22:30:00 +0000</pubDate>
            
            <guid>https://leandeep.com/construire-une-voiture-t%C3%A9l%C3%A9guid%C3%A9e-autonome-part-1/</guid>
            <description>Introduction Mon objectif est de construire une voiture téléguidée autonome. Réaliser ce projet me permettra de développer davantage mes compétences sur le sujet de la conduite autonome et plus généralement du Deep Learning. J&#39;ai déjà réalisé un premier projet sur ce sujet (j&#39;ai publié un article et une vidéo Youtube) mais mon expérimentation utilisait le simulateur Unity. Maintenant avec ce nouveau projet, je veux sortir du virtuel et aller un cran plus loin en passant au monde réel.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Mon objectif est de construire une voiture téléguidée autonome. Réaliser ce projet me permettra de développer davantage mes compétences sur le sujet de la conduite autonome et plus généralement du Deep Learning. J'ai déjà réalisé un premier projet sur ce sujet (j'ai publié un article et une vidéo Youtube) mais mon expérimentation utilisait le simulateur Unity. Maintenant avec ce nouveau projet, je veux sortir du virtuel et aller un cran plus loin en passant au monde réel.</p>
<p>Pour ce faire, j'ai donc acheté une petite voiture téléguidée. J'ai démonté la télécommande et je l'ai &ldquo;<em>hackée</em>&quot;. J'ai en effet réalisé 4 dérivations sur le circuit de commande. Les 4 boutons poussoirs que l'on retrouve dans presque toutes les télécommandes de ces voitures sont maintenant <em>bypassés</em>/ remplacés par mon Raspberry Pi 3 via le GPIO.</p>
<p>J'ai pas mal de Micro-controleurs et de Micro-ordinateurs (Arduino Uno, Mega, Yun, Orange Pi, Banana Pi, Raspberry Pi 1, 2, 3, et pleins d'autres&hellip;). J'ai opté pour le Raspberry Pi 3 pour ce projet tout simplement parce qu'il a du Wifi intégré et parce qu'il devrait être assez puissant pour faire tourner Tensorflow et la vidéo (+ broadcast sur Webapp et API hostée). L'avenir me dira s'il sera suffisant puissant pour tout faire tourner. Pour le moment j'en suis encore à la partie hardware. L'idée, pour ce projet, est de ne pas avoir besoin d'une connexion internet pour que le voiture roule de façon autonome.</p>
<h2 id="rsultat-de-mon-travail">Résultat de mon travail</h2>
<p><!-- raw HTML omitted -->Première vidéo:<!-- raw HTML omitted --> Premiers tests juste après la soudure des composants et branchement des fils



</p>
<p><!-- raw HTML omitted -->Deuxième vidéo:<!-- raw HTML omitted --> Tout est branché et semble opérationnel. On peut maintenant tester la voiture et la piloter avec son Smartphone. Yeah cela fonctionne parfaitement et sans aucune latence (Websocket).</p>




<h2 id="schma-de-cablage">Schéma de cablage</h2>
<p>Voici le schéma de cablage:
<img src="/images/schema-cablage.png" alt="image"></p>
<p>Matériel nécessaire (presque rien):
<img src="/images/IMG_2746.JPG" alt="image"></p>
<ul>
<li>1 breadboard (pour v1 prototypage. Pas viable dans le temps. je vais tout souder (dès que j'ai reçu les pièces))</li>
<li>Fer à souder et étain</li>
<li>4 opto coupleurs</li>
<li>1 voiture téléguidée</li>
<li>1 Raspberry Pi 3</li>
<li>Des fils male / male et male / femelle</li>
<li>1 carte Micro SD</li>
<li>1 batterie externe (pour le Raspberry Pi)</li>
</ul>
<p>Montage terminé:
<img src="/images/IMG_2749.JPG" alt="image"></p>
<h2 id="pilotage-de-la-voiture">Pilotage de la voiture</h2>
<p>J'ai réalisé une petite interface Web très simple qui me permet de piloter la voiture.
Il y a aussi un petit serveur NodeJS qui permet de transmettre les commandes de l'interface au GPIO du Raspberry Pi via Websocket et de servir les fichiers statiques (html et js).</p>
<p>Tout est opensource et disponible <a href="https://github.com/oeeckhoutte/RC-Car">ici</a>.</p>
<p>Voici à quoi ressmemble l'interface qui ne va pas me servir très longtemps puisque mon objectif est que la voiture soit autonome.</p>
<p><img src="/images/IMG_2747.PNG" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Coding Coneway&#39;s Game of Life en TDD</title>
            <link>https://leandeep.com/coding-coneways-game-of-life-en-tdd/</link>
            <pubDate>Sat, 15 Dec 2018 18:31:00 +0000</pubDate>
            
            <guid>https://leandeep.com/coding-coneways-game-of-life-en-tdd/</guid>
            <description>Ce weekend, j&#39;ai pris pas mal de plaisir à faire un Kata en JavaScript et coder le jeu Conway&#39;s Game of Life.
Si vous ne connaissez pas ce jeu il y a une formidable vidéo explicative sur la chaine science étonnante: https://www.youtube.com/watch?v=S-W0NX97DB0
Voici le code source de la partie front en React: https://github.com/oeeckhoutte/gol-kata-front
Voici la partie &amp;ldquo;business logic&amp;rdquo;: https://github.com/oeeckhoutte/gol-kata
En faisant un npm i ou yarn le module gol-kata dont le code est ci-dessus et que j&#39;ai codé en TDD (Test Driven Development) se téléchargera dans le répertoire node_modules.</description>
            <content type="html"><![CDATA[<p>Ce weekend, j'ai pris pas mal de plaisir à faire un Kata en JavaScript et coder le jeu <em>Conway's Game of Life</em>.</p>
<p>Si vous ne connaissez pas ce jeu il y a une formidable vidéo explicative sur la chaine science étonnante: <a href="https://www.youtube.com/watch?v=S-W0NX97DB0">https://www.youtube.com/watch?v=S-W0NX97DB0</a></p>
<p>Voici le code source de la partie front en React: <a href="https://github.com/oeeckhoutte/gol-kata-front">https://github.com/oeeckhoutte/gol-kata-front</a></p>
<p>Voici la partie &ldquo;business logic&rdquo;: <a href="https://github.com/oeeckhoutte/gol-kata">https://github.com/oeeckhoutte/gol-kata</a></p>
<p>En faisant un <code>npm i</code> ou <code>yarn</code> le module <code>gol-kata</code> dont le code est ci-dessus et que j'ai codé en TDD (Test Driven Development) se téléchargera dans le répertoire <code>node_modules</code>. N'hésitez pas à jeter un oeil au code.</p>
<p>Voici une vidéo du résultat:</p>

    <iframe 
        width="100%" 
        height="400px"
        src="//www.youtube.com/embed/uOMwzMhDhnY?autoplay=1&mute=1" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>


]]></content>
        </item>
        
        <item>
            <title>Convertir une video .webm en .mp4</title>
            <link>https://leandeep.com/convertir-une-video-.webm-en-.mp4/</link>
            <pubDate>Sun, 02 Dec 2018 11:14:00 +0000</pubDate>
            
            <guid>https://leandeep.com/convertir-une-video-.webm-en-.mp4/</guid>
            <description>Si comme moi vous aimez écouter en voiture des conférences enregistrées et que vous avez un iPhone, vous savez que le format mp4 est indispensable pour passer par iTunes.
Pour convertir une vidéo .webm en .mp4, il suffit d&#39;utiliser les commandes suivantes:
# Si vous ne l&#39;avez pas déjà # brew install ffmpeg ffmpeg -i &amp;lt;votre-video&amp;gt;.webm &amp;lt;votre-video&amp;gt;.mp4 Il ne faut surtout pas de logiciel payant !</description>
            <content type="html"><![CDATA[<p>Si comme moi vous aimez écouter en voiture des conférences enregistrées et que vous avez un iPhone, vous savez que le format mp4 est indispensable pour passer par iTunes.</p>
<p>Pour convertir une vidéo .webm en .mp4, il suffit d'utiliser les commandes suivantes:</p>
<pre><code># Si vous ne l'avez pas déjà
# brew install ffmpeg

ffmpeg -i &lt;votre-video&gt;.webm &lt;votre-video&gt;.mp4
</code></pre><p>Il ne faut surtout pas de logiciel payant !</p>
]]></content>
        </item>
        
        <item>
            <title>Tester une tâche Gitlab CI localement sans Gitlab</title>
            <link>https://leandeep.com/tester-une-t%C3%A2che-gitlab-ci-localement-sans-gitlab/</link>
            <pubDate>Sun, 18 Nov 2018 21:18:00 +0000</pubDate>
            
            <guid>https://leandeep.com/tester-une-t%C3%A2che-gitlab-ci-localement-sans-gitlab/</guid>
            <description>Dans cet article nous allons voir comment tester une pipeline Gitlab CI en local. Il n&#39;est pas nécessaire d&#39;installer un Gitlab en local; ce qui peut être ennuyeux avec la gestion des certificats SSL. Pouvoir tester son fichier .gitlab-ci.yml en local est très utile pour 2 raisons. D&#39;un côté c&#39;est plus rapide car il ne faut pas pousser son code sur un Gitlab distant et attendre qu&#39;un runner soit disponible. D&#39;un autre côté on ne pollue pas le repository Git distant avec d&#39;innombrables commits de tests (on peut réécrire l&#39;historique je sais bien) ou avec des notifications aux collègues.</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons voir comment tester une pipeline Gitlab CI en local. Il n'est pas nécessaire d'installer un Gitlab en local; ce qui peut être ennuyeux avec la gestion des certificats SSL. Pouvoir tester son fichier <code>.gitlab-ci.yml</code> en local est très utile pour 2 raisons. D'un côté c'est plus rapide car il ne faut pas pousser son code sur un Gitlab distant et attendre qu'un runner soit disponible. D'un autre côté on ne pollue pas le repository Git distant avec d'innombrables commits de tests (on peut réécrire l'historique je sais bien) ou avec des notifications aux collègues.</p>
<p>Prenons par exemple le fichier <code>.gitlab-ci.yml</code> suivant:</p>
<pre><code>build:
    image: nodejs:8
    stage: build
    before_script:
        - npm i
    script:
        - npm run build

</code></pre><p>Avec la commande suivante on peut directement tester sa tâche build en local:</p>
<pre><code>gitlab-runner exec docker build
</code></pre><p>Lorsqu'on utilise Gitlab CI on faut parfois faire appel à du cache entre les stages. C'est possible d'en avoir avec la commande suivante:</p>
<pre><code>gitlab-runner exec docker --docker-volumes `pwd`/cache:/cache build
</code></pre><p>On peut aussi se faire un petit <code>Makefile</code> pour se simplifier la vie:</p>
<pre><code>.PHONY: clean

.DEFAULT: cache
    gitlab-runner exec docker --docker-volumes `pwd`/cache:/cache $@

cache:
    mkdir $@

clean:
    rm -rf cache
</code></pre><p>Enfin, si vous voulez passer des variables d'environnement dans un stage de votre pipeline cela se fait ainsi:</p>
<pre><code>gitlab-runner exec docker --env YOUR_ENV_VAR=&quot;&quot; build
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Partager des clés privées entre les différents membres d&#39;une équipe</title>
            <link>https://leandeep.com/partager-des-cl%C3%A9s-priv%C3%A9es-entre-les-diff%C3%A9rents-membres-dune-%C3%A9quipe/</link>
            <pubDate>Thu, 01 Nov 2018 19:37:00 +0000</pubDate>
            
            <guid>https://leandeep.com/partager-des-cl%C3%A9s-priv%C3%A9es-entre-les-diff%C3%A9rents-membres-dune-%C3%A9quipe/</guid>
            <description>Lorsqu&#39;on travaille dans une équipe de Devops il n&#39;est pas rare de devoir partager des fichiers sécurisés (clés privées&amp;hellip;). Ce sont les fichiers que l&#39;on doit impérativement sauvegarder (si le Devops est en congés ou quitte l&#39;entreprise) et que l&#39;on ne peut pas mettre sur Git.
Pour ce genre de fichiers heureuesement il y a des outils comme EncFS qui permettent de crypter des dossiers. On peut ainsi créer un dossier dans un espace partagé (Dropbox, Google Drive&amp;hellip;), le partager à toute une équipe et seules les personnes qui ont le mot de passe pourront le décrypter.</description>
            <content type="html"><![CDATA[<p>Lorsqu'on travaille dans une équipe de Devops il n'est pas rare de devoir partager des fichiers sécurisés (clés privées&hellip;). Ce sont les fichiers que l'on doit impérativement sauvegarder (si le Devops est en congés ou quitte l'entreprise) et que l'on ne peut pas mettre sur Git.</p>
<p>Pour ce genre de fichiers heureuesement il y a des outils comme EncFS qui permettent de crypter des dossiers. On peut ainsi créer un dossier dans un espace partagé (Dropbox, Google Drive&hellip;), le partager à toute une équipe et seules les personnes qui ont le mot de passe pourront le décrypter. L'intérêt d'EncFS est qu'il est cross-platforms. Il y a des clients pour Windows, Linux, OSX, Android et iOS&hellip;</p>
<p>Voici l'installation sur OSX.</p>
<pre><code>brew install osxfuse
brew install sshfs
brew install encfs
</code></pre><p>Ensuite il n'y a plus qu'à exécuter la commande suivante pour créer un répertoire crypté sur Dropbox par exemple.</p>
<pre><code>encfs ~/Dropbox/dossier_securise ~/dossier_securise
</code></pre><p>Tout ce que vous déposerez dans ~/dossier_securise sera crypté à la volé, copié dans le répertoire Dropbox et donc synchronisé avec les personnes de votre choix.
Tant que ces personnes n'auront pas à leur tour monté le dossier de Dropbox dans un répertoire local via encfs, elles ne verront que des fichiers crypté comme ceci:</p>
<pre><code>.encfs6.xml
25G6HONULIE75F57UMITNZR2GBEJF
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Être notifié lorsqu&#39;un long traitement est terminé</title>
            <link>https://leandeep.com/%C3%AAtre-notifi%C3%A9-lorsquun-long-traitement-est-termin%C3%A9/</link>
            <pubDate>Thu, 01 Nov 2018 19:02:00 +0000</pubDate>
            
            <guid>https://leandeep.com/%C3%AAtre-notifi%C3%A9-lorsquun-long-traitement-est-termin%C3%A9/</guid>
            <description>Personnellement je trouve cela inutile de rester à rien faire derrière mon écran en attendant qu&#39;un long traitement (entrainement Machine Learning, installation d&#39;un Cluster&amp;hellip;) se termine. Du coup, je passe à autre en attendant. Pour éviter de devoir sans cesse basculer d&#39;une fenêtre à une autre, j&#39;utilise des notifications. Je suis notifié lorsque mes traitements sont terminés.
Pour ce faire j&#39;ai juste à executer la commande suivante derrière la commande qui exécutera un long process  &amp;amp;&amp;amp; warnov.</description>
            <content type="html"><![CDATA[<p>Personnellement je trouve cela inutile de rester à rien faire derrière mon écran en attendant qu'un long traitement (entrainement Machine Learning, installation d'un Cluster&hellip;) se termine.
Du coup, je passe à autre en attendant. Pour éviter de devoir sans cesse basculer d'une fenêtre à une autre, j'utilise des notifications. Je suis notifié lorsque mes traitements sont terminés.</p>
<p>Pour ce faire j'ai juste à executer la commande suivante derrière la commande qui exécutera un long process <code> &amp;&amp; warnov</code>. (Je n'ai pas cherché longtemps pour le nom de ma commande: warnov pour &ldquo;<strong>warn</strong> when it is <strong>over</strong>&quot;.</p>
<p>C'est simple et cela fonctionne très bien sur OSX.
J'utilise les notifications système via l'alias suivant dans mon <code>~/zshrc</code>.</p>
<pre><code># Notifications
function _sys_notify() {
    local notification_command=&quot;display notification \&quot;$2\&quot; with title \&quot;$1\&quot;&quot;
    osascript -e &quot;$notification_command&quot;
}
alias warnov=&quot;_sys_notify 'Done' 'The long running process is over'&quot;
</code></pre><p>Après un source <code>~/.zshrc</code> essayez un <code>echo 'toto' &amp;&amp; warnov</code>.</p>
]]></content>
        </item>
        
        <item>
            <title>Rendre Tensorflow compatible avec plus de cartes graphiques</title>
            <link>https://leandeep.com/rendre-tensorflow-compatible-avec-plus-de-cartes-graphiques/</link>
            <pubDate>Sat, 29 Sep 2018 19:50:00 +0000</pubDate>
            
            <guid>https://leandeep.com/rendre-tensorflow-compatible-avec-plus-de-cartes-graphiques/</guid>
            <description>Installer les dépendances Installer openjdk 8:
sudo apt-get install openjdk-8-jdk Installer les autres dépendances:
sudo apt-get install pkg-config zip g++ zlib1g-dev unzip  Installer Bazel wget https://github.com/bazelbuild/bazel/releases/download/0.17.2/bazel-0.17.2-installer-linux-x86_64.sh chmod +x bazel-0.17.2-installer-linux-x86_64.sh ./bazel-0.17.2-installer-linux-x86_64.sh --user Pour pouvoir utiliser Bazel, modifier votre .bashrc ou .zshrc et ajouter cette commande:
export PATH=&amp;quot;$PATH:$HOME/bin&amp;quot;  Install libcudnn Télécharger le binaire directement depuis le site: https://developer.nvidia.com/cudnn. Cette étape nécessite de créer une compte chez Nvidia.
Pour installer le binaire il suffit d&#39;exécuter la commande suivante:</description>
            <content type="html"><![CDATA[<h2 id="installer-les-dpendances">Installer les dépendances</h2>
<p>Installer openjdk 8:</p>
<pre><code>sudo apt-get install openjdk-8-jdk
</code></pre><p>Installer les autres dépendances:</p>
<pre><code>sudo apt-get install pkg-config zip g++ zlib1g-dev unzip
</code></pre><br/>
<h2 id="installer-bazel">Installer Bazel</h2>
<pre><code>wget https://github.com/bazelbuild/bazel/releases/download/0.17.2/bazel-0.17.2-installer-linux-x86_64.sh
chmod +x bazel-0.17.2-installer-linux-x86_64.sh
./bazel-0.17.2-installer-linux-x86_64.sh --user
</code></pre><p>Pour pouvoir utiliser Bazel, modifier votre .bashrc ou .zshrc et ajouter cette commande:</p>
<pre><code>export PATH=&quot;$PATH:$HOME/bin&quot;
</code></pre><br/>
<h2 id="install-libcudnn">Install libcudnn</h2>
<p>Télécharger le binaire directement depuis le site: <a href="https://developer.nvidia.com/cudnn">https://developer.nvidia.com/cudnn</a>. Cette étape nécessite de créer une compte chez Nvidia.</p>
<p>Pour installer le binaire il suffit d'exécuter la commande suivante:</p>
<pre><code>sudo dpkg -i libcudnn7_7.3.0.29-1+cuda9.0_amd64.deb
sudo dpkg -i libcudnn7-dev_7.3.0.29-1+cuda9.0_amd64.deb
sudo dpkg -i libcudnn7-doc_7.3.0.29-1+cuda9.0_amd64.deb
</code></pre><!-- raw HTML omitted -->
<p>Vérifier que cudnn est bien installé:</p>
<pre><code># Copy the cuDNN sample to a writable path.
cp -r /usr/src/cudnn_samples_v7/ $HOME
# Go to the writable path.
cd  $HOME/cudnn_samples_v7/mnistCUDNN
# Compile the mnistCUDNN sample.
make clean &amp;&amp; make
# Run the mnistCUDNN sample.
./mnistCUDNN
# If cuDNN is properly installed and running on your Linux system, you will see a message similar to the following:
$ Test passed!
</code></pre><p>Maintenons les paquets afin qu'ils ne soient pas updatés ou effacés:</p>
<pre><code>sudo apt-mark hold libcudnn7 libcudnn7-dev libcudnn7-doc
</code></pre><br/>
<h2 id="installer-tensorflow">Installer Tensorflow</h2>
<p>Commencer par installer les dépendances:</p>
<pre><code>sudo apt-get install python-numpy swig python-dev git python-pip
</code></pre><p>Puis cloner Tensorflow repo:</p>
<pre><code>git clone --recurse-submodules https://github.com/tensorflow/tensorflow.git -b r1.11
</code></pre><p>Configurer le build pour que Tensorflow puisse fonctionner avec (dans mon cas) les cartes supportant cuda 3.0 compute:
Pour voir quelle version appliquer pour votre carte graphique rendez-vous sur <a href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a></p>
<p>Obtenir le modèle de sa carte graphique:</p>
<pre><code>sudo lshw -C display | grep product
</code></pre><pre><code>cd tensorflow
TF_UNOFFICIAL_SETTING=1 ./configure

# Pour les questions suivantes répondre comme ceci: 

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]:


Please specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]:


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/lib/x86_64-linux-gnu/

</code></pre><p>Installer la dépendance Keras:</p>
<pre><code>pip install keras_applications
pip install keras_preprocessing
</code></pre><p>Compiler Tensorflow:</p>
<pre><code>$HOME/bin/bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer

bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu
</code></pre><p>Installer l'interface Python.
On commence par créer un package pip avec Bazel:</p>
<pre><code>$HOME/bin/bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
</code></pre><p>On install ensuite le package:</p>
<pre><code>bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
</code></pre><p>Et on installe le package Tensorflow disponible dans /tmp/tensorflow_pkg/:</p>
<pre><code>pip install /tmp/tensorflow_pkg/tensorflow-1.11.0-cp27-cp27mu-linux_x86_64.whl
</code></pre><p>On vérifie que cela fonctionne:</p>
<pre><code>python
Python 2.7.12 (default, Dec  4 2017, 14:50:18)
[GCC 5.4.0 20160609] on linux2
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import tensorflow as tf
&gt;&gt;&gt; hello = tf.constant('Hello, TensorFlow!')
&gt;&gt;&gt; sess = tf.Session()
2018-09-29 17:03:03.939989: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2018-09-29 17:03:03.981711: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-09-29 17:03:03.982119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1411] Found device 0 with properties:
name: GeForce GTX 660 Ti major: 3 minor: 0 memoryClockRate(GHz): 0.98
pciBusID: 0000:01:00.0
totalMemory: 1.95GiB freeMemory: 1.89GiB
2018-09-29 17:03:03.982143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0
2018-09-29 17:03:04.240898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-09-29 17:03:04.240938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0
2018-09-29 17:03:04.240950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N
2018-09-29 17:03:04.241102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1663 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 660 Ti, pci bus id: 0000:01:00.0, compute capability: 3.0)
</code></pre><br/>
<p>Perfect! Maintenant je peux utiliser mon GPU sur mon serveur.</p>
]]></content>
        </item>
        
        <item>
            <title>Comment j&#39;organise mes projets de data science ?</title>
            <link>https://leandeep.com/comment-jorganise-mes-projets-de-data-science/</link>
            <pubDate>Thu, 27 Sep 2018 13:22:00 +0000</pubDate>
            
            <guid>https://leandeep.com/comment-jorganise-mes-projets-de-data-science/</guid>
            <description>J&#39;ai travaillé sur multiples projets de développement et clairement ceux qui fonctionnent le mieux sont ceux qui sont les plus structurés que ce soit en terme de:
 Méthodologie et d&#39;organisation d&#39;équipe (Agile) Mindset Pratiques de développement (TDD, refactoring, pair programing) une bonne usine logiciel (CircleCI, Gitlab CI, tests unitaires et e2e auto, monitoring&amp;hellip;) bon staffing  A chaque fois qu&#39;il y avait ces 5 composantes, le projet était couronné de succès.</description>
            <content type="html"><![CDATA[<p>J'ai travaillé sur multiples projets de développement et clairement ceux qui fonctionnent le mieux sont ceux qui sont les plus structurés que ce soit en terme de:</p>
<ul>
<li>Méthodologie et d'organisation d'équipe (Agile)</li>
<li>Mindset</li>
<li>Pratiques de développement (TDD, refactoring, pair programing)</li>
<li>une bonne usine logiciel (CircleCI, Gitlab CI, tests unitaires et e2e auto, monitoring&hellip;)</li>
<li>bon staffing</li>
</ul>
<p>A chaque fois qu'il y avait ces 5 composantes, le projet était couronné de succès. Finalement c'est assez simple, il suffit de réappliquer toutes ces bonnes pratiques et cela tourne.</p>
<p>Lorsque j'ai commencé à travailler sur de la data science avec les outils d'exploration type Jupyter Notebook, j'ai été dérouté.
Comment gérer les données dans le projet ? Git n'accepte pas plus de 100 Mo (et puis cela devient lourd) Comment faire en sorte que l'on puisse reproduire les résultats (immutabilité des données) ?
Comment faire des merges avec des fichiers json illisibles de Jupyter ?<br>
Comment moins attendre ? En effet, les traitements sont longs car les volumes de données sont conséquents.</p>
<p>Tout comme en développement il existe des guidelines. Par exemples, les développeurs JS pourront vous citer les guidelines de Johnpapa (<a href="https://github.com/johnpapa/angular-styleguide">https://github.com/johnpapa/angular-styleguide</a>) ou d'Airbnb (<a href="https://github.com/airbnb/javascript">https://github.com/airbnb/javascript</a>) dont certaines sont directement comprises dans des outils de scaffoling (Yeoman) ou d'analyse de code (Eslint).</p>
<p>J'ai trouvé les guideline suivante: <a href="http://drivendata.github.io/cookiecutter-data-science">http://drivendata.github.io/cookiecutter-data-science</a>. Je partage totalement le choix des outils présentés et la structuration proposée. Je l'utilise pour mes projets et suis très satisfait.</p>
<p>N'hésitez pas à me contacter si vous pensez que ces pratiques sont mauvaises. Je suis friand de ce genre de débat.</p>
]]></content>
        </item>
        
        <item>
            <title>Datalab made portable on any server or laptop to work from anywhere with or without internet</title>
            <link>https://leandeep.com/datalab-made-portable-on-any-server-or-laptop-to-work-from-anywhere-with-or-without-internet/</link>
            <pubDate>Fri, 31 Aug 2018 10:46:30 +0000</pubDate>
            
            <guid>https://leandeep.com/datalab-made-portable-on-any-server-or-laptop-to-work-from-anywhere-with-or-without-internet/</guid>
            <description>Introduction Cet article n&#39;est pas vraiment détaillé et structuré. Il s&#39;agit plus de notes personnelles pour avoir toujours à disposition mon datalab avec toutes les données (max 1 To for now) nécessaires pour travailler. Il s&#39;agit d&#39;une installation très rapide à usage personnel. Ici je ne parle pas du tout d&#39;industrialisation ou de setup pour une grande entreprise&amp;hellip; L&#39;idée ici est de pouvoir travailler de partout que ce soit avec ou sans internet.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Cet article n'est pas vraiment détaillé et structuré. Il s'agit plus de notes personnelles pour avoir toujours à disposition mon datalab avec toutes les données (max 1 To for now) nécessaires pour travailler. Il s'agit d'une installation très rapide à usage personnel. Ici je ne parle pas du tout d'industrialisation ou de setup pour une grande entreprise&hellip; L'idée ici est de pouvoir travailler de partout que ce soit avec ou sans internet.</p>
<h2 id="etapes-pour-reproduire-la-config">Etapes pour reproduire la config</h2>
<ul>
<li>
<p>Installer les drivers Cuda pour pouvoir utiliser le GPU.</p>
</li>
<li>
<p>Builder l'image kaggle/python en local pour que tensorflow-gpu puisse fonctionner</p>
</li>
<li>
<p>Ouvrir le firewall sur 443 pour let's encrypt et exposition de Jupyter Notebook</p>
</li>
<li>
<p>Monter automatiquement les disques (voir mon tip sur le sujet): <a href="https://leandeep.com/monter-automatiquement-les-disques-au-demarrage-du-systeme/">https://leandeep.com/monter-automatiquement-les-disques-au-demarrage-du-systeme/</a></p>
</li>
<li>
<p>Créer script de démarrage simple (exemple: launch_datalab.sh)</p>
</li>
</ul>
<pre><code>cd ~/hdd2_mount
docker run -v $PWD:/tmp/working -w=/tmp/working -p 8888:8888 --rm -itd kaggle/python jupyter notebook --allow-root --ip=&quot;0.0.0.0&quot; --notebook-dir=/tmp/working --NotebookApp.trust_xheaders='True' --NotebookApp.allow_origin='*'  --NotebookApp.token='' --NotebookApp.password=''
cd ~/Dev/jupyter-reverse-proxy
caddy &amp;
</code></pre><ul>
<li>Pour le password ci-dessus utiliser Jupyter directement:</li>
</ul>
<pre><code>In [1]: from IPython.lib import passwd
In [2]: passwd()
Enter password:
Verify password:
Out[2]: 'sha1:67c9e60bb8b6:9ffede0825894254b2e042ea597d771089e11aed'
</code></pre><ul>
<li>
<p>Changer les droits sur le script <code>chmod +x</code></p>
</li>
<li>
<p>Ajouter une entrée dans crontab -e pour que le script soit lancé au boot de la machine
<code>@reboot /Home/olivier/Dev/launch_datalab.sh</code></p>
</li>
<li>
<p>Installer Caddy (<a href="https://caddyserver.com/">https://caddyserver.com/</a>) dans <code>/usr/bin/</code></p>
</li>
<li>
<p>Créer un caddyfile</p>
</li>
</ul>
<pre><code>&lt;site-datalab-masqué&gt;   # Your site's address

ext .html   # Clean URLs
errors error.log {       # Error log
    404 error-404.html   # Custom error page
}

# API load balancer
proxy / &lt;hostname-masqué&gt;:&lt;port-masqué&gt; {
    websocket
}
</code></pre><ul>
<li>
<p>Faire en sorte que Caddy puisse établir une connexion sur le port 443 lorsqu'il n'est pas lancé en mode sudo <code>sudo setcap CAP_NET_BIND_SERVICE=+eip /usr/bin/caddy</code></p>
</li>
<li>
<p>Changer les droits <code>chmod</code> du certificat SSL pour que ce puisse être exécuté par utilisateur qui boot la machine. Le répertoire sera fournit par Caddy directement</p>
</li>
<li>
<p>Synchro automatique des répertoires du disque interne vers disque externe en USB-C</p>
</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Comment exporter et restaurer un modèle Tensorflow ?</title>
            <link>https://leandeep.com/comment-exporter-et-restaurer-un-mod%C3%A8le-tensorflow/</link>
            <pubDate>Sun, 26 Aug 2018 20:49:00 +0000</pubDate>
            
            <guid>https://leandeep.com/comment-exporter-et-restaurer-un-mod%C3%A8le-tensorflow/</guid>
            <description>1. Exporter le modèle Voici le contenu avant l&#39;initialisation du modèle. Il n&#39;y a presque rien.
$ ls sample_data/ On initialise des variables, on démarre une session Tensorflow et on sauvegarde un premier modèle:
import tensorflow as tf import os w1 = tf.Variable(tf.truncated_normal(shape=[10]), name=&#39;w1&#39;) w2 = tf.Variable(tf.truncated_normal(shape=[20]), name=&#39;w2&#39;) tf.add_to_collection(&#39;vars&#39;, w1) tf.add_to_collection(&#39;vars&#39;, w2) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) saver = tf.train.Saver() saver.save(sess, os.path.join(os.getcwd(), &#39;trained_variables.ckpt&#39;)) On affiche le contenu du dossier:
ls -l checkpoint trained_variables.</description>
            <content type="html"><![CDATA[<h1 id="1-exporter-le-modle">1. Exporter le modèle</h1>
<p>Voici le contenu avant l'initialisation du modèle. Il n'y a presque rien.</p>
<pre><code>$ ls

sample_data/
</code></pre><p>On initialise des variables, on démarre une session Tensorflow et on sauvegarde un premier modèle:</p>
<pre><code>import tensorflow as tf
import os

w1 = tf.Variable(tf.truncated_normal(shape=[10]), name='w1')
w2 = tf.Variable(tf.truncated_normal(shape=[20]), name='w2')
tf.add_to_collection('vars', w1)
tf.add_to_collection('vars', w2)

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    saver = tf.train.Saver()
    saver.save(sess, os.path.join(os.getcwd(), 'trained_variables.ckpt'))
</code></pre><p>On affiche le contenu du dossier:</p>
<pre><code>ls -l

checkpoint
trained_variables.ckpt.index
sample_data/
trained_variables.ckpt.meta
trained_variables.ckpt.data-00000-of-00001
</code></pre><h1 id="2-restauration-du-modle">2. Restauration du modèle</h1>
<pre><code>sess = tf.Session()
new_saver = tf.train.import_meta_graph(os.path.join(os.getcwd(), 'trained_variables.ckpt.meta'))
new_saver.restore(sess, tf.train.latest_checkpoint(os.getcwd()))
all_vars = tf.get_collection('vars')
for v in all_vars:
    v_ = sess.run(v)
    print(v_)
</code></pre><p>Output:</p>
<pre><code>INFO:tensorflow:Restoring parameters from /content/trained_variables.ckpt
[ 1.1396145   1.6572006  -0.2603495  -0.09486181 -0.7648224  -1.34456
  0.14422925 -0.13617352  0.8662389   1.8259109 ]
[-0.15675354  0.22852097 -0.0374865   0.072795   -1.0221673  -0.75996536
  0.37354338 -0.38855395 -1.0035655   0.92454773 -1.2595061   0.13349424
 -1.2397587  -0.34336722  0.53958344  0.323387   -0.43925637 -0.088446
  0.18330242 -0.04366637]
[ 1.1396145   1.6572006  -0.2603495  -0.09486181 -0.7648224  -1.34456
  0.14422925 -0.13617352  0.8662389   1.8259109 ]
[-0.15675354  0.22852097 -0.0374865   0.072795   -1.0221673  -0.75996536
  0.37354338 -0.38855395 -1.0035655   0.92454773 -1.2595061   0.13349424
 -1.2397587  -0.34336722  0.53958344  0.323387   -0.43925637 -0.088446
  0.18330242 -0.04366637]
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Damn! Toujours pas d’HTTPS…</title>
            <link>https://leandeep.com/damn-toujours-pas-dhttps/</link>
            <pubDate>Mon, 06 Aug 2018 23:11:00 +0000</pubDate>
            
            <guid>https://leandeep.com/damn-toujours-pas-dhttps/</guid>
            <description>Honte à moi, je passe mon temps à jouer avec des serveurs et je n&#39;ai toujours pas configuré d&#39;HTTPS pour mon blog. Il fallait que je prenne un peu de temps pour rétablir la situation&amp;hellip; J&#39;en profite pour écrire rapidement cet article.
 Voici comment j’ai fait pour avoir un certificat HTTPS gratuit pour mon blog en moins de 5 minutes top chrono.
Avant, sans HTTPS, pour démarrer ce blog j’exécutais la commande suivante:</description>
            <content type="html"><![CDATA[<p>Honte à moi, je passe mon temps à jouer avec des serveurs et je n'ai toujours pas configuré d'HTTPS pour mon blog.
Il fallait que je prenne un peu de temps pour rétablir la situation&hellip; J'en profite pour écrire rapidement cet article.</p>
<br/>
<p>Voici comment j’ai fait pour avoir un certificat HTTPS gratuit pour mon blog en moins de 5 minutes top chrono.</p>
<p>Avant, sans HTTPS, pour démarrer ce blog j’exécutais la commande suivante:</p>
<pre><code>docker run -d --restart=always -e url=http://leandeep.com -e NODE_ENV=production --name some-ghost-v2 -v /var/lib/ghost:/var/lib/ghost/content -p 80:2368 ghost
</code></pre><p>C’était plutôt simple et efficace. En effet, je n’ai jamais dû intervenir sur le serveur depuis avril 2015. (Enfin jamais sauf une fois pour upgrader l'OS et passer à Ubuntu 16.04 . Mais c'est un autre sujet)</p>
<br/>
<p>Aujourd’hui, pour avoir un certificat HTTPS simplement, je vais utiliser Nginx comme reverse proxy. Ce dernier portera le certificat.</p>
<p>Pour utiliser Nginx, je vais passer par Docker. C'est beaucoup plus rapide et propre que faire des apt-get install nginx&hellip; Et pour me simplifier la vie, je vais utiliser un docker-compose puisque j’aurais plus d’un container à gérer sur ce serveur.</p>
<br/>
<p>Voici ci-dessous à quoi ressemble mon docker-compose.yml. Vous verrez que j'utilise 2 projets opensource que je vous invite à consulter sur Github: <a href="https://github.com/jwilder/nginx-proxy">https://github.com/jwilder/nginx-proxy</a> et <a href="https://github.com/JrCs/docker-letsencrypt-nginx-proxy-companion">https://github.com/JrCs/docker-letsencrypt-nginx-proxy-companion</a>. C'est grâce à ces projets que mes certificats se génèrent tout seul et que je peux avoir des HTTPS pour mes nouveaux projets sans rien faire.</p>
<pre><code>version: '3.1'
services:
  nginx-proxy:
    image: jwilder/nginx-proxy
    ports:
      - &quot;80:80&quot;
      - &quot;443:443&quot;
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock:ro
      - ./nginx/certs:/etc/nginx/certs:ro
      - ./nginx/vhost.d:/etc/nginx/vhost.d
      - nginx.html:/usr/share/nginx/html
    labels:
      com.github.jrcs.letsencrypt_nginx_proxy_companion.nginx_proxy: &quot;true&quot;
  nginx-proxy-companon:
    image: jrcs/letsencrypt-nginx-proxy-companion
    depends_on:
      - &quot;nginx-proxy&quot;
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./nginx/certs:/etc/nginx/certs:rw
      - ./nginx/vhost.d:/etc/nginx/vhost.d
      - nginx.html:/usr/share/nginx/html
    environment:
      - NGINX_PROXY_CONTAINER=nginx-proxy
  ghost:
    image: ghost:1-alpine
    restart: always
    depends_on:
      - &quot;nginx-proxy&quot;
    ports:
      - 127.0.0.1:8080:2368
    volumes:
      - ./blog:/var/lib/ghost/content
    environment:
      - url=https://leandeep.com
      - VIRTUAL_HOST=leandeep.com
      - LETSENCRYPT_HOST=leandeep.com
      - LETSENCRYPT_EMAIL=&lt;mon_email&gt;
  staticweb:
    image: nginx:alpine
    depends_on:
      - &quot;nginx-proxy&quot;
    ports:
      - 127.0.0.1:8081:80
    volumes:
      - ./staticweb:/usr/share/nginx/html:ro
    environment:
      - url=https://www.leandeep.com
      - VIRTUAL_HOST=www.leandeep.com
      - LETSENCRYPT_HOST=www.leandeep.com
      - LETSENCRYPT_EMAIL=&lt;mon_email&gt;
volumes:
  nginx.html:
</code></pre><p>Comme vous pouvez le voir, ce docker-compose définit 2 sites: <a href="https://leandeep.com">https://leandeep.com</a> et <a href="https://www.leandeep.com">https://www.leandeep.com</a>.
Le premier renvoie vers un blog Ghost et le deuxième vers un dossier statique servi par Nginx.</p>
<br/>
<p>Avant de faire un docker-compose up -d , j’ai créé 2 dossiers pour chacun des 2 sites web.
Le premier dossier blog/ contient le contenu de mon blog Ghost <a href="https://leandeep.com">https://leandeep.com</a>. Il contient donc l’arborescence suivante:</p>
<pre><code>apps/
data/
images/
logs/
settings/
themes/
</code></pre><br/>
<p>Le deuxième dossier staticweb/ pour le site internet <a href="https://www.leandeep.com">https://www.leandeep.com</a> contient une simple page HTML qui redirige vers <a href="https://leandeep.com">https://leandeep.com</a> via ces 3 lignes de code:</p>
<pre><code>&lt;script&gt;
window.location.href = 'https://leandeep.com';
&lt;/script&gt;
</code></pre><blockquote>
<p>A la place de cette redirection bête et méchante, on pourrait avoir un tout autre site internet bien plus intéressant. Ici c’est une redirection que j’ai laissé volontairement à titre d'exemple pour montrer comment avoir plusieurs sites web avec cet unique docker-compose.</p>
</blockquote>
<br/>
<p>Enfin, pour générer le certificat, il faudra créer un fichier ./nginx/vhost.d/leandeep.com qui contiendra la configuration pour let's encrypt:</p>
<pre><code>## Start of configuration add by letsencrypt container
location ^~ /.well-known/acme-challenge/ {
    auth_basic off;
    allow all;
    root /usr/share/nginx/html;
    try_files $uri =404;
    break;
}
## End of configuration add by letsencrypt container
add_header X-Frame-Options &quot;SAMEORIGIN&quot;;
add_header Content-Security-Policy &quot;script-src 'self' 'unsafe-inline' https://code.jquery.com&quot;;
add_header X-XSS-Protection &quot;1; mode=block&quot;;
add_header X-Content-Type-Options &quot;nosniff&quot;;
add_header Referrer-Policy &quot;no-referrer-when-downgrade&quot;;
server_tokens off;
</code></pre><br/>
<p>Voilà. Il n'y a plus qu'à lancer le docker-compose avec la commande:</p>
<pre><code>docker-compose up -d
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer Fission sur Minikube avec Helm</title>
            <link>https://leandeep.com/installer-fission-sur-minikube-avec-helm/</link>
            <pubDate>Wed, 01 Aug 2018 21:48:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-fission-sur-minikube-avec-helm/</guid>
            <description>Introduction Fission est un Framework perfomant et efficace permettant de faire du serverless sur Kubernetes.
Ce Framework permet d&#39;exécuter des fonctions dans n&#39;importe quel langage et sont coeur est écrit en Go.Fission supporte actuellement le NodeJS, Python, Ruby, Go, PHP, Bash et n&#39;importe quel exécutable Linux. Le support d&#39;autres langages est prévu.
Dans cet article, nous allons voir comment l&#39;installer sur un Minikube.
Installation On considère que Virtualbox, kubectl et minikube sont déjà installés sur votre poste.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Fission est un Framework perfomant et efficace permettant de faire du serverless sur Kubernetes.</p>
<p>Ce Framework permet d'exécuter des fonctions dans n'importe quel langage et sont coeur est écrit en Go.Fission supporte actuellement le NodeJS, Python, Ruby, Go, PHP, Bash et n'importe quel exécutable Linux. Le support d'autres langages est prévu.</p>
<p>Dans cet article, nous allons voir comment l'installer sur un Minikube.</p>
<h2 id="installation">Installation</h2>
<p>On considère que Virtualbox, kubectl et minikube sont déjà installés sur votre poste.</p>
<p>Sinon voici les commandes pour une machine sous Ubuntu.</p>
<pre><code># Installation de virtualbox
sudo apt install virtualbox

# Installation de Kubectl
curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/darwin/amd64/kubectl &amp;&amp; chmod +x kubectl &amp;&amp; sudo mv kubectl /usr/local/bin

# Installation de Minikube
curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.14.0/minikube-darwin-amd64 &amp;&amp; chmod +x minikube &amp;&amp; sudo mv minikube /usr/local/bin/
</code></pre><p>Ensuite on démarre minikube:</p>
<pre><code># Démarrage de Minikube
minikube start

# On vérifie que minikube &amp; kubernetes fonctionnent bien avec les commandes suivantes:
kubectl get nodes
# NAME       STATUS    AGE
# minikube   Ready     14s

kubectl config current-context
# minikube

minikube ip
# 192.168.99.100

kubectl cluster-info
# Kubernetes master is running at https://192.168.99.100:8443
# KubeDNS is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kube-dns
# kubernetes-dashboard is running at https://192.168.99.100:8443/api/v1/proxy/namespaces/kube-system/services/kubernetes-dashboard
</code></pre><p>On installer Helm:</p>
<pre><code># Installation de Helm
curl -Lo /tmp/helm-linux-amd64.tar.gz https://kubernetes-helm.storage.googleapis.com/helm-v2.1.3-linux-amd64.tar.gz
tar -xvf /tmp/helm-linux-amd64.tar.gz -C /tmp/
chmod +x  /tmp/linux-amd64/helm &amp;&amp; sudo mv /tmp/linux-amd64/helm /usr/local/bin/

# Initialisation de helm et installation de Tiller (le serveur helm)
helm init

# On met à jour les derniers charts de Helm
helm repo update
# * Happy Helming * 

# On liste les packages Helm installés
helm ls
</code></pre><p>On installe Fission:</p>
<pre><code># Clone Fission Repo
git clone https://github.com/fission/fission.git
cd fission/charts/

# Installation de Fission Chart via Helm
helm install --name fission-sample --set serviceType=NodePort fission/

# Followup notes in output
curl http://fission.io/linux/fission &gt; fission &amp;&amp; chmod +x fission &amp;&amp; sudo mv fission /usr/local/bin/

export FISSION_URL=http://$(minikube ip):31313
export FISSION_ROUTER=$(minikube ip):31314

echo $FISSION_URL $FISSION_ROUTER
# http://192.168.99.100:31313 192.168.99.100:31314

# Installation de fission CLI
curl -Lo /tmp/fission http://fission.io/linux/fission &amp;&amp; chmod +x /tmp/fission &amp;&amp; sudo mv /tmp/fission /usr/local/bin/
</code></pre><p>Création de son premier environnement Nodejs sur Fission:</p>
<pre><code># Création d'un environnement nodejs
fission env create --name nodejs --image fission/node-env

# Example de code Nodejs
echo 'module.exports = function(context, callback) { callback(200, &quot;Hello, world!\n&quot;); }' &gt; hello.js

# Creation d'une fonction
fission function create --name hello --env nodejs --code hello.js

# Création d'une Route
fission route create --method GET --url /hello --function hello

fission env list
# NAME   UID                                  IMAGE
# nodejs 39c20a26-272a-402d-b384-53e48574c6fb fission/node-env

fission route list
# NAME                                 METHOD URL    FUNCTION_NAME FUNCTION_UID
# 47f15d32-ebce-4ab5-847d-bdee521bd597 GET    /hello hello         

fission function list
# NAME  UID                                  ENV
# hello e0aec068-4ff7-4e2d-8913-ed9283b6e81c nodejs

# Test requête
curl http://$FISSION_ROUTER/hello
# Hello, world!
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer un cluster Kubernetes</title>
            <link>https://leandeep.com/installer-un-cluster-kubernetes/</link>
            <pubDate>Tue, 17 Jul 2018 21:02:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-un-cluster-kubernetes/</guid>
            <description>Pour faire de la Prod Il suffit d&#39;utiliser Rancher 2. Pour cela, il suffit d&#39;utiliser ce container Docker:
sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher C&#39;est tout ! Il suffit de suivre les instructions&amp;hellip;
Note: Use absolutely a supported Docker version
To install specific Docker version: (see README: https://github.com/rancher/rancher) Go to https://download.docker.com/linux/static/stable/ Extract the archive using the tar utility. The dockerd and docker binaries are extracted. $ tar xzvf /path/to/&amp;lt;FILE&amp;gt;.</description>
            <content type="html"><![CDATA[<h2 id="pour-faire-de-la-prod">Pour faire de la Prod</h2>
<p>Il suffit d'utiliser Rancher 2. Pour cela, il suffit d'utiliser ce container Docker:</p>
<pre><code>sudo docker run -d --restart=unless-stopped -p 80:80 -p 443:443 rancher/rancher
</code></pre><p>C'est tout ! Il suffit de suivre les instructions&hellip;</p>
<p>Note:
Use absolutely a supported Docker version</p>
<pre><code>To install specific Docker version: (see README: https://github.com/rancher/rancher)

Go to https://download.docker.com/linux/static/stable/ 

Extract the archive using the tar utility. The dockerd and docker binaries are extracted.

$ tar xzvf /path/to/&lt;FILE&gt;.tar.gz
Optional: Move the binaries to a directory on your executable path, such as /usr/bin/. If you skip this step, you must provide the path to the executable when you invoke docker or dockerd commands.

$ sudo cp docker/* /usr/bin/
Start the Docker daemon:

$ sudo dockerd &amp;
If you need to start the daemon with additional options, modify the above command accordingly or create and edit the file /etc/docker/daemon.json to add the custom configuration options.

Verify that Docker is installed correctly by running the hello-world image.

$ sudo docker run hello-world
</code></pre><h2 id="pour-du-dveloppement-ie-devops">Pour du Développement (i.e. DevOps)</h2>
<p>On installe Virtualbox:</p>
<pre><code>sudo apt-get install -y virtualbox virtualbox-ext-pack
</code></pre><p>Installation de Minikube et kubectl:</p>
<pre><code>curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
chmod +x minikube
sudo mv -v minikube /usr/local/bin

curl -Lo kubectl https://storage.googleapis.com/kubernetes-release/release/v1.8.0/bin/linux/amd64/kubectl
chmod +x kubectl
sudo mv -v kubectl /usr/local/bin
</code></pre><p>On vérifie que cela fonctionne. On commence par démarrer minikube et on démarre un service Nginx:</p>
<pre><code>minikube start
kubectl run dh-nginx --image=nginx --port=80
kubectl expose deployment dh-nginx --type=NodePort
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Modules Python populaires</title>
            <link>https://leandeep.com/modules-python-populaires/</link>
            <pubDate>Tue, 10 Apr 2018 19:58:00 +0000</pubDate>
            
            <guid>https://leandeep.com/modules-python-populaires/</guid>
            <description>Voici une liste de modules Python populaires trouvée sur le site https://pymotw.com/3/index.html. L&#39;avantage de ce site est qu&#39;il fournit des exemples clairs pour les utiliser.
Text
 string: Text Constants and Templates textwrap: Formatting Text Paragraphs re: Regular Expressions difflib: Compare Sequences  Data Structures
 enum: Enumeration Type collections: Container Data Types array: Sequence of Fixed-type Data heapq: Heap Sort Algorithm bisect: Maintain Lists in Sorted Order queue: Thread-Safe FIFO Implementation struct: Binary Data Structures weakref: Impermanent References to Objects copy: Duplicate Objects pprint: Pretty-Print Data Structures forwardable: Delegate methods creation for composition in OOP (https://pypi.</description>
            <content type="html"><![CDATA[<p>Voici une liste de modules Python populaires trouvée sur le site <a href="https://pymotw.com/3/index.html">https://pymotw.com/3/index.html</a>. L'avantage de ce site est qu'il fournit des exemples clairs pour les utiliser.</p>
<p><strong>Text</strong></p>
<ul>
<li>string: Text Constants and Templates</li>
<li>textwrap: Formatting Text Paragraphs</li>
<li>re: Regular Expressions</li>
<li>difflib: Compare Sequences</li>
</ul>
<p><strong>Data Structures</strong></p>
<ul>
<li>enum: Enumeration Type</li>
<li>collections: Container Data Types</li>
<li>array: Sequence of Fixed-type Data</li>
<li>heapq: Heap Sort Algorithm</li>
<li>bisect: Maintain Lists in Sorted Order</li>
<li>queue: Thread-Safe FIFO Implementation</li>
<li>struct: Binary Data Structures</li>
<li>weakref: Impermanent References to Objects</li>
<li>copy: Duplicate Objects</li>
<li>pprint: Pretty-Print Data Structures</li>
<li>forwardable: Delegate methods creation for composition in OOP (<a href="https://pypi.org/project/forwardable/">https://pypi.org/project/forwardable/</a>)</li>
</ul>
<p><strong>Algorithms</strong></p>
<ul>
<li>functools: Tools for Manipulating Functions</li>
<li>itertools: Iterator Functions</li>
<li>operator: Functional Interface to Built-in Operators</li>
<li>contextlib: Context Manager Utilities</li>
</ul>
<p><strong>Dates and Times</strong></p>
<ul>
<li>time: Clock Time</li>
<li>datetime: Date and Time Value Manipulation</li>
<li>calendar: Work with Dates</li>
</ul>
<p><strong>Mathematics</strong></p>
<ul>
<li>decimal: Fixed and Floating Point Math</li>
<li>fractions: Rational Numbers</li>
<li>random: Pseudorandom Number Generators</li>
<li>math: Mathematical Functions</li>
<li>statistics: Statistical Calculations</li>
</ul>
<p><strong>The File System</strong></p>
<ul>
<li>os.path: Platform-independent Manipulation of Filenames</li>
<li>pathlib: Filesystem Paths as Objects</li>
<li>glob: Filename Pattern Matching</li>
<li>fnmatch: Unix-style Glob Pattern Matching</li>
<li>linecache: Read Text Files Efficiently</li>
<li>tempfile: Temporary File System Objects</li>
<li>shutil: High-level File Operations</li>
<li>filecmp: Compare Files</li>
<li>mmap: Memory-map Files</li>
<li>codecs: String Encoding and Decoding</li>
<li>io: Text, Binary, and Raw Stream I/O Tools</li>
</ul>
<p><strong>Data Persistence and Exchange</strong></p>
<ul>
<li>pickle: Object Serialization</li>
<li>shelve: Persistent Storage of Objects</li>
<li>dbm: Unix Key-Value Databases</li>
<li>sqlite3: Embedded Relational Database</li>
<li>xml.etree.ElementTree: XML Manipulation API</li>
<li>csv: Comma-separated Value Files</li>
</ul>
<p><strong>Data Compression and Archiving</strong></p>
<ul>
<li>zlib: GNU zlib Compression</li>
<li>gzip: Read and Write GNU zip Files</li>
<li>bz2: bzip2 Compression</li>
<li>tarfile: Tar Archive Access</li>
<li>zipfile: ZIP Archive Access</li>
</ul>
<p><strong>Cryptography</strong></p>
<ul>
<li>hashlib: Cryptographic Hashing</li>
<li>hmac: Cryptographic Message Signing and Verification</li>
</ul>
<p><strong>Concurrency with Processes, Threads, and Coroutines</strong></p>
<ul>
<li>subprocess: Spawning Additional Processes</li>
<li>signal: Asynchronous System Events</li>
<li>threading: Manage Concurrent Operations Within a Process</li>
<li>multiprocessing: Manage Processes Like Threads</li>
<li>asyncio: Asynchronous I/O, event loop, and concurrency tools</li>
<li>concurrent.futures: Manage Pools of Concurrent Tasks</li>
</ul>
<p><strong>Networking</strong></p>
<ul>
<li>ipaddress: Internet Addresses</li>
<li>socket: Network Communication</li>
<li>selectors: I/O Multiplexing Abstractions</li>
<li>select: Wait for I/O Efficiently</li>
<li>socketserver: Creating Network Servers</li>
</ul>
<p><strong>The Internet</strong></p>
<ul>
<li>urllib.parse: Split URLs into Components</li>
<li>urllib.request: Network Resource Access</li>
<li>urllib.robotparser: Internet Spider Access Control</li>
<li>base64: Encode Binary Data with ASCII</li>
<li>http.server: Base Classes for Implementing Web Servers</li>
<li>http.cookies: HTTP Cookies</li>
<li>webbrowser: Displays web pages</li>
<li>uuid: Universally Unique Identifiers</li>
<li>json: JavaScript Object Notation</li>
<li>xmlrpc.client: Client Library for XML-RPC</li>
<li>xmlrpc.server: An XML-RPC server</li>
</ul>
<p><strong>Email</strong></p>
<ul>
<li>smtplib: Simple Mail Transfer Protocol Client</li>
<li>smtpd: Sample Mail Servers</li>
<li>mailbox: Manipulate Email Archives</li>
<li>imaplib: IMAP4 Client Library</li>
</ul>
<p><strong>Application Building Blocks</strong></p>
<ul>
<li>argparse: Command-Line Option and Argument Parsing</li>
<li>getopt: Command Line Option Parsing</li>
<li>readline: The GNU readline Library</li>
<li>getpass: Secure Password Prompt</li>
<li>cmd: Line-oriented Command Processors</li>
<li>shlex: Parse Shell-style Syntaxes</li>
<li>configparser: Work with Configuration Files</li>
<li>logging: Report Status, Error, and Informational Messages</li>
<li>fileinput: Command-Line Filter Framework</li>
<li>atexit: Program Shutdown Callbacks</li>
<li>sched: Timed Event Scheduler</li>
</ul>
<p><strong>Internationalization and Localization</strong></p>
<ul>
<li>gettext: Message Catalogs</li>
<li>locale: Cultural Localization API</li>
</ul>
<p><strong>Developer Tools</strong></p>
<ul>
<li>pydoc: Online Help for Modules</li>
<li>doctest: Testing Through Documentation</li>
<li>unittest: Automated Testing Framework</li>
<li>trace: Follow Program Flow</li>
<li>traceback: Exceptions and Stack Traces</li>
<li>cgitb: Detailed Traceback Reports</li>
<li>pdb: Interactive Debugger</li>
<li>profile and pstats: Performance Analysis</li>
<li>timeit: Time the execution of small bits of Python code.</li>
<li>tabnanny: Indentation validator</li>
<li>compileall: Byte-compile Source Files</li>
<li>pyclbr: Class Browser</li>
<li>venv: Create Virtual Environments</li>
<li>ensurepip: Install the Python Package Installer</li>
</ul>
<p><strong>Runtime Features</strong></p>
<ul>
<li>site: Site-wide Configuration</li>
<li>sys: System-specific Configuration</li>
<li>os: Portable access to operating system specific features</li>
<li>platform: System Version Information</li>
<li>resource: System Resource Management</li>
<li>gc: Garbage Collector</li>
<li>sysconfig: Interpreter Compile-time Configuration</li>
</ul>
<p><strong>Language Tools</strong></p>
<ul>
<li>warnings: Non-fatal Alerts</li>
<li>abc: Abstract Base Classes</li>
<li>dis: Python Bytecode Disassembler</li>
<li>inspect: Inspect Live Objects</li>
</ul>
<p><strong>Modules and Packages</strong></p>
<ul>
<li>importlib: Python’s Import Mechanism</li>
<li>pkgutil: Package Utilities</li>
<li>zipimport: Load Python Code from ZIP Archives</li>
</ul>
<p><strong>Unix-specific Services</strong></p>
<ul>
<li>pwd: Unix Password Database</li>
<li>grp: Unix Group Database</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Pytest tricks</title>
            <link>https://leandeep.com/pytest-tricks/</link>
            <pubDate>Wed, 04 Apr 2018 21:53:00 +0000</pubDate>
            
            <guid>https://leandeep.com/pytest-tricks/</guid>
            <description>Mocker l&#39;ouverture d&#39;un fichier et tester les exceptions Pour la fonction suivante, il est possible d&#39;exécuter différents tests. Les 3 exemples de tests ci-dessous montrent:
 Comment vérifier qu&#39;un appel de fonction raise une exception Comment vérifier qu&#39;un fichier de config est valide Comment créer un fichier de config temporaire &amp;ldquo;bouchonné&amp;rdquo;.  import os import json class InvalidConfig(Exception): pass def load_config(config_path): try: with open(config_path, &#39;r&#39;) as json_file: return json.load(json_file) except (OSError, IOError, json.</description>
            <content type="html"><![CDATA[<h2 id="mocker-louverture-dun-fichier-et-tester-les-exceptions">Mocker l'ouverture d'un fichier et tester les exceptions</h2>
<p>Pour la fonction suivante, il est possible d'exécuter différents tests.
Les 3 exemples de tests ci-dessous montrent:</p>
<ul>
<li>Comment vérifier qu'un appel de fonction raise une exception</li>
<li>Comment vérifier qu'un fichier de config est valide</li>
<li>Comment créer un fichier de config temporaire &ldquo;bouchonné&rdquo;.</li>
</ul>
<pre><code>import os 
import json

class InvalidConfig(Exception):
    pass

def load_config(config_path):
  try:
      with open(config_path, 'r') as json_file:
          return json.load(json_file)
  except (OSError, IOError, json.JSONDecodeError) as exception:
      raise InvalidConfig(exception)

</code></pre><pre><code>def test_missing_conf_file():
	with pytest.raises(InvalidConfig):
	    load_config('does-not-exist.json')

</code></pre><pre><code>def test_invalid_conf_file(tmpdir):
	json_content = (
    	'%%%%%%%%%%\n'
	)
    tmp_config = tmpdir.join('temp-config_file.json')
    tmp_config.write_text(json_content, encoding='utf-8')
    with pytest.raises(InvalidConfig):
    	load_config(tmp_config.strpath)
</code></pre><pre><code>def test_valid_conf_file(tmpdir):
	json_content = (
    	'{\n'
        '&quot;hello&quot;: &quot;olivier&quot;, \n'
        '&quot;titi&quot;: &quot;tata&quot;\n'
        '}\n'
	)
    tmp_config = tmpdir.join('temp-config_file.json')
    tmp_config.write_text(json_content, encoding='utf-8')
    parsed_config = load_config(tmp_config.strpath)
    assert parsed_config['hello'] == 'olivier'
    assert parsed_config['titi'] == 'tata'

</code></pre><h2 id="parametrize-tests-with-fixtures">Parametrize tests with fixtures</h2>
<p><strong>Option 1</strong></p>
<p>Exemple:</p>
<pre><code>import pytest

def integer_to_binary(input, zero_pad_length=0):
    &quot;&quot;&quot;
    Converts an integer to a zero-padded binary string.
    &quot;&quot;&quot;
    return &quot;{{:0{}b}}&quot;.format(zero_pad_length).format(input)

@pytest.fixture(params=[{&quot;input&quot;: 8, &quot;expectedResult&quot;: &quot;1000&quot;}, {&quot;input&quot;: 5, &quot;expectedResult&quot;: &quot;0&quot;}, {&quot;input&quot;: 1, &quot;expectedResult&quot;: &quot;1&quot;}])
def testCase(request):
    return request.param

def test_my_converter(testCase):
    result = integer_to_binary(testCase[&quot;input&quot;])
    assert result == testCase[&quot;expectedResult&quot;]

</code></pre><p>Output:</p>
<pre><code>====================================================================================================== test session starts ======================================================================================================
platform darwin -- Python 3.7.3, pytest-4.5.0, py-1.8.0, pluggy-0.11.0 -- /Users/olivier/Dev/.venv/bin/python3.7
cachedir: .pytest_cache
rootdir: /Users/olivier/Dev/
collected 3 items

test_tmp.py::test_my_converter[testCase0] PASSED                                                                                                                                                                          [ 33%]
test_tmp.py::test_my_converter[testCase1] FAILED                                                                                                                                                                          [ 66%]
test_tmp.py::test_my_converter[testCase2] PASSED                                                                                                                                                                          [100%]

=========================================================================================================== FAILURES ============================================================================================================
_________________________________________________________________________________________________ test_my_converter[testCase1] __________________________________________________________________________________________________

testCase = {'expectedResult': '0', 'input': 5}

    def test_my_converter(testCase):
        result = integer_to_binary(testCase[&quot;input&quot;])
&gt;       assert result == testCase[&quot;expectedResult&quot;]
E       AssertionError: assert '101' == '0'
E         - 101
E         + 0

test_tmp.py:15: AssertionError
============================================================================================== 1 failed, 2 passed in 0.08 seconds ===============================================================================================
</code></pre><p><strong>Option 2</strong></p>
<p>Example</p>
<pre><code>import pytest

def integer_to_binary(input, zero_pad_length=0):
    &quot;&quot;&quot;
    Converts an integer to a zero-padded binary string.
    &quot;&quot;&quot;
    return &quot;{{:0{}b}}&quot;.format(zero_pad_length).format(input)


@pytest.mark.parametrize('input, expectedResult', [(8, &quot;1000&quot;), (5, &quot;0&quot;), (1, &quot;1&quot;)])
def test_integer_to_binary(input, expectedResult):
    assert expectedResult == integer_to_binary(input)
    
</code></pre><p>Same Output.</p>
<h2 id="scopes-des-fixtures">Scopes des fixtures</h2>
<p><strong>Une fixture peut avoir plusieurs scopes: test, module ou session.</strong></p>
<p>Exemple de fixture au niveau des tests:</p>
<pre><code>@pytest.fixture()
def user():
	print(&quot;Creating user&quot;)
    return User('Python', 'Awesome')

def test_is_prime(user):
	assert is_prime(user, 2) is True
	assert is_prime(user, 3) is True    
	assert is_prime(user, 4) is False

def test_prime_factors(user):
	assert prime_factors(user, 2) == [2]
	assert prime_factors(user, 12) == [2, 2, 3]

</code></pre><p>Exemple de fixture au niveau du module:</p>
<blockquote>
<p>Il suffit de changer le scope dans l'annotation <code>@pytest.fixture()</code>:</p>
</blockquote>
<pre><code>@pytest.fixture(scope='module')
def user():
	print(&quot;Creating user&quot;)
    return User('Python', 'Awesome')

...

</code></pre><h2 id="tagger-ses-tests-avec-des-fixtures">Tagger ses tests avec des fixtures</h2>
<p>Exemple:</p>
<pre><code>import pytest
import math_func

@pytest.mark.strings
def test_add_strings():
	result = math_func.add('Hello', ' World')
    assert result == 'Hello World'
    assert type(result) is str

</code></pre><p>Appeler les tests ayant un tag particulier:</p>
<pre><code>pytest -v -m strings
</code></pre><h2 id="skipper-un-test-grce--un-tag">Skipper un test (grâce à un tag)</h2>
<p><strong>Simple skip</strong></p>
<p>Exemple:</p>
<pre><code>import pytest
import math_func

@pytest.mark.skip(reason='do not run this test for no reason')
def test_add_strings():
	result = math_func.add('Hello', ' World')
    assert result == 'Hello World'
    assert type(result) is str

</code></pre><p>Exécution:</p>
<pre><code>pytest -v
</code></pre><p><strong>skipif</strong></p>
<p>Exemple:</p>
<pre><code>import pytest
import math_func
import sys

@pytest.mark.skipif(sys.version_info &lt; (3, 3), reason='')
def test_add_strings():
	result = math_func.add('Hello', ' World')
    assert result == 'Hello World'
    assert type(result) is str

</code></pre><p>Exécution:</p>
<pre><code>pytest -v
</code></pre><h2 id="code-dinitialisation-et-de-clture-des-tests">Code d'initialisation et de clôture des tests</h2>
<p><strong>Option 1: Setup and Teardown</strong></p>
<p>Exemple de code de setup (Connection à une BDD par exemple):</p>
<p>Au lieu de:</p>
<pre><code>import pytest

def test_olivier_data():
	db = StudentDB()
    db.connect('data.json')
    olivier_data = db.get_data('Olivier')
    assert olivier_data['id'] == 1
    assert olivier_data['name'] == 'Olivier'

</code></pre><p>On peut initialiser la fonction <code>setup_module</code> qui sera exécutée au démarrage des tests:</p>
<p>On écrit plutôt:</p>
<pre><code>import pytest

db = None
def setup_module(module):
	db = StudentDB()
    db.connect('data.json')

def test_olivier_data():
    olivier_data = db.get_data('Olivier')
    assert olivier_data['id'] == 1
    assert olivier_data['name'] == 'Olivier'

</code></pre><p>Avec la fonction <code>teardown_module</code> on exécute du code lorsque les tests sont terminés (pour fermer la connexion avec une BDD par exemple)</p>
<p>Exemple:</p>
<pre><code>def teardown_module(module):
	db.close()
</code></pre><p><strong>Option 2: Avec des Fixtures avec un scope module et un générateur</strong></p>
<p>On peut réécrire le code précédent avec des fixtures.</p>
<pre><code>import pytest

@pytest.fixture(scope='module')
def db():
	print(&quot;{}setup{}&quot;.format(&quot;-&quot;*10, &quot;-&quot;*10))
	db = StudentDB()
    db.connect('data.json')
	yield db ## yield is canceled by return 
	print(&quot;{}teardown{}&quot;.format(&quot;-&quot;*10, &quot;-&quot;*10))
	db.close()
    ## implicit return when not specified

def test_olivier_data(db):
    olivier_data = db.get_data('Olivier')
    assert olivier_data['id'] == 1
    assert olivier_data['name'] == 'Olivier'

</code></pre><h2 id="excuter-les-tests-en-parallle">Exécuter les tests en parallèle</h2>
<p>Le paquet suivant est nécessaire:</p>
<pre><code>pip install pytest-xdist
</code></pre><p>Puis pour exécuter les tests en parallèle, il faut spécifier l'option suivante au module pytest:</p>
<pre><code>python -m pytest -v tests/ -n auto

# ou python -m pytest -v tests/ -n 2
</code></pre><h2 id="ajouter-du-code-coverage">Ajouter du code coverage</h2>
<p>Installer le paquet suivant:</p>
<pre><code>pip install pytest-cov
</code></pre><p>Puis exécuter la commande:</p>
<pre><code>python -m pytest -v --cov=path_to_analyze_coverage
</code></pre><h2 id="configuration-files">Configuration files</h2>
<ul>
<li>
<p>pytest.ini (permet par exemple de définir le rootdir des tests)</p>
</li>
<li>
<p>conftest.py (exécuté automatiquement, c'est un bon endroit pour écrire des fixtures)</p>
</li>
</ul>
<h2 id="useful-commands">Useful commands:</h2>
<p><strong>Run last failing test:</strong></p>
<pre><code>python -m pytest -v --lf

# ou pytest -v --lf
</code></pre><p><strong>Display print statements:</strong></p>
<pre><code>python -v -s

# ou pytest -v -s
</code></pre><p><strong>Run one specific test:</strong></p>
<pre><code>python -m pytest -v -k &quot;nom_du_test_complet_ou_regex&quot;

# ou pytest -v -k &quot;nom_du_test_complet_ou_regex&quot;

# Or est également possible
# ou pytest -v -k &quot;regex1 or regex2&quot;

# And est également possible
# ou pytest -v -k &quot;regex1 and regex2&quot;
</code></pre><p><strong>Run one specific test in a particular file:</strong></p>
<pre><code>python -m pytest -v mon_fichier_de_test::nom_du_test

# ou pytest -v mon_fichier_de_test::nom_du_test
</code></pre><p><strong>Run one test file:</strong></p>
<pre><code>python -m pytest -v tests/votre_fichier_de_test.py

# ou pytest -v tests/votre_fichier_de_test.py
</code></pre><p><strong>Stopper l'exécution des tests dès la première failure:</strong></p>
<pre><code>python -m pytest -v -x

# ou pytest -v -x
</code></pre><p><strong>Stopper l'exécution des tests après x failed tests:</strong></p>
<pre><code>python -m pytest -v --maxfail=2

# ou pytest -v --maxfail=2
</code></pre><p>Voir les commandes disponibles: <a href="https://docs.pytest.org/en/latest/usage.html">https://docs.pytest.org/en/latest/usage.html</a></p>
<h2 id="cool-pytest-plugins">Cool Pytest plugins</h2>
<table>
<thead>
<tr>
<th>PLUGIN</th>
<th align="center">DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr>
<td>pytest-server-fixtures</td>
<td align="center">Extensible server-running framework with a suite of well-known databases and webservices included: mongodb, redis, rethinkd, Jenkins, Apache httpd, Xvfb</td>
</tr>
<tr>
<td>pytest-shutil</td>
<td align="center">Unix shell and environment management tools</td>
</tr>
<tr>
<td>pytest-profiling</td>
<td align="center">Profiling plugin with tabular heat graph output and gprof support for C-Extensions</td>
</tr>
<tr>
<td>pytest-devpi-server</td>
<td align="center">DevPI server runnning fixture for testing package management code</td>
</tr>
<tr>
<td>pytest-pyramid-server</td>
<td align="center">Pyramid server fixture for running up servers in integration tests</td>
</tr>
<tr>
<td>pytest-webdriver</td>
<td align="center">Selenium webdriver fixture for testing web applications</td>
</tr>
<tr>
<td>pytest-virtualenv</td>
<td align="center">Create and teardown virtual environments, run tests and commands in the scope of the virtualenv</td>
</tr>
<tr>
<td>pytest-qt-app</td>
<td align="center">PyQT application fixture</td>
</tr>
<tr>
<td>pytest-listener</td>
<td align="center">TCP Listener/Reciever for testing remote systems</td>
</tr>
<tr>
<td>pytest-git</td>
<td align="center">Git repository fixture</td>
</tr>
<tr>
<td>pytest-svn</td>
<td align="center">SVN repository fixture</td>
</tr>
<tr>
<td>pytest-fixture-config</td>
<td align="center">Configuration tools for Py.test fixtures</td>
</tr>
<tr>
<td>pytest-verbose-parametrize</td>
<td align="center">Makes py.test’s parametrize output a little more verbose</td>
</tr>
</tbody>
</table>
<h2 id="tricks">Tricks</h2>
<p><strong>Créer et importer des <em>helper functions</em> dans les tests sans créer de package dans le dossier <code>tests</code></strong></p>
<p>Par exemple, vous voulez créer ceci:</p>
<pre><code># Dans le fichier common.py
def assert_nimporte_quoi_entre_deux_proprietes(x, y):
    assert ...


# Dans tests/my_test.py
def test_something_with(x):
    some_value = some_function_of_(x)
    assert_nimporte_quoi_entre_deux_proprietes(x, some_value)

</code></pre><p>Créer un dossier <code>helpers</code> dans le répertoire <code>tests</code> et ajouter le path de ce dernier via <code>pythonpath</code> dans le fichier <code>conftest.py</code>.</p>
<pre><code>tests/
    helpers/
      utils.py
      ...
    conftest.py
setup.cfg
</code></pre><p>Dans le fichier <code>conftest.py</code>:</p>
<pre><code>import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'helpers'))
</code></pre><p>Dans le fichier <code>setup.cfg</code>:</p>
<pre><code>[pytest]
norecursedirs=tests/helpers
</code></pre><p>Ce module sera accessible via <code>import utils</code>.</p>
<p><strong>Avoir des modules de tests qui ont le même nom</strong></p>
<p>Pour ce faire, il faut ajouter un fichier <code>__init__.py</code> dans le dossier <code>tests</code> ainsi que dans ses sous-répertoires. (Le répertoire <code>tests</code>devient donc un module):</p>
<pre><code>setup.py
mypkg/
    ...
tests/
    __init__.py
    foo/
        __init__.py
        test_view.py
    bar/
        __init__.py
        test_view.py

</code></pre><p>Maintenant pytest va charger les modules comme ceci: <code>tests.foo.test_view</code> et <code>tests.bar.test_view</code>
Cela permet d'avoir des modules qui ont le même nom.</p>
<p><strong>Organiser un grand nombre de fixtures</strong></p>
<p>On peut par exemple ajouter les lignes suivantes dans le fichier <code>tests/unit/conftest.py</code>:</p>
<pre><code>pytest_plugins = [
   &quot;tests.unit.fixtures.some_stuff&quot;,
]
</code></pre><p>Et un fichier de fixture <code>tests/unit/fixtures/some_stuff.py</code> peut être défini ainsi:</p>
<pre><code>import pytest

@pytest.fixture
def foo():
    return 'foobar'

</code></pre><p>(Il faudra également créer un fichier <code>__init__.py</code>)</p>
<h2 id="outils">Outils</h2>
<ul>
<li>Reporting: <a href="http://allure.qatools.ru/">Allure</a></li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Devenir Atari Pong master grâce à l&#39;apprentissage par renforcement</title>
            <link>https://leandeep.com/devenir-atari-pong-master-gr%C3%A2ce-%C3%A0-lapprentissage-par-renforcement/</link>
            <pubDate>Thu, 29 Mar 2018 21:09:00 +0000</pubDate>
            
            <guid>https://leandeep.com/devenir-atari-pong-master-gr%C3%A2ce-%C3%A0-lapprentissage-par-renforcement/</guid>
            <description>&lt;h2 id=&#34;quest-ce-que-lapprentissage-par-renforcement-&#34;&gt;Qu&#39;est-ce que l&#39;apprentissage par renforcement ?&lt;/h2&gt;
&lt;p&gt;En apprentissage par renforcement, l&#39;ordinateur essaye de déterminer les actions qui maximisent un nombre total de récompenses.&lt;/p&gt;
&lt;p&gt;En trading par exemple, on évalue quelle stratégie va maximiser les récompenses qui sont le retour sur investissement. Les récompenses peuvent être obtenues longtemps après une action.&lt;/p&gt;
&lt;p&gt;Autre exemple, avec un jeu d&#39;échec, on peut obtenir des récompenses mieux que ce qu&#39;on aurait pu jouer simplement en sacrifiant des pièces pour jouer un meilleur coup.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;En apprentissage par renforcement, on crée une &lt;strong&gt;politique&lt;/strong&gt; qui définit l&amp;rsquo;&lt;strong&gt;action&lt;/strong&gt; qui maximisera les &lt;strong&gt;récompenses&lt;/strong&gt; lorsqu&#39;une action sera exécutée en fonction de l&#39;état du système.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;atari-pong&#34;&gt;Atari Pong&lt;/h2&gt;
&lt;p&gt;Pour coder mon réseau de neurones et faire de l&#39;apprentissage par renforcement sur un cas pratique et simple, j&#39;ai utilisé le framework &lt;a href=&#34;https://gym.openai.com/docs/&#34;&gt;OpenAI gym&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;Gym is a toolkit for developing and comparing reinforcement learning algorithms&amp;rdquo;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Ce framework permet d&#39;intéragir avec des jeux basiques Atari.
J&#39;ai choisi le jeu Atari Pong pour implémenter mon algorithme gradients de politique.&lt;/p&gt;
&lt;p&gt;Voici 2 vidéos que j&#39;ai enregistré qui montrent des parties jouées entre un agent qui est l&#39;ordinateur et un agent qui est piloté par un réseau de neurones.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Dans la première vidéo, le réseau de neurones n&#39;a pas encore été entraîné.&lt;/li&gt;
&lt;/ul&gt;

    &lt;iframe 
        width=&#34;100%&#34; 
        height=&#34;400&#34; 
        src=&#34;//www.youtube.com/embed/fmxJNCf4REY?rel=0&#34; 
        frameborder=&#34;0&#34; 
        allow=&#34;autoplay; encrypted-media&#34; 
        allowfullscreen&gt;
    &lt;/iframe&gt;




&lt;ul&gt;
&lt;li&gt;Dans la seconde vidéo, le réseau de neurones a été entraîné pendant des jours avec un algorithme policy gradients.&lt;/li&gt;
&lt;/ul&gt;

    &lt;iframe 
        width=&#34;100%&#34; 
        height=&#34;400&#34; 
        src=&#34;//www.youtube.com/embed/yo2c-SCFL-M?rel=0&#34; 
        frameborder=&#34;0&#34; 
        allow=&#34;autoplay; encrypted-media&#34; 
        allowfullscreen&gt;
    &lt;/iframe&gt;




&lt;!-- raw HTML omitted --&gt;</description>
            <content type="html"><![CDATA[<h2 id="quest-ce-que-lapprentissage-par-renforcement-">Qu'est-ce que l'apprentissage par renforcement ?</h2>
<p>En apprentissage par renforcement, l'ordinateur essaye de déterminer les actions qui maximisent un nombre total de récompenses.</p>
<p>En trading par exemple, on évalue quelle stratégie va maximiser les récompenses qui sont le retour sur investissement. Les récompenses peuvent être obtenues longtemps après une action.</p>
<p>Autre exemple, avec un jeu d'échec, on peut obtenir des récompenses mieux que ce qu'on aurait pu jouer simplement en sacrifiant des pièces pour jouer un meilleur coup.</p>
<blockquote>
<p>En apprentissage par renforcement, on crée une <strong>politique</strong> qui définit l&rsquo;<strong>action</strong> qui maximisera les <strong>récompenses</strong> lorsqu'une action sera exécutée en fonction de l'état du système.</p>
</blockquote>
<h2 id="atari-pong">Atari Pong</h2>
<p>Pour coder mon réseau de neurones et faire de l'apprentissage par renforcement sur un cas pratique et simple, j'ai utilisé le framework <a href="https://gym.openai.com/docs/">OpenAI gym</a>.</p>
<blockquote>
<p>&ldquo;Gym is a toolkit for developing and comparing reinforcement learning algorithms&rdquo;</p>
</blockquote>
<p>Ce framework permet d'intéragir avec des jeux basiques Atari.
J'ai choisi le jeu Atari Pong pour implémenter mon algorithme gradients de politique.</p>
<p>Voici 2 vidéos que j'ai enregistré qui montrent des parties jouées entre un agent qui est l'ordinateur et un agent qui est piloté par un réseau de neurones.</p>
<ul>
<li>Dans la première vidéo, le réseau de neurones n'a pas encore été entraîné.</li>
</ul>

    <iframe 
        width="100%" 
        height="400" 
        src="//www.youtube.com/embed/fmxJNCf4REY?rel=0" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>




<ul>
<li>Dans la seconde vidéo, le réseau de neurones a été entraîné pendant des jours avec un algorithme policy gradients.</li>
</ul>

    <iframe 
        width="100%" 
        height="400" 
        src="//www.youtube.com/embed/yo2c-SCFL-M?rel=0" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>




<!-- raw HTML omitted -->
<h2 id="algorithmes-gradients-de-politique-policy-gradients">Algorithmes gradients de politique <em>(Policy Gradients)</em></h2>
<p>L'objectif des algorithmes <em>Policy Gradients</em> est d'optimiser les paramètres d'une politique en suivant les gradients vers les récompenses les plus élevées.
L'objectif de ces algorithmes est de ne pas coder des politiques en dur. Cela permet d'avoir des systèmes plus fiables.</p>
<p>Voici un très bon cours pour comprendre en détail comment fonctionnent ces algorithmes:
<a href="http://rll.berkeley.edu/deeprlcourse/">http://rll.berkeley.edu/deeprlcourse/</a> (voir lecture 4 policy gradient).</p>
<p>Il y a également une vidéo qui traite spécifiquement de ces algorithmes.</p>




<p>En synthèse, voici un résumé de l'algo implémenté:</p>
<ul>
<li>
<p>On commence par laisser la politique du réseau de neurones jouer plusieurs parties de Pong et à chaque étape on calcule les gradients qui augmenteraient la probabilité de l'action choisie. Au début, on ne fait rien d'autre que calculer les gradients.</p>
</li>
<li>
<p>Après plusieurs parties, on calcule le score de chaque action. On évalue une action en fonction de la somme de toutes les récompenses qui s'ensuivent en appliquant à chaque étape un taux de rabais (<strong>discount rate</strong>) r.
Par exemple, si on considère que notre agent va 3 fois de suite vers le haut et qu'on prend les hypothèses suivantes:</p>
<ul>
<li>Il reçoit +10 comme récompense après la première étape</li>
<li>0 après la deuxième</li>
<li>-50 après la troisième</li>
<li>r = 0,8 (plus le taux de rabais est proche de 1 et plus les récompenses arrivant tardivement comptent autant que les récompenses immédiates. Généralemement r varie entre 0,95 et 0,99.</li>
<li>Conclusion: le score total est de 10 * r^0 + 0 * r^1 + (-50) * r^2 = -22</li>
</ul>
</li>
<li>
<p>Si le score est positif, cela signifie que l'action était bonne. On applique les gradients calculés lors de la première étape. Appliquer les gradients signifie que l'on multiplie son vecteur par le score de l'action correspondante. L'action sera ainsi davantage utilisée dans le futur.
Si l'action n'était pas bonne, on applique les gradients opposés.</p>
</li>
<li>
<p>Pour terminer, on calcule la moyenne de tous les vecteurs de gradients obtenus et on l'utilise pour effectuer une étape de descente de gradient.</p>
</li>
</ul>]]></content>
        </item>
        
        <item>
            <title>Voiture autonome avec Unity et Keras</title>
            <link>https://leandeep.com/voiture-autonome-avec-unity-et-keras/</link>
            <pubDate>Sun, 04 Mar 2018 15:43:00 +0000</pubDate>
            
            <guid>https://leandeep.com/voiture-autonome-avec-unity-et-keras/</guid>
            <description>&lt;p&gt;
    &lt;iframe 
        width=&#34;100%&#34; 
        height=&#34;400&#34; 
        src=&#34;//www.youtube.com/embed/Pl6MbEZ3liM?rel=0&#34; 
        frameborder=&#34;0&#34; 
        allow=&#34;autoplay; encrypted-media&#34; 
        allowfullscreen&gt;
    &lt;/iframe&gt;




&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>
    <iframe 
        width="100%" 
        height="400" 
        src="//www.youtube.com/embed/Pl6MbEZ3liM?rel=0" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>




<!-- raw HTML omitted --></p>
<p>Cet article présente le résultat de mon travail sur la construction d'un véhicule autonome dans un simulateur. J'ai suivi un <em>whitepaper</em> rédigé par une équipe de Nvidia qui est disponible à l'adresse suivante: <a href="http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf">http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf</a></p>
<p>Le training a été fait non pas sur une Nvidia Drive PX comme précisé dans le <em>paper</em> mais sur un Macbook Pro durant 1 nuit.</p>
<p><img src="/images/implemented-model.png" alt="image"></p>
<p>Le problème de conduite de véhicule autonome est ramené à un problème d'apprentissage supervisé.
Grâce au simulateur <a href="https://github.com/udacity/self-driving-car-sim"><em>opensource</em></a> d&rsquo;<a href="https://eu.udacity.com/">Udacity</a>, des données d'apprentissage peuvent être extraites.</p>
<ul>
<li>En entrée X, on a des images de la route.
En effet, à l'avant du véhicule, il y a 3 caméras. Une filme le côté gauche du véhicule, une autre le devant et une dernière filme le côté droit.</li>
<li>En sortie Y, on a l'angle du volant.</li>
</ul>
<p>Le modèle est construit et entraîné avec Keras (et Tensorflow en backend).</p>
<p>Le modèle suivant est implémenté:</p>
<p><img src="/images/cnn-autonomous-vehicule.png" alt="image"></p>
<p>Comme vous avez pu le voir sur la vidéo au dessus, après une nuit d'apprentissage, notre véhicule suit bien la route en toute autonomie.</p>
<p>Maintenant, si vous voulez construire votre propre voiture autonome grandeur nature vous savez comment faire&hellip; Il faut placer 3 caméras sur le capot de votre véhicule, lire le bus CAN et pouvoir agir sur l'angle du volant (et sur les pédales aussi!).</p>
<p><img src="/images/lol.gif" alt="image"></p>]]></content>
        </item>
        
        <item>
            <title>Installer OpenShift sur OSX</title>
            <link>https://leandeep.com/installer-openshift-sur-osx/</link>
            <pubDate>Wed, 28 Feb 2018 22:13:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-openshift-sur-osx/</guid>
            <description>Qu&#39;est-ce qu&#39;OpenShift ? OpenShift est une plateforme de PAAS développée par RedHat qui repose sur Kubernetes. En gros, c&#39;est Kubernetes avec des outils en plus faits pour simplifier la vie des développeurs. Et en plus c&#39;est opensource&amp;hellip;
MiniShift Si vous voulez tester l&#39;outil ou avoir un environnement local qui ressemble un peu à votre cluster de production, il existe un outil appelé MiniShift.
Ce dernier permet de faire tourner un cluster Openshift sur un seul noeud dans une VM en local.</description>
            <content type="html"><![CDATA[<h2 id="quest-ce-quopenshift-">Qu'est-ce qu'OpenShift ?</h2>
<p>OpenShift est une plateforme de PAAS développée par RedHat qui repose sur <a href="https://kubernetes.io/">Kubernetes</a>. En gros, c'est Kubernetes avec des outils en plus faits pour simplifier la vie des développeurs. Et en plus c'est opensource&hellip;</p>
<h2 id="minishift">MiniShift</h2>
<p>Si vous voulez tester l'outil ou avoir un environnement local qui ressemble un peu à votre cluster de production, il existe un outil appelé MiniShift.</p>
<p>Ce dernier permet de faire tourner un cluster Openshift sur un seul noeud dans une VM en local.</p>
<h2 id="installation-de-minishift">Installation de MiniShift</h2>
<p>Voici la procédure pour l'installer avec les dépendances nécessaires:</p>
<ul>
<li>Docker CE pour OSX</li>
<li>docker-machine</li>
<li>Minikube</li>
<li>xhyve (hyperviseur par défault pour OSX)</li>
<li>xhyve driver</li>
<li>MiniShift</li>
</ul>
<pre><code># Installer docker
# Rendez à l'adresse suivante https://docs.docker.com/docker-for-mac/install/ pour télécharger Docker CE. Il suffit de déplacer le binaire dans /Applications 

# Installer docker-machine
$ curl -L https://github.com/docker/machine/releases/download/v0.13.0/docker-machine-`uname -s`-`uname -m` &gt;/usr/local/bin/docker-machine &amp;&amp; \
  chmod +x /usr/local/bin/docker-machine

# Installer Minikube
$ brew cask install minikube

# Installer MiniShift
$ brew cask install minishift

# Installer xhyve
$ brew install --HEAD xhyve 

# Installer xhyve driver
$ brew install docker-machine-driver-xhyve
$ sudo chown root:wheel $(brew --prefix)/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve
$ sudo chmod u+s $(brew --prefix)/opt/docker-machine-driver-xhyve/bin/docker-machine-driver-xhyve
</code></pre><h2 id="cration-de-la-vm">Création de la VM</h2>
<pre><code># Créer une VM dans xhyve et créer un cluster OpenShift sur cette dernière
minishift start

# Pour utiliser minishift avec virtualbox 
# minishift start --vm-driver=virtualbox
</code></pre><p>Si tout se passe bien, vous devriez avoir ceci:</p>
<p><img src="/images/oc-login.png" alt="image"></p>
<h2 id="test-avec-une-application-exemple">Test avec une application exemple</h2>
<p>Dans cette section, nous allons déployer une application NodeJS fournie par OpenShift qui nous permettra de vérifier que tout fonctionne.</p>
<p>Il y a 3 manières de &ldquo;piloter&rdquo; OpenShift. Vous pouvez le faire avec le CLI, l'interface Web ou directement via l'API. Bien que l'interface Web soit très simple à utiliser, on va utiliser le CLI pour la suite de cet article.</p>
<p>Pour l'installer, il suffit d'exécuter la commande suivante:</p>
<pre><code>$ brew install openshift-cli

# Vérifier l'installation
$ oc version
oc v3.7.1+ab0f056
kubernetes v1.7.6+a08f5eeb62
features: Basic-Auth

Server https://192.168.64.5:8443
openshift v3.7.1+a8deba5-34
kubernetes v1.7.6+a08f5eeb62
</code></pre><p>Si vous souhaitez obtenir des informations sur l'interface Web, il y a un <a href="https://learn.openshift.com/introduction/getting-started/">très bon tutoriel sur le site d'OpenShift</a> qui vous expliquera les points ci-dessous en vous aidant à déployer la webapp qui ressemble à cela:</p>
<p><img src="/images/map-app-openshift.png" alt="image"></p>
<ul>
<li>Comment déployer une image disponible sur dockerhub</li>
<li>Comment <em>scaler</em> votre application extrèmement rapidement</li>
<li>Comment fonctionne le Routing HTTP avec HaProxy pour les services créés automatiquement lors du déploiement de l'image. (Prenez le temps de regarder, sécuriser vos routes par TLS est vraiment très simple. C'est limite une case à cocher&hellip;)</li>
<li>Comment <em>builder</em> une image à partir de votre code source sur Git (via l'outil S2I opensource. La documentation de cet outil est disponible <a href="https://docs.openshift.org/latest/creating_images/s2i.html">ici</a>)</li>
</ul>
<pre><code>oc login
# Utilisez developer/developer comme credentials

# Création d'un pod et déploiement de l'application test (git clone, build et push de l'image)
oc new-app https://github.com/openshift/nodejs-ex -l name=myapp

# Surveiller le déploiement en accédant aux logs
oc logs -f bc/nodejs-ex

# Création d'un service Kubernetes 
# i.e: Exposer le port 80 en configurant un reverse proxy qui pointe sur le port 8080 du Pod précédement créé. 
oc expose svc/nodejs-ex
</code></pre><p>Si tout s'est bien passé, une URL &ldquo;publique&rdquo; va être générée et vous permettra d'accéder à l'application juste déployée. L'application d'exemple déployée <strong>via le CLI</strong> ressemble à ceci:</p>
<p><img src="/images/front-app-example-openshift.png" alt="image"></p>
<h2 id="commandes-utiles-pour-le-cli">Commandes utiles pour le CLI</h2>
<p><strong>Switcher de compte OpenShift</strong></p>
<pre><code>oc login --username developer 

# oc login --username &lt;username&gt; --password &lt;password&gt;
# oc login --token &lt;token&gt;
</code></pre><p><strong>Lister les clusters sur lesquels on s'est déjà connecté</strong></p>
<pre><code>oc config get-clusters
</code></pre><p><strong>Se connecter à un cluster spécifique avec un compte particulier</strong></p>
<pre><code>oc login https://clusterA.leandeep.com --username superadmin
</code></pre><p><strong>Lister tous les contextes</strong></p>
<pre><code>oc config get-contexts
</code></pre><p><strong>Who am I ?</strong></p>
<pre><code>oc whoami

# oc whoami --token (voir le token actuel)
# oc whoami --show-server (voir le cluster actuel)
</code></pre><p><strong>Lister les projets</strong></p>
<pre><code>oc get projects
</code></pre><p><strong>Créer un projet</strong></p>
<pre><code>oc new-project mon_super_projet
</code></pre><p><strong>Accéder à un projet</strong></p>
<pre><code>oc project &lt;nom-du-projet&gt;
</code></pre><p><strong>Créer une app s2i (source 2 image)</strong></p>
<pre><code>oc new-app --source-secret &lt;nom-de-votre-secret-pour-se-connecter-a-votre-source-control&gt; &lt;image-docker-permettant-de-faire-du-s2i&gt;~https://bitbucket.org/user/repo-avec-du-nodejs-et-un-dockerfile.git --name nom-de-votre-app-dans-votre-projet
</code></pre><p>Les ressources suivantes vont être automatiquement créées:</p>
<pre><code>--&gt; Creating resources ...
    imagestream &quot;image-docker-permettant-de-faire-du-s2i&quot; created
    imagestream &quot;nom-de-votre-app-dans-votre-projet&quot; created
    buildconfig &quot;nom-de-votre-app-dans-votre-projet&quot; created
    deploymentconfig &quot;nom-de-votre-app-dans-votre-projet&quot; created
    service &quot;nom-de-votre-app-dans-votre-projet&quot; created
</code></pre><p><strong>Update une app s2i</strong></p>
<pre><code>oc start-build &lt;nom-du-build-pour-votre-app&gt;
</code></pre><p><strong>Delete une app</strong></p>
<pre><code>oc delete all -l app=bla-bla-bla-https
</code></pre><p><strong>Donner les droits en lecture à un utilisateur</strong></p>
<pre><code>oc adm policy add-role-to-user view developer -n mon_super_projet

# oc adm policy add-role-to-user edit &lt;username&gt; -n &lt;project&gt; (donne les droits d'écriture + création de déploiements + effacement d'applications)

# oc adm policy add-role-to-user admin &lt;username&gt; -n &lt;project&gt; (donne tous les droits sur le projet)
</code></pre><p><strong>Lister toutes les ressources d'un projet (dont DNS exposé)</strong></p>
<pre><code>oc get all

# Plus direct pour obtenir la route exposée
# oc get routes

# Lister et filtrer sur un label
oc get all -o name --selector app=apinodejs
</code></pre><p><strong>Obtenir plus d'information sur une ressource</strong></p>
<pre><code>oc describe route/apinodejs
# alternative 
# oc describe route apinodejs
</code></pre><p><strong>Comprendre OpenShift (obtenir des informations sur les ressources)</strong></p>
<pre><code>oc get 
# ou 
# oc types
# ou
# oc explain route.spec.host (utile lorsqu'on sort les réponses au format JSON. Exemple oc get route/apinodejs -o json ==&gt; lire l'arborescence) 
</code></pre><p><strong>Editer une ressource</strong></p>
<pre><code>oc edit route/apinodejs 

ou 
oc edit route/apinodejs -o json
</code></pre><p><strong>Créer une ressource (formats json ou yml acceptés)</strong></p>
<pre><code>oc create -f apinodejs-fqdn.json

# Commande disponible pour la création de route
# oc create route edge apinodejs-fqdn --service apinodejs --insecure-policy Allow --hostname www.example.com
</code></pre><p><strong>Editer une ressource</strong></p>
<pre><code>oc replace -f apinodejs-fqdn.json

# Erreur si la ressource n'existe pas. L'alternative: oc apply 
</code></pre><p><strong>Editer à la volée</strong></p>
<pre><code>oc patch route/apinodejs-fqdn --patch '{&quot;spec&quot;:{&quot;tls&quot;: {&quot;insecureEdgeTerminationPolicy&quot;: &quot;Allow&quot;}}}'

# Erreur si la ressource n'existe pas. L'alternative: oc apply
</code></pre><p><strong>Ajouter/Retirer un label sur un service</strong></p>
<pre><code># Ajouter le label
oc label service/apinodejs web=true

# Retirer le label
oc label service/apinodejs web-
</code></pre><p><strong>Effacer une ressource</strong></p>
<pre><code>oc delete route/apinodejs-fqdn

# Effacer plusieurs ressources
# oc delete all [--all] --selector app=apinodejs
</code></pre><p><strong>Créer un environnement from scratch</strong></p>
<pre><code>conda create --name py35 python=3.5 
</code></pre><p><strong>Connect as Minishift superadmin</strong></p>
<pre><code>oc login -u system:admin
</code></pre><p><strong>Accéder à Minishift en local</strong></p>
<pre><code>oc login https://&lt;IP&gt;:8443 -u system:admin --insecure-skip-tls-verify=true
</code></pre><p><strong>Obtenir l'IP de Minishift</strong></p>
<pre><code>minishift ip
</code></pre><h2 id="troubleshooting">Troubleshooting</h2>
<p><strong>Un pod en terminating state ne se kill pas</strong></p>
<pre><code>oc get po 
oc delete pod &lt;pod-name&gt; -n &lt;pod-namespace&gt; --grace-period=0 --force
</code></pre><p><strong>Un provisioned service &ldquo;marked for deletion&rdquo; ne s'efface pas</strong></p>
<pre><code>oc edit serviceinstance &lt;provisioned-service&gt; -n &lt;namespace&gt;
# Effacer metadata.finalizers de l'instance comme workaround
</code></pre><p><strong>L'application ne s'affiche pas</strong></p>
<p>Si vous avez l'erreur suivante, c'est qu'il y a un problème de résolution DNS sur votre Mac:</p>
<p><img src="/images/openshift-app-unreachable.png" alt="image"></p>
<p>Pour corriger le problème, changez le DNS de votre Mac et utilisez celui de Google.
Pour ce faire, allez dans Préférences Système &ndash;&gt; Network &ndash;&gt; Cliquez sur le bouton avancé en bas à droit après avoir sélectionné l'interface réseau que vous utilisez &ndash;&gt; Cliquez sur l'onglet DNS &ndash;&gt; Ajoutez 8.8.8.8 dans la section DNS</p>
<p><strong>Vous avez tout crashé et vous voulez tout recommencer de 0</strong></p>
<p>En cas d'erreur avec votre VM, cette commande peut être utile pour effacer les dossiers en cache. Supprimer la VM dans VirtualBox ne suffit pas.</p>
<pre><code># Effacer le cache et la VM
minishift delete --clear-cache

# recréer votre VM
minishift start delete

# Si éventuellement vous ne pouvez pas recréer votre nouvelle VM car il reste des fichiers persistants, effacer le dossier suivant:
rm -rf ~/.minishift/machines/*
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer Keras (et Tensorflow) sur OS X</title>
            <link>https://leandeep.com/installer-keras-et-tensorflow-sur-os-x/</link>
            <pubDate>Sat, 10 Feb 2018 19:11:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-keras-et-tensorflow-sur-os-x/</guid>
            <description>Dans cet article nous allons voir comment installer Keras sur OS X (High Sierra) pour faire du Deep Learning.
Pré-requis Si vous voulez utiliser Keras, vous allez sans doute avoir besoin d&#39;OpenCV. J&#39;ai réalisé un article sur l&#39;installation d&#39;OpenCV 3 pour Python 3.6. Cela explique également comment installer des environnements virtuels; ce qui est vraiment très utile. Si vous voulez installer Keras en suivant cet article et ne rencontrer aucun problème, je vous recommande de suivre le tutoriel suivant: installer OpenCV 3 sur Python 3.</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons voir comment installer Keras sur OS X (High Sierra) pour faire du Deep Learning.</p>
<h2 id="pr-requis">Pré-requis</h2>
<p>Si vous voulez utiliser Keras, vous allez sans doute avoir besoin d'OpenCV.
J'ai réalisé un article sur l'installation d'OpenCV 3 pour Python 3.6. Cela explique également comment installer des environnements virtuels; ce qui est vraiment très utile. Si vous voulez installer Keras en suivant cet article et ne rencontrer aucun problème, je vous recommande de suivre le tutoriel suivant: <a href="http://blog.leandeep.com/installer-python-3-et-opencv-3-sur-os-x/">installer OpenCV 3 sur Python 3.6</a>.</p>
<h2 id="installation-de-keras">Installation de Keras</h2>
<p>Commencez par créez un nouvel environnement virtuel (même si vous en avez déjà créé un auparavant) et donnez lui un nom explicite.</p>
<pre><code>$ mkvirtualenv py3_keras_tf -p python3
</code></pre><p>Dans votre nouvel environnement virtuel, installez les librairies suivantes:</p>
<pre><code>$ pip install scipy #Librairie dédiée aux méthodes numériques (Résolution de système d'équations linéaire, Transformée de Fourier, Interpolation...)
$ pip install pillow imutils # Librairie de manipulation d'image 
$ pip install h5py # Permet de gérer les binaires au format HDF5
$ pip install requests progressbar2 # Utilitaires
$ pip install scikit-learn scikit-image # Librairie de machine learning

$ pip install matplotlib # Permet de tracer et visualiser des données sous formes de graphiques
# Les 3 commandes qui suivent permettent de gérer l'affichage sur OSX 
$ mkdir ~/.matplotlib
$ touch ~/.matplotlib/matplotlibrc 
$ echo &quot;backend: TkAgg&quot; &gt;&gt; ~/.matplotlib/matplotlibrc 
</code></pre><p>Nous utiliserons Keras avec Tensorflow comme backend. Il est possible d'en utiliser d'autres comme <a href="http://deeplearning.net/software/theano/">Theano</a> ou encore <a href="https://www.microsoft.com/en-us/cognitive-toolkit/">CNTK</a> mais ce n'est pas l'objet de cet article.</p>
<p>Il faut donc installer Tensorflow</p>
<pre><code>$ pip install tensorflow
</code></pre><p>Vous pouvez maintenant installer Keras</p>
<pre><code>$ pip install keras
</code></pre><h2 id="vrification-de-linstallation">Vérification de l'installation</h2>
<pre><code>$ python
&gt;&gt;&gt; import keras
Using TensorFlow backend.
&gt;&gt;&gt; Ctrl-D
</code></pre><p>Voilà c'est tout !
Nous ne verrons pas dans cet article comment utiliser le GPU pour optimiser la phase d'apprentissage de votre réseau de neurones. Je ne vous recommande pas de le faire avec un Mac ou Macbook. Utilisez plutôt des machines conçues pour cela avec des vraies GPU faits pour cela.</p>
]]></content>
        </item>
        
        <item>
            <title>Installer Python 3.6.x et OpenCV 3 sur OS X</title>
            <link>https://leandeep.com/installer-python-3.6.x-et-opencv-3-sur-os-x/</link>
            <pubDate>Tue, 06 Feb 2018 23:05:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-python-3.6.x-et-opencv-3-sur-os-x/</guid>
            <description>Comme l&#39;installatin d&#39;OpenCV n&#39;est vraiment pas aisée. J&#39;ai donc décidé d&#39;écrire cet article. Si vous suivez cette procédure vous devriez pouvoir faire tourner OpenCV 3 sur OSX High Sierra dans un environnement virtuel.
Il s&#39;agit du deuxième article que j&#39;écris sur l&#39;installation d&#39;OpenCV. Cette article se focalise sur l&#39;installation d&#39;OpenCV 3 pour Python 3.6.x. Si vous souhaitez installer OpenCV 3 pour python 2.7.x, vous pouvez lire mon autre article.
Pré-requis  Xcode doit être installé Xcode a déjà dû être démarré et vous avez accepté les conditions générales Les commandes lines tools ont déjà été installés.</description>
            <content type="html"><![CDATA[<p>Comme l'installatin d'OpenCV n'est vraiment pas aisée. J'ai donc décidé d'écrire cet article. Si vous suivez cette procédure vous devriez pouvoir faire tourner OpenCV 3 sur OSX High Sierra dans un environnement virtuel.</p>
<p>Il s'agit du deuxième article que j'écris sur l'installation d'OpenCV. Cette article se focalise sur l'installation d'OpenCV 3 pour Python 3.6.x. Si vous souhaitez installer OpenCV 3 pour python 2.7.x, vous pouvez lire <a href="http://blog.leandeep.com/installer-python-2-7-x-et-opencv-3-sur-os-x/">mon autre article</a>.</p>
<h2 id="pr-requis">Pré-requis</h2>
<ul>
<li>Xcode doit être installé</li>
<li>Xcode a déjà dû être démarré et vous avez accepté les conditions générales</li>
<li>Les commandes lines tools ont déjà été installés. Si ce n'est pas le cas exécutez la commande suivante: $ sudo xcode-select &ndash;install</li>
<li><a href="https://brew.sh/index_fr.html">Homebrew</a> doit être installé</li>
</ul>
<h2 id="installer-python-3">Installer Python 3</h2>
<p>Même si Python est déjà installé sur votre Mac, installez le une nouvelle fois avec Homebrew:</p>
<pre><code>$ brew install python3
</code></pre><p>Vérifiez que Python 3 et pip fonctionnent.</p>
<pre><code>$ python3 --version
$ pip3 --version
</code></pre><p>Vérifiez aussi que ce sont bien les nouvelles versions de Python et pip qui sont utilisées</p>
<pre><code>$ which python3
$ which pip3
</code></pre><h2 id="crer-un-environnement-virtuel">Créer un environnement virtuel</h2>
<pre><code>$ pip3 install virtualenv virtualenvwrapper # /!\ il se peut que sudo soit nécessaire
</code></pre><p>Ajoutez les lignes suivantes dans votre ~/.zshrc (ou ~/.bash_profile)</p>
<pre><code># Support d'environnements virtuels pour Python 3
export VIRTUALENVWRAPPER_PYTHON=/usr/local/bin/python3
source /usr/local/bin/virtualenvwrapper.sh
</code></pre><p>Une fois ces lignes ajoutées, &ldquo;rechargez&rdquo; votre terminal en exécutant la commande suivante:</p>
<pre><code>$ source ~/.zshrc # ou $ source ~/.bash_profile
</code></pre><p>Vous pouvez maintenant créer votre environnement virtuel pour OpenCV 3 et Python 3</p>
<pre><code>$ mkvirtualenv py3_cv3 -p python3
</code></pre><p>Une fois créé, fermez votre terminal et réouvrez en un nouveau.
Par défault vous n'êtes pas dans l'environnement Python que vous avez créé. Si vous souhaitez rentrer dedans, utilisez la commande suivante:</p>
<pre><code>$ workon py3_cv3
</code></pre><p>Si tout se passe bien, votre prompt du terminal sera préfixé du nom de votre environnement entre parenthèses.</p>
<p><em>Remarquez que vous n'avez pas besoin d'utiliser pip3 dans cet environnement virtuel. La commande $ pip &ndash;version nous indique bien que pip est lié à Python 3.6.x. En dehors de cet environnement virtuel vous devrez utiliser pip3 pour que des librairies liées à Python 3 soient téléchargées.</em></p>
<p>Si vous souhaitez quitter votre environnement virtuel utilisez la commande suivante:</p>
<pre><code>$ deactivate
</code></pre><p><em>Pour tout ce qui suit, travaillez dans le nouvel environnement virtuel que l'on vient de créer</em></p>
<h2 id="installer-numpy">Installer Numpy</h2>
<p>Numpy est une bibliothèque très connue de calculs scientiques nécessaire pour OpenCV.</p>
<pre><code>pip install numpy
</code></pre><h2 id="installer-les-pr-requis--opencv-3">Installer les pré-requis à OpenCV 3</h2>
<p>Pour qu'on OpenCV 3 fonctionne certains pré-requis sont nécessaires.
Heureusement l'installation de ces pré-requis est aisée grâce à Homebrew.</p>
<pre><code>$ brew install cmake pkg-config # Nécessaire pour compiler OpenCV
$ brew install jpeg libpng libtiff openexr # Nécessaire pour manipuler les images 
$ brew install eigen # Nécessaire pour faire des calculs algébriques
$ brew install tbb # Nécessaire pour faire les calculs parallèles
</code></pre><h2 id="installer-opencv">Installer OpenCV</h2>
<p>Commencez par télécharger OpenCV. Il y a 2 repositories git à cloner.
(Vous n'avez pas besoin de tout l'historique du repository)</p>
<pre><code>$ cd
$ git clone https://github.com/opencv/opencv --depth 1
$ git clone https://github.com/opencv/opencv_contrib --depth 1
</code></pre><p>Vous allez maintenant pouvoir builder OpenCV.</p>
<pre><code>$ cd ~/opencv
$ mkdir build
$ cd build

# Configuration
$ cmake -D CMAKE_BUILD_TYPE=RELEASE \
    -D CMAKE_INSTALL_PREFIX=/usr/local \
    -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules \
    -D PYTHON3_LIBRARY=`python -c 'import subprocess ; import sys ; s = subprocess.check_output(&quot;python-config --configdir&quot;, shell=True).decode(&quot;utf-8&quot;).strip() ; (M, m) = sys.version_info[:2] ; print(&quot;{}/libpython{}.{}.dylib&quot;.format(s, M, m))'` \
    -D PYTHON3_INCLUDE_DIR=`python -c 'import distutils.sysconfig as s; print(s.get_python_inc())'` \
    -D PYTHON3_EXECUTABLE=$VIRTUAL_ENV/bin/python \
    -D BUILD_opencv_python2=OFF \
    -D BUILD_opencv_python3=ON \
    -D INSTALL_PYTHON_EXAMPLES=ON \
    -D INSTALL_C_EXAMPLES=OFF \
    -D BUILD_EXAMPLES=ON ..

# Compilation
$ make -j4 # -j4 permet d'utiliser les 4 cœurs de mon Mac lors de la compilation

# Installation
$ sudo make install

# Symlink
$ cd /usr/local/lib/python3.6/site-packages
$ ls -l | grep cv2.cpython-36m-darwin.so # Vérifiez que le fichier cv2.cpython-36m-darwin.so est bien présent
$ cd ~/.virtualenvs/py3_cv3/lib/python3.6/site-packages
$ ln -s /usr/local/lib/python3.6/site-packages/cv2.cpython-36m-darwin.so cv2.so
</code></pre><h2 id="vrification-de-linstallation">Vérification de l'installation</h2>
<p>Ouvrez un nouveau terminal et vérifiez que l'installation d'OpenCV fonctionne dans votre environnement virtuel.</p>
<pre><code>$ workon py3_cv3
$ python
&gt;&gt;&gt; import cv2
&gt;&gt;&gt; cv2.__version__
'3.4.0-dev'
&gt;&gt;&gt; Ctrl-D
</code></pre><p>Et voilà l'installation d'OpenCV 3 pour Python 3.6.x est terminée!
J'espère que vous ne rencontrerez pas de problème et que je vous aurais fait gagner des heures; tout comme avec mon autre article sur l&rsquo;<a href="http://blog.leandeep.com/installer-python-2-7-x-et-opencv-3-sur-os-x/">installation d'OpenCV 3 pour Python 2.7.x</a> !</p>
]]></content>
        </item>
        
        <item>
            <title>Installer Python 2.7.x et OpenCV 3 sur OS X</title>
            <link>https://leandeep.com/installer-python-2.7.x-et-opencv-3-sur-os-x/</link>
            <pubDate>Fri, 02 Feb 2018 13:45:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-python-2.7.x-et-opencv-3-sur-os-x/</guid>
            <description>Comme l&#39;installatin d&#39;OpenCV n&#39;est vraiment pas aisée. J&#39;ai donc décidé d&#39;écrire cet article. Si vous suivez cette procédure vous devriez pouvoir faire tourner OpenCV 3 sur OSX High Sierra dans un environnement virtuel.
OpenCV 3 est bien sûr compatible avec Python 3 mais comme beaucoup de développeurs Python utilisent encore la version 2, j&#39;ai décidé de faire 2 tutoriaux. Il y a celui-ci pour Python 2.7.x et il y en un autre pour installer OpenCV 3 pour Python 3.</description>
            <content type="html"><![CDATA[<p>Comme l'installatin d'OpenCV n'est vraiment pas aisée. J'ai donc décidé d'écrire cet article. Si vous suivez cette procédure vous devriez pouvoir faire tourner OpenCV 3 sur OSX High Sierra dans un environnement virtuel.</p>
<p>OpenCV 3 est bien sûr compatible avec Python 3 mais comme beaucoup de développeurs Python utilisent encore la version 2, j'ai décidé de faire 2 tutoriaux. Il y a celui-ci pour Python 2.7.x et il y en un autre pour <a href="http://blog.leandeep.com/installer-python-3-et-opencv-3-sur-os-x/">installer OpenCV 3 pour Python 3.5.x</a>.</p>
<h2 id="pr-requis">Pré-requis</h2>
<ul>
<li>Xcode doit être installé</li>
<li>Xcode a déjà dû être démarré et vous avez accepté les conditions générales</li>
<li>Les commandes lines tools ont déjà été installés. Si ce n'est pas le cas exécutez la commande suivante: $ sudo xcode-select &ndash;install</li>
<li><a href="https://brew.sh/index_fr.html">Homebrew</a> doit être installé</li>
</ul>
<h2 id="installer-python">Installer Python</h2>
<p>Même si Python est déjà installé sur votre Mac, installez le une nouvelle fois avec Homebrew:</p>
<pre><code>$ brew install python
# Cela va installer python dans /usr/local/opt/
</code></pre><p>Ajoutez au PATH de votre Mac la nouvelle installation de Python.
Si comme moi vous utilisez le terminal <a href="http://ohmyz.sh/">ohmyzsh</a>, vous devez ajoutez les lignes suivantes dans le ficher ~/.zshrc.
Si vous utilisez le terminal classique d'OSX, ajoutez les lignes suivantes en bas du fichier ~/.bash_profile</p>
<pre><code># Ajout de Python 2 installé via Homebrew dans le PATH
export PATH=&quot;/usr/local/opt/python/libexec/bin:$PATH&quot;
</code></pre><p>Une fois ajouté, &ldquo;rechargez&rdquo; votre terminal en exécutant la commande $ source ~/.zshrc ($ source ~/.bash_profile)</p>
<p>Vérifiez que Python et pip fonctionnent.
Vérifiez aussi que ce sont bien les nouvelles versions de Python et pip qui sont utilisées</p>
<pre><code>$ which python
$ which pip
</code></pre><h2 id="installer-les-packages-de-cration-denvironnements-virtuels">Installer les packages de création d'environnements virtuels</h2>
<p>Les packages virtualenv et virtualenvwrapper vont vous permettre de créer environnements Python différents. Tout est isolé; vous pouvez avoir des librairies différentes dans chaque environnement. C'est extrèmement pratique; je le recommande fortement.</p>
<pre><code>$ pip install virtualenv virtualenvwrapper # /!\ il se peut que sudo soit nécessaire
</code></pre><p>Ajoutez les lignes suivantes dans votre ~/.zshrc (ou ~/.bash_profile)</p>
<pre><code># Support d'environnement virtuel pour Python 2
source /usr/local/bin/virtualenvwrapper.sh
</code></pre><p>Une fois ces lignes ajoutées, &ldquo;rechargez&rdquo; votre terminal en exécutant la commande $ source ~/.zshrc ($ source ~/.bash_profile)</p>
<h2 id="crer-un-environnement-virtuel">Créer un environnement virtuel</h2>
<p>Pour créer un nouvel environement, il suffit d'utiliser la commande suivante. Afin de vous y retrouver avec les différents environnement, je vous conseille d'utiliser un nom court et très explicite avec les numéros de version.</p>
<pre><code>$ mkvirtualenv py2_cv3
</code></pre><p>Une fois créé, fermez votre terminal et réouvrez en un nouveau.
Par défault vous n'êtes pas dans l'environnement Python que vous avez créé. Si vous souhaitez rentrer dedans, utilisez la commande suivante:</p>
<pre><code>$ workon py2_cv3
</code></pre><p>Si tout se passe bien, votre prompt du terminal sera préfixé du nom de votre environnement entre parenthèses.</p>
<p>Si vous souhaitez quitter votre environnement virtuel utilisez la commande suivante:</p>
<pre><code>$ deactivate
</code></pre><p><em>Pour tout ce qui suit, travaillez dans le nouvel environnement virtuel que l'on vient de créer</em></p>
<h2 id="installer-numpy">Installer Numpy</h2>
<p>Numpy est une bibliothèque très connue de calculs scientiques nécessaire pour OpenCV.</p>
<pre><code>pip install numpy
</code></pre><h2 id="installer-les-pr-requis--opencv-3">Installer les pré-requis à OpenCV 3</h2>
<p>Pour qu'on OpenCV 3 fonctionne certains pré-requis sont nécessaires.
Heureusement l'installation de ces pré-requis est aisée grâce à Homebrew.</p>
<pre><code>$ brew install cmake pkg-config # Nécessaire pour compiler OpenCV
$ brew install jpeg libpng libtiff openexr # Nécessaire pour manipuler les images 
$ brew install eigen # Nécessaire pour faire des calculs algébriques
$ brew install tbb # Nécessaire pour faire les calculs parallèles
</code></pre><h2 id="installer-opencv">Installer OpenCV</h2>
<p>Commencez par télécharger OpenCV. Il y a 2 repositories git à cloner.
(Vous n'avez pas besoin de tout l'historique du repository)</p>
<pre><code>$ cd
$ git clone https://github.com/opencv/opencv --depth 1
$ git clone https://github.com/opencv/opencv_contrib --depth 1
</code></pre><p>Vous allez maintenant pouvoir builder OpenCV.</p>
<pre><code>$ cd ~/opencv
$ mkdir build
$ cd build

# Configuration
$ cmake -D CMAKE_BUILD_TYPE=RELEASE \
    -D CMAKE_INSTALL_PREFIX=/usr/local \
    -D OPENCV_EXTRA_MODULES_PATH=~/opencv_contrib/modules \
    -D PYTHON2_LIBRARY=`python -c 'import subprocess ; import sys ; s = subprocess.check_output(&quot;python-config --configdir&quot;, shell=True).decode(&quot;utf-8&quot;).strip() ; (M, m) = sys.version_info[:2] ; print(&quot;{}/libpython{}.{}.dylib&quot;.format(s, M, m))'` \
    -D PYTHON2_INCLUDE_DIR=`python -c 'import distutils.sysconfig as s; print(s.get_python_inc())'` \
    -D PYTHON2_EXECUTABLE=$VIRTUAL_ENV/bin/python \
    -D BUILD_opencv_python2=ON \
    -D BUILD_opencv_python3=OFF \
    -D INSTALL_PYTHON_EXAMPLES=ON \
    -D INSTALL_C_EXAMPLES=OFF \
    -D BUILD_EXAMPLES=ON ..

# Compilation
$ make -j4 # -j4 permet d'utiliser les 4 cœurs de mon Mac lors de la compilation

# Installation
$ sudo make install

# Symlink
$ cd /usr/local/lib/python2.7/site-packages/
$ ls -l | grep cv2.so # Vérifiez que le fichier cv2.so est bien présent
$ cd ~/.virtualenvs/py2_cv3/lib/python2.7/site-packages/
$ ln -s /usr/local/lib/python2.7/site-packages/cv2.so cv2.so
</code></pre><h2 id="vrification-de-linstallation">Vérification de l'installation</h2>
<p>Ouvrez un nouveau terminal et vérifiez que l'installation d'OpenCV fonctionne dans votre environnement virtuel.</p>
<pre><code>$ workon py2_cv3
$ python
&gt;&gt;&gt; import cv2
&gt;&gt;&gt; cv2.__version__
&gt;&gt;&gt; Ctrl-D
</code></pre><p>Et voilà l'installation d'OpenCV 3 pour Python 2.7.x est terminée!
J'espère que vous ne rencontrerez pas de problème et que je vous aurais fait gagner des heures !
Si vous suivez bien ce tutoriel et que vous êtes sur la même version d'OS X, normalement tout se passera bien.</p>
]]></content>
        </item>
        
        <item>
            <title>Lancer un Datalab en quelques minutes</title>
            <link>https://leandeep.com/lancer-un-datalab-en-quelques-minutes/</link>
            <pubDate>Fri, 19 Jan 2018 23:39:00 +0000</pubDate>
            
            <guid>https://leandeep.com/lancer-un-datalab-en-quelques-minutes/</guid>
            <description>Il m’arrive assez régulièrement de devoir switcher de machine de développement lorsque je travaille sur du Machine ou Deep Learning. C’est d’autant plus vrai lorsque je travaille avec Tensorflow avec support GPU et que je manipule des datasets de plusieurs Go. Pour accélérer la phase d’apprentissage de mes algorithmes, il m’arrive de louer, durant plusieurs heures, des VM survitaminées chez Amazon Web Services.
Pour éviter de devoir reconfigurer à chaque fois mon environnement de datascience, j’utilise 2 images Docker.</description>
            <content type="html"><![CDATA[<p>Il m’arrive assez régulièrement de devoir switcher de machine de développement lorsque je travaille sur du Machine ou Deep Learning. C’est d’autant plus vrai lorsque je travaille avec Tensorflow avec support GPU et que je manipule des datasets de plusieurs Go. Pour accélérer la phase d’apprentissage de mes algorithmes, il m’arrive de louer, durant plusieurs heures, des VM survitaminées chez Amazon Web Services.</p>
<p>Pour éviter de devoir reconfigurer à chaque fois mon environnement de datascience, j’utilise 2 images Docker.
Grâce à Docker et à l’image que j’ai à disposition, je peux lancer un nouvel environnement de datascience from Scratch en moins de 5 minutes. De plus, je peux faire une sauvegarde parfaite de toutes les configurations et librairies que j’utilise. It’s definitely worth it ! Avez-vous déjà perdu votre temps à installer xgboost ou Cuda sur OSX 😀 ?</p>
<p>Ma première image est la parfaite toolbox du data scientist.</p>
<p><img src="/images/docker-jupyter-spark.png" alt="image"></p>
<p>Elle contient les outils suivants:</p>
<ul>
<li>Spark</li>
<li>Python3</li>
<li>R</li>
<li>SQL</li>
<li>Jupyter</li>
</ul>
<p>De nombreuses librairies pour la datascience
Vous pouvez cloner mon repository, builder et démarrer l’image sur votre environnement:</p>
<p><a href="https://github.com/oeeckhoutte/fast-datalab">https://github.com/oeeckhoutte/fast-datalab</a></p>
<p>Je vous recommande d’exécuter la deuxième commande dans mon README. Elle vous permettra de monter un volume entre votre Host Docker et le container. Vos données seront ainsi préservées si le container venait à crasher. Si vous n’êtes pas dans une logique d’industrialisation de vos modèles, je vous recommande également de créer un cron et de sauvegarder automatiquement vos notebooks Jupyter sur Bitbucket (free private repositories).</p>
<p>Après avoir exécuté les 2 commandes pour builder votre image et lancer un container (moins de 5 minutes), votre environnement avec Jupyter Notebook et tous les outils actuels pour faire du Machine Learning seront prêts. Vous n’aurez plus qu’à ouvrir un nouvel onglet dans votre navigateur et vous rendre à l’adresse indiquée:</p>
<p><img src="/images/jupyter-launched.png" alt="image"></p>
<p>Pour faire du Deep Learning avec la version optimisée pour GPU de TensorFlow, j’ai rencontré pas mal de difficultés à tout installer et configurer. Même si mon poste de développement est puissant (Mac Pro avec i7, GPU NVIDIA élevé, 32 go RAM), je n’ai pas la patience d’attendre durant les phases d’apprentissage.</p>
<p>Pour avoir le maximum de puissance (plusieurs GPU en parallèle) et pour ne plus jamais avoir à installer et configurer CUDA, j’exécute directement mes algorithmes dans des containers Docker sur la plateforme AWS. Je loue une machine survitaminée (une machine que je n’aurais jamais chez moi) le temps de l’apprentissage et je l’arrête quand c’est terminé. Cela ne me coûte presque rien. Merci AWS !</p>
<p>Je parlerai de ce sujet plus en détails dans un prochain article.</p>
]]></content>
        </item>
        
        <item>
            <title>Restaurer une base de données Mysql et voir la progression</title>
            <link>https://leandeep.com/restaurer-une-base-de-donn%C3%A9es-mysql-et-voir-la-progression/</link>
            <pubDate>Wed, 10 Jan 2018 19:59:00 +0200</pubDate>
            
            <guid>https://leandeep.com/restaurer-une-base-de-donn%C3%A9es-mysql-et-voir-la-progression/</guid>
            <description>En pré-requis il vous faut 2 binaires: pv et mysql-client
Pour les installer, il suffit d&#39;exécuter les commandes suivantes:
brew install pv mysql-client  Ensuite, pour restaurer le dump d&#39;une base de données et voir la progression, vous pouvez exécuter la commande suivante:
pv dump.sql | mysql -u DB_USER -h DB_HOST -D DB_NAME -p  Rappel: commande pour dumper une base MySQL: mysqldump -u DB_USER -h DB_HOST -D DB_NAME -p &amp;gt; dump.</description>
            <content type="html"><![CDATA[<p>En pré-requis il vous faut 2 binaires: <code>pv</code> et <code>mysql-client</code></p>
<p>Pour les installer, il suffit d'exécuter les commandes suivantes:</p>
<pre><code>brew install pv mysql-client
</code></pre><br/>
<p>Ensuite, pour restaurer le dump d'une base de données et voir la progression, vous pouvez exécuter la commande suivante:</p>
<pre><code>pv dump.sql | mysql -u DB_USER -h DB_HOST -D DB_NAME -p
</code></pre><blockquote>
<p>Rappel: commande pour dumper une base MySQL: <code>mysqldump -u DB_USER -h DB_HOST -D DB_NAME -p &gt; dump.sql</code></p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Algorithmes de Marchine Learning organisés par famille</title>
            <link>https://leandeep.com/algorithmes-de-marchine-learning-organis%C3%A9s-par-famille/</link>
            <pubDate>Sat, 06 Jan 2018 19:22:00 +0000</pubDate>
            
            <guid>https://leandeep.com/algorithmes-de-marchine-learning-organis%C3%A9s-par-famille/</guid>
            <description>Mindmap source machinelearningmastery; site internet que je recommande vraiment. Tout n&#39;est pas présent mais il y a quoi faire pour s&#39;amuser.</description>
            <content type="html"><![CDATA[<p><em>Mindmap source <a href="https://machinelearningmastery.com">machinelearningmastery</a>; site internet que je recommande vraiment. Tout n'est pas présent mais il y a quoi faire pour s'amuser.</em></p>
<p><img src="/images/MachineLearningAlgorithms.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Smart Gate ou comment ouvrir un portail électrique par reconnaissance faciale</title>
            <link>https://leandeep.com/smart-gate-ou-comment-ouvrir-un-portail-%C3%A9lectrique-par-reconnaissance-faciale/</link>
            <pubDate>Sat, 21 Oct 2017 19:55:00 +0000</pubDate>
            
            <guid>https://leandeep.com/smart-gate-ou-comment-ouvrir-un-portail-%C3%A9lectrique-par-reconnaissance-faciale/</guid>
            <description>&lt;p&gt;
    &lt;iframe 
        width=&#34;100%&#34; 
        height=&#34;400&#34; 
        src=&#34;//www.youtube.com/embed/qPFkhyp6WOI?rel=0&#34; 
        frameborder=&#34;0&#34; 
        allow=&#34;autoplay; encrypted-media&#34; 
        allowfullscreen&gt;
    &lt;/iframe&gt;




&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>
    <iframe 
        width="100%" 
        height="400" 
        src="//www.youtube.com/embed/qPFkhyp6WOI?rel=0" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>




<!-- raw HTML omitted --></p>
<p>Solution maison réalisée uniquement à partir de frameworks opensource. Il n'y a pas de dépendance avec des solutions SAAS telles que Watson ou d'autres services cognitifs chez Azure ou AWS. Cette solution peut être déployée n'importe où et utiliser n'importe quelle caméra.</p>
<p>De plus, une application mobile cross-platform (iOS et Android) permet de gérer les personnes autorisées à entrer. Elle permet également d'afficher les personnes inconnues et d'envoyer des alertes (via push ou SMS) au propriétaire du portail. Ce dernier peut alors voir en temps réel ce qu'il se passe devant chez lui. Les serveurs sont à Frankfort (AWS). La latence est seulement de 3 ou 4 secondes malgré la distance des serveurs avec mon portail, la quantité d'images à ingérer (flux vidéo en HD) et les traitements à effectuer pour reconnaître les visages.</p>]]></content>
        </item>
        
        <item>
            <title>Gérer proprement ses variables d&#39;environnement de type boolean sur Ansible</title>
            <link>https://leandeep.com/g%C3%A9rer-proprement-ses-variables-denvironnement-de-type-boolean-sur-ansible/</link>
            <pubDate>Sun, 17 Sep 2017 18:20:00 +0000</pubDate>
            
            <guid>https://leandeep.com/g%C3%A9rer-proprement-ses-variables-denvironnement-de-type-boolean-sur-ansible/</guid>
            <description>Cet article très rapide explique comment caster proprement des variables d&#39;environnement de type bool passées à un Playbook.
Si l&#39;utilisateur entre yes, 1, True cela sera considéré de la même manière si vous utilisez cette commande:
{{ votre_var | d() | bool }} Le d() (pour default) est utile pour ne pas avoir une erreur disant que votre_var n&#39;est pas définie.
from jinja2 import Template from ansible.runner.filter_plugins.core import bool Template(&#39;&#39;).environment.filters[&#39;bool&#39;] = bool tmpl = Template(&#39;{{ var | d() | bool }}&#39;) &amp;gt;&amp;gt;&amp;gt; print tmpl.</description>
            <content type="html"><![CDATA[<p>Cet article très rapide explique comment <em>caster</em> proprement des variables d'environnement de type bool passées à un Playbook.</p>
<p>Si l'utilisateur entre <code>yes</code>, <code>1</code>, <code>True</code> cela sera considéré de la même manière si vous utilisez cette commande:</p>
<pre><code>{{ votre_var | d() | bool }}
</code></pre><p>Le d() (pour default) est utile pour ne pas avoir une erreur disant que <code>votre_var</code> n'est pas définie.</p>
<pre><code>from jinja2 import Template
from ansible.runner.filter_plugins.core import bool
Template('').environment.filters['bool'] = bool
tmpl = Template('{{ var | d() | bool }}')
&gt;&gt;&gt; print tmpl.render()
False
&gt;&gt;&gt; print tmpl.render(var=None)
None
&gt;&gt;&gt; print tmpl.render(var='')
False
&gt;&gt;&gt; print tmpl.render(var='toto')
False
&gt;&gt;&gt; print tmpl.render(var=' ')
False
&gt;&gt;&gt; print tmpl.render(var='True')
True
&gt;&gt;&gt; print tmpl.render(var=[])
False
&gt;&gt;&gt; print tmpl.render(var=['list'])
False
&gt;&gt;&gt; print tmpl.render(var={})
False
&gt;&gt;&gt; print tmpl.render(var={'key': 'value'})
False
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Support des modules ES6 dans Chrome 61</title>
            <link>https://leandeep.com/support-des-modules-es6-dans-chrome-61/</link>
            <pubDate>Wed, 06 Sep 2017 13:03:00 +0000</pubDate>
            
            <guid>https://leandeep.com/support-des-modules-es6-dans-chrome-61/</guid>
            <description>Excellente news, Chrome supporte maintenant nativement les modules ES6. Enfin!
Exemple:
index.html &amp;lt;!DOCTYPE html&amp;gt; &amp;lt;html lang=&amp;quot;en&amp;quot;&amp;gt; &amp;lt;head&amp;gt; &amp;lt;meta charset=&amp;quot;UTF-8&amp;quot;&amp;gt; &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width, initial-scale=1.0&amp;quot;&amp;gt; &amp;lt;meta http-equiv=&amp;quot;X-UA-Compatible&amp;quot; content=&amp;quot;ie=edge&amp;quot;&amp;gt; &amp;lt;title&amp;gt;Test module ES6&amp;lt;/title&amp;gt; &amp;lt;/head&amp;gt; &amp;lt;body&amp;gt; &amp;lt;p&amp;gt;2+3 = &amp;lt;span class=&amp;quot;result&amp;quot;&amp;gt;&amp;lt;/span&amp;gt;&amp;lt;/p&amp;gt; &amp;lt;script type=&amp;quot;module&amp;quot;&amp;gt; import { add } from &#39;./common.js&#39;; (function () { document.querySelector(&#39;.result&#39;).innerText = add(2, 3); console.log(add(2, 3)); }()); &amp;lt;/script&amp;gt; &amp;lt;/body&amp;gt; &amp;lt;/html&amp;gt; common.js console.log(&#39;common.js&#39;); export function add (a, b) { return a + b; } </description>
            <content type="html"><![CDATA[<p>Excellente news, Chrome supporte maintenant nativement les modules ES6. Enfin!</p>
<p>Exemple:</p>
<h2 id="indexhtml">index.html</h2>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
  &lt;meta charset=&quot;UTF-8&quot;&gt;
  &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
  &lt;meta http-equiv=&quot;X-UA-Compatible&quot; content=&quot;ie=edge&quot;&gt;
  &lt;title&gt;Test module ES6&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;p&gt;2+3 = &lt;span class=&quot;result&quot;&gt;&lt;/span&gt;&lt;/p&gt;

  &lt;script type=&quot;module&quot;&gt;
    import { add } from './common.js'; 
    (function () { 
      document.querySelector('.result').innerText = add(2, 3); 
      console.log(add(2, 3));
    }());
  &lt;/script&gt;
  
&lt;/body&gt;
&lt;/html&gt;
</code></pre><h2 id="commonjs">common.js</h2>
<pre><code>console.log('common.js');
export function add (a, b) {
    return a + b;
}
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Ma présentation du Deep Learning</title>
            <link>https://leandeep.com/ma-pr%C3%A9sentation-du-deep-learning/</link>
            <pubDate>Thu, 22 Jun 2017 21:51:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ma-pr%C3%A9sentation-du-deep-learning/</guid>
            <description>&lt;p&gt;Ces dernières semaines j’ai été invité à parler de Deep Learning dans plusieurs entreprises des Hauts de France.&lt;/p&gt;
&lt;p&gt;Ma présentation est publiques et accessible ci-dessous:&lt;/p&gt;

    &lt;iframe
        src=&#34;//www.slideshare.net/slideshow/embed_code/key/k2FBLJDR6XX6EX&#34;
        title=&#34;SlideShare Presentation&#34;
        height=&#34;485&#34;
        width=&#34;595&#34;
        frameborder=&#34;0&#34;
        marginwidth=&#34;0&#34;
        marginheight=&#34;0&#34;
        scrolling=&#34;no&#34;
        style=&#34;border: 1px solid #CCC; border-width: 1px; margin-bottom: 20px; width: 100%;&#34;
        allowfullscreen=&#34;true&#34;&gt;
    &lt;/iframe&gt;





&lt;p&gt;Vous trouverez ci-dessous les 2 des 3 vidéos que j&#39;ai présenté durant la phase de démo de ma présentation.
Les 2 apps font appel à des modèles Tensorflow.
La première app est construite en Ionic. La seconde en React.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>Ces dernières semaines j’ai été invité à parler de Deep Learning dans plusieurs entreprises des Hauts de France.</p>
<p>Ma présentation est publiques et accessible ci-dessous:</p>

    <iframe
        src="//www.slideshare.net/slideshow/embed_code/key/k2FBLJDR6XX6EX"
        title="SlideShare Presentation"
        height="485"
        width="595"
        frameborder="0"
        marginwidth="0"
        marginheight="0"
        scrolling="no"
        style="border: 1px solid #CCC; border-width: 1px; margin-bottom: 20px; width: 100%;"
        allowfullscreen="true">
    </iframe>





<p>Vous trouverez ci-dessous les 2 des 3 vidéos que j'ai présenté durant la phase de démo de ma présentation.
Les 2 apps font appel à des modèles Tensorflow.
La première app est construite en Ionic. La seconde en React.</p>
    <iframe 
        width="100%" 
        height="400" 
        src="//www.youtube.com/embed/8IEiUx4x-SU?rel=0" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>





    <iframe 
        width="100%" 
        height="400" 
        src="//www.youtube.com/embed/fIZ4HMX5xbE?rel=0" 
        frameborder="0" 
        allow="autoplay; encrypted-media" 
        allowfullscreen>
    </iframe>




<p>Si vous souhaitez que je fasse une intervention dans votre entreprise, n’hésitez pas à me contacter via Linkedin. Voici le lien pour accéder à mon profil: <a href="https://www.linkedin.com/in/oliviereeckhoutte/">https://www.linkedin.com/in/oliviereeckhoutte/</a></p>]]></content>
        </item>
        
        <item>
            <title>Installer (Mini)Conda sur OSX</title>
            <link>https://leandeep.com/installer-miniconda-sur-osx/</link>
            <pubDate>Sun, 04 Jun 2017 20:57:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-miniconda-sur-osx/</guid>
            <description>Qu&#39;est-ce que Conda ? Conda est un outil permettant de gérer les packages scientifiques utiles notamment pour faire du Machine Learning. Il gère aussi les dépendances de ces packages; même celles en dehors de Python (Librairies C, Paquets R&amp;hellip;). Il permet également de gérer des environnements virtuels comme virtualenv. C&#39;est un outil très répandu que vous retrouverez dans beaucoup de cours ou tutoriels. Il est donc intéressant de l&#39;installer sur votre poste.</description>
            <content type="html"><![CDATA[<h2 id="quest-ce-que-conda-">Qu'est-ce que Conda ?</h2>
<p>Conda est un outil permettant de gérer les packages scientifiques utiles notamment pour faire du Machine Learning. Il gère aussi les dépendances de ces packages; même celles en dehors de Python (Librairies C, Paquets R&hellip;). Il permet également de gérer des environnements virtuels comme virtualenv. C'est un outil très répandu que vous retrouverez dans beaucoup de cours ou tutoriels. Il est donc intéressant de l'installer sur votre poste.</p>
<h2 id="quest-ce-quanaconda-">Qu'est-ce qu'Anaconda ?</h2>
<p>Conda est le gestionnaire de paquets d'Anaconda. Anaconda est une distribution gratuite de Python délivré par la société Continuum Analytics qui contient plus d'un milliers de paquets permettant de faire des sciences, des mathématiques, de l'ingénierie et de l'analyse de données. C'est une sorte de gros package incluant tous les outils nécessaires pour faire du Machine Learning.</p>
<h2 id="quest-ce-que-miniconda-">Qu'est-ce que Miniconda ?</h2>
<p>C'est une alternative à Anaconda. C'est beaucoup plus léger car il ne contient que Conda et quelques dépendances nécessaires à son fonctionnement.</p>
<h2 id="installer-miniconda-sur-osx">Installer Miniconda sur OSX</h2>
<p>Il faut commencer par télécharger un script bash disponible à l&rsquo;<a href="https://conda.io/miniconda.html">adresse suivante</a>.</p>
<pre><code>$ wget https://repo.continuum.io/miniconda/Miniconda3-latest-MacOSX-x86_64.sh
</code></pre><p>Une fois téléchargé, il faut exécuter le script dans le terminal et suivre les instructions affichées à l'écran:</p>
<pre><code>$ bash Miniconda3-latest-MacOSX-x86_64.sh
</code></pre><p>Si comme moi vous utilisez ohmyzsh à la place bash, ajoutez la ligne suivante dans le fichier ~/.zshrc (prenez soin de changer l'utilisateur &ldquo;olivier&rdquo; par le votre):</p>
<pre><code># added by Miniconda3 installer
export PATH=&quot;/Users/olivier/miniconda3/bin:$PATH&quot;
</code></pre><p>Rechargez votre terminal pour prendre en compte la modification.</p>
<pre><code>$ source ~/.zshrc
</code></pre><p>Vérifiez enfin que l'installation s'est bien déroulée:</p>
<pre><code>$ conda -V
</code></pre><h2 id="commandes-conda-utiles">Commandes Conda utiles</h2>
<p><strong>Lister les environnements virtuels</strong></p>
<pre><code>$ conda env list
</code></pre><p><strong>Supprimer un environnement et tous les packages</strong></p>
<pre><code>$ conda env remove --name nom-environnement
</code></pre><p><strong>Sortir de l'environnement actuel</strong></p>
<pre><code>$ source deactivate
</code></pre><p>**Activer un environnement **</p>
<pre><code>$ conda activate nom-environnement
</code></pre><p><strong>Créer un environnement à partir d'un fichier de config (.yml)</strong></p>
<pre><code>$ conda env create -f environments.yml 
</code></pre><p>Le fichier environnement ressemble à ceci:</p>
<pre><code>name: self-driving
channels:
    - https://conda.anaconda.org/menpo
    - conda-forge
dependencies:
    - python==3.5.2
    - numpy
    - matplotlib
    - jupyter
    - opencv3
    - pillow
    - scikit-learn
    - scikit-image
    - scipy
    - h5py
    - eventlet
    - flask-socketio
    - seaborn
    - pandas
    - imageio
    - pip:
        - moviepy
        - tensorflow==1.1
        - keras==1.2
</code></pre><p>Voici la spécification des numéros de version des paquets du fichier de configuration:</p>
<ul>
<li>Fuzzy: &ldquo;numpy=1.11&rdquo; (1.11.0, 1.11.1, 1.11.2, 1.11.18 etc.)</li>
<li>Exact: &ldquo;numpy==1.11&rdquo; (1.11.0)</li>
<li>Greater than or equal to: &ldquo;numpy&gt;=1.11&rdquo; (1.11.0 or higher)</li>
<li>OR: &ldquo;numpy=1.11.1|1.11.3&rdquo; (1.11.1, 1.11.3)</li>
<li>AND: &ldquo;numpy&gt;=1.8,&lt;2&rdquo; (1.8, 1.9, not 2.0)</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Programmer un réseau de neurones en JavaScript</title>
            <link>https://leandeep.com/programmer-un-r%C3%A9seau-de-neurones-en-javascript/</link>
            <pubDate>Sat, 03 Jun 2017 22:45:00 +0000</pubDate>
            
            <guid>https://leandeep.com/programmer-un-r%C3%A9seau-de-neurones-en-javascript/</guid>
            <description>Pour bien comprendre comment fonctionnent les réseaux de neurones, nous allons en créer un from scratch en JavaScript. Je pense que c&#39;est intéressant d&#39;en créer un de toute pièce avant de s&#39;attaquer à des réseaux de neurones profonds ou d&#39;utiliser des frameworks qui masquent toute la complexité.
Introduction Un neurone biologique est composé d&#39;un corps cellulaire, d&#39;un réseau de dendrites et d&#39;un axone.
 Le corps cellulaire contient le patrimoine génétique.</description>
            <content type="html"><![CDATA[<p>Pour bien comprendre comment fonctionnent les réseaux de neurones, nous allons en créer un <em>from scratch</em> en JavaScript. Je pense que c'est intéressant d'en créer un de toute pièce avant de s'attaquer à des réseaux de neurones profonds ou d'utiliser des frameworks qui masquent toute la complexité.</p>
<h1 id="introduction">Introduction</h1>
<p>Un neurone biologique est composé d'un corps cellulaire, d'un réseau de dendrites et d'un axone.</p>
<ul>
<li>Le corps cellulaire contient le patrimoine génétique.</li>
<li>Les signaux électriques transitent par le réseau de dendrites. Ces dernières correspondent aux entrées du neurone.</li>
<li>L'axone à la sortie du neurone permet de véhiculer l'influx nerveux.</li>
</ul>
<p>Les neurones artificiels s'inspirent du comportement des neurones biologiques; c'est-à-dire de leur capacité à s'activer à partir d'un seuil.</p>
<p><img src="/images/neurone-biologique-neurone-artificiel.jpg" alt="image"></p>
<p>Si on entre plus dans le détail, un neurone calcule la somme pondérée de ses entrées, puis il compare le résultat à un seuil (dit seuil d'activation). Basiquement, si la somme est supérieure au seuil, alors il s'active et sort la valeur 1. Réciproquement, si la somme est inférieure au seuil, alors il ne s'active pas et sort la valeur 0.</p>
<p>En ce qui concerne la somme pondérée, chaque entrée valant 0 ou 1 est multipliée par un coefficient qui représente son poids (on parle de poids synaptique).
A noter, que si un signal d'entrée est à 1, alors la valeur ce ce signal prend tout simplement la valeur du coefficient. De même, si le signal d'entrée est à 0, alors sa valeur reste à 0.</p>
<p>Un neurone fonctionne ainsi: il faut additionner toutes les valeurs obtenues par les sommes pondérées en entrée et comparer le résultat à la valeur d'un seuil.</p>
<h1 id="prcision-sur-les-seuils-dactivation">Précision sur les seuils d'activation</h1>
<p>Nous venons de voir dans le paragraphe précédent que la sortie d'un neurone nous donnait 1 ou 0 en fonction du seuil d'activation. C'est tout à fait vrai lorsqu'on utilise une fonction à seuil binaire. Mais en pratique on utilise d'autres fonctions d'activation nous donnant des valeurs numériques comprises entre 0 et 1. La plus répandue est la &ldquo;fonction sigmoïde&rdquo; (aussi appelée &ldquo;fonction logistique&rdquo; ou &ldquo;courbe en S&rdquo;).</p>
<p>Avec cette fonction, le passage de 0 à 1 est plus progressif comme on peut le voir sur la courbe suivante:</p>
<p><img src="/images/sigmoide.png" alt="image"></p>
<p>L'équation de la fonction sigmoïde est la suivante:</p>
<p><img src="/images/equation-sigmoide.png" alt="image"></p>
<h1 id="initialisation-de-notre-rseau-de-neurones">Initialisation de notre réseau de neurones</h1>
<p>Nous allons créer un réseau simple permettant de résoudre un problème simple.
Nous allons classifier en 4 catégories des images noir et blanc réduites à seulement 4 pixels. C'est un exemple pédagagique bien sûr.</p>
<p>Pendant la phase d'apprentissage, nous allons présenter au réseau les images que l'on souhaite reconnaître. Puis pendant la phase de reconnaissance, on présente des images aléatoires afin de vérifier si le réseau a bien appris.</p>
<p>Voici les images dont on va se servir pour entraîner notre réseau.</p>
<p><img src="/images/combinaison-images-apprentissage.png" alt="image"></p>
<p>Pour se simplifier la vie, nous allons représenter ces images sous forme de tableau.</p>
<p><img src="/images/image-to-tableau.png" alt="image"></p>
<p>Nous allons les représenter les 4 catégories d'images via un tableau à 2 valeurs.</p>
<ul>
<li>[0, 0] pour les images n'ayant aucun ou tous les pixels noirs</li>
<li>[0, 1] pour les images comprenant 1 pixel noir</li>
<li>[1, 0] pour les images comprenant 2 pixels noirs</li>
<li>[1, 1] pour les images comprenant 3 pixels noirs</li>
</ul>
<p>Nous allons construire un réseau comprenant 3 couches:</p>
<ul>
<li>La première couche (couche d'entrée) contient 4 neurones en entrée pour les 4 pixels de l'image.</li>
<li>La deuxième couche est une couche cachée. Elle permet de faire la liaison entre la couche d'entrée et la couche de sortie.</li>
<li>La 3ème couche (couche de sortie) contient 2 neurones pour les 2 valeurs représentant notre catégorie.</li>
</ul>
<p><img src="/images/Reseau-de-neurones-simple.png" alt="image"></p>
<p>Pour construire un réseau de neurones avec une structure simple comme celle-ci, il suffit d'assembler les neurones les uns derrières les autres. On connecte les sorties des uns aux entrées des autres.
Entre chaque couche, nous relions les sorties des neurones de la couche précédente à tous les neurones de la couche suivante.
Dans notre exemple simple, on appelle ce genre de réseau un réseau totalement connecté.</p>
<p>En JavaScript, on initialise les couches du réseau via des tableaux:</p>
<pre><code>let input = [];
let hidden = [];
let output = [];
</code></pre><p>En plus de ces tableaux, il nous en faut 2 autres pour stocker les valeurs des poids synaptiques associés aux connexions entre la 1ère et 2ème couches et la 2ème et 3ème couches:</p>
<pre><code>let Wh = [];
let Wo = [];
</code></pre><p>On va créer un dernier tableau pour notre input:</p>
<pre><code>// Tableau représentant notre image en input
let inputData = [0, 1, 0, 1]
</code></pre><p>On crée une fonction d'initialisation des différents tableaux.</p>
<pre><code>const reset = () =&gt; {
    input = [0, 0, 0, 0];
    hidden = [0, 0, 0, 0];
    output = [0, 0];
    
    // 0.5 a été choisi totalement arbitrairement
    // En pratique, on aurait pu générer des valeurs aléatoires distribuées uniformément sur l'intervalle [-1; 1] et dont la moyenne aurait été nulle.
    Wh = [[0.5, 0.5, 0.5, 0.5],
         [0.5, 0.5, 0.5, 0.5], 
         [0.5, 0.5, 0.5, 0.5]
         [0.5, 0.5, 0.5, 0.5]];
         
    Wo = [[0.5, 0.5, 0.5, 0.5],
         [0.5, 0.5, 0.5, 0.5]];
}

</code></pre><p>Chaque neurone de la couche d'entrée est connecté à tous les neurones de la couche cachée. Par conséquent, il y aura 4 poids synaptiques à prendre en compte dans le calcul de la moyenne pondérée pour chaque neurone de la couche cachée. Wh contient donc 4 tableaux de 4 poids.</p>
<p>Pour Wo, on a 2 neurones dans la couche de sortie. Donc on a 2 tableaux. Ces 2 tableaux contiennent les 4 poids de la couche cachée.</p>
<h1 id="propagation-des-donnes">Propagation des données</h1>
<p>Les données d'input sont propagées dans le réseau de neurones.
Pour propager les données de la couche d'entrée vers la couche de sortie, il faut réaliser une succession de calculs de couche en couche et de neurone en neurone. Ces calculs sont simples car ce ne sont que des multiplications et des additions. Par contre, il faut en faire beaucoup. Nous n'allons pas détailler les calculs car cela n'a pas d'intérêt et c'est fastidieux. On va plutôt utiliser des matrices et faire des produits matriciels&hellip;</p>
<p>Nous allons commencer par créer notre fonction sigmoïde qui permettra de calculer la valeur de sortie des neurones.</p>
<pre><code>const sigmoid = (x) =&gt; {
    return 1 / (1 + Math.pow(Math.E, (-1 * x)));
}
</code></pre><p>En programmation, si on veut connecter deux couches de neurones (par exemple connecter la couche A avec la couche B), voici le pseudo-code:</p>
<pre><code>Pour chaque neurone de la couche B:
    Pour chaque neurone de la couche A:
        Calcul sur le lien Wba;
    Fin pour;
Fin pour;
</code></pre><p>En JavaScript, cela donne:</p>
<pre><code>for (let j = 0; j &lt; B.length; j++) {
    for (let i = 0; j &lt; A.length; i++) {
        // Calcul sur le lien w[j][i]
    }
}
</code></pre><p>Après ces quelques explications, nous allons créer une fonction de propagation des données de la couche d'entrée vers la couche de sortie. Cette fonction va appliquer la fonction d'activation sur les sommes pondérées calculées entre les neurones des différentes couches. On va créer une fonction appelée propagate().</p>
<pre><code>const propagate = (d) =&gt; {

    // On copie les données dans la couche d'entrée
    for (let i = 0; i &lt; input.length; i++) {
        input[i] = d[i];
    }

    // On propage dans la couche cachée
    // Xh contient les sommes cumulées pour la couche cachée
    Xh = [0, 0, 0, 0];
    for (let j = 0; j &lt; hidden.length; j++) {
        for (let i = 0; i &lt; input.length; i++) {
            Xh[j] += Wh[j][i] * input[i];
        }   
    }

    // On applique la fonction d'activation
    for (let j = 0; j &lt; hidden.length; j++) {
        hidden[j] = sigmoid(Xh[j]);
    }

    // On propage dans la couche de sortie
    // Xo contient les sommes pondérées de chaque neurone de sortie
    Xo = [0, 0];
    for (let k = 0; k &lt; output.length; k++) {
        for (let j = 0; j &lt; hidden.length; j++) {
            Xo[k] += Wo[k][j] * hidden[j];
        }
    }

    // On applique la fonction d'activation
    for (let k = 0; k &lt; output.length; k++) {
        output[k] = sigmoid(Xo[k]);
    }
    
}
</code></pre><h1 id="test-de-la-propagation">Test de la propagation</h1>
<p>On va créer une petite interface en HTML permettant de visualiser la propagation. Si la valeur des 2 neurones de la dernière couche ont une valeur différente de [0, 0] (valeur d'initialisation), c'est que la propagation des données s'est bien produite.</p>
<iframe  src='//jsfiddle.net/oeeckhoutte/440La2wz/32/embedded/result/dark/' allowpaymentrequest allowfullscreen="allowfullscreen" frameborder="0"></iframe>
<h1 id="apprentissage">Apprentissage</h1>
<p>Nous allons passer à la phase la plus importante qui est l'apprentissage.
Cette phase est indispensable pour que notre réseau puisse apprendre à reconnaître nos images. Nous allons créer une fonction learn() qui implémente <a href="https://fr.wikipedia.org/wiki/R%C3%A9tropropagation_du_gradient">l'algorithme de rétropropagation du gradient de l'erreur</a>.</p>
<p>On va commencer par créer 2 nouvelles variables qui vont nous servir à définir le taux d'apprentissage et à définir la cible que l'on souhaite obtenir en sortie du réseau de neurones.</p>
<ul>
<li>Le taux d'apprentissage va être initialisé à 0.5 et sera représenté par la variable <strong>alpha</strong>.</li>
<li>La cible est un tableau de 2 valeurs. Il va être initialisé à [0, 0] et s'appelera <strong>target</strong>. Il s'agit de la cible à atteindre pour nos neurones de sortie.</li>
</ul>
<pre><code>let alpha = 0.5;
let target = [0, 0];
</code></pre><p>Nous allons passer à l'implémentation de l'algorithme de rétropropagation du gradient de l'erreur.
Pour notre exemple, cet algorithme comporte 4 étapes qui sont exécutées les unes à la suite des autres de manière cyclique. La boucle s'arrête lorsqu'un critère d'arrêt est atteint. On considère donc que l'apprentissage est terminé.
Le critère d'arrêt peut être soit un seuil d'erreur atteint ou soit un nombre d'itérations maximum atteint.</p>
<p>Les 4 étapes de l'algorithme sont les suivantes:</p>
<ul>
<li>Calcul de l'erreur en sortie de la propagation des données.</li>
<li>Calcul des gradients d'erreurs pour corriger les poids synaptiques des neurones de la couche de sortie.</li>
</ul>
<blockquote>
<p>Voici la formule que nous coderons qui permet de calculer l'erreur propagée:
<img src="/images/derivee-partielle.png" alt="image"></p>
</blockquote>
<ul>
<li>Calcul des gradients d'erreurs pour corriger les poids synaptiques des neurones de la couche cachée.</li>
<li>Mise à jour des poids synaptiques de la couche de sortie et de la couche cachée</li>
</ul>
<p>Ci dessous, le code JavaScript qui implémente cet algorithme:</p>
<pre><code>
const learn = () =&gt; {

    // 1ère étage:
    // On calcule l'erreur sur les neurones de sortie
    let error = [];

    for (let k = 0; k &lt; output.length; k++) {
        error[k] = target[k] - output[k]
    }
    
    // 2ème étage:
    // Calcul des gradients d'erreurs de la couche de sortie
    let gradErrOutput = [[0, 0, 0, 0], [0, 0, 0, 0]];
    for (let k = 0; k &lt; output.length; k++) {
        for (let j = 0; j &lt; hidden.length; j++) {
            gradErrOutput[k][j] = -error[k] * output[k] * ( 1 - output[k]) * hidden[j];
        }
    }
    
    // 3ème étage:
    // a. 
    // On retropropage l'erreur de sortie vers les neurones de la couche cachée proportionnellement à leurs poids synaptiques
    // b.
    // Ensuite on calcule les gradients d'erreurs dans la couche cachée
    let gradErrHidden = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]];
    for (let j = 0; j &lt; hidden.length; j++) {
        for (let i = 0; i &lt; input.length; i++) {
            // Variable locale permettant de cumuler l'erreur proportionnellement aux poids synaptiques
            let e = 0;
            for (k = 0; k &lt; output.length; k++) {
                // Rappel: 
                // Wo contient les poids synaptiques associés aux connexions entre la 2ème et 3ème couches
                e += Wo[k][j] * error[k];
                gradErrHidden[j][i] = -e * hidden[j] * (1 - hidden[j]) * input[i];
            }
        }
    }
    
    // 4ème étape:
    // Mise à jour de l'ensemble des poids synaptiques. Pour chaque poids, on soustrait une portion du gradient d'erreur par application du taux d'apprentissage alpha.
    for (let k = 0; k &lt; output.length; k++) {
        for (let j = 0; j &lt; hidden.length; j++) {
            Wo[k][j] -= alpha * gradErrOutput[k][j];
        }
    }
    
    for (let j = 0; j &lt; hidden.length; j++) {
        for (let i = 0; i &lt; input.length; i++) {
            Wh[j][i] -= alpha * gradErrHidden[j][i];
        }
    }
}
</code></pre><h1 id="test-de-la-rtropropagation">Test de la rétropropagation</h1>
<p>Nous allons modifier l'interface que nous avons précédemment codée afin de tester le bon fonctionnement de notre algorithme.</p>
<p>Tout le code est accessible ci-dessous:</p>
<iframe  src='//jsfiddle.net/oeeckhoutte/bxt2wy25/72/embedded/js,html,result/dark/' allowpaymentrequest allowfullscreen="allowfullscreen" frameborder="0"></iframe>
<p>Si vous appuyez une dizaine de fois sur les boutons <strong>Propagate</strong> et <strong>Learn</strong> alternativement, vous verrez que le réseau de neurones fonctionne bien. Les erreurs diminuent et les valeurs en output convergent bien vers [1, 0].</p>
<p><img src="/images/front-propagation-neuronal-net.png" alt="image"></p>
<h1 id="conclusion">Conclusion</h1>
<p>Si vous prenez le temps de bien lire cet article et de recoder l'ensemble du réseau de neurones, vous comprendrez comment ils fonctionnent. Bien comprendre ces réseaux simples est indispensable pour aller plus loin et faire du <em>Deep Learning</em>.
L'implémentation de notre réseau pour notre exemple simple était trivial. Par contre, en pratique, les use cases sont beaucoup plus complexes et donc cela se corse rapidement car l'algorithme de rétropropagation du gradient de l'erreur est sensible aux conditions de son exécution. Il faudra faire attention au surapprentissage (<em>overfitting</em>) et à la disparition du gradient (<em>vanishing gradient</em>) en jouant sur les fonctions d'activation, le taux d'apprentissage, pré-traiter les données d'entrée en les normalisant par exemple&hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Pourquoi il faut utiliser Object.is() pour comparer des éléments</title>
            <link>https://leandeep.com/pourquoi-il-faut-utiliser-object.is-pour-comparer-des-%C3%A9l%C3%A9ments/</link>
            <pubDate>Mon, 10 Apr 2017 19:51:00 +0000</pubDate>
            
            <guid>https://leandeep.com/pourquoi-il-faut-utiliser-object.is-pour-comparer-des-%C3%A9l%C3%A9ments/</guid>
            <description>Nous savons tous que le langage JavaScript manque de typage et qu&#39;il faut faire du Typescript et qu&#39;on peut obtenir des résultats bizarres à cause de ce qu&#39;on appelle la coercion ou le casting.
 &amp;ldquo;Converting a value from one type to another is often called &amp;ldquo;type casting,&amp;rdquo; when done explicitly, and &amp;ldquo;coercion&amp;rdquo; when done implicitly (forced by the rules of how a value is used) Source: https://github.com/getify/You-Dont-Know-JS
 Exemple &amp;ldquo;What the fuck&amp;rdquo; :</description>
            <content type="html"><![CDATA[<p>Nous savons tous que le langage JavaScript manque de typage <del>et qu'il faut faire du Typescript</del> et qu'on peut obtenir des résultats bizarres à cause de ce qu'on appelle la <em>coercion</em> ou le <em>casting</em>.</p>
<blockquote>
<p>&ldquo;Converting a value from one type to another is often called &ldquo;type casting,&rdquo; when done explicitly, and &ldquo;coercion&rdquo; when done implicitly (forced by the rules of how a value is used) Source: <a href="https://github.com/getify/You-Dont-Know-JS">https://github.com/getify/You-Dont-Know-JS</a></p>
</blockquote>
<p>Exemple &ldquo;What the fuck&rdquo; :</p>
<pre><code>0 == ' ' //true 
null == undefined //true
[1] == true //true
</code></pre><p>Il existe l'opérateur <code>===</code> qui améliore les choses en bloquant la conversion de type implicite mais qui ne résoud pas tout:</p>
<pre><code>Nan == NaN //false
</code></pre><p>ES6 a introduit une nouvelle feature qui améliore encore les choses <code>Object.is()</code>:</p>
<p>Par exmple:</p>
<pre><code>Object.is(0 , ' '); //false
Object.is(null, undefined); //false
Object.is([1], true); //false
Object.is(NaN, NaN); //true
</code></pre><p>Plus de détails (source Mozilla: <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness):">https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness):</a></p>
<p><img src="/images/elements_comparisons.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Evaluer ses modèles de classification</title>
            <link>https://leandeep.com/evaluer-ses-mod%C3%A8les-de-classification/</link>
            <pubDate>Wed, 15 Mar 2017 15:27:00 +0000</pubDate>
            
            <guid>https://leandeep.com/evaluer-ses-mod%C3%A8les-de-classification/</guid>
            <description>Introduction Voici les métriques à analyser pour évaluer la performance de son modèle.
Classification Justesse / Accuracy
  Justesse, (ou Taux de réussite ou encore taux de prédiction; accuracy en anglais). Mais attention, il ne faut pas se fier qu&#39;à cette seule métrique.
Pour la calculer, c&#39;est simple: accuracy = justesse (%) = nombre de prédictions correctes / (nombre total de prédictions données * 100)
ou accuracy = justesse = VP + VN / ( VP + VN + FP + FN )</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Voici les métriques à analyser pour évaluer la performance de son modèle.</p>
<h2 id="classification">Classification</h2>
<p><strong>Justesse / Accuracy</strong></p>
<ul>
<li>
<p><code>Justesse</code>, (ou <code>Taux de réussite</code> ou encore <code>taux de prédiction</code>; <code>accuracy</code> en anglais). <strong>Mais attention, il ne faut pas se fier qu'à cette seule métrique.</strong></p>
<p>Pour la calculer, c'est simple:
accuracy = justesse (%) = nombre de prédictions correctes / (nombre total de prédictions données * 100)</p>
<p>ou
accuracy = justesse = VP + VN / ( VP + VN + FP + FN )</p>
</li>
</ul>
<p>Exemple (source developer.google.com):</p>
<p><img src="/images/exemple-justesse.png" alt="image"></p>
<ul>
<li>CART (Classification And Regression Tree) Voir wikipédia: <a href="http://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees">http://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees</a></li>
</ul>
<p><strong>Matrice de confusion</strong></p>
<ul>
<li>
<p>La <code>Matrice de confusion</code> (<code>tableau de contingence</code>; <code>contingency table</code> en anglais) est une manière simple et non ambigue de présenter les résultats d'un classifier. (Voici un exemple sur ce notebook: <a href="https://leandeep.com/datalab-own/analyse-donnees-dataset-desequilibre.htm">https://leandeep.com/datalab-own/analyse-donnees-dataset-desequilibre.htm</a>)</p>
<p>Pour un sujet de classification binaire et non multi-classes (comme l'example plus haut), la matrice de confusion ressemble à ceci:</p>
</li>
</ul>
<p><img src="/images/matrice-confusion.png" alt="image"></p>
<p><em>En haut, on a ce qui est observé et sur le côté ce qui est prédit.</em></p>
<p>Parfois et par exemple pour des sujets où les classes sont déséquilibrées il vaut mieux ne pas se fier au taux de précision (<em>accuracy</em>) et plus utiliser une matrice de confusion.</p>
<p>En effet, utiliser le <code>nombre de faux positifs</code> ou <code>faux négatifs</code> pour les sujets liés à la santé par exemple a plus de sens que le taux de précision du modèle. <strong>Un modèle qui prédit si oui ou non on a le cancer ne doit pas avoir de faux négatif. Le taux de précision a donc moins d'importance dans ce cas. Au contraire, un modèle qui prédit qu'un patient est en bonne santé alors qu'il a un cancer c'est grave car le patient peut en mourir puisqu'il ne sera pas soigné !</strong>)</p>
<p><strong>Precision</strong></p>
<p><img src="/images/precision-rappel.png" alt="image"></p>
<p>La <code>précision</code> permet de répondre à la question: &ldquo;Quelle proportion d'identifications positives était effectivement correcte ?&rdquo;</p>
<p>La précision se calcule comme ceci:</p>
<p><img src="/images/precision.png" alt="image"></p>
<p>Example (source developer.google.com):</p>
<p><img src="/images/exemple-precision.png" alt="image"></p>
<p>**Rappel **</p>
<p>Le <code>rappel</code> (<em><code>recall</code></em> en anglais ou aussi <code>sensibilité</code> ou encore <code>taux de vrais positifs (TVP)</code>) permet de répondre à la question suivante: &ldquo;Quelle proportion de résultats positifs réels a été identifiée correctement ?&rdquo;</p>
<p>Le rappel se calcule comme ceci:</p>
<p><img src="/images/rappel.png" alt="image"></p>
<p>Example (source developer.google.com):</p>
<p><img src="/images/exemple-rappel.png" alt="image"></p>
<p>Pour évaluer les performances d'un modèle de façon complète, vous devez analyser à la fois la précision et le rappel. Malheureusement, précision et rappel sont fréquemment en tension. Ceci est dû au fait que l'amélioration de la précision se fait généralement au détriment du rappel et réciproquement.</p>
<p>Dans l'exemple du dépistage de cancer c'est la proportion de vrais positifs parmi les personnes à dépister.</p>
<p>**Spécificité **</p>
<p>La <code>spécificité</code> se calcule comme ceci:</p>
<p><img src="/images/specificite.png" alt="image"></p>
<p>Dans l'exemple du dépistage du cancer c'est proportion de vrais négatifs chez les non-malades.</p>
<p><strong>Différence avec la sensibilité:</strong></p>
<p>La <code>sensibilité</code> est l'indice qui évalue la capacité d'une mesure à bien classer les malades (ou les exposés), et la <code>spécificité</code> celui qui évalue la capacité à bien classer les non-malades (ou les non-exposés).</p>
<p>**Score F1 **</p>
<p>Aussi appelé <em>F Score</em> ou <em>F Measure</em>, le <code>score F1</code> permet de traduire l'équilibre entre la précision et le rappel. Attention, le problème de cette métrique est qu'elle ne tient pas compte de l'éventuel déséquilibre entre les classes.</p>
<p>Il se calcule comme ceci:</p>
<p><img src="/images/f1-score.png" alt="image"></p>
<p><strong>Courbe ROC</strong></p>
<p>La <code>courbe ROC</code> (Receiver Operating Characteristic) trace le taux de vrais positifs en fonction du taux de faux positifs.</p>
<p>Le taux de vrais positifs (TVP) est l'équivalent du rappel.</p>
<p>Le taux de faux positifs (TFP) se calcule comme ceci:</p>
<p><img src="/images/taux-faux-positifs-TFP.png" alt="image"></p>
<p><img src="/images/courbe-roc.png" alt="image"></p>
<p>Elle résume le trade-off entre le taux de vrais positifs et le taux de faux négatifs pour un modèle prédictif en utilisant différent seuils de probabilité.</p>
<p>Cette courbe sert également à comparer différents classifieurs. <strong>Plus une courbe a des valeurs élevées, plus l’aire sous la courbe est grande, moins le classifieur fait d’erreur.</strong></p>
<blockquote>
<p>Il existe aussi la Precision-Recall curves.
The latter summarizes the trade-off between the true positive rate and the positive predictive value for a predictive model using different probability thresholds.</p>
</blockquote>
<p><strong>ROC curves are appropriate when the observations are balanced between each class, whereas precision-recall curves are appropriate for imbalanced datasets.</strong> En savoir plus sur cet article: <a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/">https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/</a></p>
<p><strong>AUC</strong></p>
<p>En savoir plus sur l'aire sous la courbe ROC (<code>AUC</code> pour Area Under the Curve ROC) sur le même site qu'au dessus: <a href="https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/">https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/</a></p>
<p>&ldquo;An excellent model has AUC near to the 1 which means it has good measure of separability. A poor model has AUC near to the 0 which means it has worst measure of separability.
And when AUC is 0.5, it means model has no class separation capacity whatsoever. It would be a naive model.&rdquo;</p>
<p>En gros l'AUC correspond à l’intégrale de la fonction ROC.</p>
<p>Voici une vidéo explicative: <a href="https://www.dataschool.io/roc-curves-and-auc-explained/">https://www.dataschool.io/roc-curves-and-auc-explained/</a></p>
<h2 id="conclusion">Conclusion</h2>
<p>Un &ldquo;bon&rdquo; classifieur doit présenter d’une part un rappel élevé et, d’autre part, une précision et une spécificité élevée (et un taux de faux positifs faible).</p>
<p>Scikit Learn fournit un tas de métriques par défaut: <a href="https://scikit-learn.org/stable/modules/model_evaluation.html">https://scikit-learn.org/stable/modules/model_evaluation.html</a></p>
<p>Voici enfin un article intéressant sur les métriques en général pour des sujets de classification, de recommandation et de régression.
<a href="https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/3/evaluation-metrics">https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/3/evaluation-metrics</a></p>
]]></content>
        </item>
        
        <item>
            <title>Tradeoff biais variance</title>
            <link>https://leandeep.com/tradeoff-biais-variance/</link>
            <pubDate>Wed, 01 Mar 2017 13:34:00 +0000</pubDate>
            
            <guid>https://leandeep.com/tradeoff-biais-variance/</guid>
            <description>Introduction Le biais conduit à du sous-apprentissage (underfitting) et la variance amène du sur-apprentissage (overfitting) et donc à de hautes erreurs de tests.
Example pour un jeu de données composé de 8 points:
Polynomials of various degrees. d = 1 under-fits the data, while d = 6 over-fits the data.
On peut éviter cela en:
 ajoutant de la régularisation à notre modèle Si la data est under-fit le modèle est trop simple.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Le biais conduit à du sous-apprentissage (<em>underfitting</em>) et la variance amène du sur-apprentissage (<em>overfitting</em>) et donc à de hautes erreurs de tests.</p>
<p>Example pour un jeu de données composé de 8 points:</p>
<p><img src="/images/plot_bias_variance_examples.png" alt="image"></p>
<p><em>Polynomials of various degrees. d = 1 under-fits the data, while d = 6 over-fits the data.</em></p>
<p>On peut éviter cela en:</p>
<ul>
<li>ajoutant de la régularisation à notre modèle</li>
<li>Si la data est <em>under-fit</em> le modèle est trop simple. On dit qu'il souffre de <em>High-bias</em>. Le modèle est biaisé et cela se traduit par le fait que les data sont <em>poorly fit</em>. On pourrait trouver un autre modèle plus complexe.</li>
<li>Attention au contraire à ne pas avoir un modèle trop complexe qui ferait que les données <em>&ldquo;over-fitterait&rdquo;</em> car il pourrait s'ajuster parfaitement aux données d'entrainement grâce à tous ses degrés de liberté.</li>
<li>Si le modèle over-fit on peut aussi ajouter des données au dataset&hellip;</li>
</ul>
<p><img src="/images/over-under-fitted.png" alt="image"></p>
<blockquote>
<p>Pour déterminer le bon algorithme à utiliser par rapport à notre jeu de données, il faut pouvoir identifier quantitativement le bias et la variance pour pouvoir optimiser les metaparamètres.</p>
</blockquote>
<p><em>C'est faisable grâce au process de <code>cross-validation</code>.</em></p>
<h2 id="dtecter-loverfitting-grce--la-cross-validation">Détecter l'overfitting grâce à la cross-validation</h2>
<p>Pour quantifier les effets du biais et de la variance et construire le meilleur estimateur possible, on va découper notre dataset en 3 parties:</p>
<ul>
<li>training set (60% du dataset)</li>
<li>cross-validation set (20%)</li>
<li>test set (20%)</li>
</ul>
<p>L'idée générale est la suivante:</p>
<ol>
<li>Les paramètres du modèles (dans notre cas, les coefficients du polynôme) sont appris en utilisant le training set.</li>
<li>L'erreur est évaluée sur le cross-validation set et les meta-paramètres  (dans notre cas les degrés du polynôme) sont ajustés pour que l'erreur de cross-validation soit minimisée.</li>
<li>Finalement les labels sont prédits pour le test set. Ces labels sont utilisés pour évaluer la performance de l'algorithme à labeliser des nouvelles données.</li>
</ol>
<blockquote>
<p>Pourquoi a-t-on besoin à la fois d'un cross-validation set et d'un test set ?</p>
</blockquote>
<blockquote>
<p>Certains data scientists utilisent les mêmes set de données pour le cross-validation set et le test set. Ce n'est pas la meilleure approche car les meta-paramètres peuvent &ldquo;<em>over-fittés</em>&rdquo; le cross-validation set tout comme les paramètres peuvent &ldquo;<em>over-fittés</em>&rdquo; le training set.</p>
</blockquote>
<p>L'erreur de cross-validation de notre classifieur polynomial peut être visualisée en affichant l'erreur comme une fonction du polynôme de degré d. (Ici exemple avec 100 points)</p>
<p><img src="/images/plot_bias_variance_examples_cross_validation_error.png" alt="image"></p>
<blockquote>
<p>De manière générale, plus on a données d'entraînement et plus on peut utiliser un modèle complexe. <em><code>The learning curve</code></em>&hellip;</p>
</blockquote>
<h2 id="la-courbe-dapprentissage">La courbe d'apprentissage</h2>
<p>La courbe d'apprentissage est l'affichage des erreurs de training et de cross-validation en fonction du nombre de <em>training points</em>.</p>
<p><img src="/images/plot_bias_variance_examples_learning_curve.png" alt="image"></p>
<p><em>Learning Curves for a case of high bias (left, d = 2) and high variance (right, d = 20)</em></p>
<ul>
<li>
<p>Sur la gauche, le polynôme de degré 1 est un estimateur hautement biaisé qui sous-apprend les données. C'est indiqué par le fait qu'à la fois les erreurs d'entrainement et les erreurs de cross-validation sont élevées.</p>
</li>
<li>
<p>Sur la droite, le polynôme est de degré 20. L'erreur d'entrainement est beaucoup plus faible que l'erreur de cross-validation. Plus on ajoute de données dans le training set et plus l'erreur d'entrainement augmente alors que l'erreur de cross-validation diminue.</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p><strong>Fort biais</strong></p>
<p>Si notre algorithme montre un fort biais, il faut:</p>
<ul>
<li>Ajouter plus de features</li>
<li>Utiliser un modèle plus sophistiqué</li>
<li>Diminuer le training set pour booster la durée d'entrainement. On arrivera à la même erreur plus rapidement; avec moins de données d'entrainement. Par contre, cela ne va pas améliorer la classification.</li>
<li>Diminuer la régularisation: la régularisation est une technique utilisée pour simplifier certains modèles de Machine Learning en ajoutant des termes de pénalité qui dépendent des caractéristiques des paramètres.</li>
</ul>
<p><strong>Forte variance</strong></p>
<ul>
<li>Utiliser moins de features</li>
<li>Augmenter le training set. Ajouter des données dans le training set peut réduire l'effet d'over-fitting et conduire à diminuer la variance de l'estimateur.</li>
<li>Augmenter la régularisation qui est faite justement pour éviter l'over-fitting.</li>
</ul>
<h2 id="code-des-graphs">Code des graphs</h2>
<pre><code>import pylab as pl
from matplotlib import ticker
from matplotlib.patches import FancyArrow

np.random.seed(42)

def test_func(x, err=0.5):
    return np.random.normal(10 - 1. / (x + 0.1), err)


def compute_error(x, y, p):
    yfit = np.polyval(p, x)
    return np.sqrt(np.mean((y - yfit) ** 2))


#------------------------------------------------------------
# Plot linear regression example
np.random.seed(42)
x = np.random.random(20)
y = np.sin(2 * x)
p = np.polyfit(x, y, 1)  # fit a 1st-degree polynomial to the data

xfit = np.linspace(-0.2, 1.2, 10)
yfit = np.polyval(p, xfit)

pl.scatter(x, y, c='k')
pl.plot(xfit, yfit)
pl.xlabel('x')
pl.ylabel('y')
pl.title('Linear Regression Example')

#------------------------------------------------------------
# Plot example of over-fitting and under-fitting

N = 8
np.random.seed(42)
x = 10 ** np.linspace(-2, 0, N)
y = test_func(x)

xfit = np.linspace(-0.2, 1.2, 1000)

titles = ['d = 1 (under-fit)', 'd = 2', 'd = 6 (over-fit)']
degrees = [1, 2, 6]

pl.figure(figsize = (9, 3.5))
for i, d in enumerate(degrees):
    pl.subplot(131 + i, xticks=[], yticks=[])
    pl.scatter(x, y, marker='x', c='k', s=50)

    p = np.polyfit(x, y, d)
    yfit = np.polyval(p, xfit)
    pl.plot(xfit, yfit, '-b')
    
    pl.xlim(-0.2, 1.2)
    pl.ylim(0, 12)
    pl.xlabel('house size')
    if i == 0:
        pl.ylabel('price')

    pl.title(titles[i])

pl.subplots_adjust(left = 0.06, right=0.98,
                   bottom=0.15, top=0.85,
                   wspace=0.05)

#------------------------------------------------------------
# Plot training error and cross-val error
#   as a function of polynomial degree

Ntrain = 100
Ncrossval = 100
error = 1.0

np.random.seed(0)
x = np.random.random(Ntrain + Ncrossval)
y = test_func(x, error)

xtrain = x[:Ntrain]
ytrain = y[:Ntrain]

xcrossval = x[Ntrain:]
ycrossval = y[Ntrain:]

degrees = np.arange(1, 21)
train_err = np.zeros(len(degrees))
crossval_err = np.zeros(len(degrees))

for i, d in enumerate(degrees):
    p = np.polyfit(xtrain, ytrain, d)

    train_err[i] = compute_error(xtrain, ytrain, p)
    crossval_err[i] = compute_error(xcrossval, ycrossval, p)

pl.figure()
pl.title('Error for 100 Training Points')
pl.plot(degrees, crossval_err, lw=2, label = 'cross-validation error')
pl.plot(degrees, train_err, lw=2, label = 'training error')
pl.plot([0, 20], [error, error], '--k', label='intrinsic error')
pl.legend()
pl.xlabel('degree of fit')
pl.ylabel('rms error')

pl.gca().add_patch(FancyArrow(5, 1.35, -3, 0, width = 0.01,
                              head_width=0.04, head_length=1.0,
                              length_includes_head=True))
pl.text(5.3, 1.35, &quot;High Bias&quot;, fontsize=18, va='center')

pl.gca().add_patch(FancyArrow(19, 1.22, 0, -0.1, width = 0.25,
                              head_width=1.0, head_length=0.05,
                              length_includes_head=True))
pl.text(19.8, 1.23, &quot;High Variance&quot;, ha='right', fontsize=18)

#------------------------------------------------------------
# Plot training error and cross-val error
#   as a function of training set size

Ntrain = 100
Ncrossval = 100
error = 1.0

np.random.seed(0)
x = np.random.random(Ntrain + Ncrossval)
y = test_func(x, error)

xtrain = x[:Ntrain]
ytrain = y[:Ntrain]

xcrossval = x[Ntrain:]
ycrossval = y[Ntrain:]

sizes = np.linspace(2, Ntrain, 50).astype(int)
train_err = np.zeros(sizes.shape)
crossval_err = np.zeros(sizes.shape)

pl.figure(figsize=(10, 5))

for j,d in enumerate((1, 20)):
    for i, size in enumerate(sizes):
        p = np.polyfit(xtrain[:size], ytrain[:size], d)
        crossval_err[i] = compute_error(xcrossval, ycrossval, p)
        train_err[i] = compute_error(xtrain[:size], ytrain[:size], p)

    ax = pl.subplot(121 + j)
    pl.plot(sizes, crossval_err, lw=2, label='cross-val error')
    pl.plot(sizes, train_err, lw=2, label='training error')
    pl.plot([0, Ntrain], [error, error], '--k', label='intrinsic error')

    pl.xlabel('traning set size')
    if j == 0:
        pl.ylabel('rms error')
    else:
        ax.yaxis.set_major_formatter(ticker.NullFormatter())
    
    pl.legend(loc = 4)
    
    pl.ylim(0.0, 2.5)
    pl.xlim(0, 99)

    pl.text(98, 2.45, 'd = %i' % d, ha='right', va='top', fontsize='large')

pl.subplots_adjust(wspace = 0.02, left=0.07, right=0.95)
pl.suptitle('Learning Curves', fontsize=18)


pl.show()
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Class iterator en Python</title>
            <link>https://leandeep.com/class-iterator-en-python/</link>
            <pubDate>Thu, 09 Feb 2017 22:01:00 +0000</pubDate>
            
            <guid>https://leandeep.com/class-iterator-en-python/</guid>
            <description>Après les list, dict, set comprehensions, il est possible de créer des class iterator. Il devient alors possible de boucler sur des objets.
 Ce n&#39;est pas pas la seule manière de boucler sur des objets. Il existe aussi les generators et les generator expressions.
 Exemple simple:
class Repeater: def __init__(self, value): self.value = value def __iter__(self): return self def __next__(self): return self.value repeater = Repeater(&#39;Hello&#39;) for item in repeater: print(item) Output:</description>
            <content type="html"><![CDATA[<p>Après les <em>list, dict, set comprehensions</em>, il est possible de créer des <em>class iterator</em>. Il devient alors possible de boucler sur des objets.</p>
<blockquote>
<p>Ce n'est pas pas la seule manière de boucler sur des objets. Il existe aussi les <em>generators</em> et les <em>generator expressions</em>.</p>
</blockquote>
<p><strong>Exemple simple:</strong></p>
<pre><code>class Repeater:
	def __init__(self, value):
		self.value = value
	
    def __iter__(self):
		return self

	def __next__(self):
		return self.value

repeater = Repeater('Hello')
for item in repeater:
	print(item)

</code></pre><p>Output:</p>
<pre><code>...
Hello
Hello
Hello
...

</code></pre><p>Bravo on vient de créer un iterator qui ne finit jamais d'afficher Hello. Ce n'est pas très utile&hellip; On va maintenant écrire une autre <em>class iterator</em> qui aura un nombre fini de répétitions.</p>
<pre><code>class BoundedRepeater:
	def __init__(self, value, max_repeats):
    	self.value = value
        self.max_repeats = max_repeats
        self.count = 0
        
	def __iter__(self):
    	return self
        
	def __next__(self):
    	if self.count &gt;= self.max_repeats:
        	raise StopIteration
		self.count += 1
        return self.value

repeater = BoundedRepeater('Hello', 3)
for item in repeater:
	print(item)
    
</code></pre><p>Output:</p>
<pre><code>Hello
Hello
Hello

</code></pre><p>L'appel de la <em>class iterator</em> BoundedRepeater avec le <em>fency</em> for-loop revient à écrire le code suivant beaucoup moins simple et lisible:</p>
<pre><code>repeater = BoundedRepeater('Hello', 3)
iterator = iter(repeater)
while True:
	try:
    	item = next(iterator)
    except StopIteration:
    	break
    print(item)
    
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Diviser par 5 la durée d’apprentissage de son réseau de neurones profonds</title>
            <link>https://leandeep.com/diviser-par-5-la-dur%C3%A9e-dapprentissage-de-son-r%C3%A9seau-de-neurones-profonds/</link>
            <pubDate>Mon, 06 Feb 2017 23:42:00 +0000</pubDate>
            
            <guid>https://leandeep.com/diviser-par-5-la-dur%C3%A9e-dapprentissage-de-son-r%C3%A9seau-de-neurones-profonds/</guid>
            <description>Avec l’engouement des Chatbots et l’émergence de nouveaux services SAAS, je me suis dit qu’il fallait que je regarde de plus près comment cela fonctionne…
J’ai d’abord testé des solutions Cloud et notamment le nouveau service d’AWS Amazon Lex et il faut avouer que la mise en place est vraiment simple. Ils proposent une intégration sur mobile natif via un SDK et une intégration sur Web avec un simple script JS.</description>
            <content type="html"><![CDATA[<p>Avec l’engouement des Chatbots et l’émergence de nouveaux services SAAS, je me suis dit qu’il fallait que je regarde de plus près comment cela fonctionne…</p>
<p>J’ai d’abord testé des solutions Cloud et notamment le nouveau service d’AWS Amazon Lex et il faut avouer que la mise en place est vraiment simple. Ils proposent une intégration sur mobile natif via un SDK et une intégration sur Web avec un simple script JS. En 1 heure vous pouvez avoir à disposition un Chatbot et exécuter des actions en fonction des intents que vous avez configuré. Le Chatbot peut communiquer avec AWS Lambda.</p>
<p><img src="/images/Diagrams_lex_messaging-platform.png" alt="image"></p>
<p><em>Source: Amazon</em></p>
<p>J’ai également testé le <a href="http://www.ibm.com/watson/developercloud/conversation.html">service conversation de Watson</a> et idem la mise en place est aisée. Il y a projet boilerplate en NodeJS sur Github: <a href="https://github.com/watson-developer-cloud/conversation-simple;">https://github.com/watson-developer-cloud/conversation-simple;</a> ainsi qu’un Chatbot de démo plutôt bien fait: <a href="https://conversation-demo.mybluemix.net/">https://conversation-demo.mybluemix.net/</a></p>
<p>(On m’a aussi parlé des services Wit.ai et API.ai . Je n’ai pas encore testé)</p>
<p>Dans un but pédagogique, j’ai voulu implémenter un Chatbot maison un mon propre réseau neuronal. Je me suis donc inspiré d’un <a href="https://arxiv.org/pdf/1506.05869.pdf">papier</a> écrit par un ingénieur chez Google et créé un modèle Seq2Seq avec un RNN (Recurrent Neural Network).</p>
<p>Dans cet article, je ne vais pas m’entendre sur le RNN ou le modèle Seq2Seq. (Cela pourrait faire l’objet d’un autre article…)</p>
<blockquote>
<p>Ce dont je voulais parler dans cet article c’est comment j’ai divisé par 5 le temps d’apprentissage de mon Recurrent Neural Network !</p>
</blockquote>
<p>C’est tout simplement grâce aux GPU ! Et dans mon cas précis grâce aux GPU d’Amazon Web Services.</p>
<p><img src="/images/aws.png" alt="image"></p>
<p>Jusqu’à présent, lorsque je voulais entraîner mes réseaux de neurones profonds, j’utilisais le CPU de mon Mac Pro. Entraîner un réseau avec un corpus d’environ 220 000 conversations m’a pris environ 3600 minutes soit 2,5 jours. En utilisant le GPU d’une instance AWS, je suis passé à une demi journée et je pense cela peut encore être optimisé. En effet, je n’ai pas loué les machines avec les plus grosses cartes graphiques…</p>
<p>L’autre gros travail que j’ai fait est de complètement Dockeriser mon projet et faire en sorte que le container Docker puisse accéder au GPU du Host.</p>
<p>Pour ce faire, j’ai utilisé la technologie Compute Unified Device Architecture (CUDA) et un projet open source appelé <a href="https://github.com/NVIDIA/nvidia-docker">nvidia-docker</a>.</p>
<p><img src="/images/NVIDIA-CUDA.jpg" alt="image"></p>
<p>Voici un lien intéressants pour comprendre ce qu’est CUDA: <a href="https://fr.wikipedia.org/wiki/Compute_Unified_Device_Architecture">https://fr.wikipedia.org/wiki/Compute_Unified_Device_Architecture</a></p>
<p>Le gros intérêt d’avoir Dockerisé mon projet est que je peux le faire tourner n’importe où. Bien sûr, si je veux bénéficier de performances optimales pour entraîner mon RNN, il me faut un bon GPU et un GPU de la marque Nvidia.</p>
<p>Voici la procédure à suivre pour faire tourner TensorFlow sur des GPUs sur AWS:</p>
<p>Commencez par démarrer une instance sur AWS. Avec les commandes que vous trouverez ci-dessous, je vous conseille de démarrer une Instance Ubuntu 16.04 LTS:</p>
<p><img src="/images/ubuntu.png" alt="image"></p>
<p>Choisissez ensuite une instance de type p2 ou g2:</p>
<p><img src="/images/p2-g2-aws.png" alt="image"></p>
<p><img src="/images/g2-aws.png" alt="image"></p>
<p>Récupérez l’adresse IP publique de votre instance et connectez vous en SSH</p>
<pre><code>ssh -i ~/.ssh/&lt;votre-fichier-pem&gt; ubuntu@&lt;addresse-ip&gt;
</code></pre><p>Installer le dernier Driver Nvidia</p>
<pre><code>$ apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub
$ sh -c 'echo &quot;deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64 /&quot; &amp;&amp; /etc/apt/sources.list.d/cuda.list'
$ apt-get update 
$ apt-get install -y --no-install-recommends cuda-drivers
</code></pre><p>Installer la dernière version de Docker (tutorial réalisé avec Docker 1.13)</p>
<pre><code>$ apt-get update
$ curl -fsSL https://get.docker.com/ | sh
$ curl -fsSL https://get.docker.com/gpg | sudo apt-key add -
</code></pre><p>Installer Nvidia Docker</p>
<pre><code>$ wget https://github.com/NVIDIA/nvidia-docker/releases/download/v1.0.0/nvidia-docker_1.0.0-1_amd64.deb
$ dpkg -i nvidia-docker_1.0.0-1_amd64.deb
$ rm nvidia-docker_1.0.0-1_amd64.deb
</code></pre><p>Téléchargez l’image Docker TensorFlow GPU</p>
<pre><code>$ docker pull tensorflow/tensorflow:latest-gpu
</code></pre><p>Démarrez ensuite un container Docker depuis l’image téléchargée. Je vous conseille d’exposer les ports 6006 et 8888 pour tensorboard et Jupyter Notebook.</p>
<pre><code>$ nvidia-docker run -itd --name=gpu-tensorflow -p 8888:8888 -p 6006:6006 tensorflow/tensorflow:latest-gpu
</code></pre><p>Vous pouvez à présent vous connecter en SSH dans le container Docker et utiliser TensorFlow. Python 3 devrait être installé.</p>
<pre><code>$ sudo nvidia-docker exec -it gpu-tensorflow bash
</code></pre><p>La commande suivante vous permettra de vérifier qu’il y a bien une carte GPU accessible:</p>
<pre><code>$ nvidia-smi
</code></pre><p>Par exemple avec une instance g2.2xlarge (1 Nvidia K520 GPU), vous devriez voir ceci:</p>
<p><img src="/images/nvidia-smi.png" alt="image"></p>
<p>Il ne vous reste plus qu’à cloner votre projet TensorFlow et à l’exécuter.</p>
<p>Si vous ne l’avez pas configuré autrement, vous devriez voir que TensorFlow utilise bien le GPU.</p>
<p><img src="/images/tensorflow-gpu.png" alt="image"></p>
<p>Lorsque vous avez terminé, n’oubliez pas d’éteindre votre instance AWS; surtout si vous choisissez une instance p2. Attention à la facture !</p>
<p>C’est d’ailleurs un point d’amélioration que j’aimerais apporter à ce projet. J’aimerais automatiser la création d’instance AWS via un bot ou un script, que TensorFlow entraîne automatiquement le modèle pendant plusieurs heures et que la VM soit automatiquement <em>terminated</em> lorsque l’apprentissage est achevé. J’aimerais évidemment que le modèle généré par TensorFlow soit sauvegardé dans un Bucket S3.</p>
<p>Pour info, voici les commandes à utiliser pour désinstaller complètement Docker sur Ubuntu. J’ai rencontré des difficultés avec des versions de Docker non compatibles avec nvidia-docker. Ces commandes pourraient aider:</p>
<pre><code>$ apt-get purge docker-engine
$ apt-get autoremove --purge docker-engine
$ rm -rf /var/lib/docker
</code></pre>]]></content>
        </item>
        
        <item>
            <title>List, set et dict comprehensions en Python </title>
            <link>https://leandeep.com/list-set-et-dict-comprehensions-en-python/</link>
            <pubDate>Sun, 05 Feb 2017 21:12:00 +0000</pubDate>
            
            <guid>https://leandeep.com/list-set-et-dict-comprehensions-en-python/</guid>
            <description>Voici quelques exemples de list et dict comprehensions en Python.
Le pattern des &amp;ldquo;X comprehensions&amp;rdquo; est le suivant: values = [expression for item in collection]
Il est possible d&#39;ajouter un filtre sur les éléments de l&#39;itération avant qu&#39;ils soient utilisés dans l&#39;évaluation de l&#39;expression: values = [expression for item in collection if condition]
Listes # Python provides compact syntax for deriving one list from another. These # expressions are called list comprehensions.</description>
            <content type="html"><![CDATA[<p>Voici quelques exemples de <em>list et dict comprehensions</em> en Python.</p>
<p>Le pattern des &ldquo;X comprehensions&rdquo; est le suivant: <code>values = [expression for item in collection]</code></p>
<p>Il est possible d'ajouter un filtre sur les éléments de l'itération avant qu'ils soient utilisés dans l'évaluation de l'expression: <code>values = [expression for item in collection if condition]</code></p>
<h2 id="listes">Listes</h2>
<pre><code># Python provides compact syntax for deriving one list from another. These
# expressions are called list comprehensions. For example, say you want to
# compute the square of each number in a list. You can do this by providing
# the expression for your computation and the input sequence to loop over.


a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
squares = [x*x for x in a]
print(squares)
# [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
</code></pre><pre><code># Unless you're applying a single-argument functions, list comprehensions are
# clearer than map built-in function cases, map requires creating a lambda
# function for the computation, which is visually noisy.


squares = map(lambda x: x*x, a)
print(squares)
# Python 2
# [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
# Python 3
print(list(squares))
# [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]
</code></pre><pre><code># Unlike may, list comprehensions let you easily filter items from the input
# list, removing corresponding outputs from the result. For example, say you
# only want to compute the squares of the numbers that are divisible by 2.
# Here, I do this by adding a conditional expression to the list
# comprehension after the loop:


even_squares = [x*x for x in a if x % 2 == 0]
print(even_squares)
# [4, 16, 36, 64, 100]
</code></pre><pre><code># The filter built-in function can be used along with map to achieve the same
# outcome, but it is much harder to read.


alt = map(lambda x: x*x, filter(lambda x: x % 2 == 0, a))
assert even_squares == list(alt)
</code></pre><h2 id="sets">Sets</h2>
<blockquote>
<p>Attention, l'ordre des éléments n'est pas gardé.</p>
</blockquote>
<p><strong>Exemple simple:</strong></p>
<pre><code>&gt;&gt;&gt; {x * x for x in range(-9, 10) }
set([61, 1, 36, 0, 49, 9, 16, 81, 25, 4])
</code></pre><h2 id="dictionnaires">Dictionnaires</h2>
<p><strong>Exemple simple:</strong></p>
<pre><code>&gt;&gt;&gt; { x: x * x for x in range(5) }
{0: 0, 1: 1, 2: 4, 3: 9, 4: 16} 
</code></pre><pre><code># Dictionaries and sets have their own equivalents of list comprehensions.
# These make it easy to create derivative data structures when writing
# algorithms.

chile_ranks = {'ghost': 1, 'habanero': 2, 'cayenne': 3}

rank_dict = {rank: name for name, rank in chile_ranks.items()}

print(rank_dict)
# {1: 'ghost', 2: 'habanero', 3: 'cayenne'}

chile_len_set = {len(name) for name in rank_dict.values()}

print(chile_len_set)
# {8, 5, 7}
</code></pre><h2 id="listes--2-niveaux">Listes à 2 niveaux</h2>
<p>Il est possible d'avoir des <em>lists comprehensions</em> avec 2 expressions. Il est possible d'aller au-delà mais ce n'est pas recommandé pour la lisibilité.</p>
<pre><code>matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
flat = [x for array in matrix for x in array]
print(flat)

# [1, 2, 3, 4, 5, 6, 7, 8, 9]
</code></pre><pre><code># The example above is simple, readable, and a reasonable usage of multiple
# loops. Another reasonable usage of multiple loops is replicating the
# two-level deep layout of the input list. For example, say you want to square
# the value in each cell of a two-dimensional matrix. This expression is
# noisier because of the extra [] characters, but it's still easy to read.

matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
data = [[x*x for x in row] for row in matrix]
print(data)
# [[1, 4, 9], [16, 25, 36], [49, 64, 81]]
</code></pre><pre><code># If this expression included another loop, the list comprehension would get
# so long that you'd have to split it over multiple lines.

my_lists = [
    [[1, 2, 3], [4, 5, 6]],
    # ...
    [[11, 22, 33], [44, 55, 66]]
]
flat = [x for sublist1 in my_lists
        for sublist2 in sublist1
        for x in sublist2]
print(flat)
# [1, 2, 3, 4, 5, 6, 11, 22, 33, 44, 55, 66]
</code></pre><pre><code># At this point, the multiline comprehension isn't much shorter thant the
# alternative. Here, I produce the same using normal loop statements. The
# indentation of this version makes the looping clearer than the list
# comprehension.


flat = []
for sublist1 in my_lists:
    for sublist2 in sublist1:
        flat.extend(sublist2)
print(flat)
# [1, 2, 3, 4, 5, 6, 11, 22, 33, 44, 55, 66]
</code></pre><pre><code># List comprehensions also support multiple if conditions. Multiple
# conditions at the same loop level are an implicit and expression. For
# example, say you want to filter a list of numbers to only even values
# greater than four. These only list comprehensions are equivalent.


a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
b = [x for x in a if x &gt; 4 if x % 2 == 0]
c = [x for x in a if x &gt; 4 and x % 2 == 0]
print(b)
print(c)
# [6, 8, 10]
# [6, 8, 10]
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Slicing dans tous les sens en Python</title>
            <link>https://leandeep.com/slicing-dans-tous-les-sens-en-python/</link>
            <pubDate>Sat, 04 Feb 2017 21:16:00 +0000</pubDate>
            
            <guid>https://leandeep.com/slicing-dans-tous-les-sens-en-python/</guid>
            <description>Voici quelques exemples d&#39;utilisation de slicing en Python. Cela fonctionne très bien sur les list, str et bytes. On peut ajouter du slicing sur des classes qui implémentent __getitem__ et __setitem__ magic methods.
a = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;] print(&#39;First four: &#39;, a[:4]) print(&#39;Last four: &#39;, a[-4:]) print(&#39;Middle two: &#39;, a[3:-3]) # First four: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] # Last four: [&#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;] # Middle two: [&#39;d&#39;, &#39;e&#39;] # When slicing from the start of a list, you should leave out the zero index # to reduce visual noise.</description>
            <content type="html"><![CDATA[<p>Voici quelques exemples d'utilisation de <em>slicing</em> en Python.
Cela fonctionne très bien sur les <code>list</code>, <code>str</code> et <code>bytes</code>.
On peut ajouter du <em>slicing</em> sur des classes qui implémentent <code>__getitem__</code> et <code>__setitem__</code> <em>magic methods</em>.</p>
<pre><code>a = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
print('First four: ', a[:4])
print('Last four:  ', a[-4:])
print('Middle two: ', a[3:-3])
# First four:  ['a', 'b', 'c', 'd']
# Last four:   ['e', 'f', 'g', 'h']
# Middle two:  ['d', 'e']
</code></pre><pre><code># When slicing from the start of a list, you should leave out the zero index
# to reduce visual noise.


assert a[:5] == a[0:5]


# When slicing to the end of a list, you should leave out the final index
# because it's redundant.


assert a[5:] == a[5:len(a)]
</code></pre><pre><code># Using negative numbers for slicing is helpful for doing offsets relative
# to the end of a list. All of these forms of slicing would be clear to a new
# reader of your code. There are no surprises, and I encourage you to use
# these variations.


print(a[:])
print(a[:5])
print(a[:-1])
print(a[4:])
print(a[-3:])
print(a[2:5])
print(a[2:-1])
print(a[-3:-1])
# ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
# ['a', 'b', 'c', 'd', 'e']
# ['a', 'b', 'c', 'd', 'e', 'f', 'g']
# ['e', 'f', 'g', 'h']
# ['f', 'g', 'h']
# ['c', 'd', 'e']
# ['c', 'd', 'e', 'f', 'g']
# ['f', 'g']
</code></pre><pre><code># Slicing deals properly with start and end indexes that are beyond the
# boundaries of the list. That makes it easy for your code to establish
# a maximum length to consider for an input sequence.


first_twenty_items = a[:20]
last_twenty_items = a[-20:]
print(first_twenty_items)
print(last_twenty_items)
# ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
# ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']

# In contrast, accessing the same index directly causes an exception.
# print(a[20])
# IndexError: list index out of range


# Note
# Beware that indexing a list by a negative variable is one of the few
# situations in which you can get surprising results from slicing. For
# example, the expression somelist[-n:] will work fine when n is greater
# than one (e.g. somelist[-3:]). However, when n is zero, the expression
# somelist[-0:] will result in a copy of the original list.
</code></pre><pre><code># The result of slicing a list is a whole new list. References to the objects
# from the original list are maintained. Modifying the result of slicing won't
# affect the original list.

b = a[4:]
print('Before:    ', b)
b[1] = 99
print('After:     ', b)
print('No change: ', a)
# Before:     ['e', 'f', 'g', 'h']
# After:      ['e', 99, 'g', 'h']
# No change:  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
</code></pre><pre><code># When used in assignments, slices will replace the specified range in the
# original list. Unlike tuple assignments (like a, b = c[:2), the length of
# slice assignments don't need to be the same. The values before and after
# the assigned slice will be preserved. The list will grow or shrink to
# accommodate the new values.

print('Before: ', a)
a[2:7] = [99, 22, 14]
print('After:  ', a)
# Before:  ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
# After:   ['a', 'b', 99, 22, 14, 'h']
</code></pre><pre><code># If you leave out both the start and the end indexes when slicing, you'll end
# up with a copy of the original list.

b = a[:]
assert b == a and b is not a
</code></pre><pre><code># if you assign a slice with no start or end indexes, you'll replace its
# entire contents with a copy of what's referenced (instead of allocating a
# new list).


b = a
print('Before: ', a)
a[:] = [101, 102, 103]
assert a is b
print('After:  ', a)
# Before:  ['a', 'b', 99, 22, 14, 'h']
# After:   [101, 102, 103]
</code></pre><pre><code># In addition to basic slicing (see Item 5: Knowing how to slice sequences),
# Python has special syntax for the stride of a slice in the form
# somelist[start🔚stride]. This lets you take every n-th item when slicing
# a sequence. For example, the stride makes it easy to group by even and odd
# indexes in a list.

a = ['red', 'orange', 'yellow', 'green', 'blue', 'purple']
odds = a[::2]
evens = a[1::2]
print(odds)
print(evens)
# ['red', 'yellow', 'blue']
# ['orange', 'green', 'purple']
</code></pre><pre><code># The problem is that the stride syntax ofter cause unexpected behavior that
# can introduce bugs. For example, a common Python trick for reversing a byte
# string is to slice the string with a stride of -1.


x = b'mongoose'
y = x[::-1]
print(y)
# b'esoognom'
</code></pre><pre><code># That works well for byte strings and ASCII characters, but it will break for
# Unicode characters encoded as UTF-8 byte strings.


w = '谢谢谢谢'
# x = w.enocde('utf-8')
# y = x[::-1]
# z = y.decode('utf-8')
# print(y)
# print(z)
# AttributeError: 'str' object has no attribute 'enocde'
</code></pre><pre><code># Are negative strides besides -1 useful? Consider the following examples.


a = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']
print(a[::2])
print(a[::-2])
# ['a', 'c', 'e', 'g']
# ['h', 'f', 'd', 'b']
</code></pre><pre><code># Here, ::2 means select every second item starting at the beginning.
# Trickier, ::-2 means select every second item starting at the end and moving
# backwards.


# What do you think 2::2 means? What about -2::-2 vs. -2:2:-2 vs. 2:2:-2?
print(a[2::2])
print(a[-2::-2])
print(a[-2:2:-2])
print(a[2:2:-2])
# ['c', 'e', 'g']
# ['g', 'e', 'c', 'a']
# ['g', 'e']
# []


# The point is that the stride part of the slicing syntax can be extremely
# confusing. Having three numbers within the brackets is hard enough to read
# because of its density. Then it's not obvious when the start and end indexes
# come into effect relative to the stride value, especially when stride is
# negative.


# To prevent problems, avoid using stride along with start and end indexes. If
# you must use a stride, prefer making it a positive value and omit start and
# end indexes. If you must use stride with start and end indexes, consider
# using one assignment to stride and another to slice.


b = a[::2]
c = b[1:-1]
print(b)
print(c)
# ['a', 'c', 'e', 'g']
# ['c', 'e']
</code></pre><pre><code># Slicing and then striding will create an extra shallow copy of the data.
# The first operation should try to reduce the size of the resulting slice by
# as much as possible. If your program can't afford the time or memory
# required for two steps, consider using the itertools built-in module's
# islice method (see Item 46: Use built-in algorithms and data structures),
# which doesn't permit negative values for start, end or stride.
</code></pre><pre><code># Things to remember

# 1. Avoid being verbose: Don't supply 0 for the start index or the length of
#     the sequence for the end index.
# 2. Slicing is forgiving of start or end indexes that are out of bounds,
#     making it easy to express slices on the front or back boundaries of a
#     sequence (like a[:20] or a[-20:]).
# 3. Assigning to a list slice will replace that range in the original
#     sequence with what's referenced even if their lengths are different.
# 4. Specifying start, end, and stride in a slice can be extremely confusing.
# 5. Prefer using positive stride values in slices without start or end
#     indexes. Avoid negative stride values if possible.
# 6. Avoid using start, end and stride together in a single slice. If you need
#     all three parameters, consider doing two assignments (one to slice,
#     another to stride) or using islice form itertools built-in module.
</code></pre><p>Source: Livre &ldquo;Effective Python: 59 Specific Ways to Write Better Python&rdquo; par Brett Slatkin. Je vous recommande grandement de l'acheter et de le lire.</p>
]]></content>
        </item>
        
        <item>
            <title>Style guide PEP8 en Python</title>
            <link>https://leandeep.com/style-guide-pep8-en-python/</link>
            <pubDate>Wed, 01 Feb 2017 21:54:00 +0000</pubDate>
            
            <guid>https://leandeep.com/style-guide-pep8-en-python/</guid>
            <description>Je recommande de suivre le style guide PEP 8 pour coder en Python.
# Whitespace: In Python, whitespace is syntactically significant. Python # programmers are especially sensitive to the effects of whitespace on # code clarity. # 1. Use spaces instead of tabs for indentation. # 2. Use four spaces for each level of syntactically significant indenting. # 3. Lines should be 79 characters in length or less. # 4. Continuations of long expressions onto additional lines should be # indented by four extra spaces from their normal indentation level.</description>
            <content type="html"><![CDATA[<p>Je recommande de suivre le style guide PEP 8 pour coder en Python.</p>
<pre><code># Whitespace: In Python, whitespace is syntactically significant. Python
# programmers are especially sensitive to the effects of whitespace on
# code clarity.

# 1. Use spaces instead of tabs for indentation.
# 2. Use four spaces for each level of syntactically significant indenting.
# 3. Lines should be 79 characters in length or less.
# 4. Continuations of long expressions onto additional lines should be
#     indented by four extra spaces from their normal indentation level.
# 5. In a file, functions and classes should be separated by two blank lines.
# 6. In a class, methods should be separated by one blank line.
# 7. Don't put spaces around list indexes, function calls, or keyword
#     argument assignments.
# 8. Put one-and only one-space before and after variable assignments.
</code></pre><pre><code># Naming: PEP 8 suggests unique styles of naming for different part in the
# language.

# 1. Functions, variables, and attributs should be in lovercase_underscore
#     format.
# 2. Protected instance attributes should be in _leading_underscore format.
# 3. Private instance attributes should be in __double_leading_underscore
#     format.
# 4. Classes and exceptions should be in CapitalizedWord format.
# 5. Module-level constants should be in ALL_CAPS format.
# 6. Instance methods in classes should use self as the name of the first
#     parameter (which refers to the object).
# 7. Class methods should use cls as the name of the first parameter (which
# refers to the class).
</code></pre><pre><code># Expressions and Statements: The Zen of Python states: &quot;There should be one-
# and preferably only one-obvious way to do it.&quot;

# 1. Use inline negation (if a is not b) instead of negative of positive
#     expressions (if not a is b)
# 2. Don't check for empty value (like [] or '') by checking the length
#     (if len(somelist) == 0). Use if not somelist and assume empty values
#     implicitly evaluate to False.
# 3. The same thing goes for non-empty values (like [1] or 'hi'). The statement
#     if somelist is implicitly True for non-empty values.
# 4. Avoid single-line if statements, for and while loops, and except compound
#     statements. Spread these over multiple lines for clarity.
# 5. Always put import statements as the top of a file.
# 6. Always use absolute names for modules when importing them, not names
#     relative to the current module's own path. For example, to import the foo
#     module for the bar package, you should do from bar import foo, not just
#     import foo.
# 7. If you must do relative imports, use the explicit syntax from . import foo.
# 8. Imports should be in sections in the following order: standard library
#     modules, third-party modules, your own modules. Each subsection should
#     have imports in alphabetical order.
</code></pre><p>&hellip; Ceci n'est qu'un aperçu.</p>
<p>Avec de bons outils comme flake8, il est facile de linter son code pour faire en sorte qu'il respecte certains style guides. Le slogan de Flake8 est parlant: &ldquo;Your Tool For Style Guide Enforcement&rdquo;.</p>
<blockquote>
<p>Attention à ceci:
&ldquo;It is very important to install Flake8 on the correct version of Python for your needs. If you want Flake8 to properly parse new language features in Python 3.5 (for example), you need it to be installed on 3.5 for Flake8 to understand those features. In many ways, Flake8 is tied to the version of Python on which it runs.&rdquo; Source <a href="http://flake8.pycqa.org">http://flake8.pycqa.org</a></p>
</blockquote>
<p>Flake8 c'est un outil qui vérifie grâce à pyflakes la conformité du code Python avec pep8 et la <em>circular complexity</em>.</p>
<p>Pour utiliser flake8 avec VScode, il suffit de créer un fichier <code>.flake8</code> à la racine de votre projet et de coller le contenu suivant:</p>
<pre><code>[flake8]
filename = *.py,*.pyx,*.pxd,*.pxi
ignore = E402,E731,D100,D101,D102,D103,D104,D105,W503,W504,E252
exclude = .git,__pycache__,build,dist,.eggs,postgres,vendor

per-file-ignores = *.pyx,*.pxd,*.pxi: E211, E222, E225, E226, E227, E999

max-line-length = 160
</code></pre><p>Comme vous pouvez le remarquer il est possible d'ignorer certaines rêgles.</p>
<p>Il faut aussi créer un fichier <code>.vscode/settings.json</code> pour dire à VScode d'utiliser flake8 comme linter.</p>
<p>Voici un exemple de fichier settings.</p>
<pre><code>{
    &quot;python.pythonPath&quot;: &quot;.venv/bin/python3.5&quot;,
    &quot;python.linting.pylintEnabled&quot;: false,
    &quot;python.linting.flake8Enabled&quot;: true,
    &quot;python.linting.enabled&quot;: true
}
</code></pre>]]></content>
        </item>
        
        <item>
            <title>« Ok google… Ouvre le portail » !</title>
            <link>https://leandeep.com/ok-google-ouvre-le-portail/</link>
            <pubDate>Sun, 08 Jan 2017 20:28:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ok-google-ouvre-le-portail/</guid>
            <description>&lt;p&gt;Pour bien commencer l’année et ce blog avec ce premier article, voici comment j’ai transformé mon portail en un portail connecté.&lt;/p&gt;
&lt;p&gt;Lorsque je prononce les mots « Ok Google… Ouvre le portail » sur mon Smartphone, ce dernier déclenche une commande qui actionne le moteur du portail. Je peux ainsi en fonction des messages que j’ai programmé, ouvrir ou fermer le portail de n’importe où.&lt;/p&gt;
&lt;h2 id=&#34;description-du-fonctionnement&#34;&gt;Description du fonctionnement&lt;/h2&gt;
&lt;p&gt;Voici un schéma qui décrit globalement le fonctionnement du système.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://leandeep.com/images/article-ok-google-portail.png&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>Pour bien commencer l’année et ce blog avec ce premier article, voici comment j’ai transformé mon portail en un portail connecté.</p>
<p>Lorsque je prononce les mots « Ok Google… Ouvre le portail » sur mon Smartphone, ce dernier déclenche une commande qui actionne le moteur du portail. Je peux ainsi en fonction des messages que j’ai programmé, ouvrir ou fermer le portail de n’importe où.</p>
<h2 id="description-du-fonctionnement">Description du fonctionnement</h2>
<p>Voici un schéma qui décrit globalement le fonctionnement du système.</p>
<p><img src="/images/article-ok-google-portail.png" alt="image"></p>
<p>Comme l’indique le schéma ci-dessus, j’ai le choix entre 2 options pour actionner mon portail. Je peux le faire avec les commandes par défaut qui sont les télécommandes ou le visiophone. Et je peux le faire grâce à des commandes vocales.</p>
<p>Mon portail possède un actionneur de marque BFT (Ultra BT A 400). Ce dernier est fourni avec un moteur et sa carte électronique de commande qui me permettent d’ouvrir ou fermer le portail. Je me suis branché directement sur cette carte électronique et je la pilote grâce à un relais et un Raspberry Pi. Si on regarde le schéma de la carte électronique de commande du moteur ci-dessous, on peut voir qu’il y a deux inputs <code>IC1</code> et <code>IC2</code>.</p>
<p><img src="/images/moteur-1.png" alt="image"></p>
<p><code>IC1</code> permet d’ouvrir ou fermer le portail en grand et <code>IC2</code> permet de le faire en mode piéton.</p>
<p>Pour piloter le portail, il faut donc tirer 2 fils entre cette carte de commande et le relais et ensuite piloter le relais avec un Raspberry Pi. Le schéma du câblage est présent dans le paragraphe suivant.</p>
<h2 id="hardware">Hardware</h2>
<p>Voici le matériel que j’ai utilisé:</p>
<ul>
<li>Raspberry Pi 2</li>
<li>Dongle Wifi Netgear</li>
<li>Alimentation 220V</li>
<li>Relay 5V</li>
<li>Quelques fils électriques</li>
<li>Une boite de dérivation</li>
</ul>
<p>Finalement il y a assez peu de matériel. La boite de dérivation, n’est pas indispensable mais elle permet de cacher les cables et cartes et ainsi d’avoir quelque chose de propre. En gros, une fois terminé, il n’y a pas des fils qui pendent à côté du tableau électrique. Voici à quoi cela ressemble chez moi:</p>
<p><img src="/images/DSC_0051.jpg" alt="image"></p>
<p>Voici comment j’ai câblé mon relais et Raspberry Pi avec la commande IC1:</p>
<p><img src="/images/schema-pi-relay.jpeg" alt="image"></p>
<h2 id="software">Software</h2>
<p>Pour piloter le GPIO du Raspberry Pi, j’utilise un script que j’ai réalisé en Python. En exécutant le script, la PIN 17 du GPIO prend alternativement la valeur 0 ou 5V. A chaque fois que le relais reçoit une impulsion de 5V, il change d’état; ce qui crée une impulsion sur IC1.</p>
<p>J’ai également créé une API NodeJS qui me permet d’exposer l’exécution de mon script Python, de sécuriser le tout et de créer une interface WEB de contrôle du portail (je ne la présente pas dans cet article).</p>
<p>Tout est donc exécuté directement sur le Raspberry Pi qui est accessible sur internet via ma box internet.</p>
<h2 id="prparation-environnement">Préparation environnement</h2>
<h3 id="installation-de-nodejs">Installation de NodeJS</h3>
<pre><code>wget -qO- https://raw.githubusercontent.com/creationix/nvm/v0.33.0/install.sh | bash
</code></pre><p>Ajouter les 2 commandes suivantes dans votre ~/.bashrc pour activer NVM.</p>
<pre><code>export NVM_DIR=&quot;$HOME/.nvm&quot; 
[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; . &quot;$NVM_DIR/nvm.sh&quot; # This loads nvm
</code></pre><p>Vous pouvez maintenant utiliser NVM et utiliser la version de NodeJS que vous souhaitez.
Exécutez simplement la commande suivante:</p>
<pre><code>nvm use 6.9.1 # sélectionnez la version de NodeJS que vous voulez
</code></pre><h3 id="installation-de-python">Installation de Python</h3>
<pre><code>apt-get update
apt-get install gcc
apt-get install python-dev
apt-get install python-pip
pip install RPi.GPIO
</code></pre><h2 id="api-nodejs">API NodeJS</h2>
<p>Voici un extrait de code. C’est le endpoint ExpressJS qui exécute mon script Python via un fork unix.</p>
<pre><code>router.get('/portail/toggle', (req, res) =&gt; {
  var exec = require('child_process').exec;
  var cmd = 'python /home/pi/relay.py 2';
 
  exec(cmd, function(error, stdout, stderr) {
    if(error)
      return next(error);
    res.send({msg: 'Yeah it works!'});
  });
});
</code></pre><h3 id="script-python">Script Python</h3>
<pre><code>#!/usr/bin/python
 
import sys
import time
import RPi.GPIO as GPIO
GPIO.setwarnings(False)
GPIO.setmode(GPIO.BCM)
 
args = sys.argv
pin = 17 # GPIO PIN 17
GPIO.setup(pin, GPIO.OUT)
ctl = args[1]
 
# [...] Reste du code ici. En effet, mon Raspberry ne me sert pas qu'à piloter le portail.
 
if (int(ctl) == 2):
  GPIO.output(pin,GPIO.HIGH)
  time.sleep(2)
  GPIO.output(pin, GPIO.LOW)
</code></pre><h3 id="automatisation-sur-android-via-tasker">Automatisation sur Android via Tasker</h3>
<p>Voyons maintenant comment j’ai fait pour que mon téléphone comprenne ce que je lui dis et comment il communique avec  l’API NodeJS pour ouvrir ou fermer mon portail.</p>
<p>Pour avancer de façon Lean sur ce projet, j’ai commencé par quelque chose de simple. Je vous parlerais de la finalité de ce que je veux faire avec ce projet en conclusion de cet article.</p>
<p>J’ai utilisé les fonctionnalités de reconnaissance vocale de Google Now sans rien développer.</p>
<p>Pour ce faire, j’ai utilisé l’application d’automatisation de tâches appelée Tasker ainsi que son plugin AutoVoice.</p>
<p>Pour que mon téléphone envoie une requête à mon API Node pour ouvrir le portail quand je prononce la phrase: « Sésame ouvre-toi », il suffit de définir une tâche qui permet d’envoyer une requête vers une URL et définir des profils. Un exemple de profil peut être: si Google Now reconnait une phrase en particulier comme par exemple « Sésame ouvre-toi » alors j’exécute une tâche.</p>
<p>Beaucoup de tutoriaux sont disponibles sur internet. En voici un par exemple: <a href="http://lifehacker.com/how-to-create-custom-voice-commands-with-tasker-and-aut-1282209195">http://lifehacker.com/how-to-create-custom-voice-commands-with-tasker-and-aut-1282209195</a></p>
<h3 id="tests-et-industrialisation">Tests et industrialisation</h3>
<p>J’ai eu beaucoup de chance car je n’ai rencontré absolument aucun obstacle et avais tout ce qu’il me fallait sous la main. Après quelques tests tout a très vite fonctionné.</p>
<p>Ma dernière tâche, avant de ranger tous les câbles proprement dans le tableau électrique, a consisté à créer un script de démarrage et à installer un process manager pour NodeJS (PM2).</p>
<p>J’ai donc créé un script nodeStartupHomeAutomation dans /etc/init.d/ et installé les 2 librairies suivantes sur le Raspberry Pi.</p>
<pre><code>apt-get install psmisc
npm install -g pm2
</code></pre><p>Voici à quoi peut ressembler le script de démarrage:</p>
<pre><code>#! /bin/sh
# /etc/init.d/nodeStartupHomeAutomation
 
# If you want a command to always run, put it here
 
# Carry out specific functions when asked to by the system
case &quot;$1&quot; in
start)
echo &quot;Starting Node Server&quot;
 
export NVM_DIR=&quot;/home/pi/.nvm&quot;
[ -s &quot;$NVM_DIR/nvm.sh&quot; ] &amp;&amp; . &quot;$NVM_DIR/nvm.sh&quot; # This loads nvm
 
# run application you want to start
cd /home/pi/home-automation/
pm2 start app.js --name=&quot;homeAuto&quot;
# node app.js &amp;
;;
stop)
echo &quot;Stopping Node Server&quot;
 
# kill application you want to stop
pm2 stop homeAuto
# killall node
;;
*)
echo &quot;Usage: /etc/init.d/nodeStartupHomeAutomation {start|stop}&quot;
exit 1
;;
esac
 
exit 0
</code></pre><p>Pour vérifier que le service démarre convenablement, qu’il se stoppe bien et pour l’enregistrer aux services de démarrage, vous pouvez utiliser les commandes suivantes:</p>
<pre><code>chmod 755 /etc/init.d/nodeStartupHomeAutomation
 
# Test du démarrage du script
/etc/init.d/nodeStartupHomeAutomation start
 
# Test de l'arrêt du script
/etc/init.d/nodeStartupHomeAutomation stop 
 
#Enregistrement du script pour être lancé au démarrage de la machine une fois qu'il est ok 
update-rc.d nodeStartupHomeAutomation defaults 
</code></pre><h2 id="conclusion">Conclusion</h2>
<p>Voilà c’est à peu près tout pour cet article. Il n’en faut pas beaucoup plus pour piloter un portail avec des commandes vocales sur un Smartphone.</p>
<p>Pour ce projet, je ne veux pas en rester là. Je vais passer le tout sur Docker si bien sûr je peux accéder au GPIO depuis un container.</p>
<p>De plus aujourd’hui je dépends d’internet. Si je n’ai plus internet sur mon Smartphone, aucune commande ne peut être envoyée vers mon Raspberry Pi.</p>
<p>Pour palier à ce problème et faire du Deep Learning sur un cas concret, je vais mettre en place une caméra à l’extérieure de chez moi qui va filmer en permanence ce qui vient vers le portail. Si ma voiture est reconnue, alors je vais ouvrir le portail et allumer les lumières de chez moi. Pour ce faire, je vais utiliser TensorFlow et un réseau de neurones profond. Cela fera l’objet d’un autre article.</p>
<p>Si le temps me le permet et purement à des fins d’apprentissage, j’essayerai de mettre en place manuellement de la reconnaissance vocale et remplacer Google Now.</p>]]></content>
        </item>
        
        <item>
            <title>Obtenir les sous-titres d&#39;un film en 2 secondes</title>
            <link>https://leandeep.com/obtenir-les-sous-titres-dun-film-en-2-secondes/</link>
            <pubDate>Fri, 30 Dec 2016 21:26:00 +0000</pubDate>
            
            <guid>https://leandeep.com/obtenir-les-sous-titres-dun-film-en-2-secondes/</guid>
            <description>Aujourd&#39;hui nous allons voir une petite astuce plutôt utile si vous aimez regarder des films ou séries en VO et avoir à disposition les sous-titres (en français ou anglais). J&#39;ai trouvé un projet opensource permettant de télécharger automatiquement les sous-titres. https://github.com/Diaoul/subliminal
Si vous avez Docker, exécutez la commande suivante:
docker run --rm --name subliminal -v /Users/olivier/Movies/Series/subliminal_cache:/usr/src/cache -v /Users/olivier/Movies/Series:/Users/olivier/Movies/Series -it diaoulael/subliminal download -l en /Users/olivier/Movies/Series/votre_serie_ou_film.mkv Si vous voulez automatiser davantage, ce repository vous donne un snippet permettant de scanner le contenu d&#39;un dossier et télécharger des sous-titres.</description>
            <content type="html"><![CDATA[<p>Aujourd'hui nous allons voir une petite astuce plutôt utile si vous aimez regarder des films ou séries en VO et avoir à disposition les sous-titres (en français ou anglais).
J'ai trouvé un projet opensource permettant de télécharger automatiquement les sous-titres. <a href="https://github.com/Diaoul/subliminal">https://github.com/Diaoul/subliminal</a></p>
<p>Si vous avez Docker, exécutez la commande suivante:</p>
<pre><code>docker run --rm --name subliminal -v /Users/olivier/Movies/Series/subliminal_cache:/usr/src/cache -v /Users/olivier/Movies/Series:/Users/olivier/Movies/Series -it diaoulael/subliminal download -l en /Users/olivier/Movies/Series/votre_serie_ou_film.mkv
</code></pre><p>Si vous voulez automatiser davantage, ce repository vous donne un snippet permettant de scanner le contenu d'un dossier et télécharger des sous-titres.</p>
<pre><code>from datetime import timedelta

from babelfish import Language
from subliminal import download_best_subtitles, region, save_subtitles, scan_videos

# configure the cache
region.configure('dogpile.cache.dbm', arguments={'filename': 'cachefile.dbm'})

# scan for videos newer than 2 weeks and their existing subtitles in a folder
videos = scan_videos('/video/folder', age=timedelta(weeks=2))

# download best subtitles
subtitles = download_best_subtitles(videos, {Language('eng'), Language('fra')})

# save them to disk, next to the video
for v in videos:
    save_subtitles(v, subtitles[v])
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Commandes utiles Google Dork</title>
            <link>https://leandeep.com/commandes-utiles-google-dork/</link>
            <pubDate>Thu, 29 Dec 2016 06:48:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-utiles-google-dork/</guid>
            <description>Voici une liste de commandes utiles pour télécharger l&#39;intégralité de directory listings trouvés grâce à des Google Dorks:
Un google Dork est une signature typique d’une technologie Web parmi tout ce qui est indexé par Google. Ils sont lié à ce qu&#39;on appelle plus généralement les Google Hacks. Vous savez les fameuses commandes comme par exemple intitle:index.of? mkv &amp;lt;Movie Name&amp;gt; ou encore &amp;lt;Movie Name&amp;gt; -inurl:(htm|html|php|pls|txt) intitle:index.of “last modified” (mp4|wma|aac|avi)
 Le Google hacking est une technique consistant à utiliser un moteur de recherche, généralement Google, en vue de chercher des vulnérabilités ou de récupérer des données sensibles.</description>
            <content type="html"><![CDATA[<p>Voici une liste de commandes utiles pour télécharger l'intégralité de <em>directory listings</em> trouvés grâce à des Google Dorks:</p>
<p>Un google Dork est une signature typique d’une technologie Web parmi tout ce qui est indexé par Google. Ils sont lié à ce qu'on appelle plus généralement les Google Hacks. Vous savez les fameuses commandes comme par exemple <code>intitle:index.of? mkv &lt;Movie Name&gt;</code> ou encore <code>&lt;Movie Name&gt; -inurl:(htm|html|php|pls|txt) intitle:index.of “last modified” (mp4|wma|aac|avi)</code></p>
<blockquote>
<p>Le Google hacking est une technique consistant à utiliser un moteur de recherche, généralement Google, en vue de chercher des vulnérabilités ou de récupérer des données sensibles. Cette technique s'appuie sur les résultats de l'exploration et de l'indexation des sites internet par le robot Googlebot. Source: Wikipédia</p>
</blockquote>
<p>Pour reprendre le téléchargement depuis là où il s'était arrêté:</p>
<pre><code>wget -c www.myfileserver.com/file1.zip
</code></pre><p>Pour télécharger depuis différents sites:</p>
<pre><code>wget -i /path/to/inputfile
# /path/to/inputfile will contain:
http://www.myfileserver.com/file1.zip
http://www.myfileserver.com/file2.zip
http://www.myfileserver.com/file3.zip
</code></pre><p>Pour faire 10 retries en cas d'arrêt de téléchargement:</p>
<pre><code>wget -t 10 -i /path/to/inputfile
</code></pre><p>Pour faire 10 retries en cas d'arrêt de téléchargement + timeout de 10 secondes entre 2 retries:</p>
<pre><code>wget -t 10 -T 10 -i /path/to/inputfile
</code></pre><p>Pour attendre entre 2 téléchargements:</p>
<pre><code>wget -w 60 -i /path/to/inputfile
</code></pre><p>Pour ajouter un quota de 100m (en cas de limitation de bandwidth):</p>
<pre><code>wget -q 100m -i /path/to/inputfile
</code></pre><p>Pour télécharger tous les fichiers d'un dossier de manière récursive:</p>
<pre><code>wget -r www.myfileserver.com
</code></pre><p>Par défaut la profondeur de téléchargement est de 5. Pour avoir un téléchargement de tout le contenu d'un site:</p>
<pre><code>wget -r -l inf www.myfileserver.com
</code></pre><p>Pour télécharger tous les fichiers d'un dossier de manière récursive et tout mettre dans le même dossier:</p>
<pre><code>wget -nd -r
</code></pre><p>L'inverse (i.e. créer l'arborescence de dossiers):</p>
<pre><code>wget -x -r
</code></pre><p>Pour télécharger seulement certains types de fichiers:</p>
<pre><code>wget -A &quot;*.mp3&quot; -r
</code></pre><p>L'inverse (télécharger tous les types de fichiers sauf):</p>
<pre><code>wget -R &quot;*.exe&quot; -r
</code></pre><p>Fake 302 redirects et Robots.txt</p>
<pre><code>wget -x -P local_dir -U Mozilla --wait=60 --limit-rate=20K --convert-links -p -m &lt;url-du-site-a-scraper&gt;
</code></pre><p>Ajouter <code>-nH</code> à la commande précédente pour télécharger uniquement un dossier.</p>
]]></content>
        </item>
        
        <item>
            <title>Retour d&#39;expérience, Évaluation d’Ionic 2 Beta 11</title>
            <link>https://leandeep.com/retour-dexp%C3%A9rience-%C3%A9valuation-dionic-2-beta-11/</link>
            <pubDate>Wed, 10 Aug 2016 19:16:00 +0000</pubDate>
            
            <guid>https://leandeep.com/retour-dexp%C3%A9rience-%C3%A9valuation-dionic-2-beta-11/</guid>
            <description>Ionic a annoncé la sortie de sa version Ionic 2 beta 11. J’ai voulu tester Ionic 2 et les nouveaux services disponibles.
Franchement c’est très impressionnant. En quelques heures seulement j’ai pu réaliser une application Android qui permet de recevoir les dernières news sur TensorFlow, d’envoyer des push notifications et qui se met à jour toute seule grâce au service Deploy.
C’est une première application minimaliste mais cela m’a permis de tester Ionic 2.</description>
            <content type="html"><![CDATA[<p>Ionic a annoncé la sortie de sa version Ionic 2 beta 11.
J’ai voulu tester Ionic 2 et les nouveaux services disponibles.</p>
<p>Franchement c’est très impressionnant. En quelques heures seulement j’ai pu réaliser une application Android qui permet de recevoir les dernières news sur TensorFlow, d’envoyer des push notifications et qui se met à jour toute seule grâce au service <a href="https://ionicframework.com/products/deploy">Deploy</a>.</p>
<p>C’est une première application minimaliste mais cela m’a permis de tester Ionic 2. Vivement sa sortie définitive… L’application est téléchargeable ici: <a href="https://play.google.com/store/apps/details?id=ml.leandeep.com">https://play.google.com/store/apps/details?id=ml.leandeep.com</a></p>
<p><img src="/images/screenshot-app-playstore-ionic.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Insights pour Use Cases Sequences Machine Learning</title>
            <link>https://leandeep.com/insights-pour-use-cases-sequences-machine-learning/</link>
            <pubDate>Sun, 31 Jul 2016 21:39:00 +0000</pubDate>
            
            <guid>https://leandeep.com/insights-pour-use-cases-sequences-machine-learning/</guid>
            <description>Cette compilation de compétitions Kaggle autour de sujets de NLP peut vous faire gagner du temps dans vos propres Use Cases.
======
Integer Sequence Learning Thu 2 Jun 2016 - Fri 30 Sep 2016
The On-Line Encyclopedia of Integer Sequences is a 50+ year effort by mathematicians the world over to catalog sequences of integers.
======
The Winton Stock Market Challenge Tue 27 Oct 2015 – Tue 26 Jan 2016</description>
            <content type="html"><![CDATA[<p>Cette compilation de compétitions Kaggle autour de sujets de NLP peut vous faire gagner du temps dans vos propres Use Cases.</p>
<p>======</p>
<h3 id="integer-sequence-learninghttpswwwkagglecomcinteger-sequence-learning"><a href="https://www.kaggle.com/c/integer-sequence-learning">Integer Sequence Learning</a></h3>
<p>Thu 2 Jun 2016 - Fri 30 Sep 2016</p>
<p>The On-Line Encyclopedia of Integer Sequences is a 50+ year effort by mathematicians the world over to catalog sequences of integers.</p>
<p>======</p>
<h3 id="the-winton-stock-market-challengehttpswwwkagglecomcthe-winton-stock-market-challenge"><a href="https://www.kaggle.com/c/the-winton-stock-market-challenge">The Winton Stock Market Challenge</a></h3>
<p>Tue 27 Oct 2015 – Tue 26 Jan 2016</p>
<p>In this recruiting competition, Winton challenges you to take on the very difficult task of predicting the future (stock returns). Given historical stock performance and a host of masked features, can you predict intra and end of day returns without being deceived by all the noise?</p>
<p>======</p>
<h3 id="denoising-dirty-documentshttpswwwkagglecomcdenoising-dirty-documents"><a href="https://www.kaggle.com/c/denoising-dirty-documents">Denoising Dirty Documents</a></h3>
<p>Mon 1 Jun 2015 – Mon 5 Oct 2015</p>
<p>Remove noise from printed text</p>
<p>======</p>
<h3 id="grasp-and-lift-eeg-detectionhttpswwwkagglecomcgrasp-and-lift-eeg-detection"><a href="https://www.kaggle.com/c/grasp-and-lift-eeg-detection">Grasp-and-Lift EEG Detection</a></h3>
<p>Mon 29 Jun 2015 – Mon 31 Aug 2015</p>
<p>Identify hand motions from EEG recordings</p>
<p>======</p>
<h3 id="bag-of-words-meets-bags-of-popcornhttpswwwkagglecomcword2vec-nlp-tutorial"><a href="https://www.kaggle.com/c/word2vec-nlp-tutorial">Bag of Words Meets Bags of Popcorn</a></h3>
<p>Tue 9 Dec 2014 – Tue 30 Jun 2015</p>
<p>Use Google's Word2Vec for movie reviews</p>
<p>======</p>
<h3 id="billion-word-imputationhttpswwwkagglecomcbillion-word-imputation"><a href="https://www.kaggle.com/c/billion-word-imputation">Billion Word Imputation</a></h3>
<p>Thu 8 May 2014 – Fri 1 May 2015</p>
<p>Find and impute missing words in the billion word corpus</p>
<p>======</p>
<h3 id="sentiment-analysis-on-movie-reviewshttpswwwkagglecomcsentiment-analysis-on-movie-reviews"><a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews">Sentiment Analysis on Movie Reviews</a></h3>
<p>Fri 28 Feb 2014 – Sat 28 Feb 2015</p>
<p>Classify the sentiment of sentences from the Rotten Tomatoes dataset</p>
<p>======</p>
<h3 id="predict-seizures-in-intracranial-eeg-recordingshttpswwwkagglecomcseizure-prediction"><a href="https://www.kaggle.com/c/seizure-prediction">Predict seizures in intracranial EEG recordings</a></h3>
<p>Mon 25 Aug 2014 – Mon 17 Nov 2014</p>
<p>Predict seizures in intracranial EEG recordings</p>
<p>======</p>
<h3 id="tradeshift-text-classificationhttpswwwkagglecomctradeshift-text-classification"><a href="https://www.kaggle.com/c/tradeshift-text-classification">Tradeshift Text Classification</a></h3>
<p>Thu 2 Oct 2014 – Mon 10 Nov 2014</p>
<p>Classify text blocks in documents</p>
<p>======</p>
<h3 id="the-hunt-for-prohibited-contenthttpswwwkagglecomcavito-prohibited-content"><a href="https://www.kaggle.com/c/avito-prohibited-content">The Hunt for Prohibited Content</a></h3>
<p>Tue 24 Jun 2014 – Sun 31 Aug 2014</p>
<p>Predict which ads contain illicit content</p>
<p>======</p>
<h3 id="large-scale-hierarchical-text-classificationhttpswwwkagglecomclshtc"><a href="https://www.kaggle.com/c/lshtc">Large Scale Hierarchical Text Classification</a></h3>
<p>Wed 22 Jan 2014 – Tue 22 Apr 2014</p>
<p>Classify Wikipedia documents into one of 325,056 categories</p>
<p>======</p>
<h3 id="personalized-web-search-challengehttpswwwkagglecomcyandex-personalized-web-search-challenge"><a href="https://www.kaggle.com/c/yandex-personalized-web-search-challenge">Personalized Web Search Challenge</a></h3>
<p>Fri 11 Oct 2013 – Fri 10 Jan 2014</p>
<p>Re-rank web documents using personal preferences</p>
<p>======</p>
<h3 id="facebook-recruiting-iii---keyword-extractionhttpswwwkagglecomcfacebook-recruiting-iii-keyword-extraction"><a href="https://www.kaggle.com/c/facebook-recruiting-iii-keyword-extraction">Facebook Recruiting III - Keyword Extraction</a></h3>
<p>Fri 30 Aug 2013 – Fri 20 Dec 2013</p>
<p>This competition tests your text skills on a large dataset from the Stack Exchange sites.  The task is to predict the tags (a.k.a. keywords, topics, summaries), given only the question text and its title. The dataset contains content from disparate stack exchange sites, containing a mix of both technical and non-technical questions.</p>
<p>======</p>
<h3 id="partly-sunny-with-a-chance-of-hashtagshttpswwwkagglecomccrowdflower-weather-twitter"><a href="https://www.kaggle.com/c/crowdflower-weather-twitter">Partly Sunny with a Chance of Hashtags</a></h3>
<p>Fri 27 Sep 2013 – Sun 1 Dec 2013</p>
<p>What can a #machine learn from tweets about the #weather?</p>
<p>======</p>
<h3 id="multi-label-bird-species-classification---nips-2013httpswwwkagglecomcmultilabel-bird-species-classification-nips2013"><a href="https://www.kaggle.com/c/multilabel-bird-species-classification-nips2013">Multi-label Bird Species Classification - NIPS 2013</a></h3>
<p>Wed 16 Oct 2013 – Sun 24 Nov 2013</p>
<p>Identify which of 87 classes of birds and amphibians are present into 1000 continuous wild sound recordings</p>
<p>======</p>
<h3 id="belkin-energy-disaggregation-competitionhttpswwwkagglecomcbelkin-energy-disaggregation-competition"><a href="https://www.kaggle.com/c/belkin-energy-disaggregation-competition">Belkin Energy Disaggregation Competition</a></h3>
<p>Tue 2 Jul 2013 – Wed 30 Oct 2013</p>
<p>Disaggregate household energy consumption into individual appliances</p>
<p>======</p>
<h3 id="mlsp-2013-bird-classification-challengehttpswwwkagglecomcmlsp-2013-birds"><a href="https://www.kaggle.com/c/mlsp-2013-birds">MLSP 2013 Bird Classification Challenge</a></h3>
<p>Mon 17 Jun 2013 – Mon 19 Aug 2013</p>
<p>Predict the set of bird species present in an audio recording, collected in field conditions.</p>
<p>======</p>
<h3 id="the-icml-2013-whale-challenge---right-whale-reduxhttpswwwkagglecomcthe-icml-2013-whale-challenge-right-whale-redux"><a href="https://www.kaggle.com/c/the-icml-2013-whale-challenge-right-whale-redux">The ICML 2013 Whale Challenge - Right Whale Redux</a></h3>
<p>Fri 10 May 2013 – Mon 17 Jun 2013</p>
<p>Develop recognition solutions to detect and classify right whales for BIG data mining and exploration studies</p>
<p>======</p>
<h3 id="the-icml-2013-bird-challengehttpswwwkagglecomcthe-icml-2013-bird-challenge"><a href="https://www.kaggle.com/c/the-icml-2013-bird-challenge">The ICML 2013 Bird Challenge</a></h3>
<p>Wed 8 May 2013 – Mon 17 Jun 2013</p>
<p>Identify bird species from continuous audio recordings</p>
<p>======</p>
<h3 id="cprod1-consumer-products-contest-1httpswwwkagglecomccprod1"><a href="https://www.kaggle.com/c/cprod1">CPROD1: Consumer PRODucts contest #1</a></h3>
<p>Mon 2 Jul 2012 – Mon 24 Sep 2012</p>
<p>Identify product mentions within a largely user-generated web-based corpus and disambiguate the mentions against a large product catalog.</p>
<p>======</p>
<h3 id="detecting-insults-in-social-commentaryhttpswwwkagglecomcdetecting-insults-in-social-commentary"><a href="https://www.kaggle.com/c/detecting-insults-in-social-commentary">Detecting Insults in Social Commentary</a></h3>
<p>Tue 18 Sep 2012 – Fri 21 Sep 2012</p>
<p>The challenge is to detect when a comment from a conversation would be considered insulting to another participant in the conversation.</p>
<p>======</p>
<h3 id="gigaom-wordpress-challenge-splunk-innovation-prospecthttpswwwkagglecomcpredict-wordpress-likes"><a href="https://www.kaggle.com/c/predict-wordpress-likes">GigaOM WordPress Challenge: Splunk Innovation Prospect</a></h3>
<p>Wed 20 Jun 2012 – Fri 7 Sep 2012</p>
<p>Predict which blog posts someone will like.</p>
<p>======</p>
<h3 id="the-hewlett-foundation-short-answer-scoringhttpswwwkagglecomcasap-sas"><a href="https://www.kaggle.com/c/asap-sas">The Hewlett Foundation: Short Answer Scoring</a></h3>
<p>Mon 25 Jun 2012 – Wed 5 Sep 2012</p>
<p>Develop a scoring algorithm for student-written short-answer responses.</p>
<p>======</p>
<h3 id="emc-israel-data-science-challengehttpswwwkagglecomcemc-data-science"><a href="https://www.kaggle.com/c/emc-data-science">EMC Israel Data Science Challenge</a></h3>
<p>Mon 18 Jun 2012 – Sat 1 Sep 2012</p>
<p>Match source code files to the open source code project</p>
<p>======</p>
<h3 id="the-hewlett-foundation-automated-essay-scoringhttpswwwkagglecomcasap-aes"><a href="https://www.kaggle.com/c/asap-aes">The Hewlett Foundation: Automated Essay Scoring</a></h3>
<p>Fri 10 Feb 2012 – Mon 30 Apr 2012</p>
<p>Develop an automated scoring algorithm for student-written essays.</p>
<p>======</p>
<h3 id="the-marinexplore-and-cornell-university-whale-detection-challengehttpswwwkagglecomcwhale-detection-challenge"><a href="https://www.kaggle.com/c/whale-detection-challenge">The Marinexplore and Cornell University Whale Detection Challenge</a></h3>
<p>Fri 8 Feb 2013 – Mon 8 Apr 2013</p>
<p>Create an algorithm to detect North Atlantic right whale calls from audio recordings, prevent collisions with shipping traffic</p>
<p>======</p>
<h3 id="icfhr-2012---arabic-writer-identificationhttpswwwkagglecomcawic2012"><a href="https://www.kaggle.com/c/awic2012">ICFHR 2012 - Arabic Writer Identification</a></h3>
<p>Tue 21 Feb 2012 – Sun 15 Apr 2012</p>
<p>Identify which writer wrote which documents.</p>
<p>======</p>
<h3 id="icdar-2011---arabic-writer-identificationhttpswwwkagglecomcwic2011"><a href="https://www.kaggle.com/c/WIC2011">ICDAR 2011 - Arabic Writer Identification</a></h3>
<p>Mon 28 Feb 2011 – Sun 10 Apr 2011</p>
<p>This competition require participants to develop an algorithm to identify who wrote which documents. The winner will be honored at a special session of the ICDAR 2011 conference.</p>
<p>======</p>
]]></content>
        </item>
        
        <item>
            <title>Insights pour Use Cases inclassables Machine Learning</title>
            <link>https://leandeep.com/insights-pour-use-cases-inclassables-machine-learning/</link>
            <pubDate>Sat, 30 Jul 2016 23:42:00 +0000</pubDate>
            
            <guid>https://leandeep.com/insights-pour-use-cases-inclassables-machine-learning/</guid>
            <description>Cette compilation de compétitions Kaggle autour de sujets inclassables peut vous faire gagner du temps dans vos propres Use Cases.
======
Facebook V: Predicting Check Ins Wed 11 May 2016 – Wed 6 Jul 2016
The goal of this competition is to predict which place a person would like to check in to. For the purposes of this competition, Facebook created an artificial world consisting of more than 100,000 places located in a 10 km by 10 km square.</description>
            <content type="html"><![CDATA[<p>Cette compilation de compétitions Kaggle autour de sujets inclassables peut vous faire gagner du temps dans vos propres Use Cases.</p>
<p>======</p>
<h3 id="facebook-v-predicting-check-inshttpswwwkagglecomcfacebook-v-predicting-check-ins"><a href="https://www.kaggle.com/c/facebook-v-predicting-check-ins">Facebook V: Predicting Check Ins</a></h3>
<p>Wed 11 May 2016 – Wed 6 Jul 2016</p>
<p>The goal of this competition is to predict which place a person would like to check in to. For the purposes of this competition, Facebook created an artificial world consisting of more than 100,000 places located in a 10 km by 10 km square. For a given set of coordinates, your task is to return a ranked list of the most likely places.</p>
<p>======</p>
<h3 id="expedia-hotel-recommendationshttpswwwkagglecomcexpedia-hotel-recommendations"><a href="https://www.kaggle.com/c/expedia-hotel-recommendations">Expedia Hotel Recommendations</a></h3>
<p>Fri 15 Apr 2016 – Fri 10 Jun 2016</p>
<p>Which hotel type will an Expedia customer book?</p>
<p>======</p>
<h3 id="santas-stolen-sleighhttpswwwkagglecomcsantas-stolen-sleigh"><a href="https://www.kaggle.com/c/santas-stolen-sleigh">Santa's Stolen Sleigh</a></h3>
<p>Tue 1 Dec 2015 – Fri 8 Jan 2016</p>
<p>Given the sleigh's antiquated, weight-limited specifications, your challenge is to optimize the routes and loads Santa will take to and from the North Pole.</p>
<p>======</p>
<h3 id="coupon-purchase-predictionhttpswwwkagglecomccoupon-purchase-prediction"><a href="https://www.kaggle.com/c/coupon-purchase-prediction">Coupon Purchase Prediction</a></h3>
<p>Thu 16 Jul 2015 – Wed 30 Sep 2015</p>
<p>Predict which coupons a customer will buy</p>
<p>======</p>
<h3 id="ecmlpkdd-15-taxi-trajectory-prediction-ihttpswwwkagglecomcpkdd-15-predict-taxi-service-trajectory-i"><a href="https://www.kaggle.com/c/pkdd-15-predict-taxi-service-trajectory-i">ECML/PKDD 15: Taxi Trajectory Prediction (I)</a></h3>
<p>Mon 20 Apr 2015 – Wed 1 Jul 2015</p>
<p>Predict the destination of taxi trips based on initial partial trajectories</p>
<p>======</p>
<h3 id="learning-social-circles-in-networkshttpswwwkagglecomclearning-social-circles"><a href="https://www.kaggle.com/c/learning-social-circles">Learning Social Circles in Networks</a></h3>
<p>Mon 24 Nov 2014 – Wed 7 Jan 2015</p>
<p>In this job scheduling problem, you will assign which elves work on which toys, at what time, and for how long. The goal is to complete all of the toys as early as possible, scaled by the natural log of the number of elves that work.</p>
<p>======</p>
<h3 id="helping-santas-helpershttpswwwkagglecomchelping-santas-helpers"><a href="https://www.kaggle.com/c/helping-santas-helpers">Helping Santa's Helpers</a></h3>
<p>Tue 6 May 2014 – Tue 28 Oct 2014</p>
<p>Model friend memberships to multiple circles</p>
<p>======</p>
<h3 id="higgs-boson-machine-learning-challengehttpswwwkagglecomchiggs-boson"><a href="https://www.kaggle.com/c/higgs-boson">Higgs Boson Machine Learning Challenge</a></h3>
<p>Mon 12 May 2014 – Mon 15 Sep 2014</p>
<p>Use the ATLAS experiment to identify the Higgs boson</p>
<p>======</p>
<h3 id="the-random-number-grand-challengehttpswwwkagglecomcrandom-number-grand-challenge"><a href="https://www.kaggle.com/c/random-number-grand-challenge">The Random Number Grand Challenge</a></h3>
<p>Mon 31 Mar 2014 – Tue 1 Apr 2014</p>
<p>Decode a sequence of pseudorandom numbers</p>
<p>======</p>
<h3 id="conways-reverse-game-of-lifehttpswwwkagglecomcconway-s-reverse-game-of-life"><a href="https://www.kaggle.com/c/conway-s-reverse-game-of-life">Conway's Reverse Game of Life</a></h3>
<p>Mon 14 Oct 2013 – Sun 2 Mar 2014</p>
<p>Reverse the arrow of time in the Game of Life</p>
<p>======</p>
<h3 id="packing-santas-sleighhttpswwwkagglecomcpacking-santas-sleigh"><a href="https://www.kaggle.com/c/packing-santas-sleigh">Packing Santa's Sleigh</a></h3>
<p>Mon 2 Dec 2013 – Sun 26 Jan 2014</p>
<p>He's making a list, checking it twice; to fill up his sleigh, he needs your advice</p>
<p>======</p>
<h3 id="personalize-expedia-hotel-searches---icdm-2013httpswwwkagglecomcexpedia-personalized-sort"><a href="https://www.kaggle.com/c/expedia-personalized-sort">Personalize Expedia Hotel Searches - ICDM 2013</a></h3>
<p>Tue 3 Sep 2013 – Mon 4 Nov 2013</p>
<p>Learning to rank hotels to maximize purchases</p>
<p>======</p>
<h3 id="kdd-cup-2013---author-paper-identification-challenge-track-1httpswwwkagglecomckdd-cup-2013-author-paper-identification-challenge"><a href="https://www.kaggle.com/c/kdd-cup-2013-author-paper-identification-challenge">KDD Cup 2013 - Author-Paper Identification Challenge (Track 1)</a></h3>
<p>Thu 18 Apr 2013 – Wed 26 Jun 2013</p>
<p>Determine whether an author has written a given paper</p>
<p>======</p>
<h3 id="influencers-in-social-networkshttpswwwkagglecomcpredict-who-is-more-influential-in-a-social-network"><a href="https://www.kaggle.com/c/predict-who-is-more-influential-in-a-social-network">Influencers in Social Networks</a></h3>
<p>Sat 13 Apr 2013 – Sun 14 Apr 2013</p>
<p>Predict which people are influential in a social network</p>
<p>======</p>
<h3 id="predicting-parkinsons-disease-progression-with-smartphone-datahttpswwwkagglecomcpredicting-parkinson-s-disease-progression-with-smartphone-data"><a href="https://www.kaggle.com/c/predicting-parkinson-s-disease-progression-with-smartphone-data">Predicting Parkinson's Disease Progression with Smartphone Data</a></h3>
<p>Tue 5 Feb 2013 – Wed 27 Mar 2013</p>
<p>Can we objectively measure the symptoms of Parkinson’s disease with a smartphone? We have the data to find out!</p>
<p>======</p>
<h3 id="event-recommendation-engine-challengehttpswwwkagglecomcevent-recommendation-engine-challenge"><a href="https://www.kaggle.com/c/event-recommendation-engine-challenge">Event Recommendation Engine Challenge</a></h3>
<p>Fri 11 Jan 2013 – Wed 20 Feb 2013</p>
<p>Predict what events our users will be interested in based on user actions, event metadata, and demographic information.</p>
<p>======</p>
<h3 id="leaping-leaderboard-leapfrogshttpswwwkagglecomcleapfrogging-leaderboards"><a href="https://www.kaggle.com/c/leapfrogging-leaderboards">Leaping Leaderboard Leapfrogs</a></h3>
<p>Fri 14 Dec 2012 – Fri 8 Feb 2013</p>
<p>Provide creative visualizations of the Kaggle leaderboard</p>
<p>======</p>
<h3 id="visualize-the-state-of-public-education-in-coloradohttpswwwkagglecomcvisualize-the-state-of-education-in-colorado"><a href="https://www.kaggle.com/c/visualize-the-state-of-education-in-colorado">Visualize the State of Public Education in Colorado</a></h3>
<p>Mon 10 Dec 2012 – Sun 20 Jan 2013</p>
<p>Using 3 years of school grading data supplied by the Colorado Department of Education and R-Squared Research, visually uncover trends in the Colorado public school system.</p>
<p>======</p>
<h3 id="traveling-santa-problemhttpswwwkagglecomctraveling-santa-problem"><a href="https://www.kaggle.com/c/traveling-santa-problem">Traveling Santa Problem</a></h3>
<p>Fri 14 Dec 2012 – Sat 19 Jan 2013</p>
<p>Solve ye olde traveling salesman problem to help Santa Claus deliver his presents</p>
<p>======</p>
<h3 id="facebook-ii---mapping-the-internethttpswwwkagglecomcfacebook-ii"><a href="https://www.kaggle.com/c/facebook-ii">Facebook II - Mapping the Internet</a></h3>
<p>Wed 24 Oct 2012 – Wed 21 Nov 2012</p>
<p>The Task: you will be given a path which, at one point in the training time period, was an optimal path from node A to B. The question is then to make a probalistic prediction, for each of the 5 test graphs, whether the given path is STILL an optimal path.</p>
<p>======</p>
<h3 id="follow-the-money-investigative-reporting-prospecthttpswwwkagglecomccir-prospect"><a href="https://www.kaggle.com/c/cir-prospect">Follow the Money: Investigative Reporting Prospect</a></h3>
<p>Fri 14 Sep 2012 – Mon 15 Oct 2012</p>
<p>Find hidden patterns, connections, and ultimately compelling stories in a treasure trove of data about US federal campaign contributions</p>
<p>======</p>
<h3 id="job-recommendation-challengehttpswwwkagglecomcjob-recommendation"><a href="https://www.kaggle.com/c/job-recommendation">Job Recommendation Challenge</a></h3>
<p>Fri 3 Aug 2012 – Sun 7 Oct 2012</p>
<p>Predict which jobs users will apply to</p>
<p>======</p>
<h3 id="practice-fusion-analyze-this-2012---open-challengehttpswwwkagglecomcpf2012-at"><a href="https://www.kaggle.com/c/pf2012-at">Practice Fusion Analyze This! 2012 - Open Challenge</a></h3>
<p>Thu 7 Jun 2012 – Mon 10 Sep 2012</p>
<p>Start digging into electronic health records and submit your creative, insightful, and visually striking analyses.</p>
<p>======</p>
<h3 id="harvard-business-review-vision-statement-prospecthttpswwwkagglecomcharvard-business-review-vision-statement-prospect"><a href="https://www.kaggle.com/c/harvard-business-review-vision-statement-prospect">Harvard Business Review &lsquo;Vision Statement&rsquo; Prospect</a></h3>
<p>Sat 18 Aug 2012 – Mon 27 Aug 2012</p>
<p>Your Analysis and/or Visualization featured in the Harvard Business Review</p>
<p>======</p>
<h3 id="million-song-dataset-challengehttpswwwkagglecomcmsdchallenge"><a href="https://www.kaggle.com/c/msdchallenge">Million Song Dataset Challenge</a></h3>
<p>Thu 26 Apr 2012 – Thu 9 Aug 2012</p>
<p>Predict which songs a user will listen to.</p>
<p>======</p>
<h3 id="emi-music-data-science-hackathon---july-21st---24-hourshttpswwwkagglecomcmusichackathon"><a href="https://www.kaggle.com/c/MusicHackathon">EMI Music Data Science Hackathon - July 21st - 24 hours</a></h3>
<p>Sat 21 Jul 2012 – Sun 22 Jul 2012</p>
<p>Can you predict if a listener will love a new song?</p>
<p>======</p>
<h3 id="facebook-recruiting-competitionhttpswwwkagglecomcfacebookrecruiting"><a href="https://www.kaggle.com/c/FacebookRecruiting">Facebook Recruiting Competition</a></h3>
<p>Tue 5 Jun 2012 – Tue 10 Jul 2012</p>
<p>The challenge is to recommend missing links in a social network.  Participants will be presented with an external anonymized, directed social graph (no, not Facebook, keep guessing) from which some edges have been deleted, and asked to make ranked predictions for each user in the test set of which other users they would want to follow.</p>
<p>======</p>
<h3 id="practice-fusion-analyze-this-2012---prediction-challengehttpswwwkagglecomcpf2012"><a href="https://www.kaggle.com/c/pf2012">Practice Fusion Analyze This! 2012 - Prediction Challenge</a></h3>
<p>Thu 7 Jun 2012 – Sat 30 Jun 2012</p>
<p>Start digging into electronic health records and submit your ideas for the most promising, impactful or interesting predictive modeling competitions</p>
<p>======</p>
<h3 id="semi-supervised-feature-learninghttpswwwkagglecomcsemisupervisedfeaturelearning"><a href="https://www.kaggle.com/c/SemiSupervisedFeatureLearning">Semi-Supervised Feature Learning</a></h3>
<p>Sat 24 Sep 2011 – Mon 17 Oct 2011</p>
<p>There's been a lot of recent work done in unsupervised feature learning for classification and there are a ton of older methods that also work well. The purpose of this competition is to find out which of these methods work best on relatively large-scale high dimensional learning tasks.</p>
<p>======</p>
]]></content>
        </item>
        
        <item>
            <title>Insights pour Use Cases Image Machine Learning</title>
            <link>https://leandeep.com/insights-pour-use-cases-image-machine-learning/</link>
            <pubDate>Wed, 27 Jul 2016 22:36:00 +0000</pubDate>
            
            <guid>https://leandeep.com/insights-pour-use-cases-image-machine-learning/</guid>
            <description>Cette compilation de compétitions Kaggle autour de sujets d&#39;analyse d&#39;images peut vous faire gagner du temps dans vos propres Use Cases.
======
Digit Recognizer Wed 25 Jul 2012 - Sat 31 Dec 2016
Classify handwritten digits using the famous MNIST data
======
Facial Keypoints Detection Tue 7 May 2013 - Sat 31 Dec 2016
Detect the location of keypoints on face images
======
First Steps With Julia Mon 4 Aug 2014 - Sat 31 Dec 2016</description>
            <content type="html"><![CDATA[<p>Cette compilation de compétitions Kaggle autour de sujets d'analyse d'images peut vous faire gagner du temps dans vos propres Use Cases.</p>
<p>======</p>
<h3 id="digit-recognizerhttpswwwkagglecomcdigit-recognizer"><a href="https://www.kaggle.com/c/digit-recognizer">Digit Recognizer</a></h3>
<p>Wed 25 Jul 2012 - Sat 31 Dec 2016</p>
<p>Classify handwritten digits using the famous MNIST data</p>
<p>======</p>
<h3 id="facial-keypoints-detectionhttpswwwkagglecomcfacial-keypoints-detection"><a href="https://www.kaggle.com/c/facial-keypoints-detection">Facial Keypoints Detection</a></h3>
<p>Tue 7 May 2013 - Sat 31 Dec 2016</p>
<p>Detect the location of keypoints on face images</p>
<p>======</p>
<h3 id="first-steps-with-juliahttpswwwkagglecomcstreet-view-getting-started-with-julia"><a href="https://www.kaggle.com/c/street-view-getting-started-with-julia">First Steps With Julia</a></h3>
<p>Mon 4 Aug 2014 - Sat 31 Dec 2016</p>
<p>Use Julia to identify characters from Google Street View images</p>
<p>======</p>
<h3 id="painter-by-numbershttpswwwkagglecomcpainter-by-numbers"><a href="https://www.kaggle.com/c/painter-by-numbers">Painter by Numbers</a></h3>
<p>Fri 29 Apr 2016 - Mon 31 Oct 2016</p>
<p>Does every painter leave a fingerprint?</p>
<p>======</p>
<h3 id="ultrasound-nerve-segmentationhttpswwwkagglecomcultrasound-nerve-segmentation"><a href="https://www.kaggle.com/c/ultrasound-nerve-segmentation">Ultrasound Nerve Segmentation</a></h3>
<p>Thu 19 May 2016 - Thu 18 Aug 2016</p>
<p>Identify nerve structures in ultrasound images of the neck</p>
<p>======</p>
<h3 id="state-farm-distracted-driver-detectionhttpswwwkagglecomcstate-farm-distracted-driver-detection"><a href="https://www.kaggle.com/c/state-farm-distracted-driver-detection">State Farm Distracted Driver Detection</a></h3>
<p>Tue 5 Apr 2016 - Mon 1 Aug 2016</p>
<p>Can computer vision spot distracted drivers?</p>
<p>======</p>
<h3 id="avito-duplicate-ads-detectionhttpswwwkagglecomcavito-duplicate-ads-detection"><a href="https://www.kaggle.com/c/avito-duplicate-ads-detection">Avito Duplicate Ads Detection</a></h3>
<p>Fri 6 May 2016 – Mon 11 Jul 2016</p>
<p>Can you detect duplicitous duplicate ads?</p>
<p>======</p>
<h3 id="draper-satellite-image-chronologyhttpswwwkagglecomcdraper-satellite-image-chronology"><a href="https://www.kaggle.com/c/draper-satellite-image-chronology">Draper Satellite Image Chronology</a></h3>
<p>Fri 29 Apr 2016 – Mon 27 Jun 2016</p>
<p>Draper provides a unique dataset of images taken at the same locations over 5 days. Kagglers are challenged to predict the chronological order of the photos taken at each location. Accurately doing so could uncover approaches that have a global impact on commerce, science, and humanitarian works.</p>
<p>======</p>
<h3 id="yelp-restaurant-photo-classificationhttpswwwkagglecomcyelp-restaurant-photo-classification"><a href="https://www.kaggle.com/c/yelp-restaurant-photo-classification">Yelp Restaurant Photo Classification</a></h3>
<p>Mon 21 Dec 2015 – Tue 12 Apr 2016</p>
<p>In this competition, Yelp is challenging Kagglers to build a model that automatically tags restaurants with multiple labels using a dataset of user-submitted photos.</p>
<p>======</p>
<h3 id="second-annual-data-science-bowlhttpswwwkagglecomcsecond-annual-data-science-bowl"><a href="https://www.kaggle.com/c/second-annual-data-science-bowl">Second Annual Data Science Bowl</a></h3>
<p>Mon 14 Dec 2015 – Mon 14 Mar 2016</p>
<p>Transforming How We Diagnose Heart Disease</p>
<ul>
<li>1st place: <a href="https://github.com/ShuaiW/diagnose-heart">code</a></li>
<li>2nd place: <a href="https://github.com/ShuaiW/kaggle-heart">code</a> | <a href="http://blog.kaggle.com/2016/04/13/diagnosing-heart-diseases-with-deep-neural-networks-2nd-place-ira-korshunova/">interview</a></li>
<li>3rd place: <a href="https://github.com/ShuaiW/kaggle_ndsb2">code</a></li>
<li>[Keras code] (<a href="https://github.com/ShuaiW/kaggle-dsb2-keras):">https://github.com/ShuaiW/kaggle-dsb2-keras):</a> ~0.036</li>
</ul>
<p>======</p>
<h3 id="right-whale-recognitionhttpswwwkagglecomcnoaa-right-whale-recognition"><a href="https://www.kaggle.com/c/noaa-right-whale-recognition">Right Whale Recognition</a></h3>
<p>Thu 27 Aug 2015 – Thu 7 Jan 2016</p>
<p>Identify endangered right whales in aerial photographs</p>
<p>======</p>
<h3 id="diabetic-retinopathy-detectionhttpswwwkagglecomcdiabetic-retinopathy-detection"><a href="https://www.kaggle.com/c/diabetic-retinopathy-detection">Diabetic Retinopathy Detection</a></h3>
<p>Tue 17 Feb 2015 – Mon 27 Jul 2015</p>
<p>Identify signs of diabetic retinopathy in eye images</p>
<p>======</p>
<h3 id="national-data-science-bowlhttpswwwkagglecomcdatasciencebowl"><a href="https://www.kaggle.com/c/datasciencebowl">National Data Science Bowl</a></h3>
<p>Mon 15 Dec 2014 – Mon 16 Mar 2015</p>
<p>Predict ocean health, one plankton at a time</p>
<p>======</p>
<h3 id="cifar-10---object-recognition-in-imageshttpswwwkagglecomccifar-10"><a href="https://www.kaggle.com/c/cifar-10">CIFAR-10 - Object Recognition in Images</a></h3>
<p>Fri 18 Oct 2013 – Sat 18 Oct 2014</p>
<p>Identify the subject of 60,000 labeled images</p>
<p>======</p>
<h3 id="upenn-and-mayo-clinics-seizure-detection-challengehttpswwwkagglecomcseizure-detection"><a href="https://www.kaggle.com/c/seizure-detection">UPenn and Mayo Clinic's Seizure Detection Challenge</a></h3>
<p>Mon 19 May 2014 – Tue 19 Aug 2014</p>
<p>Detect seizures in intracranial EEG recordings</p>
<p>======</p>
<h3 id="decmeg2014---decoding-the-human-brainhttpswwwkagglecomcdecoding-the-human-brain"><a href="https://www.kaggle.com/c/decoding-the-human-brain">DecMeg2014 - Decoding the Human Brain</a></h3>
<p>Mon 21 Apr 2014 – Sun 27 Jul 2014</p>
<p>Predict visual stimuli from MEG recordings of human brain activity</p>
<p>======</p>
<h3 id="connectomicshttpswwwkagglecomcconnectomics"><a href="https://www.kaggle.com/c/connectomics">CONNECTOMICS</a></h3>
<p>Wed 5 Feb 2014 – Mon 5 May 2014</p>
<p>Reconstruct the wiring between neurons from fluorescence imaging of neural activity</p>
<p>======</p>
<h3 id="galaxy-zoo---the-galaxy-challengehttpswwwkagglecomcgalaxy-zoo-the-galaxy-challenge"><a href="https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge">Galaxy Zoo - The Galaxy Challenge</a></h3>
<p>Fri 20 Dec 2013 – Fri 4 Apr 2014</p>
<p>Classify the morphologies of distant galaxies in our Universe</p>
<p>======</p>
<h3 id="dogs-vs-catshttpswwwkagglecomcdogs-vs-cats"><a href="https://www.kaggle.com/c/dogs-vs-cats">Dogs vs. Cats</a></h3>
<p>Wed 25 Sep 2013 – Sat 1 Feb 2014</p>
<p>Create an algorithm to distinguish dogs from cats</p>
<p>======</p>
<h3 id="multi-modal-gesture-recognitionhttpswwwkagglecomcmulti-modal-gesture-recognition"><a href="https://www.kaggle.com/c/multi-modal-gesture-recognition">Multi-modal Gesture Recognition</a></h3>
<p>Fri 21 Jun 2013 – Sun 25 Aug 2013</p>
<p>Recognize gesture sequences in video and depth data from Kinect</p>
<p>======</p>
<h3 id="challenges-in-representation-learning-multi-modal-learninghttpswwwkagglecomcchallenges-in-representation-learning-multi-modal-learning"><a href="https://www.kaggle.com/c/challenges-in-representation-learning-multi-modal-learning">Challenges in Representation Learning: Multi-modal Learning</a></h3>
<p>Fri 12 Apr 2013 – Fri 24 May 2013</p>
<p>The multi-modal learning challenge</p>
<p>======</p>
<h3 id="challenges-in-representation-learning-the-black-box-learning-challengehttpswwwkagglecomcchallenges-in-representation-learning-the-black-box-learning-challenge"><a href="https://www.kaggle.com/c/challenges-in-representation-learning-the-black-box-learning-challenge">Challenges in Representation Learning: The Black Box Learning Challenge</a></h3>
<p>Fri 12 Apr 2013 – Fri 24 May 2013</p>
<p>Competitors train a classifier on a dataset that is not human readable, without knowledge of what the data consists of.</p>
<p>======</p>
<h3 id="challenges-in-representation-learning-facial-expression-recognition-challengehttpswwwkagglecomcchallenges-in-representation-learning-facial-expression-recognition-challenge"><a href="https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge">Challenges in Representation Learning: Facial Expression Recognition Challenge</a></h3>
<p>Fri 12 Apr 2013 – Fri 24 May 2013</p>
<p>Learn facial expressions from an image</p>
<p>======</p>
<h3 id="icdar2013---gender-prediction-from-handwritinghttpswwwkagglecomcicdar2013-gender-prediction-from-handwriting"><a href="https://www.kaggle.com/c/icdar2013-gender-prediction-from-handwriting">ICDAR2013 - Gender Prediction from Handwriting</a></h3>
<p>Tue 5 Mar 2013 – Mon 15 Apr 2013</p>
<p>Predict if a handwritten document has been produced by a male or a female writer</p>
<p>======</p>
<h3 id="chalearn-gesture-challenge-2httpswwwkagglecomcgesturechallenge2"><a href="https://www.kaggle.com/c/GestureChallenge2">CHALEARN Gesture Challenge 2</a></h3>
<p>Tue 8 May 2012 – Tue 11 Sep 2012</p>
<p>Develop a Gesture Recognizer for Microsoft Kinect (TM)</p>
<p>======</p>
<h3 id="chalearn-gesture-challengehttpswwwkagglecomcgesturechallenge"><a href="https://www.kaggle.com/c/GestureChallenge">CHALEARN Gesture Challenge</a></h3>
<p>Wed 7 Dec 2011 – Tue 10 Apr 2012</p>
<p>Develop a Gesture Recognizer for Microsoft Kinect (TM)</p>
<p>======</p>
]]></content>
        </item>
        
        <item>
            <title>Insights pour Use Cases Machine Classification Learning</title>
            <link>https://leandeep.com/insights-pour-use-cases-machine-classification-learning/</link>
            <pubDate>Sun, 24 Jul 2016 21:33:00 +0000</pubDate>
            
            <guid>https://leandeep.com/insights-pour-use-cases-machine-classification-learning/</guid>
            <description>Cette compilation de compétitions Kaggle autour de sujets de classification peut vous faire gagner du temps dans vos propres Use Cases.
======
Titanic: Machine Learning from Disaster Fri 28 Sep 2012 - Sat 31 Dec 2016
Predict survival on the Titanic using Excel, Python, R &amp;amp; Random Forests
======
TalkingData Mobile User Demographics Mon 11 Jul 2016 - Mon 5 Sep 2016
Get to know millions of mobile device users</description>
            <content type="html"><![CDATA[<p>Cette compilation de compétitions Kaggle autour de sujets de classification peut vous faire gagner du temps dans vos propres Use Cases.</p>
<p>======</p>
<h3 id="titanic-machine-learning-from-disasterhttpswwwkagglecomctitanic"><a href="https://www.kaggle.com/c/titanic">Titanic: Machine Learning from Disaster</a></h3>
<p>Fri 28 Sep 2012 - Sat 31 Dec 2016</p>
<p>Predict survival on the Titanic using Excel, Python, R &amp; Random Forests</p>
<p>======</p>
<h3 id="talkingdata-mobile-user-demographicshttpswwwkagglecomctalkingdata-mobile-user-demographics"><a href="https://www.kaggle.com/c/talkingdata-mobile-user-demographics">TalkingData Mobile User Demographics</a></h3>
<p>Mon 11 Jul 2016 - Mon 5 Sep 2016</p>
<p>Get to know millions of mobile device users</p>
<p>======</p>
<h3 id="shelter-animal-outcomeshttpswwwkagglecomcshelter-animal-outcomes"><a href="https://www.kaggle.com/c/shelter-animal-outcomes">Shelter Animal Outcomes</a></h3>
<p>Mon 21 Mar 2016 - Sun 31 Jul 2016</p>
<p>Help improve outcomes for shelter animals</p>
<p>======</p>
<h3 id="san-francisco-crime-classificationhttpswwwkagglecomcsf-crime"><a href="https://www.kaggle.com/c/sf-crime">San Francisco Crime Classification</a></h3>
<p>Tue 2 Jun 2015 – Mon 6 Jun 2016</p>
<p>Predict the category of crimes that occurred in the city by the bay</p>
<p>======</p>
<h3 id="santander-customer-satisfactionhttpswwwkagglecomcsantander-customer-satisfaction"><a href="https://www.kaggle.com/c/santander-customer-satisfaction">Santander Customer Satisfaction</a></h3>
<p>Wed 2 Mar 2016 – Mon 2 May 2016</p>
<p>Which customers are happy customers?</p>
<p>======</p>
<h3 id="bnp-paribas-cardif-claims-managementhttpswwwkagglecomcbnp-paribas-cardif-claims-management"><a href="https://www.kaggle.com/c/bnp-paribas-cardif-claims-management">BNP Paribas Cardif Claims Management</a></h3>
<p>Wed 3 Feb 2016 – Mon 18 Apr 2016</p>
<p>Can you accelerate BNP Paribas Cardif's claims management process?</p>
<p>======</p>
<h3 id="march-machine-learning-mania-2016httpswwwkagglecomcmarch-machine-learning-mania-2016"><a href="https://www.kaggle.com/c/march-machine-learning-mania-2016">March Machine Learning Mania 2016</a></h3>
<p>Thu 11 Feb 2016 – Tue 5 Apr 2016</p>
<p>Predict the 2016 NCAA Basketball Tournament</p>
<p>======</p>
<h3 id="telstra-network-disruptionshttpswwwkagglecomctelstra-recruiting-network"><a href="https://www.kaggle.com/c/telstra-recruiting-network">Telstra Network Disruptions</a></h3>
<p>Wed 25 Nov 2015 – Mon 29 Feb 2016</p>
<p>Telstra is challenging Kagglers to predict the severity of service disruptions on their network. Using a dataset of features from their service logs, you're tasked with predicting if a disruption is a momentary glitch or a total interruption of connectivity.</p>
<p>======</p>
<h3 id="prudential-life-insurance-assessmenthttpswwwkagglecomcprudential-life-insurance-assessment"><a href="https://www.kaggle.com/c/prudential-life-insurance-assessment">Prudential Life Insurance Assessment</a></h3>
<p>Mon 23 Nov 2015 – Mon 15 Feb 2016</p>
<p>By developing a predictive model that accurately classifies risk using a more automated approach, you can greatly impact public perception of the industry.</p>
<p>======</p>
<h3 id="the-allen-ai-science-challengehttpswwwkagglecomcthe-allen-ai-science-challenge"><a href="https://www.kaggle.com/c/the-allen-ai-science-challenge">The Allen AI Science Challenge</a></h3>
<p>Wed 7 Oct 2015 – Sat 13 Feb 2016</p>
<p>Using a dataset of multiple choice question and answers from a standardized 8th grade science exam, AI2 is challenging you to create a model that gets to the head of the class.</p>
<p>======</p>
<h3 id="airbnb-new-user-bookingshttpswwwkagglecomcairbnb-recruiting-new-user-bookings"><a href="https://www.kaggle.com/c/airbnb-recruiting-new-user-bookings">Airbnb New User Bookings</a></h3>
<p>Wed 25 Nov 2015 – Thu 11 Feb 2016</p>
<p>In this recruiting competition, Airbnb challenges you to predict in which country a new user will make his or her first booking.</p>
<p>======</p>
<h3 id="homesite-quote-conversionhttpswwwkagglecomchomesite-quote-conversion"><a href="https://www.kaggle.com/c/homesite-quote-conversion">Homesite Quote Conversion</a></h3>
<p>Mon 9 Nov 2015 – Mon 8 Feb 2016</p>
<p>Which customers will purchase a quoted insurance plan?</p>
<p>======</p>
<h3 id="walmart-recruiting-trip-type-classificationhttpswwwkagglecomcwalmart-recruiting-trip-type-classification"><a href="https://www.kaggle.com/c/walmart-recruiting-trip-type-classification">Walmart Recruiting: Trip Type Classification</a></h3>
<p>Mon 26 Oct 2015 – Sun 27 Dec 2015</p>
<p>Walmart is challenging Kagglers to focus on the (data) science and classify customer trips using only a transactional dataset of the items they've purchased.</p>
<p>======</p>
<h3 id="whats-cookinghttpswwwkagglecomcwhats-cooking"><a href="https://www.kaggle.com/c/whats-cooking">What's Cooking?</a></h3>
<p>Wed 9 Sep 2015 – Sun 20 Dec 2015</p>
<p>Use recipe ingredients to categorize the cuisine</p>
<p>======</p>
<h3 id="springleaf-marketing-responsehttpswwwkagglecomcspringleaf-marketing-response"><a href="https://www.kaggle.com/c/springleaf-marketing-response">Springleaf Marketing Response</a></h3>
<p>Fri 14 Aug 2015 – Mon 19 Oct 2015</p>
<p>Determine whether to send a direct mail piece to a customer</p>
<p>======</p>
<h3 id="truly-nativehttpswwwkagglecomcdato-native"><a href="https://www.kaggle.com/c/dato-native">Truly Native?</a></h3>
<p>Thu 6 Aug 2015 – Wed 14 Oct 2015</p>
<p>Predict which web pages served by StumbleUpon are sponsored</p>
<p>======</p>
<h3 id="flavours-of-physics-finding---httpswwwkagglecomcflavours-of-physics"><a href="https://www.kaggle.com/c/flavours-of-physics">Flavours of Physics: Finding τ → μμμ</a></h3>
<p>Mon 20 Jul 2015 – Mon 12 Oct 2015</p>
<p>Identify a rare decay phenomenon</p>
<p>======</p>
<h3 id="avito-context-ad-clickshttpswwwkagglecomcavito-context-ad-clicks"><a href="https://www.kaggle.com/c/avito-context-ad-clicks">Avito Context Ad Clicks</a></h3>
<p>Tue 2 Jun 2015 – Tue 28 Jul 2015</p>
<p>Predict if context ads will earn a user's click</p>
<p>======</p>
<h3 id="crowdflower-search-results-relevancehttpswwwkagglecomccrowdflower-search-relevance"><a href="https://www.kaggle.com/c/crowdflower-search-relevance">Crowdflower Search Results Relevance</a></h3>
<p>Mon 11 May 2015 – Mon 6 Jul 2015</p>
<p>Predict the relevance of search results from eCommerce sites</p>
<p>======</p>
<h3 id="west-nile-virus-predictionhttpswwwkagglecomcpredict-west-nile-virus"><a href="https://www.kaggle.com/c/predict-west-nile-virus">West Nile Virus Prediction</a></h3>
<p>Wed 22 Apr 2015 – Wed 17 Jun 2015</p>
<p>Predict West Nile virus in mosquitos across the city of Chicago</p>
<p>======</p>
<h3 id="facebook-recruiting-iv-human-or-robothttpswwwkagglecomcfacebook-recruiting-iv-human-or-bot"><a href="https://www.kaggle.com/c/facebook-recruiting-iv-human-or-bot">Facebook Recruiting IV: Human or Robot?</a></h3>
<p>Mon 27 Apr 2015 – Mon 8 Jun 2015</p>
<p>The goal of this competition is to identify online auction bids that are placed by &ldquo;robots&rdquo;, helping the site owners easily flag these users for removal from their site to prevent unfair auction activity.</p>
<p>======</p>
<h3 id="poker-rule-inductionhttpswwwkagglecomcpoker-rule-induction"><a href="https://www.kaggle.com/c/poker-rule-induction">Poker Rule Induction</a></h3>
<p>Wed 3 Dec 2014 – Mon 1 Jun 2015</p>
<p>Determine the poker hand of five playing cards</p>
<p>======</p>
<h3 id="random-acts-of-pizzahttpswwwkagglecomcrandom-acts-of-pizza"><a href="https://www.kaggle.com/c/random-acts-of-pizza">Random Acts of Pizza</a></h3>
<p>Thu 29 May 2014 – Mon 1 Jun 2015</p>
<p>Predicting altruism through free pizza</p>
<p>======</p>
<h3 id="otto-group-product-classification-challengehttpswwwkagglecomcotto-group-product-classification-challenge"><a href="https://www.kaggle.com/c/otto-group-product-classification-challenge">Otto Group Product Classification Challenge</a></h3>
<p>Tue 17 Mar 2015 – Mon 18 May 2015</p>
<p>Classify products into the correct category</p>
<p>======</p>
<h3 id="forest-cover-type-predictionhttpswwwkagglecomcforest-cover-type-prediction"><a href="https://www.kaggle.com/c/forest-cover-type-prediction">Forest Cover Type Prediction</a></h3>
<p>Fri 16 May 2014 – Mon 11 May 2015</p>
<p>Use cartographic variables to classify forest categories</p>
<p>======</p>
<h3 id="microsoft-malware-classification-challenge-big-2015httpswwwkagglecomcmalware-classification"><a href="https://www.kaggle.com/c/malware-classification">Microsoft Malware Classification Challenge (BIG 2015)</a></h3>
<p>Tue 3 Feb 2015 – Fri 17 Apr 2015</p>
<p>Classify malware into families based on file content and characteristics</p>
<p>======</p>
<h3 id="march-machine-learning-mania-2015httpswwwkagglecomcmarch-machine-learning-mania-2015"><a href="https://www.kaggle.com/c/march-machine-learning-mania-2015">March Machine Learning Mania 2015</a></h3>
<p>Mon 2 Feb 2015 – Tue 7 Apr 2015</p>
<p>Predict the 2015 NCAA Basketball Tournament</p>
<p>======</p>
<h3 id="bci-challenge--ner-2015httpswwwkagglecomcinria-bci-challenge"><a href="https://www.kaggle.com/c/inria-bci-challenge">BCI Challenge @ NER 2015</a></h3>
<p>Wed 19 Nov 2014 – Tue 24 Feb 2015</p>
<p>A spell on you if you cannot detect errors!</p>
<p>======</p>
<h3 id="click-through-rate-predictionhttpswwwkagglecomcavazu-ctr-prediction"><a href="https://www.kaggle.com/c/avazu-ctr-prediction">Click-Through Rate Prediction</a></h3>
<p>Tue 18 Nov 2014 – Mon 9 Feb 2015</p>
<p>Predict whether a mobile ad will be clicked</p>
<p>======</p>
<h3 id="data-science-london--scikit-learnhttpswwwkagglecomcdata-science-london-scikit-learn"><a href="https://www.kaggle.com/c/data-science-london-scikit-learn">Data Science London + Scikit-learn</a></h3>
<p>Wed 6 Mar 2013 – Wed 31 Dec 2014</p>
<p>Scikit-learn is an open-source machine learning library for Python. Give it a try here!</p>
<p>======</p>
<h3 id="display-advertising-challengehttpswwwkagglecomccriteo-display-ad-challenge"><a href="https://www.kaggle.com/c/criteo-display-ad-challenge">Display Advertising Challenge</a></h3>
<p>Tue 24 Jun 2014 – Tue 23 Sep 2014</p>
<p>Predict click-through rates on display ads</p>
<p>======</p>
<h3 id="mlsp-2014-schizophrenia-classification-challengehttpswwwkagglecomcmlsp-2014-mri"><a href="https://www.kaggle.com/c/mlsp-2014-mri">MLSP 2014 Schizophrenia Classification Challenge</a></h3>
<p>Thu 5 Jun 2014 – Sun 20 Jul 2014</p>
<p>Diagnose schizophrenia using multimodal features from MRI scans</p>
<p>======</p>
<h3 id="greek-media-monitoring-multilabel-classification-wise-2014httpswwwkagglecomcwise-2014"><a href="https://www.kaggle.com/c/wise-2014">Greek Media Monitoring Multilabel Classification (WISE 2014)</a></h3>
<p>Mon 2 Jun 2014 – Tue 15 Jul 2014</p>
<p>Multi-label classification of printed media articles to topics</p>
<p>======</p>
<h3 id="kdd-cup-2014---predicting-excitement-at-donorschooseorghttpswwwkagglecomckdd-cup-2014-predicting-excitement-at-donors-choose"><a href="https://www.kaggle.com/c/kdd-cup-2014-predicting-excitement-at-donors-choose">KDD Cup 2014 - Predicting Excitement at DonorsChoose.org</a></h3>
<p>Thu 15 May 2014 – Tue 15 Jul 2014</p>
<p>Predict funding requests that deserve an A+</p>
<p>======</p>
<h3 id="acquire-valued-shoppers-challengehttpswwwkagglecomcacquire-valued-shoppers-challenge"><a href="https://www.kaggle.com/c/acquire-valued-shoppers-challenge">Acquire Valued Shoppers Challenge</a></h3>
<p>Thu 10 Apr 2014 – Mon 14 Jul 2014</p>
<p>Predict which shoppers will become repeat buyers</p>
<p>======</p>
<h3 id="allstate-purchase-prediction-challengehttpswwwkagglecomcallstate-purchase-prediction-challenge"><a href="https://www.kaggle.com/c/allstate-purchase-prediction-challenge">Allstate Purchase Prediction Challenge</a></h3>
<p>Tue 18 Feb 2014 – Mon 19 May 2014</p>
<p>Predict a purchased policy based on transaction history</p>
<p>======</p>
<h3 id="march-machine-learning-maniahttpswwwkagglecomcmarch-machine-learning-mania"><a href="https://www.kaggle.com/c/march-machine-learning-mania">March Machine Learning Mania</a></h3>
<p>Tue 7 Jan 2014 – Tue 8 Apr 2014</p>
<p>Tip off college basketball by predicting the 2014 NCAA Tournament</p>
<p>======</p>
<h3 id="accelerometer-biometric-competitionhttpswwwkagglecomcaccelerometer-biometric-competition"><a href="https://www.kaggle.com/c/accelerometer-biometric-competition">Accelerometer Biometric Competition</a></h3>
<p>Tue 23 Jul 2013 – Fri 22 Nov 2013</p>
<p>Recognize users of mobile devices from accelerometer data</p>
<p>======</p>
<h3 id="stumbleupon-evergreen-classification-challengehttpswwwkagglecomcstumbleupon"><a href="https://www.kaggle.com/c/stumbleupon">StumbleUpon Evergreen Classification Challenge</a></h3>
<p>Fri 16 Aug 2013 – Thu 31 Oct 2013</p>
<p>Build a classifier to categorize webpages as evergreen or non-evergreen</p>
<p>======</p>
<h3 id="cause-effect-pairshttpswwwkagglecomccause-effect-pairs"><a href="https://www.kaggle.com/c/cause-effect-pairs">Cause-effect pairs</a></h3>
<p>Fri 29 Mar 2013 – Mon 2 Sep 2013</p>
<p>Given samples from a pair of variables A, B, find whether A is a cause of B.</p>
<p>======</p>
<h3 id="amazoncom---employee-access-challengehttpswwwkagglecomcamazon-employee-access-challenge"><a href="https://www.kaggle.com/c/amazon-employee-access-challenge">Amazon.com - Employee Access Challenge</a></h3>
<p>Wed 29 May 2013 – Wed 31 Jul 2013</p>
<p>Predict an employee's access needs, given his/her job role</p>
<p>======</p>
<h3 id="kdd-cup-2013---author-disambiguation-challenge-track-2httpswwwkagglecomckdd-cup-2013-author-disambiguation"><a href="https://www.kaggle.com/c/kdd-cup-2013-author-disambiguation">KDD Cup 2013 - Author Disambiguation Challenge (Track 2)</a></h3>
<p>Fri 19 Apr 2013 – Wed 12 Jun 2013</p>
<p>Identify which authors correspond to the same person</p>
<p>======</p>
<h3 id="predict-closed-questions-on-stack-overflowhttpswwwkagglecomcpredict-closed-questions-on-stack-overflow"><a href="https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow">Predict Closed Questions on Stack Overflow</a></h3>
<p>Tue 21 Aug 2012 – Sat 3 Nov 2012</p>
<p>Predict which new questions asked on Stack Overflow will be closed</p>
<p>======</p>
<h3 id="merck-molecular-activity-challengehttpswwwkagglecomcmerckactivity"><a href="https://www.kaggle.com/c/MerckActivity">Merck Molecular Activity Challenge</a></h3>
<p>Thu 16 Aug 2012 – Tue 16 Oct 2012</p>
<p>Help develop safe and effective medicines by predicting molecular activity.</p>
<p>======</p>
<h3 id="data-mining-hackathon-on-big-data-7gb-best-buy-mobile-web-sitehttpswwwkagglecomcacm-sf-chapter-hackathon-big"><a href="https://www.kaggle.com/c/acm-sf-chapter-hackathon-big">Data Mining Hackathon on BIG DATA (7GB) Best Buy mobile web site</a></h3>
<p>Sat 18 Aug 2012 – Sun 30 Sep 2012</p>
<p>Predict which BestBuy product a mobile web visitor will be most interested in based on their search query or behavior over 2 years (7 GB).</p>
<p>======</p>
<h3 id="data-mining-hackathon-on-20-mb-best-buy-mobile-web-site---acm-sf-bay-area-chapterhttpswwwkagglecomcacm-sf-chapter-hackathon-small"><a href="https://www.kaggle.com/c/acm-sf-chapter-hackathon-small">Data Mining Hackathon on (20 mb) Best Buy mobile web site - ACM SF Bay Area Chapter</a></h3>
<p>Sat 18 Aug 2012 – Sun 30 Sep 2012</p>
<p>Getting Started - Predict which Xbox game a visitor will be most interested in based on their search query. (20 MB)</p>
<p>======</p>
<h3 id="practice-fusion-diabetes-classificationhttpswwwkagglecomcpf2012-diabetes"><a href="https://www.kaggle.com/c/pf2012-diabetes">Practice Fusion Diabetes Classification</a></h3>
<p>Tue 10 Jul 2012 – Mon 10 Sep 2012</p>
<p>Identify patients diagnosed with Type 2 Diabetes</p>
<p>======</p>
<h3 id="personality-prediction-based-on-twitter-streamhttpswwwkagglecomctwitter-personality-prediction"><a href="https://www.kaggle.com/c/twitter-personality-prediction">Personality Prediction Based on Twitter Stream</a></h3>
<p>Tue 8 May 2012 – Fri 29 Jun 2012</p>
<p>Identify the best performing model(s) to predict personality traits based on Twitter usage</p>
<p>======</p>
<h3 id="predicting-a-biological-responsehttpswwwkagglecomcbioresponse"><a href="https://www.kaggle.com/c/bioresponse">Predicting a Biological Response</a></h3>
<p>Fri 16 Mar 2012 – Fri 15 Jun 2012</p>
<p>Predict a biological response of molecules from their chemical properties</p>
<p>======</p>
<h3 id="eye-movements-verification-and-identification-competitionhttpswwwkagglecomcemvic"><a href="https://www.kaggle.com/c/emvic">Eye Movements Verification and Identification Competition</a></h3>
<p>Tue 20 Mar 2012 – Sun 15 Apr 2012</p>
<p>Determine how people may be identified based on their eye movement characteristic.</p>
<p>======</p>
<h3 id="what-do-you-knowhttpswwwkagglecomcwhatdoyouknow"><a href="https://www.kaggle.com/c/WhatDoYouKnow">What Do You Know?</a></h3>
<p>Fri 18 Nov 2011 – Wed 29 Feb 2012</p>
<p>Improve the state of the art in student evaluation by predicting whether a student will answer the next test question correctly.</p>
<p>======</p>
<h3 id="dont-get-kickedhttpswwwkagglecomcdontgetkicked"><a href="https://www.kaggle.com/c/DontGetKicked">Don't Get Kicked!</a></h3>
<p>Fri 30 Sep 2011 – Thu 5 Jan 2012</p>
<p>Predict if a car purchased at auction is a lemon (new car with defects)</p>
<p>======</p>
<h3 id="give-me-some-credithttpswwwkagglecomcgivemesomecredit"><a href="https://www.kaggle.com/c/GiveMeSomeCredit">Give Me Some Credit</a></h3>
<p>Mon 19 Sep 2011 – Thu 15 Dec 2011</p>
<p>Improve on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.</p>
<p>======</p>
<h3 id="photo-quality-predictionhttpswwwkagglecomcphotoqualityprediction"><a href="https://www.kaggle.com/c/PhotoQualityPrediction">Photo Quality Prediction</a></h3>
<p>Sat 29 Oct 2011 – Sun 20 Nov 2011</p>
<p>Given anonymized information on thousands of photo albums, predict whether a human evaluator would mark them as &lsquo;good&rsquo;.</p>
<p>======</p>
<h3 id="dont-overfithttpswwwkagglecomcoverfitting"><a href="https://www.kaggle.com/c/overfitting">Don't Overfit!</a></h3>
<p>Mon 28 Feb 2011 – Sun 15 May 2011</p>
<p>With nearly as many variables as training cases, what are the best techniques to avoid disaster?</p>
<p>======</p>
<h3 id="stay-alert-the-ford-challengehttpswwwkagglecomcstayalert"><a href="https://www.kaggle.com/c/stayalert">Stay Alert! The Ford Challenge</a></h3>
<p>Wed 19 Jan 2011 – Wed 9 Mar 2011</p>
<p>Driving while not alert can be deadly. The objective is to design a classifier that will detect whether the driver is alert or not alert, employing data that are acquired while driving.</p>
<p>======</p>
<h3 id="predict-grant-applicationshttpswwwkagglecomcunimelb"><a href="https://www.kaggle.com/c/unimelb">Predict Grant Applications</a></h3>
<p>Mon 13 Dec 2010 – Sun 20 Feb 2011</p>
<p>This task requires participants to predict the outcome of grant applications for the University of Melbourne.</p>
<p>======</p>
<h3 id="ijcnn-social-network-challengehttpswwwkagglecomcsocialnetwork"><a href="https://www.kaggle.com/c/socialNetwork">IJCNN Social Network Challenge</a></h3>
<p>Mon 8 Nov 2010 – Tue 11 Jan 2011</p>
<p>This competition requires participants to predict edges in an online social network. The winner will receive free registration and the opportunity to present their solution at IJCNN 2011.</p>
<p>======</p>
<h3 id="r-package-recommendation-enginehttpswwwkagglecomcr"><a href="https://www.kaggle.com/c/R">R Package Recommendation Engine</a></h3>
<p>Sun 10 Oct 2010 – Tue 8 Feb 2011</p>
<p>The aim of this competition is to develop a recommendation engine for R libraries (or packages). (R is opensource statistics software.)</p>
<p>======</p>
<h3 id="informs-data-mining-contest-2010httpswwwkagglecomcinforms2010"><a href="https://www.kaggle.com/c/informs2010">INFORMS Data Mining Contest 2010</a></h3>
<p>Mon 21 Jun 2010 – Sun 10 Oct 2010</p>
<p>The goal of this contest is to predict short term movements in stock prices. The winners of this contest will be honoured of the INFORMS Annual Meeting in Austin-Texas (November 7-10).</p>
<p>======</p>
<h3 id="predict-hiv-progressionhttpswwwkagglecomchivprogression"><a href="https://www.kaggle.com/c/hivprogression">Predict HIV Progression</a></h3>
<p>Tue 27 Apr 2010 – Mon 2 Aug 2010</p>
<p>This contest requires competitors to predict the likelihood that an HIV patient's infection will become less severe, given a small dataset and limited clinical information.</p>
<p>======</p>
<h3 id="forecast-eurovision-votinghttpswwwkagglecomceurovision2010"><a href="https://www.kaggle.com/c/Eurovision2010">Forecast Eurovision Voting</a></h3>
<p>Wed 7 Apr 2010 – Tue 25 May 2010</p>
<p>This competition requires contestants to forecast the voting for this year's Eurovision Song Contest in Norway on May 25th, 27th and 29th.</p>
<p>======</p>
]]></content>
        </item>
        
        <item>
            <title>Insights pour Use Cases Regressions Machine Learning</title>
            <link>https://leandeep.com/insights-pour-use-cases-regressions-machine-learning/</link>
            <pubDate>Sat, 23 Jul 2016 19:30:00 +0000</pubDate>
            
            <guid>https://leandeep.com/insights-pour-use-cases-regressions-machine-learning/</guid>
            <description>Cette compilation de compétitions Kaggle autour de sujets de regression peut vous faire gagner du temps dans vos propres Use Cases.
======
Grupo Bimbo Inventory Demand Wed 8 Jun 2016 - Tue 30 Aug 2016
Maximize sales and minimize returns of bakery goods
======
Kobe Bryant Shot Selection Fri 15 Apr 2016 – Mon 13 Jun 2016
Which shots did Kobe sink?
======
Home Depot Product Search Relevance Mon 18 Jan 2016 – Mon 25 Apr 2016</description>
            <content type="html"><![CDATA[<p>Cette compilation de compétitions Kaggle autour de sujets de regression peut vous faire gagner du temps dans vos propres Use Cases.</p>
<p>======</p>
<h3 id="grupo-bimbo-inventory-demandhttpswwwkagglecomcgrupo-bimbo-inventory-demand"><a href="https://www.kaggle.com/c/grupo-bimbo-inventory-demand">Grupo Bimbo Inventory Demand</a></h3>
<p>Wed 8 Jun 2016 - Tue 30 Aug 2016</p>
<p>Maximize sales and minimize returns of bakery goods</p>
<p>======</p>
<h3 id="kobe-bryant-shot-selectionhttpswwwkagglecomckobe-bryant-shot-selection"><a href="https://www.kaggle.com/c/kobe-bryant-shot-selection">Kobe Bryant Shot Selection</a></h3>
<p>Fri 15 Apr 2016 – Mon 13 Jun 2016</p>
<p>Which shots did Kobe sink?</p>
<p>======</p>
<h3 id="home-depot-product-search-relevancehttpswwwkagglecomchome-depot-product-search-relevance"><a href="https://www.kaggle.com/c/home-depot-product-search-relevance">Home Depot Product Search Relevance</a></h3>
<p>Mon 18 Jan 2016 – Mon 25 Apr 2016</p>
<p>Predict the relevance of search results on homedepot.com</p>
<p>======</p>
<h3 id="rossmann-store-saleshttpswwwkagglecomcrossmann-store-sales"><a href="https://www.kaggle.com/c/rossmann-store-sales">Rossmann Store Sales</a></h3>
<p>Wed 30 Sep 2015 – Mon 14 Dec 2015</p>
<p>Forecast sales using store, promotion, and competitor data</p>
<p>======</p>
<h3 id="how-much-did-it-rain-iihttpswwwkagglecomchow-much-did-it-rain-ii"><a href="https://www.kaggle.com/c/how-much-did-it-rain-ii">How Much Did It Rain? II</a></h3>
<p>Thu 17 Sep 2015 – Mon 7 Dec 2015</p>
<p>Predict hourly rainfall using data from polarimetric radars</p>
<p>======</p>
<h3 id="caterpillar-tube-pricinghttpswwwkagglecomccaterpillar-tube-pricing"><a href="https://www.kaggle.com/c/caterpillar-tube-pricing">Caterpillar Tube Pricing</a></h3>
<p>Mon 29 Jun 2015 – Mon 31 Aug 2015</p>
<p>Model quoted prices for industrial tube assemblies</p>
<p>======</p>
<h3 id="liberty-mutual-group-property-inspection-predictionhttpswwwkagglecomcliberty-mutual-group-property-inspection-prediction"><a href="https://www.kaggle.com/c/liberty-mutual-group-property-inspection-prediction">Liberty Mutual Group: Property Inspection Prediction</a></h3>
<p>Mon 6 Jul 2015 – Fri 28 Aug 2015</p>
<p>Quantify property hazards before time of inspection</p>
<p>======</p>
<h3 id="ecmlpkdd-15-taxi-trip-time-prediction-iihttpswwwkagglecomcpkdd-15-taxi-trip-time-prediction-ii"><a href="https://www.kaggle.com/c/pkdd-15-taxi-trip-time-prediction-ii">ECML/PKDD 15: Taxi Trip Time Prediction (II)</a></h3>
<p>Fri 24 Apr 2015 – Wed 1 Jul 2015</p>
<p>Predict the total travel time of taxi trips based on their initial partial trajectories</p>
<p>======</p>
<h3 id="bike-sharing-demandhttpswwwkagglecomcbike-sharing-demand"><a href="https://www.kaggle.com/c/bike-sharing-demand">Bike Sharing Demand</a></h3>
<p>Wed 28 May 2014 – Fri 29 May 2015</p>
<p>Forecast use of a city bikeshare system</p>
<p>======</p>
<h3 id="walmart-recruiting-ii-sales-in-stormy-weatherhttpswwwkagglecomcwalmart-recruiting-sales-in-stormy-weather"><a href="https://www.kaggle.com/c/walmart-recruiting-sales-in-stormy-weather">Walmart Recruiting II: Sales in Stormy Weather</a></h3>
<p>Wed 1 Apr 2015 – Mon 25 May 2015</p>
<p>Walmart challenges participants to accurately predict the sales of 111 potentially weather-sensitive products (like umbrellas, bread, and milk) around the time of major weather events at 45 of their retail locations.</p>
<p>======</p>
<h3 id="how-much-did-it-rainhttpswwwkagglecomchow-much-did-it-rain"><a href="https://www.kaggle.com/c/how-much-did-it-rain">How Much Did It Rain?</a></h3>
<p>Fri 9 Jan 2015 – Fri 15 May 2015</p>
<p>Predict probabilistic distribution of hourly rain given polarimetric radar measurements</p>
<p>======</p>
<h3 id="restaurant-revenue-predictionhttpswwwkagglecomcrestaurant-revenue-prediction"><a href="https://www.kaggle.com/c/restaurant-revenue-prediction">Restaurant Revenue Prediction</a></h3>
<p>Mon 23 Mar 2015 – Mon 4 May 2015</p>
<p>Predict annual restaurant sales based on objective measurements</p>
<p>======</p>
<h3 id="finding-elohttpswwwkagglecomcfinding-elo"><a href="https://www.kaggle.com/c/finding-elo">Finding Elo</a></h3>
<p>Mon 20 Oct 2014 – Mon 23 Mar 2015</p>
<p>Predict a chess player's FIDE Elo rating from one game</p>
<p>======</p>
<h3 id="africa-soil-property-prediction-challengehttpswwwkagglecomcafsis-soil-properties"><a href="https://www.kaggle.com/c/afsis-soil-properties">Africa Soil Property Prediction Challenge</a></h3>
<p>Wed 27 Aug 2014 – Tue 21 Oct 2014</p>
<p>Predict physical and chemical properties of soil using spectral measurements</p>
<p>======</p>
<h3 id="liberty-mutual-group---fire-peril-loss-costhttpswwwkagglecomcliberty-mutual-fire-peril"><a href="https://www.kaggle.com/c/liberty-mutual-fire-peril">Liberty Mutual Group - Fire Peril Loss Cost</a></h3>
<p>Tue 8 Jul 2014 – Tue 2 Sep 2014</p>
<p>Predict expected fire losses for insurance policies</p>
<p>======</p>
<h3 id="walmart-recruiting---store-sales-forecastinghttpswwwkagglecomcwalmart-recruiting-store-sales-forecasting"><a href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting">Walmart Recruiting - Store Sales Forecasting</a></h3>
<p>Thu 20 Feb 2014 – Mon 5 May 2014</p>
<p>In this recruiting competition, job-seekers are provided with historical sales data for 45 Walmart stores located in different regions. Each store contains many departments, and participants must project the sales for each department in each store.</p>
<p>======</p>
<h3 id="pakdd-2014---asus-malfunctional-components-predictionhttpswwwkagglecomcpakdd-cup-2014"><a href="https://www.kaggle.com/c/pakdd-cup-2014">PAKDD 2014 - ASUS Malfunctional Components Prediction</a></h3>
<p>Sun 26 Jan 2014 – Tue 1 Apr 2014</p>
<p>Predict malfunctional components of ASUS notebooks</p>
<p>======</p>
<h3 id="loan-default-prediction---imperial-college-londonhttpswwwkagglecomcloan-default-prediction"><a href="https://www.kaggle.com/c/loan-default-prediction">Loan Default Prediction - Imperial College London</a></h3>
<p>Fri 17 Jan 2014 – Fri 14 Mar 2014</p>
<p>Constructing an optimal portfolio of loans</p>
<p>======</p>
<h3 id="see-click-predict-fixhttpswwwkagglecomcsee-click-predict-fix"><a href="https://www.kaggle.com/c/see-click-predict-fix">See Click Predict Fix</a></h3>
<p>Sun 29 Sep 2013 – Wed 27 Nov 2013</p>
<p>Predict which 311 issues are most important to citizens</p>
<p>======</p>
<h3 id="ams-2013-2014-solar-energy-prediction-contesthttpswwwkagglecomcams-2014-solar-energy-prediction-contest"><a href="https://www.kaggle.com/c/ams-2014-solar-energy-prediction-contest">AMS 2013-2014 Solar Energy Prediction Contest</a></h3>
<p>Mon 8 Jul 2013 – Fri 15 Nov 2013</p>
<p>Forecast daily solar energy with an ensemble of weather models</p>
<p>======</p>
<h3 id="the-big-data-combine-engineered-by-battlefinhttpswwwkagglecomcbattlefin-s-big-data-combine-forecasting-challenge"><a href="https://www.kaggle.com/c/battlefin-s-big-data-combine-forecasting-challenge">The Big Data Combine Engineered by BattleFin</a></h3>
<p>Fri 16 Aug 2013 – Tue 1 Oct 2013</p>
<p>Predict short term movements in stock prices using news and sentiment data provided by RavenPack</p>
<p>======</p>
<h3 id="see-click-predict-fix---hackathonhttpswwwkagglecomcthe-seeclickfix-311-challenge"><a href="https://www.kaggle.com/c/the-seeclickfix-311-challenge">See Click Predict Fix - Hackathon</a></h3>
<p>Sat 28 Sep 2013 – Sun 29 Sep 2013</p>
<p>Predict which 311 issues are most important to citizens</p>
<p>======</p>
<h3 id="recsys2013-yelp-business-rating-predictionhttpswwwkagglecomcyelp-recsys-2013"><a href="https://www.kaggle.com/c/yelp-recsys-2013">RecSys2013: Yelp Business Rating Prediction</a></h3>
<p>Wed 24 Apr 2013 – Sat 31 Aug 2013</p>
<p>RecSys Challenge 2013: Yelp business rating prediction</p>
<p>======</p>
<h3 id="yelp-recruiting-competitionhttpswwwkagglecomcyelp-recruiting"><a href="https://www.kaggle.com/c/yelp-recruiting">Yelp Recruiting Competition</a></h3>
<p>Wed 27 Mar 2013 – Sun 30 Jun 2013</p>
<p>The goal of this competition is to estimate the number of Useful votes a review will receive.</p>
<p>======</p>
<h3 id="dunnhumby--hackreduce-product-launch-challengehttpswwwkagglecomchack-reduce-dunnhumby-hackathon"><a href="https://www.kaggle.com/c/hack-reduce-dunnhumby-hackathon">dunnhumby &amp; hack/reduce Product Launch Challenge</a></h3>
<p>Sat 11 May 2013 – Sat 11 May 2013</p>
<p>The success or failure of a new product launch is often evident within the first few weeks of sales. Can you predict a product's destiny?</p>
<p>======</p>
<h3 id="icdar2013---handwriting-stroke-recovery-from-offline-datahttpswwwkagglecomcicdar2013-stroke-recovery-from-offline-data"><a href="https://www.kaggle.com/c/icdar2013-stroke-recovery-from-offline-data">ICDAR2013 - Handwriting Stroke Recovery from Offline Data</a></h3>
<p>Wed 20 Mar 2013 – Sat 20 Apr 2013</p>
<p>Predict the trajectory of a handwritten signature</p>
<p>======</p>
<h3 id="blue-book-for-bulldozershttpswwwkagglecomcbluebook-for-bulldozers"><a href="https://www.kaggle.com/c/bluebook-for-bulldozers">Blue Book for Bulldozers</a></h3>
<p>Fri 25 Jan 2013 – Wed 17 Apr 2013</p>
<p>Predict the auction sale price for a piece of heavy equipment to create a &ldquo;blue book&rdquo; for bulldozers.</p>
<p>======</p>
<h3 id="job-salary-predictionhttpswwwkagglecomcjob-salary-prediction"><a href="https://www.kaggle.com/c/job-salary-prediction">Job Salary Prediction</a></h3>
<p>Wed 13 Feb 2013 – Wed 3 Apr 2013</p>
<p>Predict the salary of any UK job ad based on its contents.</p>
<p>======</p>
<h3 id="observing-dark-worldshttpswwwkagglecomcdarkworlds"><a href="https://www.kaggle.com/c/DarkWorlds">Observing Dark Worlds</a></h3>
<p>Fri 12 Oct 2012 – Sun 16 Dec 2012</p>
<p>Can you find the Dark Matter that dominates our Universe? Winton Capital offers you the chance to unlock the secrets of dark worlds.</p>
<p>======</p>
<h3 id="us-census-return-rate-challengehttpswwwkagglecomcus-census-challenge"><a href="https://www.kaggle.com/c/us-census-challenge">U.S. Census Return Rate Challenge</a></h3>
<p>Fri 31 Aug 2012 – Sun 11 Nov 2012</p>
<p>Predict census mail return rates.</p>
<p>======</p>
<h3 id="global-energy-forecasting-competition-2012---wind-forecastinghttpswwwkagglecomcgef2012-wind-forecasting"><a href="https://www.kaggle.com/c/GEF2012-wind-forecasting">Global Energy Forecasting Competition 2012 - Wind Forecasting</a></h3>
<p>Thu 6 Sep 2012 – Wed 31 Oct 2012</p>
<p>A wind power forecasting problem: predicting hourly power generation up to 48 hours ahead at 7 wind farms</p>
<p>======</p>
<h3 id="global-energy-forecasting-competition-2012---load-forecastinghttpswwwkagglecomcglobal-energy-forecasting-competition-2012-load-forecasting"><a href="https://www.kaggle.com/c/global-energy-forecasting-competition-2012-load-forecasting">Global Energy Forecasting Competition 2012 - Load Forecasting</a></h3>
<p>Sat 1 Sep 2012 – Wed 31 Oct 2012</p>
<p>A hierarchical load forecasting problem: backcasting and forecasting hourly loads (in kW) for a US utility with 20 zones.</p>
<p>======</p>
<h3 id="raising-money-to-fund-an-organizational-missionhttpswwwkagglecomcraising-money-to-fund-an-organizational-mission"><a href="https://www.kaggle.com/c/Raising-Money-to-Fund-an-Organizational-Mission">Raising Money to Fund an Organizational Mission</a></h3>
<p>Wed 18 Jul 2012 – Tue 18 Sep 2012</p>
<p>Help worthy organizations more efficiently target and recruit loyal donors to support their causes.</p>
<p>======</p>
<h3 id="online-product-saleshttpswwwkagglecomconline-sales"><a href="https://www.kaggle.com/c/online-sales">Online Product Sales</a></h3>
<p>Fri 4 May 2012 – Tue 3 Jul 2012</p>
<p>Predict the online sales of a consumer product based on a data set of product features.</p>
<p>======</p>
<h3 id="psychopathy-prediction-based-on-twitter-usagehttpswwwkagglecomctwitter-psychopathy-prediction"><a href="https://www.kaggle.com/c/twitter-psychopathy-prediction">Psychopathy Prediction Based on Twitter Usage</a></h3>
<p>Mon 14 May 2012 – Fri 29 Jun 2012</p>
<p>Identify people who have a high degree of Psychopathy based on Twitter usage.</p>
<p>======</p>
<h3 id="benchmark-bond-trade-price-challengehttpswwwkagglecomcbenchmark-bond-trade-price-challenge"><a href="https://www.kaggle.com/c/benchmark-bond-trade-price-challenge">Benchmark Bond Trade Price Challenge</a></h3>
<p>Fri 27 Jan 2012 – Mon 30 Apr 2012</p>
<p>Develop models to accurately predict the trade price of a bond.</p>
<p>======</p>
<h3 id="emc-data-science-global-hackathon-air-quality-predictionhttpswwwkagglecomcdsg-hackathon"><a href="https://www.kaggle.com/c/dsg-hackathon">EMC Data Science Global Hackathon (Air Quality Prediction)</a></h3>
<p>Sat 28 Apr 2012 – Sun 29 Apr 2012</p>
<p>Build a local early warning systems to accurately predict dangerous levels of air pollutants on an hourly basis.</p>
<p>======</p>
<h3 id="algorithmic-trading-challengehttpswwwkagglecomcalgorithmictradingchallenge"><a href="https://www.kaggle.com/c/AlgorithmicTradingChallenge">Algorithmic Trading Challenge</a></h3>
<p>Fri 11 Nov 2011 – Sun 8 Jan 2012</p>
<p>Develop new models to accurately predict the market response to large trades.</p>
<p>======</p>
<h3 id="allstate-claim-prediction-challengehttpswwwkagglecomcclaimpredictionchallenge"><a href="https://www.kaggle.com/c/ClaimPredictionChallenge">Allstate Claim Prediction Challenge</a></h3>
<p>Wed 13 Jul 2011 – Wed 12 Oct 2011</p>
<p>A key part of insurance is charging each customer the appropriate price for the risk they represent.</p>
<p>======</p>
<h3 id="dunnhumbys-shopper-challengehttpswwwkagglecomcdunnhumbychallenge"><a href="https://www.kaggle.com/c/dunnhumbychallenge">dunnhumby's Shopper Challenge</a></h3>
<p>Fri 29 Jul 2011 – Fri 30 Sep 2011</p>
<p>Going grocery shopping, we all have to do it, some even enjoy it, but can you predict it? dunnhumby is looking to build a model to better predict when supermarket shoppers will next visit the store and how much they will spend.</p>
<p>======</p>
<h3 id="wikipedias-participation-challengehttpswwwkagglecomcwikichallenge"><a href="https://www.kaggle.com/c/wikichallenge">Wikipedia's Participation Challenge</a></h3>
<p>Tue 28 Jun 2011 – Tue 20 Sep 2011</p>
<p>This competition challenges data-mining experts to build a predictive model that predicts the number of edits an editor will make five months from the end date of the training dataset.</p>
<p>======</p>
<h3 id="mapping-dark-matterhttpswwwkagglecomcmdm"><a href="https://www.kaggle.com/c/mdm">Mapping Dark Matter</a></h3>
<p>Mon 23 May 2011 – Thu 18 Aug 2011</p>
<p>Measure the small distortion in galaxy images caused by dark matter</p>
<p>======</p>
<h3 id="deloittefide-chess-rating-challengehttpswwwkagglecomcchessratings2"><a href="https://www.kaggle.com/c/ChessRatings2">Deloitte/FIDE Chess Rating Challenge</a></h3>
<p>Mon 7 Feb 2011 – Wed 4 May 2011</p>
<p>This contest, sponsored by professional services firm Deloitte, will find the most accurate system to predict chess outcomes, and FIDE will also bring a top finisher to Athens to present their system</p>
<p>======</p>
<h3 id="rta-freeway-travel-time-predictionhttpswwwkagglecomcrta"><a href="https://www.kaggle.com/c/RTA">RTA Freeway Travel Time Prediction</a></h3>
<p>Tue 23 Nov 2010 – Sun 13 Feb 2011</p>
<p>This competition requires participants to predict travel time on Sydney's M4 freeway from past travel time observations.</p>
<p>======</p>
<h3 id="tourism-forecasting-part-twohttpswwwkagglecomctourism2"><a href="https://www.kaggle.com/c/tourism2">Tourism Forecasting Part Two</a></h3>
<p>Mon 20 Sep 2010 – Sun 21 Nov 2010</p>
<p>Part two requires competitors to predict 793 tourism-related time series. The winner of this competition will be invited to contribute a discussion paper to the International Journal of Forecasting.</p>
<p>======</p>
<h3 id="chess-ratings---elo-versus-the-rest-of-the-worldhttpswwwkagglecomcchess"><a href="https://www.kaggle.com/c/chess">Chess ratings - Elo versus the Rest of the World</a></h3>
<p>Tue 3 Aug 2010 – Wed 17 Nov 2010</p>
<p>This competition aims to discover whether other approaches can predict the outcome of chess games more accurately than the workhorse Elo rating system.</p>
<p>======</p>
<h3 id="tourism-forecasting-part-onehttpswwwkagglecomctourism1"><a href="https://www.kaggle.com/c/tourism1">Tourism Forecasting Part One</a></h3>
<p>Mon 9 Aug 2010 – Sun 19 Sep 2010</p>
<p>Part one requires competitors to predict 518 tourism-related time series. The winner of this competition will be invited to contribute a discussion paper to the International Journal of Forecasting.</p>
<p>======</p>
<h3 id="world-cup-2010---take-on-the-quantshttpswwwkagglecomcworldcup2010"><a href="https://www.kaggle.com/c/worldcup2010">World Cup 2010 - Take on the Quants</a></h3>
<p>Thu 3 Jun 2010 – Fri 11 Jun 2010</p>
<p>Quants at Goldman Sachs and JP Morgan have modeled the likely outcomes of the 2010 World Cup. Can you do better?</p>
<p>======</p>
<h3 id="world-cup-2010---confidence-challengehttpswwwkagglecomcworldcupconf"><a href="https://www.kaggle.com/c/worldcupconf">World Cup 2010 - Confidence Challenge</a></h3>
<p>Thu 3 Jun 2010 – Fri 11 Jun 2010</p>
<p>The Confidence Challenge requires competitors to assign a level of confidence to their World Cup predictions.</p>
<p>======</p>
]]></content>
        </item>
        
        <item>
            <title>Moderne Javascript Tips</title>
            <link>https://leandeep.com/moderne-javascript-tips/</link>
            <pubDate>Sat, 16 Jul 2016 19:00:00 +0000</pubDate>
            
            <guid>https://leandeep.com/moderne-javascript-tips/</guid>
            <description>Introduction Ce weekend, j&#39;ai fait un Kata en JS. Voici une liste de snippets utiles à connaître pour coder proprement son app.
Tips Calculer le nombre propriétés que possède un objet const fleur = { couleur: &#39;rouge&#39;, nom: &#39;rose&#39; } Object.keys(fleurs).length Trier un tableau d&#39;objets en fonction de certaines propriétés const liste = [ { couleur: &#39;blanc&#39;, taille: &#39;XXL&#39; }, { couleur: &#39;rouge&#39;, taille: &#39;XL&#39; }, { couleur: &#39;noir&#39;, taille: &#39;M&#39; } ] // Trier par ordre alphabétique le nom des couleurs: blanc, noir, rouge.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Ce weekend, j'ai fait un Kata en JS.
Voici une liste de snippets utiles à connaître pour coder proprement son app.</p>
<h1 id="tips">Tips</h1>
<h2 id="calculer-le-nombre-proprits-que-possde-un-objet">Calculer le nombre propriétés que possède un objet</h2>
<pre><code>const fleur = {
  couleur: 'rouge',
  nom: 'rose'
}

Object.keys(fleurs).length
</code></pre><h2 id="trier-un-tableau-dobjets-en-fonction-de-certaines-proprits">Trier un tableau d'objets en fonction de certaines propriétés</h2>
<pre><code>const liste = [
  { couleur: 'blanc', taille: 'XXL' },
  { couleur: 'rouge', taille: 'XL' },
  { couleur: 'noir', taille: 'M' }
]

// Trier par ordre alphabétique le nom des couleurs: blanc, noir, rouge.
liste.sort((a, b) =&gt; (a.couleur &gt; b.couleur) ? 1 : -1)

//La fonction de callback pourrait trier sur une seconde propriété, pour gérer le cas où 2 couleurs seraient identiques:
list.sort((a, b) =&gt; (a.couleur &gt; b.couleur) ? 1 : (a.couleur === b.couleur) ? ((a.taille &gt; b.taille) ? 1 : -1) : -1 )
</code></pre><h2 id="comment-dfinir-des-valeurs-par-dfaut-pour-des-fonctions">Comment définir des valeurs par défaut pour des fonctions</h2>
<p>Depuis ES6 en 2015, il est possible de définir des valeurs par défaut aux paramètres des fonctions.</p>
<pre><code>const doSomething = (param1 = 'test', param2 = 'test2') =&gt; {

}
</code></pre><p>Si on devait passer un objet d'options à une fonction, voici le code pour gérer des options undefined:</p>
<pre><code>const colorize = (options) =&gt; {
  if (!options) {
    options = {}
  }

  const color = ('color' in options) ? options.color : 'yellow'
  ...
}

// Avec le destructuring, c'est beaucoup plus simple:
const colorize = ({ color = 'yellow' }) =&gt; {
  ...
}

// Si pas l'objet n'est passé en appelant la fonction colorize on peut assigner un objet vide par défaut: 
const spin = ({ color = 'yellow' } = {}) =&gt; {
  ...
}
</code></pre><h2 id="vider-un-tableau">Vider un tableau</h2>
<pre><code>// Option 1
const list = ['a', 'b', 'c']
list.length = 0

// Option 2 en utilisant let plutôt que const
let list = ['a', 'b', 'c']
list = []
</code></pre><h2 id="encoder-une-url">Encoder une URL</h2>
<p>Pour respecter le standard RFC 3986 (<a href="http://tools.ietf.org/html/rfc3986),">http://tools.ietf.org/html/rfc3986),</a> il y a la fonction suivante:</p>
<pre><code>const fixedEncodeURIComponent = (str) =&gt; {
  return encodeURIComponent(str).replace(/[!'()*]/g, (c) =&gt; {
    return '%' + c.charCodeAt(0).toString(16)
  })
}
</code></pre><h2 id="fusionner-2-objets">Fusionner 2 objets</h2>
<p>ES6 en 2015 a introduit le <code>Spread Operator</code>, qui permet de fusionner facilement 2 simples objets:</p>
<pre><code>const object1 = {
  name: 'Flavio'
}

const object2 = {
  age: 35
}

const object3 = {...object1, ...object2 }
</code></pre><p>Si les 2 objets ont des propriétés ayant des noms identiques, le 2ème objets surchargera le premier.
Dans ce cas, il pourra utiliser la méthode <code>merge()</code> de lodash qui fera un deep merge.</p>
]]></content>
        </item>
        
        <item>
            <title>Commandes Python de base pour faire une classification en apprentissage supervisé avec scikit</title>
            <link>https://leandeep.com/commandes-python-de-base-pour-faire-une-classification-en-apprentissage-supervis%C3%A9-avec-scikit/</link>
            <pubDate>Fri, 03 Jun 2016 21:24:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-python-de-base-pour-faire-une-classification-en-apprentissage-supervis%C3%A9-avec-scikit/</guid>
            <description>Dans cet article nous allons voir comment classifier des chiffres écrits à la main. Le dataset que nous allons utiliser est publique, bien connu et accessible depuis scikit. Nous allons voir le processus pour classifier ces chiffres et voir comment évaluer la performance de notre modèle.
from sklearn.datasets import load_digits digits = load_digits() print(digits.data.shape) (1797, 64) Notre dataset contient 1797 échantillons.
On affiche les 128 premiers échantillons sur un graphique de 9x9 pouces.</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons voir comment classifier des chiffres écrits à la main. Le dataset que nous allons utiliser est publique, bien connu et accessible depuis scikit. Nous allons voir le processus pour classifier ces chiffres et voir comment évaluer la performance de notre modèle.</p>
<pre><code>from sklearn.datasets import load_digits
digits = load_digits()
print(digits.data.shape)
(1797, 64)
</code></pre><p>Notre dataset contient 1797 échantillons.</p>
<p>On affiche les 128 premiers échantillons sur un graphique de 9x9 pouces.</p>
<pre><code>fig = plt.figure(figsize=(9, 9))  # figure size in inches
fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

# plot the digits: each image is 8x8 pixels
for i in range(128):
    ax = fig.add_subplot(16, 8, i + 1, xticks=[], yticks=[])
    ax.imshow(digits.images[i], cmap=plt.cm.binary, interpolation='nearest')
    
    # label the image with the target value
    ax.text(0, 7, str(digits.target[i]))
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/mnist.png" alt="image"></p>
<h1 id="visualisation-des-donnes">Visualisation des données</h1>
<p>Pour beaucoup de problème, la première étape est de visualiser les données en utilisant une technique de réduction de dimensions. Pour se faire, l'algorithme le plus simple est PCA (Principal Component Analysis)</p>
<p>Cet algorithme cherche à trouver les combinaisons linéaires orthogonales qui ont la plus grande variance entre les <em>features</em> du dataset. Cela permet d'avoir une bonne idée de la structure du dataset.</p>
<pre><code>from sklearn.decomposition import RandomizedPCA
pca = RandomizedPCA(n_components=2)
proj = pca.fit_transform(digits.data)

plt.scatter(proj[:, 0], proj[:, 1], c=digits.target)
plt.colorbar()
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/visu1.png" alt="image"></p>
<h1 id="classifieur-naf-baysien">Classifieur naïf bayésien</h1>
<blockquote>
<p>A la base de la classification naïve bayésienne se trouve le théorème de Bayes avec l'hypothèse simplificatrice, dite naïve, d'indépendance entre toutes les paires de variables.
Le rôle de ce classifieur est de classer dans des groupes (des
classes) les échantillons qui ont des propriétés similaires, mesurées sur les observations.</p>
</blockquote>
<p>Ce classifieur simple permet d'avoir rapidement une idée de nos données. Dans notre cas, il se prête au sujet mais avec des données plus complexe, il faut passer à un classifieur plus sophistiqué.</p>
<pre><code>from sklearn.naive_bayes import GaussianNB
from sklearn.cross_validation import train_test_split

# split des données en 2 parties: apprentissage et test
X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target)

# Entrainement du modèle
clf = GaussianNB()
clf.fit(X_train, y_train)

# On utilise le modèle pour prédire les labels des données de test
predicted = clf.predict(X_test)
expected = y_test
</code></pre><p>On réaffiche les chiffres avec la prédiction de notre classifieur. Si le chiffre est en vert, cela signifie que notre classifieur a bien trouvé le bon chiffre. En rouge, il s'est trompé.</p>
<pre><code>fig = plt.figure(figsize=(9, 9))  # Taille du graphique en pouces
fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)

# On affiche les chiffres: chaque image fait 16x16 pixels
for i in range(128):
    ax = fig.add_subplot(16, 16, i + 1, xticks=[], yticks=[])
    ax.imshow(X_test.reshape(-1, 8, 8)[i], cmap=plt.cm.binary,
              interpolation='nearest')
    
    # On labelise l'image avec la valeur prédite
    if predicted[i] == expected[i]:
        ax.text(0, 7, str(predicted[i]), color='green')
    else:
        ax.text(0, 7, str(predicted[i]), color='red')
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/mnist2.png" alt="image"></p>
<h1 id="mesure-quantitative-de-la-performance-du-classifieur">Mesure quantitative de la performance du classifieur</h1>
<p>Une première approche simple consisterait à calculer le pourcentage de bonnes prédictions du classifieur.</p>
<pre><code>matches = (predicted == expected)
print(matches.sum())
print(len(matches))

matches.sum() / float(len(matches))
</code></pre><p><em>Résultat:</em></p>
<pre><code>372
450

0.88222222222222224
</code></pre><p>Ce résultat est pas trop mal mais d'autres métriques plus sophistiquées peuvent être utilisées pour juger de la performance du classifieur.
Les métriques données par ==classification_report== peuvent être utilisées. Cet outil est disponible dans le package ==sklearn.metrics==.</p>
<pre><code>from sklearn import metrics
print(metrics.classification_report(expected, predicted))
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/metrics-classification.png" alt="image"></p>
<p>La matrice de confusion (ou tableau de contingence) peut également nous donner des précisions sur la performance de notre classifieur. Elle est obtenue en comparant les données classées avec des données de référence qui doivent être différentes de celles ayant servi à réaliser la classification.</p>
<pre><code>print(metrics.confusion_matrix(expected, predicted))
</code></pre><p><em>Résultat:</em></p>
<pre><code>[[25  0  0  0  0  0  0  0  0  0]
 [ 0 41  1  0  0  0  0  0  5  1]
 [ 0  3 26  1  0  0  0  0 17  0]
 [ 0  0  2 30  0  2  0  1  8  0]
 [ 0  3  0  0 42  1  1  2  1  0]
 [ 0  0  0  1  0 41  0  1  1  0]
 [ 0  1  0  0  0  0 37  0  0  0]
 [ 0  0  0  0  0  0  0 51  0  0]
 [ 0  5  0  2  0  1  0  0 39  0]
 [ 0  1  0  0  0  2  0  7  7 40]]
</code></pre><p><em>Explications sur la lecture de cette Matrice:</em></p>
<pre><code>     0  1  2  3  4  5  6  7  8  9 (classe estimée)
0 [[25  0  0  0  0  0  0  0  0  0]
1  [ 0 41  1  0  0  0  0  0  5  1]
2  [ 0  3 26  1  0  0  0  0 17  0]
3  [ 0  0  2 30  0  2  0  1  8  0]
4  [ 0  3  0  0 42  1  1  2  1  0]
5  [ 0  0  0  1  0 41  0  1  1  0]
6  [ 0  1  0  0  0  0 37  0  0  0]
7  [ 0  0  0  0  0  0  0 51  0  0]
8  [ 0  5  0  2  0  1  0  0 39  0]
9  [ 0  1  0  0  0  2  0  7  7 40]]
</code></pre><ul>
<li>
<p>Sur 25 chiffres prédits à 0, il n'y a pas eu d'erreur</p>
</li>
<li>
<p>Verticalement, sur 53 chiffres prédits à 1, (additionner verticalement: 41+3+3+1+5 = 53)</p>
<ul>
<li>3 étaient en fait des 2,</li>
<li>3 étaient des 4</li>
<li>1 chiffre prédit à 1 était en fait un 6</li>
<li>5 étaient des 8</li>
<li><em>Soit un total de 12 erreurs</em></li>
</ul>
</li>
<li>
<p>Verticalement, sur 71 chiffres prédits à 8, seulement 39 sont bons</p>
<ul>
<li>17 étaient en fait des 2</li>
<li>8 étaient des 3</li>
<li><em>39 erreurs de prédictions quand le classifieur a estimé des chiffres à 8</em></li>
</ul>
</li>
<li>
<p>Horizontalement, sur 47 chiffres qui étaient à 2, 26 sont biens estimés</p>
</li>
<li>
<p>Horizontalement, sur 43 chiffres qui étaient des 3, 30 sont biens estimés</p>
</li>
</ul>
<p><strong>Ce qu'on voit surtout en conclusion, c'est les chiffres 1, 2, 3, et 9 sont souvent labelisé comme des 8.</strong></p>
]]></content>
        </item>
        
        <item>
            <title>Gérer plusieurs environnements virtuels sans se prendre la tête</title>
            <link>https://leandeep.com/g%C3%A9rer-plusieurs-environnements-virtuels-sans-se-prendre-la-t%C3%AAte/</link>
            <pubDate>Fri, 13 May 2016 21:36:00 +0000</pubDate>
            
            <guid>https://leandeep.com/g%C3%A9rer-plusieurs-environnements-virtuels-sans-se-prendre-la-t%C3%AAte/</guid>
            <description>virtualenvwrapper est un utilitaire intéressant pour pouvoir switcher d&#39;un environnement à un autre très simplement sur le même projet ou sur des projets différents.
 Cet outil ne fonctionne pas sur Windows
 Installation pip install virtualenv pip install --user virtualenvwrapper Ensuite il faut rajouter quelques lignes dans ~/.zshrc (ou ~/.bashrc ou ~/.bash_profile):
export WORKON_HOME=~/.virtualenvs mkdir -p $WORKON_HOME source ~/.local/bin/virtualenvwrapper.sh  Selon où vous avez installé virtualenvwrapper, la dernière ligne peut changer.</description>
            <content type="html"><![CDATA[<p><strong>virtualenvwrapper</strong> est un utilitaire intéressant pour pouvoir switcher d'un environnement à un autre très simplement sur le même projet ou sur des projets différents.</p>
<blockquote>
<p>Cet outil ne fonctionne pas sur Windows</p>
</blockquote>
<h2 id="installation">Installation</h2>
<pre><code>pip install virtualenv
pip install --user virtualenvwrapper
</code></pre><p>Ensuite il faut rajouter quelques lignes dans <code>~/.zshrc</code> (ou <code>~/.bashrc</code> ou <code>~/.bash_profile</code>):</p>
<pre><code>export WORKON_HOME=~/.virtualenvs
mkdir -p $WORKON_HOME
source ~/.local/bin/virtualenvwrapper.sh
</code></pre><blockquote>
<p>Selon où vous avez installé virtualenvwrapper, la dernière ligne peut changer.
Vérifiez que votre PATH contient bien le répertoire <code>~/.local/bin</code>. Si ce n'est pas le cas, ajoutez la commande suivante à votre fichier <code>~/.zshrc</code>: <code>export PATH=$PATH:~/.local/bin</code></p>
</blockquote>
<p>&mdash; Update du 15/11/2019 &mdash;</p>
<p><strong>Installer virtualenvwrapper sur OS X Catalina:</strong></p>
<p>Installer Python 2.x:</p>
<pre><code>brew install python@2
</code></pre><p>Ajouter la ligne suivante dans votre <code>~/.zshrc</code>:</p>
<pre><code>export PATH=&quot;/usr/local/opt/python/libexec/bin:/usr/local/bin:$PATH&quot;
</code></pre><p>Installer virtualenv et virtualenvwrapper:</p>
<pre><code>pip install virtualenv
pip install virtualenvwrapper
</code></pre><p>Vérifier le bon fonctionnement:</p>
<pre><code>mkvirtualenv -p /usr/bin/python3 -a . ai_env
</code></pre><h2 id="commandes-de-base">Commandes de base</h2>
<p>On a maintenant accès à de nouvelles commandes:</p>
<pre><code># Créer un virtualenv dans le dossier ~/.virtualenvs, où que vous soyez
mkvirtualenv [-p /Users/olivier/.pyenv/shims/python] [-a .] nom_de_votre_env


# Activer automatiquement un env, où que vous soyez.
workon nom_de_votre_env 

# supprimer un environnement 
rmvirtualenv nom_de_votre_env 
</code></pre><p><strong>Les options de <code>mkvirtualenv</code> sont les mêmes que pour la commande <code>virtualenv</code>, vous n’avez juste plus à vous souciez de où sont vos environnements, ni de où vous êtes.</strong></p>
<h2 id="autres-commandes-utiles">Autres commandes utiles</h2>
<p>Lister tous les environnements:</p>
<pre><code>lsvirtualenv
</code></pre><p>Naviguez dans le répertoire de l’environnement virtuel activé:</p>
<pre><code>cdvirtualenv
</code></pre><p>Accéder au répertoire site-packages de l'environnement activé:</p>
<pre><code>cdsitepackages
</code></pre><p>Montre le contenu du répertoire site-packages:</p>
<pre><code>lssitepackages
</code></pre><p>Redéfinir le répertoire par défault du virtualenv</p>
<pre><code>cd /votre/nouveau/repertoire/par/defaut
setvirtualenvproject
</code></pre><p>Liste complète des commandes:
<a href="http://virtualenvwrapper.readthedocs.org/en/latest/command_ref.html">http://virtualenvwrapper.readthedocs.org/en/latest/command_ref.html</a></p>
]]></content>
        </item>
        
        <item>
            <title>Formatage automatique du code Python sur n&#39;importe quel IDE</title>
            <link>https://leandeep.com/formatage-automatique-du-code-python-sur-nimporte-quel-ide/</link>
            <pubDate>Fri, 15 Apr 2016 21:14:00 +0000</pubDate>
            
            <guid>https://leandeep.com/formatage-automatique-du-code-python-sur-nimporte-quel-ide/</guid>
            <description>Editorconfig est un formidable outil pour laisser aux développeurs le choix d&#39;utiliser l&#39;IDE qu&#39;ils préfèrent sans avoir des problèmes de formatage de code.
Voici un exemple d&#39;utilisation simple avec Python:
Au niveau root de votre projet créez un fichier .editorconfig. Par exemple, ajoutez une conf de formatage des indentations:
[*.py] indent_style = space indent_size = 4 Si comme moi vous êtes passé à visual studio code (ou atom), il suffit d&#39;installer un plugin appelé EditorConfig for VS Code et le package Python autopep8 via pip.</description>
            <content type="html"><![CDATA[<p>Editorconfig est un formidable outil pour laisser aux développeurs le choix d'utiliser l'IDE qu'ils préfèrent sans avoir des problèmes de formatage de code.</p>
<p>Voici un exemple d'utilisation simple avec Python:</p>
<p>Au niveau <code>root</code> de votre projet créez un fichier <code>.editorconfig</code>.
Par exemple, ajoutez une conf de formatage des indentations:</p>
<pre><code>[*.py]
indent_style = space
indent_size = 4
</code></pre><p>Si comme moi vous êtes passé à visual studio code (ou atom), il suffit d'installer un plugin appelé <code>EditorConfig for VS Code</code> et le package Python autopep8 via pip. Ce dernier s'installera tout seul si vous pressez les commandes de formatage automatique <code>alt</code> + <code>Shift</code> + <code>f</code>.</p>
<p>Une fois que tout est installé, vous pouvez reformater votre code automatiquement via la commande précédente <code>alt</code> + <code>Shift</code> + <code>f</code>.</p>
]]></content>
        </item>
        
        <item>
            <title>Liste des exceptions Python</title>
            <link>https://leandeep.com/liste-des-exceptions-python/</link>
            <pubDate>Fri, 01 Apr 2016 20:06:00 +0000</pubDate>
            
            <guid>https://leandeep.com/liste-des-exceptions-python/</guid>
            <description>Liste à garder sous le coude pour gérer le plus explicitement possible les erreurs en Python. Pratique si vous utilisez des outils comme Sentry.
BaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception +-- StopIteration +-- StopAsyncIteration +-- ArithmeticError | +-- FloatingPointError | +-- OverflowError | +-- ZeroDivisionError +-- AssertionError +-- AttributeError +-- BufferError +-- EOFError +-- ImportError +-- ModuleNotFoundError +-- LookupError | +-- IndexError | +-- KeyError +-- MemoryError +-- NameError | +-- UnboundLocalError +-- OSError | +-- BlockingIOError | +-- ChildProcessError | +-- ConnectionError | | +-- BrokenPipeError | | +-- ConnectionAbortedError | | +-- ConnectionRefusedError | | +-- ConnectionResetError | +-- FileExistsError | +-- FileNotFoundError | +-- InterruptedError | +-- IsADirectoryError | +-- NotADirectoryError | +-- PermissionError | +-- ProcessLookupError | +-- TimeoutError +-- ReferenceError +-- RuntimeError | +-- NotImplementedError | +-- RecursionError +-- SyntaxError | +-- IndentationError | +-- TabError +-- SystemError +-- TypeError +-- ValueError | +-- UnicodeError | +-- UnicodeDecodeError | +-- UnicodeEncodeError | +-- UnicodeTranslateError +-- Warning +-- DeprecationWarning +-- PendingDeprecationWarning +-- RuntimeWarning +-- SyntaxWarning +-- UserWarning +-- FutureWarning +-- ImportWarning +-- UnicodeWarning +-- BytesWarning +-- ResourceWarning Exemple:</description>
            <content type="html"><![CDATA[<p>Liste à garder sous le coude pour gérer le plus explicitement possible les erreurs en Python. Pratique si vous utilisez des outils comme <a href="https://sentry.io/welcome/">Sentry</a>.</p>
<pre><code>BaseException
 +-- SystemExit
 +-- KeyboardInterrupt
 +-- GeneratorExit
 +-- Exception
      +-- StopIteration
      +-- StopAsyncIteration
      +-- ArithmeticError
      |    +-- FloatingPointError
      |    +-- OverflowError
      |    +-- ZeroDivisionError
      +-- AssertionError
      +-- AttributeError
      +-- BufferError
      +-- EOFError
      +-- ImportError
           +-- ModuleNotFoundError
      +-- LookupError
      |    +-- IndexError
      |    +-- KeyError
      +-- MemoryError
      +-- NameError
      |    +-- UnboundLocalError
      +-- OSError
      |    +-- BlockingIOError
      |    +-- ChildProcessError
      |    +-- ConnectionError
      |    |    +-- BrokenPipeError
      |    |    +-- ConnectionAbortedError
      |    |    +-- ConnectionRefusedError
      |    |    +-- ConnectionResetError
      |    +-- FileExistsError
      |    +-- FileNotFoundError
      |    +-- InterruptedError
      |    +-- IsADirectoryError
      |    +-- NotADirectoryError
      |    +-- PermissionError
      |    +-- ProcessLookupError
      |    +-- TimeoutError
      +-- ReferenceError
      +-- RuntimeError
      |    +-- NotImplementedError
      |    +-- RecursionError
      +-- SyntaxError
      |    +-- IndentationError
      |         +-- TabError
      +-- SystemError
      +-- TypeError
      +-- ValueError
      |    +-- UnicodeError
      |         +-- UnicodeDecodeError
      |         +-- UnicodeEncodeError
      |         +-- UnicodeTranslateError
      +-- Warning
           +-- DeprecationWarning
           +-- PendingDeprecationWarning
           +-- RuntimeWarning
           +-- SyntaxWarning
           +-- UserWarning
           +-- FutureWarning
           +-- ImportWarning
           +-- UnicodeWarning
           +-- BytesWarning
           +-- ResourceWarning
</code></pre><p>Exemple:</p>
<pre><code>try:
    f = open(&quot;myfile.txt&quot;)
    for line in f:
        print(line)
except FileNotFoundError:
    print(&quot;The file does not exist&quot;)
except PermissionError:
    print(&quot;You don't have the permission to open the file&quot;)
except Exception:
    print(&quot;Unexpected error occured&quot;)
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Clean Architecture</title>
            <link>https://leandeep.com/clean-architecture/</link>
            <pubDate>Tue, 15 Mar 2016 21:34:00 +0000</pubDate>
            
            <guid>https://leandeep.com/clean-architecture/</guid>
            <description>Bonjour à tous,
Dans cet article nous allons parler de clean architecture en référence à ce que présente Robert C. Martin (alias Oncle Bob) dans cette vidéo. Si vous ne l&#39;avez pas vu, je vous la recommande fortement !
Tous les concepts dont il parle dans sa proposition &amp;ldquo;d&#39;Architecture propre&amp;rdquo; ne sont pas nouveaux car déjà utilisés dans d&#39;autres architectures antérieures. (Il le dit lui-même dans sa vidéo.)
Voici la proposition d&#39;Architecture propre: Partie 1 Le schéma à gauche (en forme d&#39;oignon) est la combinaison de 2 architectures plus anciennes:</description>
            <content type="html"><![CDATA[<p>Bonjour à tous,</p>
<p>Dans cet article nous allons parler de <em>clean architecture</em> en référence à ce que présente Robert C. Martin (alias <a href="https://fr.wikipedia.org/wiki/Robert_C._Martin">Oncle Bob</a>) dans cette <a href="https://www.youtube.com/watch?v=Nsjsiz2A9mg">vidéo</a>. Si vous ne l'avez pas vu, je vous la recommande fortement !</p>
<p>Tous les concepts dont il parle dans sa proposition &ldquo;d'Architecture propre&rdquo; ne sont pas nouveaux car déjà utilisés dans d'autres architectures antérieures. (Il le dit lui-même dans sa vidéo.)</p>
<p>Voici la proposition d'Architecture propre:
<img src="/images/clean-architecture-diagram.jpg" alt="image"></p>
<h1 id="partie-1">Partie 1</h1>
<p>Le schéma à gauche (en forme d'oignon) est la combinaison de 2 architectures plus anciennes:</p>
<ul>
<li><a href="http://jeffreypalermo.com/blog/the-onion-architecture-part-1/">Onion Architecture</a> de Jeffrey Palermo, 2008</li>
<li><a href="http://alistair.cockburn.us/Hexagonal+architecture">Ports &amp; Adapters Architecture</a> d'Alistair Cockburn, 2005. Cette dernière est également appelée <strong>Architecture Hexagonale</strong>)</li>
</ul>
<p>Voici une synthèse des différents concepts présentés.</p>
<h2 id="externalisation-des-outils-et-des-mcanismes-de-livraison">Externalisation des outils et des mécanismes de livraison</h2>
<p>Dans une Architecture Hexagonale on se focuse sur l'externalisation des outils et mécanismes de livraison de l'application en utilisant des interfaces (ports) et des <em>adapters</em>.</p>
<p>Cette approche est aussi un des fondements de l'Onion Architecture comme on peut le voir sur le schéma ci-dessous. Comme on peut le voir, les tests, la couche infrastructure, le UI et la couche d'API sont situés à l'extrémité du diagramme.</p>
<p><img src="/images/Onion-Architecture.png" alt="image"></p>
<p>Dans la clean Architecture, c'est similaire. Au final tout le <em>core</em> applicatif se retrouve au centre et est agnostique des différents frameworks et librairies.</p>
<h2 id="direction-des-dpendances">Direction des dépendances</h2>
<p>Dans l'Archictecture Hexagonale rien n'explicite la direction des dépendances. Néanmoins on peut facilement la déduire.
L'application a un port (ou interface) qui doit être implémenté ou utilisé par un <em>adpater</em>. Donc l&rsquo;<em>adapter</em> dépend de l'interface qui dépend du <em>core</em> applicatif qui est au centre. Ce qui est à l'extérieur dépend de ce qui est à l'intérieur. Donc la direction des dépendances est vers le centre.</p>
<p>In the Hexagonal Architecture, we don’t have anything explicitly telling us the direction of the dependencies. Nevertheless, we can easily infer it: The Application has a port (an interface) which must be implemented or used by an adapter. So the Adapter depends on the interface, it depends on the application which is in the centre. What is outside depends on what is inside, the direction of the dependencies is towards the centre.
Dans le diagramme de la Clean Architecture c'est très explicite. Il y a des flèches en direction du centre. Elles introduisent le principe d'inversion de dépendances. Le centre du cercle ne connait rien de ce qu'il y a à l'extérieur. De plus, lorsque les données circulent entre les couches c'est toujours dans une forme qui convient le mieux aux couches les plus proches du centre.</p>
<h2 id="couches">Couches</h2>
<p>Le diagramme de l'Architecture Hexagonale ne montre que 2 couches: intérieur de l'application et extérieur de l'application.</p>
<p><img src="/images/archi-hexa.jpeg" alt="image"></p>
<p>L'Onion Architecture quant à elle apporte les couches identifiées par le DDD (Domain Driven Design):</p>
<ul>
<li>Application Services qui porte la logique du <em>use case</em>.</li>
<li>Domain Services qui encapsule la logique du domaine qui n'appartient pas aux <em>Entites</em> ou au <em>Value Objects</em>.</li>
<li>Les Entities, Value Objects&hellip;</li>
</ul>
<p>Quand on compare l'Onion Architecture et la Clean Architecture on voit que la Clean Architecture garde toutes les couches de l'Onion Architecture sauf la partie <em>Domain Services layer</em>.
Cependant lorsque l'on rentre dans le détail des articles de Robert C. Martin on se rend compte qu'il considère les Entities pas simplement comme les Entities en DDD mais comme un Domain Object.</p>
<h2 id="testabilit-et-isolation">Testabilité et isolation</h2>
<p>Les 3 types d'Architecture pronent l'isolation de l'application et de la  <em>domain logic</em> . Cela signifie que pour tous les use cases on peut &ldquo;<em>mocker</em>&rdquo; les outils externes et mécanismes de livraison et que les différentes partie de l'application peuvent être testées de manière isolée.</p>
<h1 id="partie-2">Partie 2</h1>
<p>Dans cette partie on va s'intéresser à la partie droite du schéma de la Clean Architecture.</p>
<p><img src="/images/clean-architecture-right-side.png" alt="image"></p>
<p>Ce n'est pas très explicite !
Par contre, on retrouve plus d'explication avec le schéma suivant:</p>
<p><img src="/images/clean-architecture-design.png" alt="image"></p>
<p>On y retrouve sur la gauche une Architecture MVC et sur la droite une Architecture EBI (on voit clairement les <em>Boundaries</em>, l&rsquo;<em>Interactor</em> et les <em>Entities</em>), the “Application” in Hexagonal Architecture, the “Application Core” in the Onion Architecture, and the “Entities” and “Use Cases” layers in the Clean Architecture diagram above.</p>
<p>Ce dernier permet d'illustrer les Architectures suivantes:</p>
<ul>
<li>EBI (Entity-Boundary-Interactor) Architecture par Ivar Jacobson, 1992</li>
<li>Architecture MVC, 1970s</li>
</ul>
<p>Le pattern EBI est au backend ce que MVC est au frontend. Ces 2 approches sont complémentaires.</p>
<blockquote>
<p>Rappel sur MVC:
<a href="https://herbertograca.com/2017/08/17/mvc-and-its-variants/#model-view-view_model">https://herbertograca.com/2017/08/17/mvc-and-its-variants/#model-view-view_model</a></p>
</blockquote>
<p>Le pattern MVC separe le code en 3 parties:</p>
<ul>
<li>Le Modèle représente la <em>business logic</em></li>
<li>La Vue représente un widget dans le UI: un bouton, text box&hellip;</li>
<li>Le Controleur permet de coordonner la vue avec le modèle; c'est-à-dire décider quelle Vue afficher avec quelle donnée. Il traduit les actions utilisateur (i.e. clic sur bouton) en business logic.</li>
</ul>
<blockquote>
<p>EBI (Entity-Boundary-Interactor) ou Single Responsibility Principle ?</p>
</blockquote>
<h3 id="entity">Entity</h3>
<p>L'objet <em>Entity</em> contient la donnée utilisée par le système ainsi que tous les comportements couplés à cette donnée.
&ldquo;An Entity object should contain the logic that would change when the Entity itself changes, that is to say: if the data structure it holds changes, the operations on that data will also need to change and therefore they should be located in the Entity as well.&quot;, Ivar Jacobson 1992</p>
<h3 id="boundary-interface">Boundary (Interface)</h3>
<p>L'object Boundary est l'interface avec le système.</p>
<p>&ldquo;Everything concerning the interface of the system is placed in an interface object&rdquo;, Ivar Jacobson 1992</p>
<p>Toutes les fonctionnalités qui dépendent de l'environnement du système (outils et mécanismes de livraison) appartiennent à l'objet <em>Boundary</em>.</p>
<p>Chaque intéraction avec le système au travers d'un &ldquo;acteur&rdquo; passe par l'objet Boundary. Un &ldquo;acteur&rdquo; peut être un humain (admin, client) ou non (alarme, trigger, API externe).</p>
<h3 id="interactor-control">Interactor (Control)</h3>
<p>L'objet <em>Interactor</em> va contenir les comportements par naturellement liés aux autres types d'objets.</p>
<p>Ces comportement peuvent typiquement être des opérations sur plusieurs Entities retournant des résultats (qui passeront par l'objet boundary).</p>
<p>&ldquo;Behaviour that remains after the Interface objects and Entity objects have obtained their parts will be placed in the control objects&rdquo; Ivar Jacobson 1992</p>
<p>Cela signifie que tous les comportements qui ne se situent pas dans les objets Boundary ou Entity seront placés dans un ou plusieurs objets Interactor.</p>
<h1 id="conclusion">Conclusion</h1>
<p>Avec cette approche, Robert C. Martin a n'a rien inventé mais rappelle et clarifie des <em>patterns</em> importants souvent oubliés. Il explique quand même comment tous ces patterns, règles et concepts peuvent coexister ensemble pour construire de manière standardisée et propre des applications complexes et facilement maintenables. Je dirais donc que c'est à adopter&hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Réduire un tableau en JavaScript</title>
            <link>https://leandeep.com/r%C3%A9duire-un-tableau-en-javascript/</link>
            <pubDate>Sat, 27 Feb 2016 20:20:00 +0000</pubDate>
            
            <guid>https://leandeep.com/r%C3%A9duire-un-tableau-en-javascript/</guid>
            <description>Réduire un tableau en JavaScript peut être effectué en utilisant la méthode reduce(). Cette méthode applique une fonction contre un accumulateur qui prend chaque valeur du tableau (de gauche à droite) pour le réduire à une seule valeure.
Signature de la méthode reduce() La méthode reduce() prend 2 paramètres:
 (Obligatoire) Une fonction callback de réduction. Elle sera appliquée à chaque paire: valeur précédente (résultat de la dernière exécution) et valeur suivante.</description>
            <content type="html"><![CDATA[<p>Réduire un tableau en JavaScript peut être effectué en utilisant la méthode <code>reduce()</code>. Cette méthode applique une fonction contre un accumulateur qui prend chaque valeur du tableau (de gauche à droite) pour le réduire à une seule valeure.</p>
<h2 id="signature-de-la-mthode-reduce">Signature de la méthode reduce()</h2>
<p>La méthode <code>reduce()</code> prend 2 paramètres:</p>
<ul>
<li>(Obligatoire) Une fonction <em>callback</em> de réduction. Elle sera appliquée à chaque paire: valeur précédente (résultat de la dernière exécution) et valeur suivante.</li>
<li>(Facultatif) Une valeur initiale qui sera utilisée comme paramètre du premier appel à la fonction de callback</li>
</ul>
<h2 id="exemple-accumulation-concatnation">Exemple: accumulation, concaténation</h2>
<p>Calcul du prix d'un panier:</p>
<pre><code>// Elements du panier
var items = [{price: 50}, {price: 100}, {price: 500}];

// Fonction de réduction (callback function)
var reducer = function add(sumSoFar, item) { return sumSoFar + item.price; };

//
var totalPrice = items.reduce(reducer, 0);

console.log(totalPrice);
// 650
</code></pre><h2 id="usage-avanc-combinaison">Usage avancé (combinaison)</h2>
<p><em>Inspiré de redux combineReducers.</em></p>
<p>Combiner plusieurs reducers en une seule fonction de réduction:</p>
<pre><code>var reducers = {
  totalInDollar: function(state, item) {
    // specific statements...
    return state.dollars += item.price;
  },
  totalInEuros : function(state, item) {
    return state.euros += item.price * 0.897424392;
  },
  totalInPounds : function(state, item) {
    return state.pounds += item.price * 0.692688671;
  },
  totalInYen : function(state, item) {
    return state.yens += item.price * 113.852;
  }
  // more...
};
</code></pre><p>On crée une fonction qui retourne une fonction callback de réduction qui va appliquer chaque fonction de réduction individuellement.</p>
<pre><code>var combineTotalPriceReducers = function(reducers) {
  return function(state, item) {
    return Object.keys(reducers).reduce(
      function(nextState, key) {
        reducers[key](state, item);
        return state;
      },
      {}      
    );
  }
};
</code></pre><p>Voici le code pour l'utiliser:</p>
<pre><code>var bigTotalPriceReducer = combineTotalPriceReducers(reducers);

var initialState = {dollars: 0, euros:0, yens: 0, pounds: 0};

var totals = items.reduce(bigTotalPriceReducer, initialState);

console.log(totals);

/*
Object {dollars: 1130, euros: 1015.11531904, yens: 127524.24, pounds: 785.81131152}
*/
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Importer des données depuis Numpy et Pandas dans Tensorflow</title>
            <link>https://leandeep.com/importer-des-donn%C3%A9es-depuis-numpy-et-pandas-dans-tensorflow/</link>
            <pubDate>Fri, 26 Feb 2016 07:31:00 +0000</pubDate>
            
            <guid>https://leandeep.com/importer-des-donn%C3%A9es-depuis-numpy-et-pandas-dans-tensorflow/</guid>
            <description>Exemple avec le jeu de données Iris:
On importe le dataset:
!mkdir /content/data !ls !wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -P /content/data Output:
data sample_data --2018-11-16 09:37:26-- https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249 Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 4551 (4.4K) [text/plain] Saving to: ‘/content/data/iris.data’ iris.data 100%[===================&amp;gt;] 4.44K --.-KB/s in 0s 2018-11-16 09:37:27 (102 MB/s) - ‘/content/data/iris.data’ saved [4551/4551] On crée le modèle Tensorflow en réutilisant les données que l&#39;on vient de télécharger:</description>
            <content type="html"><![CDATA[<p>Exemple avec le jeu de données Iris:</p>
<p>On importe le dataset:</p>
<pre><code>!mkdir /content/data
!ls
!wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -P /content/data


</code></pre><p>Output:</p>
<pre><code>data  sample_data
--2018-11-16 09:37:26--  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data
Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249
Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 4551 (4.4K) [text/plain]
Saving to: ‘/content/data/iris.data’

iris.data           100%[===================&gt;]   4.44K  --.-KB/s    in 0s      

2018-11-16 09:37:27 (102 MB/s) - ‘/content/data/iris.data’ saved [4551/4551]
</code></pre><p>On crée le modèle Tensorflow en réutilisant les données que l'on vient de télécharger:</p>
<pre><code>import tensorflow as tf 
import numpy
import pandas as pd
df = pd.read_csv('/content/data/iris.data', usecols = [0,1,2,3], header=None)
d = df.values
l = pd.read_csv('/content/data/iris.data', usecols = [4], header=None)
labels = l.values
data = numpy.float32(d)
labels = numpy.array(l, 'str')


#tensorflow
x = tf.placeholder(tf.float32,shape=(150, 4))
x = data
w = tf.random_normal([100,150], mean=0.0, stddev=1.0, dtype=tf.float32)
y = tf.nn.softmax(tf.matmul(w,x))

with tf.Session() as sess:
    print(sess.run(y))
</code></pre><p>Output:</p>
<pre><code>[[6.05230798e-06 9.99951363e-01 4.28714886e-09 4.25937251e-05]
 [9.99996185e-01 1.03216182e-13 3.80070583e-06 6.39829425e-19]
 [1.64993300e-17 2.94252706e-04 7.82768490e-14 9.99705732e-01]
...
 [9.99661326e-01 1.44316881e-15 3.38725222e-04 6.10780423e-15]
 [1.43875854e-31 1.99823014e-13 3.74144286e-19 1.00000000e+00]
 [8.89758050e-01 7.39052707e-22 1.10241950e-01 8.98781819e-22]]
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Commandes Python de base pour faire une régression en apprentissage supervisé avec scikit</title>
            <link>https://leandeep.com/commandes-python-de-base-pour-faire-une-r%C3%A9gression-en-apprentissage-supervis%C3%A9-avec-scikit/</link>
            <pubDate>Sat, 13 Feb 2016 16:25:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-python-de-base-pour-faire-une-r%C3%A9gression-en-apprentissage-supervis%C3%A9-avec-scikit/</guid>
            <description>Dans cet article nous allons travailler sur le dataset &amp;ldquo;Boston house prices&amp;rdquo; de scikit-learn et essayer de prédire le prix de l&#39;immobilier. Nous allons prédire une le prix d&#39;une maison; ce qui signifie prédire une valeur continue.
Le dataset ressemble à ceci:
from sklearn.datasets import load_boston import pandas as pd data = load_boston() print(data.data.shape) print(data.target.shape) df_data = pd.DataFrame(data.data, columns=data.feature_names) df_labels = pd.DataFrame(data.target, columns=[&#39;price in $1000\&#39;s&#39;]) df_total = pd.concat([df_data, df_labels], axis=1) print(df_total.</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons travailler sur le dataset &ldquo;Boston house prices&rdquo; de scikit-learn et essayer de prédire le prix de l'immobilier. Nous allons prédire une le prix d'une maison; ce qui signifie prédire une valeur continue.</p>
<p>Le dataset ressemble à ceci:</p>
<pre><code>from sklearn.datasets import load_boston
import pandas as pd

data = load_boston()

print(data.data.shape)
print(data.target.shape)

df_data = pd.DataFrame(data.data, columns=data.feature_names)      
df_labels = pd.DataFrame(data.target, columns=['price in $1000\'s'])      
df_total = pd.concat([df_data, df_labels], axis=1)

print(df_total.head(5))
</code></pre><p><em>Résultat:</em></p>
<pre><code>(506, 13)
(506,)
      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \
0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   
1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   
2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   
3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   
4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   

   PTRATIO       B  LSTAT  price in $1000's
0     15.3  396.90   4.98              24.0
1     17.8  396.90   9.14              21.6
2     17.8  392.83   4.03              34.7
3     18.7  394.63   2.94              33.4
4     18.7  396.90   5.33              36.2
</code></pre><blockquote>
<p>La librairie Pandas est une librairie parfaite pour manipuler les données. Nous avons déjà parlé de cette librairie dans l'article [article à indiquer].</p>
</blockquote>
<p>Les features CRIM, ZN, INDUS, CHAS, NOX,&hellip; ne veulent rien dire comme cela.
Il y a un descriptif dans l'objet data qui permet de mieux comprendre à quoi correspond ces abréviations.</p>
<pre><code>print(data.DESCR)
</code></pre><p><em>Résultat:</em></p>
<pre><code>Boston House Prices dataset
===========================

Notes
------
Data Set Characteristics:  

    :Number of Instances: 506 

    :Number of Attributes: 13 numeric/categorical predictive
    
    :Median Value (attribute 14) is usually the target

    :Attribute Information (in order):
        - CRIM     per capita crime rate by town
        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
        - INDUS    proportion of non-retail business acres per town
        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
        - NOX      nitric oxides concentration (parts per 10 million)
        - RM       average number of rooms per dwelling
        - AGE      proportion of owner-occupied units built prior to 1940
        - DIS      weighted distances to five Boston employment centres
        - RAD      index of accessibility to radial highways
        - TAX      full-value property-tax rate per $10,000
        - PTRATIO  pupil-teacher ratio by town
        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
        - LSTAT    % lower status of the population
        - MEDV     Median value of owner-occupied homes in $1000's

    :Missing Attribute Values: None
...
</code></pre><h1 id="visualisation-des-donnes-et-slection-des-features">Visualisation des données et sélection des features</h1>
<p>On va commencer par visualiser les données pour essayer de comprendre de à quoi ressemble le dataset. L'objectif n'est pas de tout visualiser et de tout comprendre tout de suite; l'objectif est plus d'avoir une première idée de ce à quoi ressemblent les données.</p>
<pre><code>%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

plt.hist(data.target)
plt.xlabel('price in $1000\'s')
plt.ylabel('nombre de maisons')
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/bar-chart-price-houses.png" alt="image"></p>
<p>On va sélectionner les features qui influent le plus le prix des maisons. On va afficher sur un graphique chaque feature et retenir celles qui sont les plus corrélées avec notre cible. Cette étape est faite manuellement. Nous aurions pu le faire automatiquement. Nous verrons ces techniques dans un prochain article.</p>
<pre><code>for index, feature_name in enumerate(data.feature_names):
    plt.figure()
    plt.scatter(data.data[:, index], data.target)
    plt.ylabel('Prix')
    plt.xlabel(feature_name)
</code></pre><p><img src="/images/charts.png" alt="image"></p>
<p><img src="/images/charts2.png" alt="image"></p>
<p><img src="/images/charts3.png" alt="image"></p>
<p><img src="/images/charts4.png" alt="image"></p>
<h1 id="prdire-le-prix-de-limmobilier">Prédire le prix de l'immobilier</h1>
<h2 id="rgression-linaire">Régression linéaire</h2>
<p>A présent nous allons construire notre modèle de régression linéaire (calcul des moindres carrés) sur l'ensemble des données.</p>
<blockquote>
<p>Cette méthode consiste à déterminer la droite théorique dont les coordonnées sont la moyenne arithmétique de toutes les données.
Pour faire plus simple, c'est la droite qui passe au plus près de tous les points de données.</p>
</blockquote>
<pre><code>from sklearn.cross_validation import train_test_split

X_train, X_test, y_train, y_test = train_test_split(data.data, data.target)

from sklearn.linear_model import LinearRegression

estimator = LinearRegression()
estimator.fit(X_train, y_train)

predicted = estimator.predict(X_test)
expected = y_test

plt.scatter(expected, predicted)
plt.plot([0, 50], [0, 50], '--k')
plt.axis('tight')
plt.xlabel('True price in $1000\'s')
plt.ylabel('Predicted price in $1000\'s')
print(&quot;RMS:&quot;, np.sqrt(np.mean((predicted - expected) ** 2)))
</code></pre><p><em>Résultat:</em></p>
<pre><code>RMS: 4.683413955906375
</code></pre><p><img src="/images/predicted-prices.png" alt="image"></p>
<p>On voit qu'il y a une correlation entre le prix prédit et le vrai prix des maisons; même s'il y a quand même pas mal de biais.</p>
<h1 id="arbre-de-dcision-gradient-boosting">Arbre de décision Gradient Boosting</h1>
<p>On va utiliser un meilleur régresseur pour obtenir un meilleur résultat.</p>
<pre><code>from sklearn.ensemble import GradientBoostingRegressor

clf = GradientBoostingRegressor()
clf.fit(X_train, y_train)

predicted = clf.predict(X_test)
expected = y_test

plt.scatter(expected, predicted)
plt.plot([0, 50], [0, 50], '--k')
plt.axis('tight')
plt.xlabel('True price in $1000\'s')
plt.ylabel('Predicted price in $1000\'s')
print(&quot;RMS:&quot;, np.sqrt(np.mean((predicted - expected) ** 2)))

</code></pre><p><em>Résultat:</em></p>
<pre><code>RMS: 3.2226035734196445
</code></pre><p><img src="/images/predicted-prices2.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Réduire la taille du contexte lors d&#39;un Docker build</title>
            <link>https://leandeep.com/r%C3%A9duire-la-taille-du-contexte-lors-dun-docker-build/</link>
            <pubDate>Mon, 01 Feb 2016 21:26:00 +0000</pubDate>
            
            <guid>https://leandeep.com/r%C3%A9duire-la-taille-du-contexte-lors-dun-docker-build/</guid>
            <description>Très simplement, il suffit d&#39;ajouter un fichier .dockerignore au même niveau que votre Dockerfile.
Voici un exemple de paths à exclure du contexte.
.git .ipynb_checkpoints/* /notebooks/* /unused/* Dockerfile .DS_Store .gitignore README.md env.* /devops/* # To prevent storing dev/temporary container data *.csv /tmp/* tmp/ </description>
            <content type="html"><![CDATA[<p>Très simplement, il suffit d'ajouter un fichier <code>.dockerignore</code> au même niveau que votre Dockerfile.</p>
<p>Voici un exemple de <em>paths</em> à exclure du contexte.</p>
<pre><code>.git
.ipynb_checkpoints/*
/notebooks/*
/unused/*
Dockerfile
.DS_Store
.gitignore
README.md
env.*
/devops/*

# To prevent storing dev/temporary container data
*.csv
/tmp/*
tmp/
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Ma présentation de Docker</title>
            <link>https://leandeep.com/ma-pr%C3%A9sentation-de-docker/</link>
            <pubDate>Wed, 27 Jan 2016 22:07:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ma-pr%C3%A9sentation-de-docker/</guid>
            <description>Voici une présentation que j&#39;ai réalisé pour motiver les Devs et les Ops à utiliser Docker au quotidien.
 </description>
            <content type="html"><![CDATA[<p>Voici une présentation que j'ai réalisé pour motiver les Devs et les Ops à utiliser Docker au quotidien.</p>

    <iframe
        src="//www.slideshare.net/slideshow/embed_code/key/HDLMVlHQGKKvUX"
        title="SlideShare Presentation"
        height="485"
        width="595"
        frameborder="0"
        marginwidth="0"
        marginheight="0"
        scrolling="no"
        style="border: 1px solid #CCC; border-width: 1px; margin-bottom: 20px; width: 100%;"
        allowfullscreen="true">
    </iframe>





]]></content>
        </item>
        
        <item>
            <title>Réaliser un one-hot encoding avec Tensorflow</title>
            <link>https://leandeep.com/r%C3%A9aliser-un-one-hot-encoding-avec-tensorflow/</link>
            <pubDate>Wed, 20 Jan 2016 19:05:00 +0000</pubDate>
            
            <guid>https://leandeep.com/r%C3%A9aliser-un-one-hot-encoding-avec-tensorflow/</guid>
            <description>On exécute la fonction tf.nn.embedding_lookup (qui permet d&#39;exécuter l&#39;opération de recherche tensorielle) entre la matrice identité et ses données:
import numpy as np a = 5 b = [1, 2, 3] # one hot an integer one_hot_a = tf.nn.embedding_lookup(np.identity(10), a) # one hot a list of integers one_hot_b = tf.nn.embedding_lookup(np.identity(max(b)+1), b) with tf.Session() as sess: print(sess.run([one_hot_a, one_hot_b])) Output:
[array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([[0., 1., 0.</description>
            <content type="html"><![CDATA[<p>On exécute la fonction tf.nn.embedding_lookup (qui permet d'exécuter l'opération de recherche tensorielle) entre la matrice identité et ses données:</p>
<pre><code>import numpy as np
a = 5 
b = [1, 2, 3]

# one hot an integer
one_hot_a = tf.nn.embedding_lookup(np.identity(10), a)

# one hot a list of integers
one_hot_b = tf.nn.embedding_lookup(np.identity(max(b)+1), b)

with tf.Session() as sess:
    print(sess.run([one_hot_a, one_hot_b]))
</code></pre><p>Output:</p>
<pre><code>[array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]), array([[0., 1., 0., 0.],
       [0., 0., 1., 0.],
       [0., 0., 0., 1.]])]
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Comprendre le hoisting en JavaScript</title>
            <link>https://leandeep.com/comprendre-le-hoisting-en-javascript/</link>
            <pubDate>Sun, 10 Jan 2016 19:52:00 +0000</pubDate>
            
            <guid>https://leandeep.com/comprendre-le-hoisting-en-javascript/</guid>
            <description>Comprendre le hoisting en JavaScript est important pour organiser vos fonctions.
 Rappel entre déclarer et définir une variable: Déclarer une variable signifie: &amp;ldquo;dire au système qu&#39;une variable existe&amp;rdquo; Définir une variable signifie: &amp;ldquo;assigner une valeur à une variable&amp;rdquo;
 Lorsqu&#39;on déclare une variable ou une fonction elles sont hoisted (hissées) en haut du fichier. Par contre, lorsqu&#39;on définit une variable ou déclare et définit sur la même ligne une variable il n&#39;y a pas de hoisting.</description>
            <content type="html"><![CDATA[<p>Comprendre le <em>hoisting</em> en JavaScript est important pour organiser vos fonctions.</p>
<blockquote>
<p>Rappel entre déclarer et définir une variable:
Déclarer une variable signifie: &ldquo;dire au système qu'une variable existe&rdquo;
Définir une variable signifie: &ldquo;assigner une valeur à une variable&rdquo;</p>
</blockquote>
<p>Lorsqu'on déclare une variable ou une fonction elles sont <em>hoisted</em> (hissées) en haut du fichier. Par contre, lorsqu'on définit une variable ou déclare et définit sur la même ligne une variable il n'y a pas de <em>hoisting</em>.</p>
<p>Du coup voici des exemples de déclarations de variables et fonctions pour voir les <em>scopes</em>.</p>
<pre><code>function maSuperFonction() {
  // ReferenceError: fonctionPasDeclaree is not defined
  console.log(fonctionPasDeclaree);
  // Outputs: undefined

  console.log(variableDefiniePlusTard);
  var variableDefiniePlusTard;

  variableDefiniePlusTard = 'contenu de ma variable';
  console.log(variableDefiniePlusTard);
  // Outputs: 'contenu de ma variable'


  console.log(variableDefinieEtDefinieSimultanement);
  // Outputs: undefined
  var variableDefinieEtDefinieSimultanement = 'contenu de cette variable';
  console.log(variableDefinieEtDefinieSimultanement);
  // Outputs: 'contenu de cette variable'

  // Outputs: 'yeah!'
  nouvelleFonction();

  function nouvelleFonction() {
    console.log('yeah!');
  }

  // TypeError: undefined is not a function
  autreFonction();

  var autreFonction = function() {
    console.log('Oops');
  }
}
</code></pre><p>Pour garder les choses simples déclarez toutes vos variables au-dessus du <em>scope</em> de vos fonctions. Definissez vos variables avant d'en avoir besoin. Definissez vos fonctions en-dessous de vos <em>scopes</em>.</p>
]]></content>
        </item>
        
        <item>
            <title>Introduction à ES6</title>
            <link>https://leandeep.com/introduction-%C3%A0-es6/</link>
            <pubDate>Mon, 04 Jan 2016 19:35:00 +0000</pubDate>
            
            <guid>https://leandeep.com/introduction-%C3%A0-es6/</guid>
            <description>Voici les bases à connaître pour utiliser ES6:
Arrow Functions (Fonctions fléchées) Exemple: Plutôt que de coder:
const myFunction = function foo() { //... } Utiliser maintenant:
const myFunction = () =&amp;gt; { //... } // Si la méthode ne possède qu&#39;une seule déclaration, on écrit la méthode comme ceci: const myFunction = i =&amp;gt; 3 * i The spread operator (Syntaxe de décomposition) Si on a:
const c = [.</description>
            <content type="html"><![CDATA[<p>Voici les bases à connaître pour utiliser ES6:</p>
<h2 id="arrow-functions-fonctions-flches">Arrow Functions (Fonctions fléchées)</h2>
<p><strong>Exemple:</strong>
Plutôt que de coder:</p>
<pre><code>const myFunction = function foo() {
  //...
}
</code></pre><p>Utiliser maintenant:</p>
<pre><code>const myFunction = () =&gt; {
  //...
}

// Si la méthode ne possède qu'une seule déclaration, on écrit la méthode comme ceci:
const myFunction = i =&gt; 3 * i
</code></pre><h2 id="the-spread-operator-syntaxe-de-dcomposition">The spread operator (Syntaxe de décomposition)</h2>
<p>Si on a:</p>
<pre><code>const c = [...a]
</code></pre><p>Cette déclaration copie le tableau a dans c.
On peut ajouter d'autres éléments derrière un spread operator:</p>
<pre><code>const c = [...a, 2, 'test']
</code></pre><h2 id="destructuring-assignments-affectation-par-dcomposition">Destructuring assignments (Affectation par décomposition)</h2>
<p>On peut extraire juste certaines propriétés d'un objet en utilisant la syntaxe suivante:</p>
<pre><code>const person = {
  firstName: 'Tom',
  lastName: 'Cruise',
  actor: true,
  age: 54 //made up
}

const { firstName: name, age } = person

</code></pre><p>Cela va créer 2 const variables appelées name et age.</p>
<p>La synataxe suivante fonctionne également:</p>
<pre><code>const a = [1,2,3,4,5]
[first, second, , , fifth] = a
</code></pre><h2 id="template-literals-modles-de-libells">Template Literals (Modèles de libellés)</h2>
<pre><code>const str = `test`
</code></pre><pre><code>const string = `something ${1 + 2 + 3}`
const string2 = `something ${foo() ? 'x' : 'y'}`
</code></pre><pre><code>const string3 = `Hey
this

string
is awesome!`
</code></pre><h2 id="async--await">Async / Await</h2>
<p>Une fonction async retourne une promesse:</p>
<pre><code>const doSomethingAsync = () =&gt; {
    return new Promise((resolve) =&gt; {
        setTimeout(() =&gt; resolve('I did something'), 3000)
    })
}
</code></pre><p>Quand on veut appeler cette fonction on ajoute await comme ceci:</p>
<pre><code>const doSomething = async () =&gt; {
    console.log(await doSomethingAsync())
}
</code></pre><p><strong>Exemple</strong></p>
<pre><code>const doSomethingAsync = () =&gt; {
    return new Promise((resolve) =&gt; {
        setTimeout(() =&gt; resolve('I did something'), 3000)
    })
}

const doSomething = async () =&gt; {
    console.log(await doSomethingAsync())
}

console.log('Before')
doSomething()
console.log('After')
</code></pre><p><em>Résultat:</em></p>
<pre><code>Before
After
I did something // Après 3s
</code></pre><p><strong>Autre exemple, au lieu de:</strong></p>
<pre><code>const getFirstUserData = () =&gt; {
  return fetch('/users.json') // get users list
    .then(response =&gt; response.json()) // parse JSON
    .then(users =&gt; users[0]) // pick first user
    .then(user =&gt; fetch(`/users/${user.name}`)) // get user data
    .then(userResponse =&gt; response.json()) // parse JSON
}

getFirstUserData()
</code></pre><p><em>Le code se simplifie avec async / await:</em></p>
<pre><code>const getFirstUserData = async () =&gt; {
  const response = await fetch('/users.json') // get users list
  const users = await response.json() // parse JSON
  const user = users[0] // pick first user
  const userResponse = await fetch(`/users/${user.name}`) // get user data
  const userData = await user.json() // parse JSON
  return userData
}

getFirstUserData()
</code></pre><p><strong>Dernier exemple avec des async / await en série:</strong></p>
<pre><code>const promiseToDoSomething = () =&gt; {
    return new Promise(resolve =&gt; {
        setTimeout(() =&gt; resolve('I did something'), 10000)
    })
}

const watchOverSomeoneDoingSomething = async () =&gt; {
    const something = await promiseToDoSomething()
    return something + ' and I watched'
}

const watchOverSomeoneWatchingSomeoneDoingSomething = async () =&gt; {
    const something = await watchOverSomeoneDoingSomething()
    return something + ' and I watched as well'
}

watchOverSomeoneWatchingSomeoneDoingSomething().then((res) =&gt; {
    console.log(res)
})
</code></pre><p><em>Résultat:</em></p>
<pre><code>I did something and I watched and I watched as well
</code></pre><h2 id="classes">Classes</h2>
<pre><code>class Person {
  constructor(name) {
    this.name = name
  }

  hello() {
    return 'Hello, I am ' + this.name + '.'
  }
  
  get fullName() {
    return `${this.firstName} ${this.lastName}`
  }
  
  set age(years) {
    this.theAge = years
  }
}

class Actor extends Person {
  hello() {
    return super.hello() + ' I am an actor.'
  }
}

var tomCruise = new Actor('Tom Cruise')
tomCruise.hello()
</code></pre><h2 id="modules">Modules</h2>
<p><strong>Importer des modules</strong></p>
<p>L'import se fait via les commandes <code>import ... from ...</code>:</p>
<pre><code>import * from 'mymodule'
import React from 'react'
import { React, Component } from 'react'
import React as MyLibrary from 'react'
</code></pre><p><strong>Exporter des modules</strong></p>
<pre><code>export var foo = 2
export function bar() { /* ... */ }
</code></pre><h2 id="for-of-loop">FOR-OF LOOP</h2>
<p>C'est un forEach avec la possibilité de faire un break</p>
<pre><code>//iterate over the value
for (const v of ['a', 'b', 'c']) {
  console.log(v);
}
a
b
c

//get the index as well, using `entries()`
for (const [i, v] of ['a', 'b', 'c'].entries()) {
  console.log(i, v);
}
0 &quot;a&quot;
1 &quot;b&quot;
2 &quot;c&quot;
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer RabbitMQ sur OSX</title>
            <link>https://leandeep.com/installer-rabbitmq-sur-osx/</link>
            <pubDate>Mon, 28 Dec 2015 22:11:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-rabbitmq-sur-osx/</guid>
            <description>Pour installer RabbitMQ sur OSX, c&#39;est vraiment très simple:
Installer RabbitMQ Exécuter la commande:
brew install rabbitmq Puis ajouter la ligne export PATH=$PATH:/usr/local/sbin dans votre fichier ~/.zshrc.
Démarrer RabbitMQ Pour démarrer le service il suffit d&#39;exécuter la commande suivante:
brew services start rabbitmq Si vous vous rendez sur http://localhost:15672 vous pourrez voir l&#39;interface d&#39;administration de RabbitMQ.
 Il est également possible de démarrer le serveur en standalone via la commande rabbitmq-server.</description>
            <content type="html"><![CDATA[<p>Pour installer RabbitMQ sur OSX, c'est vraiment très simple:</p>
<h2 id="installer-rabbitmq">Installer RabbitMQ</h2>
<p>Exécuter la commande:</p>
<pre><code>brew install rabbitmq
</code></pre><p>Puis ajouter la ligne <code>export PATH=$PATH:/usr/local/sbin</code> dans votre fichier <code>~/.zshrc</code>.</p>
<h2 id="dmarrer-rabbitmq">Démarrer RabbitMQ</h2>
<p>Pour démarrer le service il suffit d'exécuter la commande suivante:</p>
<pre><code>brew services start rabbitmq
</code></pre><p>Si vous vous rendez sur http://localhost:15672 vous pourrez voir l'interface d'administration de RabbitMQ.</p>
<blockquote>
<p>Il est également possible de démarrer le serveur en standalone via la commande <code>rabbitmq-server</code>.</p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Première expérimentation avec Sigfox</title>
            <link>https://leandeep.com/premi%C3%A8re-exp%C3%A9rimentation-avec-sigfox/</link>
            <pubDate>Sun, 27 Dec 2015 20:11:00 +0000</pubDate>
            
            <guid>https://leandeep.com/premi%C3%A8re-exp%C3%A9rimentation-avec-sigfox/</guid>
            <description>Le mois dernier j&#39;ai participé à un workshop autour de Sigfox. Franchement j&#39;ai été très impressionné par cette technologie et surtout par la couverture du réseau en France.
L&#39;intérêt de Sigfox c&#39;est que cela consomme peu d&#39;énergie (Tx: &amp;lt; 50 mA during a few seconds (25mW, 14dB)) mais on peut envoyer que 12 octets par message et jusqu&#39;à 140 messages par capteur par jour.
Voici l&#39;exemple qui a été donné en workshop: On veut envoyer des coordonnées GPS, la tempêrature et reporter l&#39;état du capteur.</description>
            <content type="html"><![CDATA[<p>Le mois dernier j'ai participé à un workshop autour de Sigfox.
Franchement j'ai été très impressionné par cette technologie et surtout par la couverture du réseau en France.</p>
<p>L'intérêt de Sigfox c'est que cela consomme peu d'énergie (Tx: &lt; 50 mA during a few seconds (25mW, 14dB)) mais on peut envoyer que 12 octets par message et jusqu'à 140 messages par capteur par jour.</p>
<p>Voici l'exemple qui a été donné en workshop:
On veut envoyer des coordonnées GPS, la tempêrature et reporter l'état du capteur.</p>
<p>Ces données vont être converties comme ceci:
<img src="/images/convert-data-sigfox.png" alt="image"></p>
<p>Pour envoyer un hello-world sur le réseau Sigfox cela ressemble à ceci avec une carte Akeru beta 3.3 (Snootlab). C'est vraiment très simple.
Ensuite il suffit de se rendre sur Sigfox Cloud <a href="https://backend.sigfox.com/device/:deviceid/info">https://backend.sigfox.com/device/:deviceid/info</a> et de cliquer sur son device pour voir les données.</p>
<pre><code>#include &lt;SoftwareSerial.h&gt;

SoftwareSerial sigfox(5,4);
void setup() {
  // put your setup code here, to run once:
  Serial.begin(9600);
  sigfox.begin(9600);
  
  delay(300);
  
  sigfox.write(&quot;AT$SF=09AF0000CAFE,2,1\r&quot;);
  

}

void loop() {
  // put your main code here, to run repeatedly:
  while (sigfox.available()){
    Serial.write(sigfox.read());
  }
  
}
</code></pre><p>Il est ensuite possible d'utiliser des boards à base d'Arduino comportant toute une panoplie de capteurs avec une antenne Sigfox intégrée. Voici le code source permettant de remonter la tempêrature (°C), la pression (mbar) et l'humidité (%)</p>
<p>Voici un exemple de board intéressante pour faire du développement: <a href="https://fr.rs-online.com/web/p/kits-de-developpement-pour-radio-frequence/9015121/">SmartEverything</a></p>
<pre><code>#include &lt;LPS25H.h&gt;
#include &lt;HTS221.h&gt;
#include &lt;Wire.h&gt;
#include &lt;Arduino.h&gt;

#define SIGFOX_FRAME_LENGTH 12
#define INTERVAL 600000
#define DEBUG 0

unsigned long previousSendTime = 0;

struct data {
  int humidity;
  float temperature;
  int pressure;
};


void setup() {
  // Init UART devices
  if (DEBUG) {
    SerialUSB.begin(115200);
  }
  smeHumidity.begin();
  smePressure.begin();
  
  SigFox.begin(19200);

  initSigfox();
}

void loop() {
  data frame;
  frame.humidity = smeHumidity.readHumidity();  
  frame.temperature = (smeHumidity.readTemperature() + smePressure.readTemperature())/2.0;
  frame.pressure = smePressure.readPressure();

  if (DEBUG) {
    SerialUSB.print(&quot;Temp &quot;);
    SerialUSB.println(frame.temperature, 6);
    SerialUSB.print(&quot;\tHumidity &quot;);
    SerialUSB.println(frame.humidity);
    SerialUSB.print(&quot;\tPressure &quot;);
    SerialUSB.println(frame.pressure);
  }
 
  bool answer = sendSigfox(&amp;frame, sizeof(data));

  // Light LED depending on modem answer
  if (answer) {
    ledGreenLight(HIGH);
    ledRedLight(LOW);
  } else {
    ledGreenLight(LOW);
    ledRedLight(HIGH);
  }
  delay(1000);
  ledGreenLight(LOW);
  ledRedLight(LOW);
  
  delay(INTERVAL);
}

void initSigfox(){
  SigFox.print(&quot;+++&quot;);
  while (!SigFox.available()){
    delay(100);
  }
  while (SigFox.available()){
    byte serialByte = SigFox.read();
    if (DEBUG){
      SerialUSB.print(serialByte);
    }
  }
  if (DEBUG){
    SerialUSB.println(&quot;\n ** Setup OK **&quot;);
  }
}
String getSigfoxFrame(const void* data, uint8_t len){
  String frame = &quot;&quot;;
  uint8_t* bytes = (uint8_t*)data;
  
  if (len &lt; SIGFOX_FRAME_LENGTH){
    //fill with zeros
    uint8_t i = SIGFOX_FRAME_LENGTH;
    while (i-- &gt; len){
      frame += &quot;00&quot;;
    }
  }

  //0-1 == 255 --&gt; (0-1) &gt; len
  for(uint8_t i = len-1; i &lt; len; --i) {
    if (bytes[i] &lt; 16) {frame+=&quot;0&quot;;}
    frame += String(bytes[i], HEX);
  }
  
  return frame;
}
bool sendSigfox(const void* data, uint8_t len){
  String frame = getSigfoxFrame(data, len);
  String status = &quot;&quot;;
  char output;
  if (DEBUG){
    SerialUSB.print(&quot;AT$SF=&quot;);
    SerialUSB.println(frame);
  }
  SigFox.print(&quot;AT$SF=&quot;);
  SigFox.print(frame);
  SigFox.print(&quot;\r&quot;);
  while (!SigFox.available());
  
  while(SigFox.available()){
    output = (char)SigFox.read();
    status += output;
    delay(10);
  }
  if (DEBUG){
    SerialUSB.print(&quot;Status \t&quot;);
    SerialUSB.println(status);
  }
  if (status == &quot;OK\r&quot;){
    //Success :)
    return true;
  }
  else{
    return false;
  }
}

</code></pre><blockquote>
<p>Pour customiser le display type&rdquo; de son device sur Sigfox Cloud: <code>pressure::uint:32 temperature::float:32 humidity::uint:32</code></p>
</blockquote>
]]></content>
        </item>
        
        <item>
            <title>Guide pour démarrer un projet de Machine Learning</title>
            <link>https://leandeep.com/guide-pour-d%C3%A9marrer-un-projet-de-machine-learning/</link>
            <pubDate>Mon, 21 Dec 2015 23:05:00 +0000</pubDate>
            
            <guid>https://leandeep.com/guide-pour-d%C3%A9marrer-un-projet-de-machine-learning/</guid>
            <description>Dans cet article nous allons voir quelles sont les étapes à suivre pour mener à bien un projet de Machine Learning.
Un projet de Machine Learning correspond bien souvent à un problème que l&#39;on souhaite résoudre. Par exemple, comment diminuer la fraude à la Carte Bleue de certains de mes clients ? Où investir dans l&#39;immobilier pour faire le plus de rentabilité ? etc. Pour résoudre ce problème et atteindre une cible (Y), il faut impérativement des données (X).</description>
            <content type="html"><![CDATA[<p>Dans cet article nous allons voir quelles sont les étapes à suivre pour mener à bien un projet de Machine Learning.</p>
<p>Un projet de Machine Learning correspond bien souvent à un problème que l'on souhaite résoudre. Par exemple, comment diminuer la fraude à la Carte Bleue de certains de mes clients ? Où investir dans l'immobilier pour faire le plus de rentabilité ? etc.
Pour résoudre ce problème et atteindre une cible (Y), il faut impérativement des données (X). Nous verrons par la suite de quoi on parle en terme de données.
Enfin il faudra définir une fonction de coût (f) qui nous permette d'évaluer la distance (autrement dit l'erreur) entre la prédiction de notre modèle et la cible réelle.</p>
<p>L'objectif final étant de trouver la meilleure fonction f qui permette de prédire Y en fonction de X:
Y ~ f(X,w) avec w un ensemble de paramètres</p>
<p>Une fois le problème bien posé, il faut se poser les questions suivantes:</p>
<h1 id="1-de-quel-type-de-problme-sagit-il-">1. De quel type de problème s'agit-il ?</h1>
<p>Est-ce qu'il s'agit d'un problème d'apprentissage supervisé ou de non supervisé ?</p>
<ul>
<li>
<p><strong>Apprentissage supervisé</strong>
<em>S'agit-il d'un problème d'apprentissage supervisé de type:</em></p>
<ul>
<li>regression <em>(i.e: est-ce que la variable à prédire est continue ? Est-ce qu'on essaye de s'en approcher le plus possible ?)</em></li>
<li>classification <em>(i.e: est-ce que la variable à prédire est une classe ou un entier ?)</em></li>
<li>ranking <em>(i.e: est-ce que la variable à prédire me permet d'ordonner une liste ? Est-ce que c'est un score ?)</em></li>
</ul>
</li>
<li>
<p><strong>Apprentissage non supervisé</strong>
<em>S'agit-il d'un problème d'apprentissage non supervisé de type:</em></p>
<ul>
<li>clustering <em>(i.e: est-ce que mes données peuvent être regroupées en clusters plus pu moins homogènes ?)</em></li>
<li>réduction du nombre de dimension</li>
<li>système de recommandations</li>
</ul>
</li>
</ul>
<p>Pour simplifier le problème et essayer de donner du sens au modèle prédictif, on essaye de le ramener à un problème d'apprentissage supervisé; même si à la base on pensait qu'il s'agissait d'un problème d'apprentissage non-supervisé.</p>
<p>En pratique, ce n'est pas si simple. Pour construire un modèle prédictif fiable, il faut assembler différents types de modèles avec parfois des étapes d'apprentissage non supervisées intermédiaires.</p>
<h1 id="2-quelles-donnes-ai-je--ma-disposition-">2. Quelles données ai-je à ma disposition ?</h1>
<ul>
<li>Y a-t-il des données temporelles ?</li>
<li>Quel est mon nombre d'observations (nombre de lignes) ?</li>
<li>Quel est mon nombre de features/ variables (nombre de colonnes) ?</li>
<li>Quelles sont les variables manquantes ?</li>
<li>Quelles sont les corrélations entre les variables et la cible à prédire ?</li>
<li>Mes variables sont-elles catégorielles, discètes ou continues ?</li>
<li>Est-ce quel type de données je travaille ? CSV ? JSON ? BDD relationnelle ? BDD Graph ?..</li>
<li>Dois-je encoder mes données catégorielles ?</li>
</ul>
<h1 id="3-quel-train-test-split-raliser-sur-mon-dataset-">3. Quel Train/ Test Split réaliser sur mon dataset ?</h1>
<p>Dans cet partie on va découper notre dataset en 2 parties pour éviter de faire de l'overfitting (apprentissage par coeur).
On va réserver environ entre 70 à 80% du dataset pour la phase d'apprentissage et on va utiliser le reste pour déterminer le modèle qui fait le moins d'erreurs durant la phase de test.</p>
<p>Attention toutefois si le problème que l'on traite est un problème de classification. Il faut que toutes les classes à prédire soient bien représentées dans les 2 splits. C'est d'autant plus vrai si l'un de nos split comporte peu d'exemples.</p>
<p>Attention aussi si le problème que l'on traite comporte des données temporelles. Il faut bien séparer temporellement les splits de données pour prédire le futur avec le passé.</p>
<h1 id="4-quel-algorithme-dois-je-utiliser-">4. Quel algorithme dois-je utiliser ?</h1>
<p>Enchaînez l'apprentissage avec plusieurs modèles et comparez les résultats. Cela peut même être fait de manière automatique (Grid Search, Tpot, Auto-Sklearn&hellip;). Dès que vous entamez un problème de Machine Learning essayez tout de suite d'apprendre un modèle et d'observer votre performance. Cela vous permettra d'estimer la complexité du sujet.</p>
<p>Il faudra ensuite itérer en améliorant votre code jusqu'à ce que la performance recherchée soit atteinte.</p>
<p>Si vous souhaitez pouvoir interprêter les prédictions de votre modèle, privilégiez les modèles linéaires ou les arbres de décision.
Dans le cas contraire privilégiez les random forests. Cela vous simplifiera la vie car vous pourrez travailler avec tout type de données et votre modèle ne sera pas victime d'un surapprentissage.</p>
<h1 id="5-quelle-est-la-performance-de-mon-modle-">5. Quelle est la performance de mon modèle ?</h1>
<p>En fonction du type de problème que vous adressez, différents indicateurs peuvent être mesurés à partir du split de test.</p>
<ul>
<li>
<p><strong>Apprentissage supervisé</strong></p>
<ul>
<li>
<p>Régression</p>
<ul>
<li>Erreur de prédiction</li>
<li>Sur un Graph XY: valeur à prédire / valeur prédite</li>
</ul>
</li>
<li>
<p>Classification</p>
<ul>
<li>Courbe de ROC</li>
</ul>
<blockquote>
<p>Pour rappel, la courbre de ROC permet de représenter le ratio précision (prédire correctement) / rappel (valider la prédiction)
Certains modèles retournent un score de confiance en plus de la prédiction. Plus ce score est élevé et plus le résultat a de chance d'être correct ou précis.</p>
</blockquote>
<ul>
<li>Matrice de confusion</li>
<li>Précision / Rappel</li>
</ul>
</li>
<li>
<p>Ranking</p>
<ul>
<li>Corrélation de rang</li>
<li>DCG</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Apprentissage non supervisé</strong></p>
<ul>
<li>
<p>Clustering</p>
<ul>
<li>Nombre d'arc coupés</li>
<li>Variance inter et intra classes</li>
</ul>
</li>
<li>
<p>Système de recommandation</p>
<ul>
<li>Corrélation de rang</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Si la performance de votre modèle n'est pas suffisante, posez-vous par exemple les questions suivantes:</p>
<ul>
<li>Est-ce que les valeurs manquantes empêchent le modèle d'apprendre ?</li>
<li>Faut-il donner plus de features à mon modèle ?</li>
<li>Ai-je distribué de manière homogène mes variables entre mes splits d'apprentissage et de test ?</li>
<li>Ai-je laissé des outliers dans ma base d'apprentissage ?</li>
<li>Est-ce que mes données sont bruitées ?</li>
</ul>
<h1 id="6-comment-puis-je-optimiser-mon-modle-">6. Comment puis-je optimiser mon modèle ?</h1>
<ul>
<li>Valorisez des valeurs manquantes en utilisant la sortie d'autres modèles de machine learning</li>
<li>Calculez de nouvelles données si des données peuvent être groupées (Par exemple, calculez des moyennes pour connaître la note d'un restaurant et savoir si oui ou non des clients sont satisfaits&hellip;)</li>
<li>Pour traiter les outliers et diminuer leur importance, il faut passer les variables au logarithme.</li>
<li>Aggrégés des données sur des périodes d'un mois ou d'un an pour des données temporelles</li>
<li>Si la performance est mauvaise essayez de comprendre quelle feature est la cause du problème</li>
<li>Si vos données sont bruitées, voire très bruitées, il est possible d'utiliser les premiers axes d'une ACP (Analyse en Composante Principale; i.e: prendre le maximum d'échantillons du dataset et diminuer le nombre de variables en les compressant) ou un réseau Diabolo.</li>
</ul>
<h1 id="7-validation-du-modle">7. Validation du modèle</h1>
<p>Pour valider que votre modèle est performant et qu'il permette de réellement prédire une cible de manière fiable, réaliser une Cross Validation.</p>
]]></content>
        </item>
        
        <item>
            <title>Installer Redis sur OSX</title>
            <link>https://leandeep.com/installer-redis-sur-osx/</link>
            <pubDate>Sun, 22 Nov 2015 21:35:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-redis-sur-osx/</guid>
            <description>Voici un petit article rapide pour installer et utiliser Redis en local sur son Mac.
Installer Redis via HomeBrew:
brew install redis Démarrage de Redis au boot d&#39;OSX:
ln -sfv /usr/local/opt/redis/*.plist ~/Library/LaunchAgents Démarrer Redis via launchctl:
launchctl load ~/Library/LaunchAgents/homebrew.mxcl.redis.plist Retirer le démarrage automatique de Redis au boot d&#39;OSX:
launchctl unload ~/Library/LaunchAgents/homebrew.mxcl.redis.plist Désinstaller Redis:
brew uninstall redis rm ~/Library/LaunchAgents/homebrew.mxcl.redis.plist Vérifier que Redis est bien démarré:
redis-cli ping # PONG Administration GUI:</description>
            <content type="html"><![CDATA[<p>Voici un petit article rapide pour installer et utiliser Redis en local sur son Mac.</p>
<p><strong>Installer Redis via HomeBrew:</strong></p>
<pre><code>brew install redis
</code></pre><p><strong>Démarrage de Redis au boot d'OSX:</strong></p>
<pre><code>ln -sfv /usr/local/opt/redis/*.plist ~/Library/LaunchAgents
</code></pre><p><strong>Démarrer Redis via launchctl:</strong></p>
<pre><code>launchctl load ~/Library/LaunchAgents/homebrew.mxcl.redis.plist
</code></pre><p><strong>Retirer le démarrage automatique de Redis au boot d'OSX:</strong></p>
<pre><code>launchctl unload ~/Library/LaunchAgents/homebrew.mxcl.redis.plist
</code></pre><p><strong>Désinstaller Redis:</strong></p>
<pre><code>brew uninstall redis
rm ~/Library/LaunchAgents/homebrew.mxcl.redis.plist
</code></pre><p><strong>Vérifier que Redis est bien démarré:</strong></p>
<pre><code>redis-cli ping

# PONG
</code></pre><p><strong>Administration GUI:</strong></p>
<p><a href="https://github.com/humante/redis-browser">https://github.com/humante/redis-browser</a></p>
<p>Web based GUI on http://localhost:4567</p>
<pre><code># Install it with $ gem install redis-browser
# gem install redis-browser

# Run it with $ redis-browser
== Sinatra (v2.0.5) has taken the stage on 4567 for development with backup from WEBrick
INFO  WEBrick::HTTPServer#start: pid=10586 port=4567

</code></pre>]]></content>
        </item>
        
        <item>
            <title>Commandes Python de base pour Scikit-Learn</title>
            <link>https://leandeep.com/commandes-python-de-base-pour-scikit-learn/</link>
            <pubDate>Thu, 15 Oct 2015 22:34:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-python-de-base-pour-scikit-learn/</guid>
            <description>1. L&#39;objet estimator Dans Scikit les algorithmes de Machine Learning sont exposés via des objets appelés &amp;ldquo;estimator&amp;rdquo;.
Exemple pour une régression linéaire:
from sklearn.linear_model import LinearRegression # Tous les paramètres pour configurer l&#39;estimator peuvent être passé à l&#39;objet lors de son instanciation model = LinearRegression(normalize=True) print(model) Résultat:
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True) L&#39;interface des méthodes de scikit-learn sont uniformes.
Pour tous les estimators:
 model.fit() : remplit le modèle avec des données d&#39;entrainement.</description>
            <content type="html"><![CDATA[<h1 id="1-lobjet-estimator">1. L'objet <em>estimator</em></h1>
<p>Dans Scikit les algorithmes de Machine Learning sont exposés via des objets appelés <em>&ldquo;estimator&rdquo;</em>.</p>
<p>Exemple pour une régression linéaire:</p>
<pre><code>from sklearn.linear_model import LinearRegression

# Tous les paramètres pour configurer l'estimator peuvent être passé à l'objet lors de son instanciation
model = LinearRegression(normalize=True)

print(model)
</code></pre><p><em>Résultat:</em></p>
<pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)
</code></pre><p>L'interface des méthodes de scikit-learn sont uniformes.</p>
<p><strong>Pour tous les <em>estimators</em>:</strong></p>
<ul>
<li>model.fit() : remplit le modèle avec des données d'entrainement. Pour un apprentissage supervisé, la méthode accepte 2 arguments: les données X et les labels y (i.e. model.fit(X, y)). Pour une apprentissage non supervisé, la méthode ne prend qu'un seul arguement, les données X (i.e. model.fit(X)).</li>
</ul>
<p><strong>Pour les <em>estimators</em> en apprentissage supervisé:</strong></p>
<ul>
<li>model.predict() : prédire le label d'un ensemble de features à partir d'un modèle entrainé. La méthode accepte un argument, les nouvelles données X_new (i.e. model.predict(X_new) et retourne les labels prédits pour chaque objet du tableau.</li>
<li>model.predict_proba() : Pour les problèmes de classification, certains <em>estimators</em> fournissent cette méthode qui retourne la probabilité qu'une nouvelle observation possède chaque label. La label qui la plus forte probabilité est retourné par model.predict().</li>
<li>model.score() : Pour les problèmes de régession ou de classification, les <em>estimators</em> implémentent une méthode de score. Cette dernière permet d'indiquer si le fit est bon ou pas. Le score peut varier entre 0 et 1.</li>
</ul>
<h1 id="2-ajouter-des-donnes--lestimator">2. Ajouter des données à l&rsquo;<em>estimator</em></h1>
<pre><code>%matplotlib inline
import numpy as np
from matplotlib import pyplot as plt

x = np.array([0, 1, 2])
y = np.array([0, 1, 2])

_ = plt.plot(x, y, marker='o')
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/plot1.png" alt="image"></p>
<pre><code>X = x[:, np.newaxis] # On incrémente la dimension car scikit prend un tableau à 2 dimensions en input: (samples == 3 x features == 1)

model.fit(X, y)

model.coef_ # Paramètre estimé par scikit à partir des données ajoutées. Tous les paramètres estimés par scikit se terminent un _.
</code></pre><h1 id="3-apprentissage-supervis-classification-et-rgression">3. Apprentissage supervisé: Classification et Régression</h1>
<p>En apprentissage supervisé, on a un dataset qui contient à la fois des <em>features</em> et des <em>labels</em>.
L'objectif est de construire un <em>estimator</em> qui est capable de prédire le <em>label</em> d'un objet à partir d'un ensemble de <em>features</em>.
En classification, le <em>label</em> est valeur discrète alors qu'en régression le <em>label</em> est une valeur continue.</p>
<h2 id="31-classification">3.1. Classification</h2>
<p>KNN (K Nearest Neighbors) ou &ldquo;K voisins les plus proches&rdquo; en français est un des algorithmes les plus simples à appréhender:
Pour une toute nouvelle observation, regarder dans une base de référence, quelle observation a ses <em>features</em> les plus proches et  lui assigner la classe prédominante.</p>
<p><img src="/images/Petal-sepal.jpg" alt="image"></p>
<pre><code># On charge d'abord le dataset Iris
from sklearn import neighbors, datasets
iris = datasets.load_iris()

# On extrait les features et labels du dataset
X, y = iris.data, iris.target

# On instancie l'*estimator*
knn = neighbors.KNeighborsClassifier(n_neighbors=1) 
# n_neighbors=1 signifie que le nombre de voisin(s) à avoir égal à 1

# On remplit l'*estimator* avec les données
knn.fit(X, y)

# On prédit l'Iris qui a les caractéristiques (features) suivantes: 
# sépale = 4cm x 3cm et pétale = 5cm x 2cm
print(iris.target_names[knn.predict([[4, 3, 5, 2]])])
</code></pre><p><em>Résultat:</em></p>
<pre><code>['virginica']
</code></pre><h3 id="afficher-un-scatter-plot-des-features-longeur-et-largeur-des-spales-ainsi-que-la-prduction-du-knn">Afficher un scatter plot des features longeur et largeur des sépales ainsi que la préduction du KNN</h3>
<p>Exemple complet:</p>
<pre><code># On charge le dataset
from sklearn import neighbors, datasets
iris = datasets.load_iris()

# On mappe 3 couleurs ou les 3 classes du problème
from matplotlib.colors import ListedColormap
cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])
cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])


X = iris.data[:, :2]  # On prend les 2 features liées aux sépales
y = iris.target

knn = neighbors.KNeighborsClassifier(n_neighbors=3)
knn.fit(X, y)

x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1
y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),
                      np.linspace(y_min, y_max, 100))

Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])

# On plot le résultat
Z = Z.reshape(xx.shape)
plt.figure()
plt.pcolormesh(xx, yy, Z, cmap=cmap_light)

# On plot également les points d'entrainement
plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)
plt.xlabel('sepal length (cm)')
plt.ylabel('sepal width (cm)')
plt.axis('tight')
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/scatter-plot.png" alt="image"></p>
<h2 id="32-rgression">3.2. Régression</h2>
<p>La régression la plus simple est la régression linéaire. Voici un exemple:</p>
<p>On crée des données aléatoires:</p>
<pre><code>import numpy as np
np.random.seed(0)
X = np.random.random(size=(20, 1))
y = 3 * X[:, 0] + 2 + np.random.normal(size=20)
print(X)
print(X.shape)
print(y)
print(y.shape)
</code></pre><p><em>Résultat:</em></p>
<pre><code>[[0.5488135 ]
 [0.71518937]
 [0.60276338]
 [0.54488318]
 [0.4236548 ]
 [0.64589411]
 [0.43758721]
 [0.891773  ]
 [0.96366276]
 [0.38344152]
 [0.79172504]
 [0.52889492]
 [0.56804456]
 [0.92559664]
 [0.07103606]
 [0.0871293 ]
 [0.0202184 ]
 [0.83261985]
 [0.77815675]
 [0.87001215]]
(20, 1)
[5.14051958 3.94040984 4.12135783 2.78055381 0.71797458 4.59130093
 4.17719783 3.93315398 7.16074291 1.69595888 4.42093363 3.39950091
 5.2369129  6.24614868 2.3680556  2.63955042 1.17286944 2.51706307
 3.9865581  4.76638541]
(20,)
</code></pre><p>On remplit l&rsquo;<em>estimator</em> avec ces données:</p>
<pre><code>from sklearn.linear_model import LinearRegression
model = LinearRegression(fit_intercept=True)
model.fit(X, y)
print(&quot;Model coefficient: %.5f, and intercept: %.5f&quot;
      % (model.coef_, model.intercept_))
</code></pre><p><em>Résultat:</em></p>
<pre><code>Model coefficient: 3.93491, and intercept: 1.46229
</code></pre><p>On affiche le graphique et le modèle prédictif</p>
<pre><code># On affiche les données d'entrainement
import pylab as pl
plt.plot(X[:, 0], y, 'o')

# On prédit les labels pour 100 points allant de 0 à 1 qu'on ajoute au graphique précédent
X_test = np.linspace(0, 1, 100)[:, np.newaxis]
y_test = model.predict(X_test)
plt.plot(X_test[:, 0], y_test)
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/regression.png" alt="image"></p>
<h1 id="4-rgularisation">4. Régularisation</h1>
<p>Cela permet de, comme son nom d'indique, régulariser les erreurs d'apprentissage. Supposez que vous créez un <em>estimator</em> KNN avec k=1, il est évident qu'il y aura des erreurs sur vos données d'apprentissage.</p>
<blockquote>
<p>Wikipédia
&ldquo;La régularisation fait référence à un processus consistant à ajouter de l'information à un problème pour éviter le surapprentissage&rdquo;</p>
</blockquote>
<p>L'idée principale de la régularisation est qu'il est préférable de construire des modèles plus simples même s'ils conduisent à plus d'erreurs sur les données d'apprentissage.</p>
<p><strong>Un schéma vaut mieux qu'un long discours</strong></p>
<p>On part des données suivantes:</p>
<pre><code>import numpy as np
rng = np.random.RandomState(0)
x = 2 * rng.rand(100) - 1

f = lambda t: 1.2 * t ** 2 + .1 * t ** 3 - .4 * t ** 5 - .5 * t ** 9
y = f(x) + .4 * rng.normal(size=100)

plt.figure()
plt.scatter(x, y, s=4)
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/scatter-plot2.png" alt="image"></p>
<p>On remplit 2 estimateurs avec des données ayant des polynômes 4 et 9.</p>
<pre><code>x_test = np.linspace(-1, 1, 100)

plt.figure()
plt.scatter(x, y, s=4)

X = np.array([x**i for i in range(5)]).T
X_test = np.array([x_test**i for i in range(5)]).T
order4 = LinearRegression()
order4.fit(X, y)
plt.plot(x_test, order4.predict(X_test), label='4th order')

X = np.array([x**i for i in range(10)]).T
X_test = np.array([x_test**i for i in range(10)]).T
order9 = LinearRegression()
order9.fit(X, y)
plt.plot(x_test, order9.predict(X_test), label='9th order')

plt.legend(loc='best')
plt.axis('tight')
plt.title('Fitting a 4th and a 9th order polynomial')
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/polynomes.png" alt="image"></p>
<p>Quelle courbe préférez-vous ?</p>
<p>Le polynôme de degré 9 a tendance à passer par tous les points du graphique. Il va intégrer le bruit spécifique à l’échantillon d’entraînement; ce qui conduira notre modèle à ne pas avoir une bonne performance sur de nouveaux exemples.</p>
<p>Un des risques majeurs avec ce type de modèles est le surapprentissage.
La régularisation donc, est une technique permettant de (régulariser) rêgler ce phénomène.</p>
]]></content>
        </item>
        
        <item>
            <title>Comment lire une Matrice de confusion</title>
            <link>https://leandeep.com/comment-lire-une-matrice-de-confusion/</link>
            <pubDate>Thu, 01 Oct 2015 20:30:00 +0000</pubDate>
            
            <guid>https://leandeep.com/comment-lire-une-matrice-de-confusion/</guid>
            <description>Chaque colonne de la matrice représente le nombre d&#39;occurrences d&#39;une classe estimée, tandis que chaque ligne représente le nombre d&#39;occurrences d&#39;une classe réelle (ou de référence). Les occurrences utilisées pour chacune de ces 2 classes doivent être différentes.
Exemple:
On considère un système de classification dont le but est de classer du mail (courrier électronique) en deux classes:
 courriel pertinent ou pourriel intempestif.  On va vouloir savoir:
 Combien de courriels seront faussement estimés comme des pourriels (fausses alarmes) et combien de pourriels ne seront pas estimés comme tels (non détections) et donc classifiés comme courriels.</description>
            <content type="html"><![CDATA[<p>Chaque colonne de la matrice représente le nombre d'occurrences d'une classe estimée, tandis que chaque ligne représente le nombre d'occurrences d'une classe réelle (ou de référence). Les occurrences utilisées pour chacune de ces 2 classes doivent être différentes.</p>
<p>Exemple:</p>
<p>On considère un système de classification dont le but est de classer du mail (courrier électronique) en deux classes:</p>
<ul>
<li>courriel pertinent ou</li>
<li>pourriel intempestif.</li>
</ul>
<p>On va vouloir savoir:</p>
<ul>
<li>Combien de courriels seront faussement estimés comme des pourriels (fausses alarmes) et</li>
<li>combien de pourriels ne seront pas estimés comme tels (non détections) et donc classifiés comme courriels.</li>
</ul>
<p>On va supposer qu'on a expérimenté notre classificateur sur 100 courriels et sur 100 pourriels, constituant ainsi un jeu initial de 200 mails correspondant au contenu de la classe réelle.</p>
<p>La matrice de confusion suivante se lit alors comme suit:</p>
<ul>
<li>horizontalement, sur les 100 courriels initiaux (ie : 95+5), 95 ont été estimés par le système de classification comme tels et 5 ont été estimés comme pourriels (ie : 5 faux-négatifs),</li>
<li>horizontalement, sur les 100 pourriels initiaux (ie : 3+97), 3 ont été estimés comme courriels (ie : 3 faux-positifs) et 97 ont été estimés comme pourriels,</li>
<li>verticalement, sur les 98 mails (ie : 95+3) estimés par le système comme courriels, 3 sont en fait des pourriels,</li>
<li>verticalement, sur les 102 mails (ie : 5+97) estimés par le système comme pourriels, 5 sont en fait des courriels.</li>
</ul>
<p><img src="/images/matrice-de-classification.png" alt="image"></p>
<p><em>Source: Wikipedia.fr</em></p>
]]></content>
        </item>
        
        <item>
            <title>Config, Commandes et tips utiles Git</title>
            <link>https://leandeep.com/config-commandes-et-tips-utiles-git/</link>
            <pubDate>Sat, 19 Sep 2015 18:25:00 +0000</pubDate>
            
            <guid>https://leandeep.com/config-commandes-et-tips-utiles-git/</guid>
            <description>Indispensable à savoir Index
L’index est une zone qui permet de préparer un commit.
 HEAD
HEAD est la référence sur le commit sur lequel on se trouve actuellement. On le change avec git checkout.
 Rebase vs Merge Préférer le rebase pour garder un historique propre
 Rebase Eviter git pull pour éviter que Git ne considère notre branche locale et remote comme 2 branches différentes alors que ce sont les mêmes.</description>
            <content type="html"><![CDATA[<h2 id="indispensable--savoir">Indispensable à savoir</h2>
<p><strong>Index</strong></p>
<p>L’index est une zone qui permet de préparer un commit.</p>
<br/>
<p><strong>HEAD</strong></p>
<p>HEAD est la référence sur le commit sur lequel on se trouve actuellement. On le change avec git checkout.</p>
<br/>
<h2 id="rebase-vs-merge">Rebase vs Merge</h2>
<p>Préférer le rebase pour garder un historique propre</p>
<br/>
<h2 id="rebase">Rebase</h2>
<p>Eviter <code>git pull</code> pour éviter que Git ne considère notre branche locale et remote comme 2 branches différentes alors que ce sont les mêmes.</p>
<p>Faire un rebase:</p>
<pre><code>git pull --rebase 
ou 
git rebase origin/master
</code></pre><p>Les commits qui n’existaient que sur la branche master sont supprimés et réappliqués/ rejoués à la suite des commits de la branche origin/master.</p>
<p>En rebasant vos branches avant de les fusionner, vous obtiendrez un historique tout plat et bien plus agréable à parcourir.</p>
<br/>
<p><strong>Exemple 1</strong></p>
<pre><code>          F---G ← bug2
         /
A---B---E---H---I ← master
     \
      C---D ← bug1
</code></pre><p>En utilisant un rebase avant chaque fusion, on obtient l'historique suivant :</p>
<pre><code>A---B---E---H---I---C---D---F---G ← master
</code></pre><p>Les commandes pour parvenir à ce résultat sont les suivantes, explications juste après.</p>
<pre><code>git rebase master bug1
git checkout master
git merge bug1
git branch -d bug1
git rebase master bug2
git checkout master
git merge bug2
git branch -d bug2
</code></pre><p>Explications des commandes.</p>
<ul>
<li>Transplante bug1 sur l'actuelle branche master. <strong>Si on est déjà en train de bosser sur bug1 on peut se contenter de taper git rebase master</strong></li>
<li>Switche sur master</li>
<li>Fusionne bug1 dans master</li>
<li>Supprime la branche bug1 devenue inutile</li>
<li>Transplante bug2 sur la branche master</li>
<li>Switche sur master</li>
<li>Fusionne bug2 dans master</li>
<li>Supprime bug2 devenue inutile.</li>
</ul>
<br/>
<p><strong>Exemple 2</strong></p>
<blockquote>
<p>Autre manière de faire, peut être plus simple&hellip;</p>
</blockquote>
<p>En supposant que l'on veuille garder la feature branche synchronisée avec la branche develop, voici les commandes à suivre:</p>
<pre><code>git fetch # depuis la feature branche (vérifier que la feature branche sur laquelle vous travaillez est à jour)

git rebase origin/develop

# S'il y a des conflits, il faut les résoudre un par un.

Utiliser git rebase --continue une fois que tous les conflits sont traités

git push origin feature_branch --force
</code></pre><br/>
<p><strong>Exemple 3 (ultra simple que je recommande)</strong></p>
<pre><code>git checkout votre_feature_branch
git fetch
git rebase origin/master
</code></pre><p>Et c'est tout!</p>
<br/>
<h2 id="merge-quand-mme">Merge (quand même)</h2>
<pre><code>git checkout master
git pull
git checkout your_feature_en_attente
git merge master
</code></pre><br/>
<h2 id="stash">Stash</h2>
<p>Cette commande permet de mettre de côté des modifications de la copie de travail et de l’index.</p>
<br/>
<p><strong>Afficher tous les stash</strong></p>
<pre><code>git stash list
</code></pre><br/>
<p><strong>Appliquer un stash</strong></p>
<pre><code># Exemple:
git stash apply stash@{0}
</code></pre><br/>
<p><strong>Créer un nouveau stash (stasher tous les fichiers)</strong></p>
<pre><code>git stash save &quot;&lt;nom du stash&gt;&quot;
</code></pre><br/>
<p><strong>Créer seulement certains fichiers</strong></p>
<p>Add to index changes we don't want to stash and then stash with &ndash;keep-index option.</p>
<pre><code>git add app/controllers/cart_controller.php
git stash --keep-index
git reset
</code></pre><br/>
<p><strong>Appliquer un stash</strong></p>
<pre><code>git stash branch myfeature
</code></pre><br/>
<p><strong>Appliquer le dernier stash (LIFO)</strong></p>
<pre><code>git stash pop
</code></pre><br/>
<h2 id="cherry-picking">Cherry-picking</h2>
<p>Cherry-pick permet de sélectionner un commit quelconque et de l’appliquer sur la branche actuelle.</p>
<pre><code>git checkout my-feature
git cherry-pick e32c529d
</code></pre><br/>
<h2 id="rsoudre-un-conflit">Résoudre un conflit</h2>
<p><strong>Pendant un merge</strong></p>
<p>Après un <code>git merge</code> ou <code>git pull</code>, on commence par exécuter la commande:</p>
<pre><code>git status # ou gss # ou git st # git stp (voir mes alias)
# On branch master
# Changes to be committed:
#
#       modified:   mon_fichier1
#
# Unmerged paths:
#   (use &quot;git add/rm &lt; file &gt;...&quot; as appropriate to mark resolution)
#
#       both modified:      mon_fichier2
#
</code></pre><p>Puis on corrige le problème de merge grâce à la commande <code>git mergetool</code> qui ouvrira l'outil de merge configuré sur votre poste.
Autre possibilité, faire la correction manuellement, faire un <code>git add</code> ou <code>git stage</code> sur le fichier corrigé et enfin un <code>git commit</code>.</p>
<blockquote>
<p>En cas de problème, il est possible d'exécuter un <code>git reset --hard HEAD</code> pour revenir en arrière sur le merge</p>
</blockquote>
<blockquote>
<p>Pour configurer git mergetool, il est possible d'utiliser la commande suivante: <code>git config --global merge.tool bc3</code> après avoir téléchargé et installé l'extension <a href="https://marketplace.visualstudio.com/items?itemName=hung-vi.terminal-git-mergetool">vscode-ext-git-mergetool</a> pour OSX .</p>
</blockquote>
<br/>
<p><strong>Pendant un rebase</strong></p>
<pre><code>git checkout master # ou git co master
git rebase origin/master # ou git pull --rebase

git status
# Unmerged paths:
#   (use &quot;git add/rm &lt; file &gt;...&quot; as appropriate to mark resolution)
#
#       both modified:      mon_fichier
#

git mergetool

# On corrige

git rebase --continue
</code></pre><blockquote>
<p>Pour revenir en arrière (état du dépot) sur un rebase qui se passe mal: <code>git rebase --abort</code></p>
</blockquote>
<p>Un schéma vaut mieux qu'un long discours. Voici ce que fait un rebase:</p>
<p><img src="/images/rebase.png" alt="image"></p>
<br/>
<p><strong>Gérer un conflit sur un binaire</strong></p>
<pre><code>git checkout --ours -- path_binary_file
git checkout --theirs -- path_binary_file
</code></pre><br/>
<h2 id="rcrire-lhistorique">Réécrire l'historique</h2>
<pre><code>git rebase --interactive HEAD~3
# ou 
# git rebase -i HEAD~3
# ou
# git rebase -i &lt;sha-de-votre-commit&gt; (via git log)
</code></pre><p>Plusieurs options s'offrent à nous pour les 3 commits:</p>
<ul>
<li>Supprimer la ligne pour supprimer le commit de l’historique</li>
<li>Changer l’ordre des lignes pour changer l’ordre d’application des commits</li>
<li>Remplacer &ldquo;pick&rdquo; par &ldquo;edit&rdquo; pour pouvoir modifier le commit</li>
<li>Remplacer &ldquo;pick&rdquo; par &ldquo;squash&rdquo; pour merger le commit avec le précédent pour n’en créer qu’un seul</li>
<li>Remplacer &ldquo;pick&rdquo; par &ldquo;reword&rdquo; pour juste changer le message de commit</li>
</ul>
<p>Pour poursuivre la réécriture de l’historique, terminer avec les commandes suivantes:</p>
<pre><code>git stage
git rebase --continue
</code></pre><br/>
<h2 id="config-en-plus-de-oh-my-zsh">Config (en plus de oh-my-zsh)</h2>
<p>A ajouter au fichier ~/.gitconfig:</p>
<pre><code>[alias]
        st = status
        stp = status --porcelain
        ci = commit
        br = branch
        co = checkout
        rz = reset --hard HEAD
        pullr = pull --rebase
        unstage = reset HEAD
        lol = log --graph --decorate --pretty=oneline --abbrev-commit
        lola = log --graph --decorate --pretty=oneline --abbrev-commit --all
        lpush = &quot;!git --no-pager log origin/$(git currentbranch)..HEAD --oneline&quot;
        lpull = &quot;!git --no-pager log HEAD..origin/$(git currentbranch) --oneline&quot;
        whatsnew = &quot;!git diff origin/$(git currentbranch)...HEAD&quot;
        whatscoming = &quot;!git diff HEAD...origin/$(git currentbranch)&quot;
        currentbranch = &quot;!git branch | grep \&quot;^\\*\&quot; | cut -d \&quot; \&quot; -f 2&quot;
...
[color]
        branch = auto
        diff = auto
        status = auto
        interactive = auto
</code></pre><br/>
<h2 id="tlcharger-en-local-les-pull-requests">Télécharger en local les Pull Requests</h2>
<p><strong>Projet par projet</strong></p>
<p>Dans le fichier .git/config, localiser le code qui ressemble à ceci:</p>
<pre><code>[remote &quot;origin&quot;]
	fetch = +refs/heads/*:refs/remotes/origin/*
	url = git@github.com:joyent/node.git
</code></pre><p>Maintenant ajouter la ligne suivante:</p>
<pre><code>(pour Gitlab) fetch = +refs/merge-requests/*/head:refs/remotes/origin/merge-requests/*

# fetch = +refs/pull/*/head:refs/remotes/origin/pr/*
</code></pre><p>La section dans le fichier devrait resssemble à cela:</p>
<pre><code>[remote &quot;origin&quot;]
	fetch = +refs/heads/*:refs/remotes/origin/*
	url = git@github.com:joyent/node.git
	fetch = +refs/merge-requests/*/head:refs/remotes/origin/merge-requests/*
</code></pre><p>Maitenant vous pouvez récupérer toutes les PR en cours:</p>
<pre><code>git fetch origin
From github.com:joyent/node
 * [new ref]         refs/pull/1000/head -&gt; origin/pr/1000
 * [new ref]         refs/pull/1002/head -&gt; origin/pr/1002
 * [new ref]         refs/pull/1004/head -&gt; origin/pr/1004
 * [new ref]         refs/pull/1009/head -&gt; origin/pr/1009
...
</code></pre><p>Vous pouvez faire un checkout sur une pull request en particulier:</p>
<pre><code>git checkout pr/999
Branch pr/999 set up to track remote branch pr/999 from origin.
Switched to a new branch 'pr/999'
</code></pre><br/>
<p><strong>Ajouter automatiquement cette commande à tous les repos</strong></p>
<pre><code>git config --global --add remote.origin.fetch &quot;+refs/pull/*/head:refs/remotes/origin/pr/*&quot;
</code></pre><br/>
<h2 id="diffrences-entre-branches">Différences entre branches</h2>
<p><strong>Différences entre branche actuelle et master:</strong></p>
<pre><code>git diff master
</code></pre><br/>
<p><strong>Différences entre 2 branches (par exemple master et staging):</strong></p>
<pre><code>git diff master..staging
</code></pre><br/>
<p><strong>Seulement montrer les fichiers différents entre 2 branches (sans les changements):</strong></p>
<pre><code>git diff --name-status master..staging
</code></pre><br/>
<p><strong>Différence entre un fichier local (déjà en stage) et le dernier commit (ou l'avant dernier):</strong></p>
<pre><code>git diff &lt;commit&gt; &lt;path&gt;
# Dernier commit 
git diff HEAD^ myfile
# Avant dernier commit 
git diff HEAD^^ myfile
</code></pre><br/>
<h2 id="commandes-en-vrac">Commandes en vrac</h2>
<p><strong>Annuler la commande <code>git commit</code> (et donc conserver/ récupérer tous les changements qui étaient prêts à être pushés:</strong></p>
<pre><code>git reset --soft HEAD^
</code></pre><br/>
<p><strong>Modifier le dernier commit:</strong></p>
<pre><code>git commit --amend
</code></pre><br/>
<p><strong>Effacer une branche locale:</strong></p>
<pre><code>git branch -d new-branch
</code></pre><br/>
<p><strong>Retourner sur la dernière branche:</strong></p>
<pre><code>git checkout -
</code></pre><br/>
<p><strong>Effacer une branche remote:</strong></p>
<pre><code>git push origin --delete new-branch
</code></pre><br/>
<p><strong>Contrôler le comportement de git push par default pour éviter de devoir specifier la branch (sur laquelle on est) avant de pusher:</strong></p>
<pre><code>git config --global push.default current
</code></pre><br/>
<p><strong>Annuler les changements en local d'un fichier</strong></p>
<pre><code>git checkout filename
</code></pre><br/>
<p><strong>Pusher un seul commit</strong></p>
<pre><code>git push &lt;remote_name&gt; &lt;commit SHA&gt;:&lt;remote_branch_name&gt;
</code></pre><p>La branche &lt;remote_branch_name&gt; doit exister sur remote. (Si ce n'est pas le cas, il est possible d'utiliser <code>git push &lt;remote_name&gt; &lt;commit SHA&gt;:refs/heads/&lt;remote_branch_name&gt;</code> pour la créer automatiquement.)</p>
<blockquote>
<p>Note:
<code>git push --set-upstream origin dev</code> ou <code>git push -u origin dev</code>
Cette commande envoie la branche « dev » vers le dépôt « origin » (i.e. celui dont on a fait un clone au départ), et l'option &ndash;set-upstream permet de dire à Git de se souvenir qu'un « git push » de notre branche « dev » a été fait. Le prochain push pourra donc se faire simplement avec un simple <code>git push</code>.</p>
</blockquote>
<br/>
<p><strong>Annuler le dernier commit</strong></p>
<p>Les commandes à appliquer dépendent du dernier commit:</p>
<ul>
<li>
<p>Quand le dernier commit <strong>n'est pas</strong> le commit initial, il suffit d'exécuter la commance suivante: <code>git reset HEAD~</code></p>
</li>
<li>
<p>Quand le dernier commit <strong>est</strong> le commit initial, il faut exécuter les commandes suivantes: <code>git update-ref -d HEAD</code> puis <code>git rm --cached -r .</code></p>
</li>
</ul>
<br/>
<p><strong>Annuler le dernier commit et garder tous les changements staged</strong></p>
<pre><code>git reset --soft HEAD~
</code></pre><p><em>C'est différent de <code>git reset HEAD~</code> qui ne garde pas staged les derniers changements.</em></p>
<br/>
<p><strong>Voir les derniers commits locaux pas encore pushé sur l'origin:</strong></p>
<pre><code>git log --branches --not --remotes
</code></pre><br/>
<p><strong>Tagguer (le dernier commit d&rsquo;) une branche</strong></p>
<pre><code>git tag mon_tag
git push origin mon_tag

# (non recommandé) pousser tous les tags
git push --tags
</code></pre><br/>
<h2 id="naviguer-dans-tout-son-historique-git">Naviguer dans tout son historique Git</h2>
<pre><code>$ git init
Initialized empty Git repository in .git/

$ echo &quot;testing reset&quot; &gt; file1
$ git add file1
$ git commit -m 'added file1'
Created initial commit 1a75c1d: added file1
 1 files changed, 1 insertions(+), 0 deletions(-)
 create mode 100644 file1

$ echo &quot;added new file&quot; &gt; file2
$ git add file2
$ git commit -m 'added file2'
Created commit f6e5064: added file2
 1 files changed, 1 insertions(+), 0 deletions(-)
 create mode 100644 file2

$ git reset --hard HEAD^
HEAD is now at 1a75c1d... added file1

$ cat file2
cat: file2: No such file or directory

$ git reflog
1a75c1d... HEAD@{0}: reset --hard HEAD^: updating HEAD
f6e5064... HEAD@{1}: commit: added file2

$ git reset --hard f6e5064
HEAD is now at f6e5064... added file2

$ cat file2
added new file
</code></pre><br/>
<h2 id="taille-en-local-du-repo">Taille en local du repo</h2>
<pre><code>$ git count-objects -v -H

count: 6
size: 24.00 KiB
in-pack: 0
packs: 0
size-pack: 0 bytes
prune-packable: 0
garbage: 0
size-garbage: 0 bytes
</code></pre><br/>
<h2 id="bisect">Bisect</h2>
<blockquote>
<p>Le bisect permet de réaliser une dichotimie sur un range de commit afin d'identifier celui qui génère une régression.</p>
</blockquote>
<pre><code>$ git bisect start          # Start the binary search process
$ git bisect bad            # Identify the end of the range
$ git bisect good v4.2.0    # Identify the start of the range
</code></pre><p>Puis après un test sur votre app ou tests unitaires préciser soit <code>git bisect bad</code> ou <code>git bisect good</code></p>
<br/>
<h2 id="workflow-pour-travailler-en-quipe">Workflow pour travailler en équipe</h2>
<p><strong>Gitflow:</strong>
<a href="http://danielkummer.github.io/git-flow-cheatsheet/">http://danielkummer.github.io/git-flow-cheatsheet/</a></p>
<br/>
<p><em>Edited 13 november 2016:</em></p>
<p><strong>Better method: Github flow:</strong></p>
<p><a href="https://blogs.technet.microsoft.com/devops/2016/06/21/a-git-workflow-for-continuous-delivery/">https://blogs.technet.microsoft.com/devops/2016/06/21/a-git-workflow-for-continuous-delivery/</a></p>
]]></content>
        </item>
        
        <item>
            <title>Basics Python commands pour Matplotlib, Numpy et debugging misc</title>
            <link>https://leandeep.com/basics-python-commands-pour-matplotlib-numpy-et-debugging-misc/</link>
            <pubDate>Mon, 14 Sep 2015 19:24:00 +0000</pubDate>
            
            <guid>https://leandeep.com/basics-python-commands-pour-matplotlib-numpy-et-debugging-misc/</guid>
            <description>Voici une liste de commandes de base pour commencer à travailler avec Matplotlib et Numpy.
Matplotlib &amp;amp; Numpy 1. Charger un dataset On charge un dataset basic (fleurs Iris très connu). On s&#39;en sert ensuite dans l&#39;affichage d&#39;un nuage de points avec Matplotlib.
from sklearn.datasets import load_iris iris = load_iris() n_samples, n_features = iris.data.shape print(n_samples) print(n_features) # 150 # 4 2. Afficher un nuage de points (scatter plot) On considère travailler avec un array (150,4).</description>
            <content type="html"><![CDATA[<p>Voici une liste de commandes de base pour commencer à travailler avec Matplotlib et Numpy.</p>
<h1 id="matplotlib--numpy">Matplotlib &amp; Numpy</h1>
<h2 id="1-charger-un-dataset">1. Charger un dataset</h2>
<p>On charge un dataset basic (fleurs Iris très connu). On s'en sert ensuite dans l'affichage d'un nuage de points avec Matplotlib.</p>
<pre><code>from sklearn.datasets import load_iris
iris = load_iris()

n_samples, n_features = iris.data.shape
print(n_samples)
print(n_features)

# 150
# 4
</code></pre><h2 id="2-afficher-un-nuage-de-points-scatter-plot">2. Afficher un nuage de points (scatter plot)</h2>
<p>On considère travailler avec un array (150,4). Voir point 1.</p>
<pre><code># La commande qui suit permet de ne pas avoir de problème avec l'affichage de graphiques dans Jupyter Notebook 
%matplotlib inline
</code></pre><p>Affichage du scratter plot:</p>
<pre><code>from matplotlib import pyplot as plt

x_index = 1
y_index = 3

# Ce formateur permet de remplacer les index des classes d'iris par leur nom dans la légende
formatter = plt.FuncFormatter(lambda i, *args: iris.target_names[int(i)])

plt.scatter(iris.data[:, x_index], iris.data[:, y_index], c=iris.target)
plt.colorbar(ticks=[0, 1, 2], format=formatter)
plt.xlabel(iris.feature_names[x_index])
plt.ylabel(iris.feature_names[y_index])
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/plot-basics.png" alt="image"></p>
<h2 id="3-manipuler-des-numpy-arrays">3. Manipuler des Numpy Arrays</h2>
<h3 id="31-gnrer-un-tableau-alatoire">3.1. Générer un tableau aléatoire</h3>
<pre><code>import numpy as np

X = np.random.random((3,5))
print(X)
</code></pre><p><em>Résultat:</em></p>
<pre><code>[[0.74271281 0.89627097 0.95309957 0.48770972 0.3841344 ]
 [0.32855405 0.11656708 0.63427992 0.51111629 0.53846283]
 [0.99568791 0.44366564 0.0842925  0.12422041 0.38149375]]
</code></pre><h3 id="32-accder--des-lments-dun-numpy-array">3.2. Accéder à des éléments d'un numpy array</h3>
<pre><code># Accéder à un seul élément
print(X[0,0])

# Accéder à une ligne
print(X[0,:]) ou print(X[0])

# Accéder à une colonne
print(X[:,0]
</code></pre><p><em>Résultat:</em></p>
<pre><code>0.7427128108295802
[0.74271281 0.89627097 0.95309957 0.48770972 0.3841344 ]
[0.74271281 0.32855405 0.99568791]
</code></pre><h3 id="33-faire-une-transpose-de-matrice-les-lignes-deviennent-les-colonnes">3.3. Faire une transposée de Matrice (les lignes deviennent les colonnes)</h3>
<pre><code>print(X.T)
</code></pre><p><em>Résultat:</em></p>
<pre><code>[[0.74271281 0.32855405 0.99568791]
 [0.89627097 0.11656708 0.44366564]
 [0.95309957 0.63427992 0.0842925 ]
 [0.48770972 0.51111629 0.12422041]
 [0.3841344  0.53846283 0.38149375]]
</code></pre><h3 id="34-faire-un-range-sans-tre-gn-par-le-dernier-lement">3.4. Faire un range sans être gêné par le dernier élement</h3>
<p>Cette méthode permet d’obtenir un tableau à une dimension allant d’une valeur de départ à une valeur de fin avec un nombre donné d’éléments.</p>
<pre><code># la fonction linspace(premier, dernier, n) évite tout désagrément
np.linspace(1., 4., 6)
</code></pre><p><em>Résultat:</em></p>
<pre><code># array([ 1. ,  1.6,  2.2,  2.8,  3.4,  4. ])
</code></pre><h3 id="35-incrmenter-la-dimension-dun-array">3.5. Incrémenter la dimension d'un array</h3>
<p>(Permet également de <strong>convertir explicitement un array à 1 dimension</strong> en un vecteur ligne ou vecteur colonne.)</p>
<pre><code>A = np.array([2, 0, 1, 8])
print(A)
A.shape

# [2 0 1 8]
# (4,)


B = A[np.newaxis, :]
print(B)
B.shape

# [[2 0 1 8]]
# (1, 4)

C = A[:, np.newaxis]
print(C)
C.shape

# [[2]
  [0]
  [1]
  [8]]
# (4,1)
</code></pre><p><strong>Alternatives:</strong></p>
<pre><code>np.expand_dims(A, 1)  # équivaut à A[:, np.newaxis]
np.expand_dims(A, 0)  # équivaut à A[np.newaxis, :]

ou

A.reshape(A.shape + (1,))  # équivaut à A[:, np.newaxis]
A.reshape((1,) + A.shape)  # équivaut à A[np.newaxis, :]
</code></pre><h2 id="4-manipuler-des-scipy-sparse-matrices">4. Manipuler des Scipy Sparse Matrices</h2>
<p>Ces matrices sont parfois utiles lorsque le dataset est extrèmement grand (millions de features) et qu'il n'y a presque que des 0 pour un échantillon donné.</p>
<p>On crée une matrice avec des données aléatoires</p>
<pre><code>from scipy import sparse

X = np.random.random((10, 5))
print(X)
</code></pre><p><em>Résultat:</em></p>
<pre><code>[[0.74668664 0.28468523 0.31235423 0.85889384 0.44178508]
 [0.42935032 0.12811469 0.10010876 0.44757517 0.85568623]
 [0.52500676 0.81764407 0.32380153 0.41696393 0.46913849]
 [0.38276909 0.93648265 0.19733164 0.42392672 0.75220776]
 [0.71149141 0.21479105 0.93260534 0.44922132 0.1069613 ]
 [0.81701    0.85721634 0.43327147 0.07404298 0.00268589]
 [0.41816508 0.45835663 0.13466681 0.65741327 0.19939561]
 [0.87886815 0.90599216 0.60680106 0.52665484 0.69824682]
 [0.75469648 0.89312007 0.10350947 0.48109062 0.61979146]
 [0.90195641 0.48118575 0.95517067 0.86300827 0.36144463]]
</code></pre><p>On fixe la majorité des éléments à 0</p>
<pre><code>X[X &lt; 0.7] = 0
print(X)
</code></pre><p><em>Résultat:</em></p>
<pre><code> [[0.74668664 0.         0.         0.85889384 0.        ]
 [0.         0.         0.         0.         0.85568623]
 [0.         0.81764407 0.         0.         0.        ]
 [0.         0.93648265 0.         0.         0.75220776]
 [0.71149141 0.         0.93260534 0.         0.        ]
 [0.81701    0.85721634 0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.87886815 0.90599216 0.         0.         0.        ]
 [0.75469648 0.89312007 0.         0.         0.        ]
 [0.90195641 0.         0.95517067 0.86300827 0.        ]]
</code></pre><p>On convertit X en une Matrice CSR (Compressed-Sparse-Row)</p>
<pre><code>X_csr = sparse.csr_matrix(X)
print(X_csr)
</code></pre><p><em>Résultat:</em></p>
<pre><code>  (0, 0)	0.7466866354064811
  (0, 3)	0.858893836600347
  (1, 4)	0.8556862339513924
  (2, 1)	0.8176440715795563
  (3, 1)	0.9364826540107359
  (3, 4)	0.7522077587621511
  (4, 0)	0.7114914132345445
  (4, 2)	0.9326053405778985
  (5, 0)	0.8170100021133657
  (5, 1)	0.8572163407003378
  (7, 0)	0.8788681533625899
  (7, 1)	0.9059921645080171
  (8, 0)	0.7546964834006666
  (8, 1)	0.893120069181746
  (9, 0)	0.9019564067395904
  (9, 2)	0.9551706684658897
  (9, 3)	0.8630082740227074
</code></pre><p>On rétablit la Matrice Sparse en numpy array</p>
<pre><code>print(X_csr.toarray())
</code></pre><p><em>Résultat:</em></p>
<pre><code>[[0.74668664 0.         0.         0.85889384 0.        ]
 [0.         0.         0.         0.         0.85568623]
 [0.         0.81764407 0.         0.         0.        ]
 [0.         0.93648265 0.         0.         0.75220776]
 [0.71149141 0.         0.93260534 0.         0.        ]
 [0.81701    0.85721634 0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.87886815 0.90599216 0.         0.         0.        ]
 [0.75469648 0.89312007 0.         0.         0.        ]
 [0.90195641 0.         0.95517067 0.86300827 0.        ]]
</code></pre><h2 id="5-visualisation-des-donnes-avec-matplotlib">5. Visualisation des données avec Matplotlib</h2>
<h3 id="51-afficher-une-fonction-simple">5.1. Afficher une fonction simple</h3>
<pre><code>import matplotlib.pyplot as plt

# Afficher une ligne
x = np.linspace(0, 10, 100)
plt.plot(x, np.sin(x))
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/plot2-basics.png" alt="image"></p>
<h3 id="52-afficher-un-nuage-de-points-scatter-plot">5.2. Afficher un nuage de points (scatter plot)</h3>
<pre><code>import matplotlib.pyplot as plt

x = np.random.normal(size=500)
y = np.random.normal(size=500)
plt.scatter(x, y)
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/scatter-plot-basics.png" alt="image"></p>
<h3 id="53-tracer-une-image">5.3. Tracer une image</h3>
<pre><code>import matplotlib.pyplot as plt

x = np.linspace(1, 12, 100)
y = x[:, np.newaxis]

im = y * np.sin(x) * np.cos(y)

plt.imshow(im)
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/draw-image-basics.png" alt="image"></p>
<h3 id="54-tracer-les-contours">5.4. Tracer les contours</h3>
<pre><code>import matplotlib.pyplot as plt

x = np.linspace(1, 12, 100)
y = x[:, np.newaxis]

im = y * np.sin(x) * np.cos(y)

plt.contour(im)
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/contour-basics.png" alt="image"></p>
<h3 id="55-gallerie-dexemples">5.5. Gallerie d'exemples</h3>
<p>Des centaines d'exemples sont disponibles sur le <a href="http://matplotlib.org/gallery.html">site de Matplotlib</a>.
En exécutant la commande suivante dans votre notebook, le code source sera téléchargé. Vous n'aurez plus qu'à le ré-excuter pour qu'un graphique s'affiche.</p>
<pre><code>%load http://matplotlib.org/mpl_examples/pylab_examples/ellipse_collection.py
</code></pre><h3 id="56-graphique-3d">5.6. Graphique 3D</h3>
<pre><code># 3D 
from mpl_toolkits.mplot3d import Axes3D

ax = plt.axes(projection='3d')
xgrid, ygrid = np.meshgrid(x, y.ravel())
ax.plot_surface(xgrid, ygrid, im, cmap=plt.cm.jet, cstride=2, rstride=2, linewidth=0)
</code></pre><p><em>Résultat:</em></p>
<p><img src="/images/3d-plots-basics.png" alt="image"></p>
<h1 id="debugging-misc">Debugging Misc</h1>
<h2 id="dumper-un-objet">&ldquo;Dumper&rdquo; un objet:</h2>
<pre><code>def dump(obj):
   for attr in dir(obj):
       if hasattr( obj, attr ):
           print( &quot;obj.%s = %s&quot; % (attr, getattr(obj, attr)))
</code></pre><h2 id="afficher-des-couleurs-dans-le-terminal">Afficher des couleurs dans le terminal</h2>
<pre><code>print('\x1b[6;30;42m' + 'Success!' + '\x1b[0m')
</code></pre><p><img src="/images/colors-terminal-basics.png" alt="image"></p>
<p>Voir toutes les couleurs disponibles:</p>
<pre><code>def print_format_table():
    &quot;&quot;&quot;
    prints table of formatted text format options
    &quot;&quot;&quot;
    for style in range(8):
        for fg in range(30,38):
            s1 = ''
            for bg in range(40,48):
                format = ';'.join([str(style), str(fg), str(bg)])
                s1 += '\x1b[%sm %s \x1b[0m' % (format, format)
            print(s1)
        print('\n')

print_format_table()
</code></pre><p>Voici quelques examples:</p>
<p><img src="/images/terminal_few_colors.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Formater un markdown dans le terminal </title>
            <link>https://leandeep.com/formater-un-markdown-dans-le-terminal/</link>
            <pubDate>Tue, 25 Aug 2015 12:28:00 +0000</pubDate>
            
            <guid>https://leandeep.com/formater-un-markdown-dans-le-terminal/</guid>
            <description>Pour avoir le rendu d&#39;un markdown directement dans le terminal, c&#39;est très simple.
Installez l&#39;utilitaire mdless
sudo gem install mdless Puis vous pourrez directement avoir le rendu sur un fichier en exécutant la commande suivante:
mdless README.md </description>
            <content type="html"><![CDATA[<p>Pour avoir le rendu d'un markdown directement dans le terminal, c'est très simple.</p>
<p>Installez l'utilitaire <code>mdless</code></p>
<pre><code>sudo gem install mdless
</code></pre><p>Puis vous pourrez directement avoir le rendu sur un fichier en exécutant la commande suivante:</p>
<pre><code>mdless README.md
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Mount HFS&#43; volume sur Ubuntu</title>
            <link>https://leandeep.com/mount-hfs-volume-sur-ubuntu/</link>
            <pubDate>Sun, 05 Jul 2015 20:36:00 +0000</pubDate>
            
            <guid>https://leandeep.com/mount-hfs-volume-sur-ubuntu/</guid>
            <description>Déterminer le nom du volume HDF+
sudo fdisk -l Installer le paquet permettant de faire du read/write sur HFS+:
sudo apt-get install hfsprogs Checker le status d&#39;un disque:
sudo fsck.hfsplus -f /dev/sdd1 Démonter un disque:
sudo umount /home/olivier/lacie_mount Monter le disque avec les droits read/write: (créer un dossier pour monter le disque au préalable)
sudo mount -t hfsplus -o force,rw /dev/sdd1 /home/olivier/lacie_mount </description>
            <content type="html"><![CDATA[<p>Déterminer le nom du volume HDF+</p>
<pre><code>sudo fdisk -l
</code></pre><p>Installer le paquet permettant de faire du read/write sur HFS+:</p>
<pre><code>sudo apt-get install hfsprogs
</code></pre><p>Checker le status d'un disque:</p>
<pre><code>sudo fsck.hfsplus -f /dev/sdd1
</code></pre><p>Démonter un disque:</p>
<pre><code>sudo umount /home/olivier/lacie_mount
</code></pre><p>Monter le disque avec les droits read/write:
(créer un dossier pour monter le disque au préalable)</p>
<pre><code>sudo mount -t hfsplus -o force,rw /dev/sdd1 /home/olivier/lacie_mount
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Charger un fichier .env composé de clés/valeurs pour VSCode dans le terminal</title>
            <link>https://leandeep.com/charger-un-fichier-.env-compos%C3%A9-de-cl%C3%A9s/valeurs-pour-vscode-dans-le-terminal/</link>
            <pubDate>Thu, 02 Jul 2015 22:23:00 +0000</pubDate>
            
            <guid>https://leandeep.com/charger-un-fichier-.env-compos%C3%A9-de-cl%C3%A9s/valeurs-pour-vscode-dans-le-terminal/</guid>
            <description>Travailler avec des fichiers .env est très utile en développement.
L&#39;exemple le plus courant pourrait ressembler à ceci:
export SERVER_URL=&#39;blablabla&#39; ... Il suffit de sourcer ce fichier et tout l&#39;environnement d&#39;exécution est configuré avec les bonnes variables.
Par contre, ce pose problème avec des outils comme VSCode. Les mots clés comme export ne sont pas compatibles. VSCode attend en effet uniquement des fichiers composés de clés/ valeurs.
Par exemple, la configuration VScode .</description>
            <content type="html"><![CDATA[<p>Travailler avec des fichiers <code>.env</code> est très utile en développement.</p>
<p>L'exemple le plus courant pourrait ressembler à ceci:</p>
<pre><code>export SERVER_URL='blablabla'
...
</code></pre><p>Il suffit de <em>sourcer</em> ce fichier et tout l'environnement d'exécution est configuré avec les bonnes variables.</p>
<p>Par contre, ce pose problème avec des outils comme VSCode. Les mots clés comme <code>export</code> ne sont pas compatibles. VSCode attend en effet uniquement des fichiers composés de clés/ valeurs.</p>
<p>Par exemple, la configuration VScode <code>.vscode/launch.json</code> suivante n'est pas compatible avec ce genre de fichiers <code>.env</code>:</p>
<pre><code>{
    &quot;name&quot;: &quot;Python: Current File&quot;,
    &quot;type&quot;: &quot;python&quot;,
    &quot;request&quot;: &quot;launch&quot;,
    &quot;program&quot;: &quot;${file}&quot;,
    &quot;console&quot;: &quot;integratedTerminal&quot;,
    &quot;stopOnEntry&quot;: true,
    &quot;python.envFile&quot;: &quot;.env&quot;
}
</code></pre><p>La solution à ce problème est de travailler avec des fichiers composés de clés/ valeurs uniquement comme ceci:</p>
<pre><code>SERVER_URL='blablabla'
...
</code></pre><p>Ce sera compatible avec VSCode et pour que cela fonctionne dans un Terminal il ne faut plus utiliser la commande source mais la commande suivante:</p>
<pre><code># Cette commande gère les espaces grâce au -d et ignore les lignes commentées grâce au grep -v '^#'

$ export $(grep -v '^#' .env | xargs -d '\n')


Sur Mac, il faut utiliser la commande suivante:

$ export $(grep -v '^#' .env | xargs -0)

Ou alternative:

$ eval $(cat .env | sed 's/^/export /')
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Debug  des  certificats SSL</title>
            <link>https://leandeep.com/debug-des-certificats-ssl/</link>
            <pubDate>Wed, 01 Jul 2015 19:43:00 +0000</pubDate>
            
            <guid>https://leandeep.com/debug-des-certificats-ssl/</guid>
            <description>Voir tous les SAN (Subjects Alternative Names) d&#39;un CSR (Certificate Signing Request):
openssl req -noout -text -in my_csr.csr | grep DNS Voir tous les SAN dans un certificat pem:
cat my_pem.pem | openssl x509 -text | grep DNS </description>
            <content type="html"><![CDATA[<p>Voir tous les SAN (Subjects Alternative Names) d'un CSR (Certificate Signing Request):</p>
<pre><code>openssl req -noout -text -in my_csr.csr | grep DNS
</code></pre><p>Voir tous les SAN dans un certificat pem:</p>
<pre><code>cat my_pem.pem | openssl x509 -text | grep DNS
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Port accessible sur une machine distante et quels ports utilisés ?</title>
            <link>https://leandeep.com/port-accessible-sur-une-machine-distante-et-quels-ports-utilis%C3%A9s/</link>
            <pubDate>Tue, 30 Jun 2015 07:04:00 +0000</pubDate>
            
            <guid>https://leandeep.com/port-accessible-sur-une-machine-distante-et-quels-ports-utilis%C3%A9s/</guid>
            <description>Ports accessibles ? Via Telnet Sur les anciens systèmes telnet est installé. Il suffit de faire:
$ telnet hostname port Alternatives à telnet Sur les machines plus récentes, telnet n&#39;est plus installé pour une question de sécurité. Il est alors possible d&#39;utiliser d&#39;autres outils.
NC $ nc -zv hostname port $ nc -zv 127.0.0.1 22 80 8080 # multiple ports $ nc -zv 127.0.0.1 20-30 # range of ports  Note: pour tester une port sur le protocole UDP, utiliser nc -u</description>
            <content type="html"><![CDATA[<h1 id="ports-accessibles-">Ports accessibles ?</h1>
<h2 id="via-telnet">Via Telnet</h2>
<p>Sur les anciens systèmes telnet est installé.
Il suffit de faire:</p>
<pre><code>$ telnet hostname port
</code></pre><h2 id="alternatives--telnet">Alternatives à telnet</h2>
<p>Sur les machines plus récentes, telnet n'est plus installé pour une question de sécurité. Il est alors possible d'utiliser d'autres outils.</p>
<h3 id="nc">NC</h3>
<pre><code>$ nc -zv hostname port
$ nc -zv 127.0.0.1 22 80 8080 # multiple ports
$ nc -zv 127.0.0.1 20-30 # range of ports
</code></pre><blockquote>
<p>Note: pour tester une port sur le protocole UDP, utiliser <code>nc -u</code></p>
</blockquote>
<h3 id="bash">bash</h3>
<pre><code>$ cat &lt; /dev/tcp/hostname/port
-bash: connect: Connection refused # closed
</code></pre><h3 id="curl">curl</h3>
<pre><code>$ curl http://hostname:port
curl: (7) couldn't connect to host #closed
curl: (7) Failed connect to hostname:port; Connection refused #closed
ou
curl: (56) Failure when receiving data from the peer #opened
</code></pre><h2 id="nmap">Nmap</h2>
<pre><code># Usage: 
# nmap [scan type(s)] [Options] {target(s)}
sudo nmap -Pn -A 192.168.99.100

# Useful scan types:
# -Pn: skip ping probes
# -sS: SYN scan
# -A: Aggressive &lt;=&gt; OS fingerprinting, service versions, traceroutes, runs script scans
# -p &lt;port&gt;: pour scanner un port particulier
</code></pre><p><img src="/images/syn-syn-ack-ack.png" alt="image"></p>
<h1 id="quel-port-est-utilis-par-un-service-">Quel port est utilisé par un service ?</h1>
<p>Exemple avec le service ntp:</p>
<pre><code>netstat -tulpn | grep ntpd
</code></pre><p>On voit que le service ntp utilise le port 123:</p>
<pre><code>udp 0 0 192.168.87.144:123 0.0.0.0:* 1885/ntpd
udp 0 0 127.0.0.1:123 0.0.0.0:* 1885/ntpd
udp 0 0 0.0.0.0:123 0.0.0.0:* 1885/ntpd
udp 0 0 fe80::20c:29ff:fe62:f03:123 :::* 1885/ntpd
udp 0 0 ::1:123 :::* 1885/ntpd
udp 0 0 :::123 :::* 1885/ntpd 
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Servir les fichiers du dossier courant via une interface web</title>
            <link>https://leandeep.com/servir-les-fichiers-du-dossier-courant-via-une-interface-web/</link>
            <pubDate>Wed, 17 Jun 2015 22:37:00 +0000</pubDate>
            
            <guid>https://leandeep.com/servir-les-fichiers-du-dossier-courant-via-une-interface-web/</guid>
            <description>Dans la catégorie réseau et SSH:
2 possibilitées en fonction de ce qui est installé sur votre machine.
 NodeJS est installé  $ npm install -g http-server $ http-server Par défaut le port 8080 sera utilisé. Pour le customiser utilisé la commande suivante:
$ http-server -p 3000  Python est installé:  $ python -m SimpleHTTPServer ou $ python3 -m http.server Par défaut le port 8000 sera utilisé Pour le customiser utilisé la commande suivante:</description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie réseau et SSH:</strong></p>
<p>2 possibilitées en fonction de ce qui est installé sur votre machine.</p>
<ul>
<li>NodeJS est installé</li>
</ul>
<pre><code>$ npm install -g http-server
$ http-server
</code></pre><p>Par défaut le port 8080 sera utilisé.
Pour le customiser utilisé la commande suivante:</p>
<pre><code>$ http-server -p 3000
</code></pre><ul>
<li>Python est installé:</li>
</ul>
<pre><code>$ python -m SimpleHTTPServer
ou
$ python3 -m http.server
</code></pre><p>Par défaut le port 8000 sera utilisé
Pour le customiser utilisé la commande suivante:</p>
<pre><code>$ python -m SimpleHTTPServer 3000
ou
$ python3 -m http.server
</code></pre><p>Que vous utilisiez NodeJS ou Python vous devrez passer en root pour utiliser les ports en dessous de 1024.</p>
]]></content>
        </item>
        
        <item>
            <title>Conversion de structure de données à une autre</title>
            <link>https://leandeep.com/conversion-de-structure-de-donn%C3%A9es-%C3%A0-une-autre/</link>
            <pubDate>Sat, 09 May 2015 21:07:00 +0000</pubDate>
            
            <guid>https://leandeep.com/conversion-de-structure-de-donn%C3%A9es-%C3%A0-une-autre/</guid>
            <description>Lorsque l&#39;on fait du preprocessing sur les données en Python, il est utile de transformer des structures de données en d&#39;autres. Voici quelques snippets utiles:
Liste vers dictionnaire¶ list = [&amp;quot;lun&amp;quot;, &amp;quot;mer&amp;quot;, &amp;quot;mar&amp;quot;, &amp;quot;mer&amp;quot;, &amp;quot;jeu&amp;quot;, &amp;quot;jeu&amp;quot;] dict = {} for el in list: dict[e] = dict.get(el, 0) + 1 print(dict) {&#39;lun&#39;: 1, &#39;mer&#39;: 2, &#39;mar&#39;: 1, &#39;jeu&#39;: 2} L&#39;usage de la méthode get regarde si une clé appartient au dictionnaire, retourne la valeur associée ou une valeur par défault dans le cas contraire.</description>
            <content type="html"><![CDATA[<p>Lorsque l'on fait du preprocessing sur les données en Python, il est utile de transformer des structures de données en d'autres.
Voici quelques snippets utiles:</p>
<h1 id="liste-vers-dictionnaire">Liste vers dictionnaire¶</h1>
<pre><code>list = [&quot;lun&quot;, &quot;mer&quot;, &quot;mar&quot;, &quot;mer&quot;, &quot;jeu&quot;, &quot;jeu&quot;]
dict = {}
for el in list:
    dict[e] = dict.get(el, 0) + 1
print(dict)
</code></pre><pre><code>{'lun': 1, 'mer': 2, 'mar': 1, 'jeu': 2}
</code></pre><p>L'usage de la méthode <a href="https://docs.python.org/3/library/stdtypes.html?highlight=get#dict.get">get</a> regarde si une clé appartient au dictionnaire, retourne la valeur associée ou une valeur par défault dans le cas contraire.</p>
<p>Sans utiliser cette méthode, le code précédent devient:</p>
<pre><code>list = [&quot;lun&quot;, &quot;mer&quot;, &quot;mar&quot;, &quot;mer&quot;, &quot;jeu&quot;, &quot;jeu&quot;]
dict = {}
for el in list:
    if el in dict:
        dict[el] += 1
    else:
        dict[el] = 1
print(dict)
</code></pre><h1 id="dictionnaire-vers-liste">Dictionnaire vers liste</h1>
<pre><code>dict = {'lun': 1, 'mer': 2, 'mar': 1, 'jeu': 2}
list = []
for key, value in dict.items():
    for i in range(value):
        list.append(key)
print(list)
</code></pre><pre><code>[&quot;lun&quot;, &quot;mer&quot;, &quot;mar&quot;, &quot;mer&quot;, &quot;jeu&quot;, &quot;jeu&quot;]
</code></pre><h1 id="dictionnaire-vers-2-listes">Dictionnaire vers 2 listes</h1>
<pre><code>dict = {'lun': 1, 'mer': 2, 'mar': 1, 'jeu': 2}
keys = []
values = []
for key, value in dict.items():
    keys.append(key)
    values.append(value)

print(keys)
print(values)
</code></pre><pre><code>['mer', 'jeu', 'lun', 'mar']
[2, 2, 1, 1]
</code></pre><h1 id="2-listes-vers-1-dictionnaire">2 listes vers 1 dictionnaire</h1>
<pre><code>keys, values = ['mer', 'jeu', 'lun', 'mar'], [2, 2, 1, 1]
dict = {x:y for x, y in zip(keys, values)}
print(dict)
</code></pre><pre><code>{'lun': 1, 'mer': 2, 'mar': 1, 'jeu': 2}
</code></pre><h1 id="dictionnaire-vers-2-listes-1">Dictionnaire vers 2 listes</h1>
<pre><code>dict = {'lun': 1, 'mer': 2, 'mar': 1, 'jeu': 2}
keys = []
values = []
for key, value in dict.items():
    keys.append(k)
    values.append(v)
print(keys)
print(values)
</code></pre><pre><code>['mer', 'jeu', 'lun', 'mar']
[2, 2, 1, 1]
</code></pre><p>Avec le zip reverse cela devient:</p>
<pre><code>dict = {'lun': 1, 'mer': 2, 'mar': 1, 'jeu': 2}
keys, values = zip(*dict.items())
print(keys)
print(values)
</code></pre><pre><code>('mer', 'jeu', 'lun', 'mar')
(2, 2, 1, 1)
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Les containers de données en Python</title>
            <link>https://leandeep.com/les-containers-de-donn%C3%A9es-en-python/</link>
            <pubDate>Sun, 03 May 2015 23:24:00 +0000</pubDate>
            
            <guid>https://leandeep.com/les-containers-de-donn%C3%A9es-en-python/</guid>
            <description>Python propose différents containers pour stocker des éléments. Voici les plus courants:
 list: tableau d’éléments indexés de 0 à n-1 auquel on peut ajouter ou retirer des éléments dict: tableau d’éléments indexés par des types immuables auquel on peut ajouter ou retirer des éléments tuple: tableau d’éléments indexés de 0 à n-1 qu’on ne peut pas modifier set: tableau d’éléments uniques non indexés frozenset: set immuables (non modifiable) deque: presque équivalent à une liste, la différence vient de l’implémentation, les mêmes opérations n’auront pas les mêmes coûts (deque = liste chaînée)  D’autres containers sont disponibles via le module collections.</description>
            <content type="html"><![CDATA[<p>Python propose différents containers pour stocker des éléments. Voici les plus courants:</p>
<ul>
<li><a href="https://docs.python.org/3.4/tutorial/datastructures.html#more-on-lists">list</a>: tableau d’éléments indexés de 0 à n-1 auquel on peut ajouter ou retirer des éléments</li>
<li><a href="https://docs.python.org/3.4/tutorial/datastructures.html#dictionaries">dict</a>: tableau d’éléments indexés par des types immuables auquel on peut ajouter ou retirer des éléments</li>
<li><a href="https://docs.python.org/3.4/tutorial/datastructures.html#tuples-and-sequences">tuple</a>: tableau d’éléments indexés de 0 à n-1 qu’on ne peut pas modifier</li>
<li><a href="https://docs.python.org/3.4/tutorial/datastructures.html#sets">set</a>: tableau d’éléments uniques non indexés</li>
<li><a href="https://docs.python.org/3.4/tutorial/datastructures.html#sets">frozenset</a>: set immuables (non modifiable)</li>
<li><a href="https://docs.python.org/3.4/library/collections.html#collections.deque">deque</a>: presque équivalent à une liste, la différence vient de l’implémentation, les mêmes opérations n’auront pas les mêmes coûts (deque = liste chaînée)</li>
</ul>
<p>D’autres containers sont disponibles via le module <a href="https://docs.python.org/3.4/library/collections.html">collections</a>.</p>
<pre><code>N = 1000000

list_example = list(range(0,1000))
for i in range(0,N) :
    if i in list_example : s += 1
    
tuple_example = tuple(list_example)
for i in range(0,N) :
    if i in tuple_example : s += 1
    
set_example = set(list_example)
for i in range(0,N) :
    if i in set_example : s += 1
    
frozenset_example = frozenset(list_example)
for i in range(0,N) :
    if i in frozenset_example : s += 1

list_example = list()
# Insertion à la fin
for i in range(0,N):
    list_example.append(i)
# Insertion au début
for i in range(0,N):
    list_example.insert(0,i)
        

import collections

collection_example = collections.deque()
# Insertion au début
for i in range(0,N) :
    collection_example.appendleft(i)
# Insertion à la fin
for i in range(0,N):
    collection_example.append(i)
</code></pre><p>Notez que les ensembles <strong>set</strong> ou <strong>frozenset</strong> sont beaucoup plus rapides que tuples et lists.</p>
]]></content>
        </item>
        
        <item>
            <title>Ma présentation d&#39;Ionic</title>
            <link>https://leandeep.com/ma-pr%C3%A9sentation-dionic/</link>
            <pubDate>Thu, 30 Apr 2015 23:16:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ma-pr%C3%A9sentation-dionic/</guid>
            <description>Voici une présentation que j&#39;ai réalisé pour présenter Ionic à mon équipe dans l&#39;éventualité de l&#39;utiliser à la place d&#39;Angular et Bootstrap pour nos applications hybrides.
 </description>
            <content type="html"><![CDATA[<p>Voici une présentation que j'ai réalisé pour présenter Ionic à mon équipe dans l'éventualité de l'utiliser à la place d'Angular et Bootstrap pour nos applications hybrides.</p>

    <iframe
        src="//www.slideshare.net/slideshow/embed_code/key/2AnieOutuKU8kY"
        title="SlideShare Presentation"
        height="485"
        width="595"
        frameborder="0"
        marginwidth="0"
        marginheight="0"
        scrolling="no"
        style="border: 1px solid #CCC; border-width: 1px; margin-bottom: 20px; width: 100%;"
        allowfullscreen="true">
    </iframe>





]]></content>
        </item>
        
        <item>
            <title>Synthèse statistiques descriptives</title>
            <link>https://leandeep.com/synth%C3%A8se-statistiques-descriptives/</link>
            <pubDate>Tue, 28 Apr 2015 10:52:00 +0000</pubDate>
            
            <guid>https://leandeep.com/synth%C3%A8se-statistiques-descriptives/</guid>
            <description>Moyenne: Average Mean en anglais Médiane: Median en anglais =&amp;gt; / par 2 =&amp;gt; valeur centrale de la distribution. Example: 3; 5; 7; 9; 10 ==&amp;gt; Mediane = 7 Mode: Mode en anglais =&amp;gt; valeur la plus fréquente dans la distribution Moyenne tronquée: Trimed mean en anglais =&amp;gt; moyenne des données après suppression des 5% des valeurs supérieures et 5% des valeurs inférieure   Dispersion
 Centile: est chacune des 99 valeurs qui divisent les données triées en 100 parts égales.</description>
            <content type="html"><![CDATA[<ul>
<li>Moyenne: <em>Average Mean</em> en anglais</li>
<li>Médiane: <em>Median</em> en anglais =&gt; / par 2 =&gt; valeur centrale de la distribution.
Example: 3; 5; 7; 9; 10 ==&gt; Mediane = 7</li>
<li>Mode: <em>Mode</em> en anglais =&gt; valeur la plus fréquente dans la distribution</li>
<li>Moyenne tronquée: <em>Trimed mean</em> en anglais =&gt; moyenne des données après suppression des 5% des valeurs supérieures et 5% des valeurs inférieure</li>
</ul>
<br/>
<p><strong>Dispersion</strong></p>
<ul>
<li>Centile: est chacune des 99 valeurs qui divisent les données triées en 100 parts égales. Par exemple, le 95ème (quatre-vingt-quinzième) centile est la valeur telle que 95% des valeurs mesurées sont en dessous et 5% sont au-dessus.</li>
<li>Quartiles: divise un échantillon en 4 quarts égaux. =&gt; Cela permet d'évaluer la dispersion des données et la tendance centrale =&gt; On divise l'effectif total par 4.</li>
<li>Range: MAX - MIN</li>
<li>Interquartile = Q3 - Q1</li>
<li>Variance: mesure de la dispersion des valeurs d'un échantillon ou d'une distribution de probabilité. Elle ne s’annule que pour une série statistique dont tous les termes ont la même valeur, elle est d’autant plus grande que les valeurs sont étalées, et invariante par ajout d’une constante.</li>
</ul>
<p>Calcul:
<img src="/images/variance.png" alt="image"></p>
<ul>
<li>Ecart-type: <em>Standard deviation</em> en anglais = √variance =&gt; Si l’écart-type est supérieur à 0,5 moyenne, on peut donc considérer que les variations sont fortes.</li>
</ul>
]]></content>
        </item>
        
        <item>
            <title>Diagnostiquer les dysfonctionnements DNS</title>
            <link>https://leandeep.com/diagnostiquer-les-dysfonctionnements-dns/</link>
            <pubDate>Mon, 27 Apr 2015 19:59:00 +0000</pubDate>
            
            <guid>https://leandeep.com/diagnostiquer-les-dysfonctionnements-dns/</guid>
            <description>Rappel des différents type d’enregistrements DNS:
A : Renvoie une adresse IPv4 pour un nom de host donné. AAA : Renvoie une adresse IPv6 pour un nom de host donné. NS : Délègue la gestion d’une zone à un serveur de nom faisant autorité. CNAME : Permet de réaliser un alias d’un host vers un autre. SOA : Définit le serveur maître du domaine. PTR : Réalise l’inverse de l’enregistrement A ou AAAA, donne un nom de host (FQDN) pour une adresse IP.</description>
            <content type="html"><![CDATA[<p>Rappel des différents type d’enregistrements DNS:</p>
<pre><code>A : Renvoie une adresse IPv4 pour un nom de host donné.
AAA : Renvoie une adresse IPv6 pour un nom de host donné.
NS : Délègue la gestion d’une zone à un serveur de nom faisant autorité.
CNAME : Permet de réaliser un alias d’un host vers un autre.
SOA : Définit le serveur maître du domaine.
PTR : Réalise l’inverse de l’enregistrement A ou AAAA, donne un nom de host (FQDN) pour une adresse IP.
MX : Définit le nom du serveur de courrier du domaine.
TXT : Une chaîne de caractères libres.
</code></pre><p>Utiliser la command dig pour :</p>
<ol>
<li>Voir les serveurs de messagerie d'un domaine (MX) :</li>
</ol>
<pre><code>dig mx leandeep.com +short
1 mx1.ovh.net.
5 mx2.ovh.net.
100 mxb.ovh.net.
</code></pre><ol start="2">
<li>Connaitre l'IP du serveur DNS:</li>
</ol>
<pre><code>dig leandeep.com

; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; leandeep.com
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 52800
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4000
;; QUESTION SECTION:
;leandeep.com.			IN	A

;; ANSWER SECTION:
leandeep.com.		200	IN	A	174.138.9.130

;; Query time: 2 msec
;; SERVER: 10.0.0.1#53(10.0.0.1)
;; WHEN: Thu Nov 08 10:40:29 CET 2018
;; MSG SIZE  rcvd: 57
</code></pre><ol start="3">
<li>Résolution inverse à partir de l'IP</li>
</ol>
<pre><code>dig -x 8.8.8.8 +short
google-public-dns-a.google.com.
</code></pre><ol start="4">
<li>Tester la résolution de nom avec un autre serveur DNS</li>
</ol>
<pre><code>dig @193.173.98.151 lean-deep.com +short
</code></pre><ol start="5">
<li>Avoir le plus d'informations possible</li>
</ol>
<pre><code>dig leandeep.com ANY
; &lt;&lt;&gt;&gt; DiG 9.10.6 &lt;&lt;&gt;&gt; leandeep.com ANY
;; global options: +cmd
;; Got answer:
;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 35656
;; flags: qr rd ra; QUERY: 1, ANSWER: 4, AUTHORITY: 0, ADDITIONAL: 4

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4000
;; QUESTION SECTION:
;leandeep.com.			IN	ANY

;; ANSWER SECTION:
leandeep.com.		2797	IN	A	174.138.9.130
leandeep.com.		2870	IN	MX	5 mx2.ovh.net.
leandeep.com.		2870	IN	MX	100 mxb.ovh.net.
leandeep.com.		2870	IN	MX	1 mx1.ovh.net.

;; ADDITIONAL SECTION:
mx2.ovh.net.		7380	IN	A	87.98.132.45
mxb.ovh.net.		7380	IN	A	46.105.45.21
mx1.ovh.net.		39570	IN	A	188.165.47.122

;; Query time: 3 msec
;; SERVER: 10.0.0.1#53(10.0.0.1)
;; WHEN: Thu Nov 08 10:57:36 CET 2018
;; MSG SIZE  rcvd: 172
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Je veux faire du Machine Learning!</title>
            <link>https://leandeep.com/je-veux-faire-du-machine-learning/</link>
            <pubDate>Sat, 25 Apr 2015 20:37:00 +0000</pubDate>
            
            <guid>https://leandeep.com/je-veux-faire-du-machine-learning/</guid>
            <description>Introduction, la révélation Nous sommes avril 2015, je reviens de mes vacances à Rome. (Franchement je recommande cette ville mais parler de Rome n&#39;est pas le sujet de cet article). Pendant mes vacances, j&#39;ai eu le temps de réfléchir sur ce que je voulais faire et j&#39;ai eu une révélation. Je veux faire du Machine Learning !
C&#39;est une discipline que je ne connais pas du tout et qui a l&#39;air vraiment cool.</description>
            <content type="html"><![CDATA[<h1 id="introduction-la-rvlation">Introduction, la révélation</h1>
<p>Nous sommes avril 2015, je reviens de mes vacances à Rome. (Franchement je recommande cette ville mais parler de Rome n'est pas le sujet de cet article).
Pendant mes vacances, j'ai eu le temps de réfléchir sur ce que je voulais faire et j'ai eu une révélation. Je veux faire du Machine Learning !</p>
<p>C'est une discipline que je ne connais pas du tout et qui a l'air vraiment cool.
Le sujet a l'air extrèmement vague et je ne sais pas vraiment par où commencer.</p>
<p>J'ai commencé par revoir quelques bases en statistique; même si je ne suis pas certain que cette discipline soit le même. J'ai vu qu'il y avait un cours sur Coursera pour sur le sujet. C'est un cours de 9 semaines. Je pense que je vais le suivre.</p>
<p>Peut-être que vous aussi vous avez <del>bouffé</del> mangé des maths pendant vos études mais que vous n'avez pas pratiqué depuis longtemps et donc que des rappels ne feront pas de mal.</p>
<h1 id="rappels-de-stats">Rappels de stats</h1>
<h2 id="esprance">Espérance</h2>
<p>Lorsqu'on a des données statistiques, l'espérance correspond à la moyenne de ces données.</p>
<h2 id="caractristiques-de-dispersion">Caractéristiques de dispersion</h2>
<p>La variance et l’écart type permettent de mesurer la « dispersion » des valeurs de la série autour de l'espérance (ou de la moyenne).
Si les valeurs de la série possèdent une unité, l’écart type s’exprime dans la même unité.</p>
<h3 id="variance">Variance</h3>
<p>Pour quantifier la dispersion d'une série par rapport à sa moyenne, il semble naturel de calculer la moyenne des différences (ou des écarts) entre les valeurs observées et la moyenne, mais avec le risque d'obtenir des nombres négatifs qui, ajoutés à des nombres positifs, s'annulent. C'est pourquoi on a choisi de calculer la « moyenne des carrés des écarts à la moyenne ».
Telle est la définition de la variance V d'une série statistique.</p>
<p>Calcul de la variance (2 options):
<img src="/images/variance-formule1.png" alt="image">
<img src="/images/variance-formule2.png" alt="image"></p>
<h3 id="cart-type">Écart-type</h3>
<p>L’écart-type est un indicateur de dispersion. Il nous informe sur la manière dont les individus se répartissent autour de la moyenne. Sont-ils tous à peu près identiques, concentrés autour de la moyenne ? Au contraire, sont-ils dispersés entre des valeurs très basses et des valeurs très hautes ?</p>
<p>L’écart-type est l’écart moyen à la moyenne pour tous les individus. Si celui-ci est faible, les individus formulent des réponses similaires, si celui-ci est fort les variations sont fortes dans la population étudiée. Le niveau qui permet de repérer un fort écart-type est 1/2 moyenne. Si l’écart-type est supérieur à 0,5 moyenne, on peut donc considérer que les variations sont fortes.</p>
<p>Pour illustrer nos propos, prenons un exemple simple. 21 étudiants reçoivent une note sur 20 en statistique, les voici :</p>
<pre><code>1 - 3 - 3 - 4 - 4 - 6 - 7 - 8 - 9 - 9 - 9 - 9 - 9 - 10 - 10 - 15 - 17 - 18 - 19 - 20 - 20
</code></pre><p>Moyenne = 10 (210/21)
Ecart-type = 5,93.</p>
<p>Dans ce cas, la dispersion est forte puisque l’écart-type est supérieur à 5 (1/2 moyenne).</p>
<p>Formule de calcul:</p>
<p><img src="/images/Ecart-type.png" alt="image"></p>
<ul>
<li>avec μ est la moyenne arithmétique de la série</li>
<li>n est l'effectif total de la série</li>
</ul>
<p>Autre formule de calcul:</p>
<p><img src="/images/ecart-type-formule.png" alt="image"></p>
<p>C'est un paramètre particulièrement utilisé dans le cas de données dites gaussiennes.</p>
<h2 id="donnes-gaussiennes">Données Gaussiennes</h2>
<p>Les données gaussiennes se caractérisent par une répartition en forme de cloche.
Elles ont l'allure suivante:</p>
<p><img src="/images/gaussienne.png" alt="image"></p>
<blockquote>
<p>Dans le cas de données gaussiennes, la médiane et la moyenne sont confondues. La médiane est, de plus, le milieu de l'intervalle interquartile ; ainsi, le corps du diagramme qui représente les données est symétrique par rapport à la médiane.</p>
</blockquote>
<h2 id="mdiane">Médiane</h2>
<p>Définition:
L’idée générale est que la médiane est une valeur du caractère qui partage la population en deux parties de même effectif.
De façon plus précise, on appelle médiane d’une série statistique discrète toute valeur M du caractère telle qu’au moins 50%
des individus aient une valeur du caractère inférieure ou égale à M et au moins 50% des individus aient une valeur du caractère
supérieure ou égale à M</p>
<p>Recherche pratique de la médiane:
On range les valeurs du caractère une par une dans l’ordre croissant (chaque valeur du caractère doit apparaître un nombre de fois
égal à l’effectif correspondant).
Si l’effectif total est impair, la médiane M est la valeur du caractère située au milieu.
Si l’effectif total est pair, la médiane M est la demi-somme des 2 valeurs situées au milieu.</p>
<p>Example 1:
Liste des valeurs du caractère :</p>
<pre><code>7 ; 7 ; 8 ; 9; 10 ; 11 ; 11 ; 14 ; 16 ; 16
</code></pre><p>L’effectif total est pair : la médiane M est la demi-somme des 2 valeurs situées au milieu. D’où, M = (10 + 11) / 2 = 10,5</p>
<p>Example 2:</p>
<pre><code>6 ; 6 ; 6 ; 8; 9 ; 9 ; 12 ; 13 ; 13 ; 13 ; 17 ; 17; 17
</code></pre><p>L’effectif total est impair : la médiane M est la valeur située au milieu. D’où, M = 12.</p>
<h2 id="paramtres-de-dispersion">Paramètres de dispersion</h2>
<p><em>Définition:</em>
Ces paramètres permettent de mesurer la façon dont les valeurs du caractère sont réparties autour de la moyenne et de la médiane.</p>
<p><em>Paramètre de dispersion associé à la médiane:</em>
L’idée générale est de partager la population en quatre parties de même effectif.</p>
<p>Etant donné une série statistique de médiane M dont la liste des valeurs est rangée dans l’ordre croissant
En coupant la liste en deux sous-séries de même effectif (Attention : quand l’effectif total est impair, la médiane ne doit pas être
incluse dans les sous-séries) :</p>
<ul>
<li>On appelle premier quartile le réel noté Q1 égal à la médiane de la sous-série inférieure.</li>
<li>On appelle troisième quartile le réel noté Q3 égal à la médiane de la sous-série supérieure.</li>
<li>L’écart interquartile est égal à Q3 - Q1.</li>
<li>] Q1 ; Q3 [  est appelé intervalle interquartile.</li>
</ul>
<p><em>Diagramme en boîtes:</em>
Le diagramme en boîtes d’une série statistique se construit alors de la façon suivante :
(les valeurs du caractère sont en abscisse - min et max représentent les valeurs minimales et maximales du caractère)</p>
<p><img src="/images/Diagramme-en-boite.png" alt="image"></p>
<p>Interprétation:</p>
<ul>
<li>25% de la population admet une valeur du caractère entre min et Q1</li>
<li>25% de la population admet une valeur du caractère entre Q1 et M</li>
<li>25% de la population admet une valeur du caractère entre M et Q3</li>
<li>25% de la population admet une valeur du caractère entre Q3 et max</li>
</ul>
<h2 id="test-du-">Test du χ²</h2>
<p>Le test de Chi-deux est utilisé pour tester l'hypothèse nulle d'absence de relation entre deux variables catégorielles. On peut également dire que ce test vérifie l'hypothèse d'indépendance de ces variables.</p>
<blockquote>
<p>En statistique, le test du χ² de Pearson ou test du χ² d'indépendance est un test statistique qui s'applique sur des ensembles de données catégorielles pour évaluer la probabilité qu'une différence observée entre les ensembles soit due au hasard. Il convient aux données non-appariées prises sur de grands échantillons (n&gt;30).
Il est le test du χ² le plus communément utilisé.</p>
</blockquote>
<h2 id="population-et-individus">Population et individus</h2>
<p>La population est l’ensemble des individus (ou unités statistiques) auxquels on décide de sintériser. Sa taille, habituellement désignée par N, est grande, ou même infinie. Le choix de la population étudiée dépend du problème qui est à l’origine de la démarche statistique, et de la façon dont on décide de le traiter.</p>
<h2 id="effectif">Effectif</h2>
<p>Nombre d’individus, d’une population ou d’une partie quelconque de cette population.</p>
<h2 id="reprsentations-gomtriques-des-distributions">Représentations géométriques des distributions</h2>
<ul>
<li>Pour une variable qualitative : diagramme circulaire (&ldquo;camembert&rdquo;).</li>
<li>Pour une variable ordinale ou quantitative discrète : diagramme ou graphique en bâtons.</li>
<li>Pour une variable ordinale ou quantitative continue : histogramme et courbe des fréquences cumulées.</li>
<li>Pour deux variables quantitatives ou ordinales : nuage de points.</li>
</ul>
<h2 id="distribution-multimodale">Distribution Multimodale</h2>
<p>Il s'agit d'une distribution qui possède plusieurs modes (donc au moins deux &ldquo;pics&rdquo;).</p>
<p><img src="/images/multimodale.png" alt="image"></p>
<p>La multimodalité d'une distribution dans un échantillon indique généralement que la distribution de la variable dans la population n'est pas normale. La multimodalité d'une distribution peut fournir une information importante quant à la nature de la variable étudiée (c'est-à-dire la qualité mesurée). Par exemple, si la variable en question représente une préférence ou une attitude déclarée, la multimodalité peut indiquer qu'il existe plusieurs points de vue ou structures de réponse dans le questionnaire. Toutefois, dans la plupart des cas, la multimodalité indique que l'échantillon n'est pas homogène et que les observations proviennent de deux distributions (ou davantage) qui se &ldquo;chevauchent&rdquo;. Parfois, la multimodalité d'une distribution peut révéler des problèmes au niveau de l'instrument de mesure (par exemple, des &ldquo;problèmes de calibration de l'appareil&rdquo; en sciences naturelles ou un &ldquo;biais dans les réponses&rdquo; en sciences sociales).</p>
]]></content>
        </item>
        
        <item>
            <title>Réutiliser le N-ième mot de la dernière commande</title>
            <link>https://leandeep.com/r%C3%A9utiliser-le-n-i%C3%A8me-mot-de-la-derni%C3%A8re-commande/</link>
            <pubDate>Wed, 05 Nov 2014 20:33:00 +0000</pubDate>
            
            <guid>https://leandeep.com/r%C3%A9utiliser-le-n-i%C3%A8me-mot-de-la-derni%C3%A8re-commande/</guid>
            <description>Dans la catégorie Historique Shell:
Si vous voulez réutiliser un mot particulier de votre dernière commande pour votre nouvelle commande vous pouvez utiliser cette commande:
!!:N Exemple:
$ du -h ~/Dev ... $ cd !!:2 $ cd ~/Dev Il est également possible de désigner la dernière commande commencée par un string. (Comme abordé en dernière partie de ce tip.)
$ cd !d:2 $ cd ~/Dev </description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie Historique Shell:</strong></p>
<p>Si vous voulez réutiliser un mot particulier de votre dernière commande pour votre nouvelle commande vous pouvez utiliser cette commande:</p>
<pre><code>!!:N
</code></pre><p>Exemple:</p>
<pre><code>$ du -h ~/Dev
...

$ cd !!:2
$ cd ~/Dev
</code></pre><p>Il est également possible de désigner la dernière commande commencée par un string. (Comme abordé en dernière partie de <a href="http://leandeep.com/executer-la-derniere-commande-en-tant-que-root/">ce tip</a>.)</p>
<pre><code>$ cd !d:2 
$ cd ~/Dev
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Installer un VNC Server sur Linux</title>
            <link>https://leandeep.com/installer-un-vnc-server-sur-linux/</link>
            <pubDate>Sun, 27 Jul 2014 23:03:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-un-vnc-server-sur-linux/</guid>
            <description>Introduction Dans cet article nous allons voir comment installer un serveur VNC sur Linux.
Steps Désinstaller le serveur Vino (souvent présent par défaut): sudo apt-get -y remove vino Installer x11vnc: sudo apt-get -y install x11vnc Créer le mot de passe encrypté: r Créer un service x11vnc dans systemd: sudo vim /lib/systemd/system/x11vnc.service Et copier/coller le code suivant à l&#39;intérieur du nouveau fichier:
[Unit] Description=x11vnc remote desktop server After=multi-user.target [Service] Type=simple ExecStart=/usr/bin/x11vnc -auth guess -forever -loop -noxdamage -repeat -rfbauth /home/olivier/.</description>
            <content type="html"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>Dans cet article nous allons voir comment installer un serveur VNC sur Linux.</p>
<h1 id="steps">Steps</h1>
<h2 id="dsinstaller-le-serveur-vino-souvent-prsent-par-dfaut">Désinstaller le serveur Vino (souvent présent par défaut):</h2>
<pre><code>sudo apt-get -y remove vino
</code></pre><h2 id="installer-x11vnc">Installer x11vnc:</h2>
<pre><code>sudo apt-get -y install x11vnc
</code></pre><h2 id="crer-le-mot-de-passe-encrypt">Créer le mot de passe encrypté:</h2>
<pre><code>r 
</code></pre><h2 id="crer-un-service-x11vnc-dans-systemd">Créer un service x11vnc dans systemd:</h2>
<pre><code>sudo vim /lib/systemd/system/x11vnc.service
</code></pre><p>Et copier/coller le code suivant à l'intérieur du nouveau fichier:</p>
<pre><code>[Unit]
Description=x11vnc remote desktop server
After=multi-user.target

[Service]
Type=simple
ExecStart=/usr/bin/x11vnc -auth guess -forever -loop -noxdamage -repeat -rfbauth /home/olivier/.vnc/passwd -rfbport 5900 -shared

Restart=on-failure

[Install]
WantedBy=multi-user.target
</code></pre><h2 id="reloader-les-services"><em>Reloader</em> les services:</h2>
<pre><code>sudo systemctl daemon-reload
</code></pre><h2 id="activer-le-service-x11vnc-au-boot">Activer le service x11vnc au <em>boot</em>:</h2>
<pre><code>sudo systemctl enable x11vnc.service
</code></pre><h2 id="dmarrer-le-service-ou-reboot">Démarrer le service (ou reboot):</h2>
<pre><code>sudo systemctl start x11vnc.service
</code></pre><p>Rebooter puis vérifier que vous pouvez établir une connection VNC sur le port 5900.</p>
<h1 id="troubleshoot">Troubleshoot</h1>
<p>Si vous rencontez l'erreur suivante:</p>
<pre><code>xauth:  unable to generate an authority file name
</code></pre><p>Utiliser le bureau lightgdm:</p>
<pre><code>cat /etc/X11/default-display-manager 
sudo apt install ubuntu-unity-desktop
# Si ubuntu-unity-desktop est déjà installé
# sudo dpkg-reconfigure gdm3 
</code></pre><p>Selectionner donc le bureau lightgdm puis rebooter pour vérifier que cela fonctionne.</p>
<p>Pour vérifier que le serveur VNC est bien démarré:</p>
<pre><code>// make sure 5900 port is listening:
$ netstat -antp | grep 5900
(Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.)
tcp        0      0 0.0.0.0:5900            0.0.0.0:*               LISTEN      -
tcp6       0      0 :::5900                 :::*                    LISTEN      -
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Retirer les commentaires et lignes vides</title>
            <link>https://leandeep.com/retirer-les-commentaires-et-lignes-vides/</link>
            <pubDate>Mon, 16 Jun 2014 21:25:00 +0000</pubDate>
            
            <guid>https://leandeep.com/retirer-les-commentaires-et-lignes-vides/</guid>
            <description>Dans la catégorie Manipulation de textes:
Voici une commande permettant de nettoyer un fichier de configuration et retirer les commentaires et lignes vides inutiles.
grep -E -v &amp;quot;^#|^$&amp;quot; file Ces commandes utilisent une regex grâce à l&#39;option -E de grep.
 &amp;ldquo;^#&amp;rdquo; permet de trouver toutes lignes qui commencent par un &amp;ldquo;#&amp;quot;. &amp;ldquo;^$&amp;rdquo; permet de trouver toutes les lignes vides.  Pour info l&#39;option -v permet d&#39;inverser la sélection.
Exemple:</description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie Manipulation de textes:</strong></p>
<p>Voici une commande permettant de nettoyer un fichier de configuration et retirer les commentaires et lignes vides inutiles.</p>
<pre><code>grep -E -v &quot;^#|^$&quot; file
</code></pre><p>Ces commandes utilisent une regex grâce à l'option -E de grep.</p>
<ul>
<li>&ldquo;^#&rdquo; permet de trouver toutes lignes qui commencent par un &ldquo;#&quot;.</li>
<li>&ldquo;^$&rdquo; permet de trouver toutes les lignes vides.</li>
</ul>
<p><em>Pour info l'option -v permet d'inverser la sélection.</em></p>
<p>Exemple:</p>
<pre><code>grep -E -v '^#|^$' nginx.conf | head
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Exécuter la dernière commande en tant que root</title>
            <link>https://leandeep.com/ex%C3%A9cuter-la-derni%C3%A8re-commande-en-tant-que-root/</link>
            <pubDate>Sun, 15 Jun 2014 22:07:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ex%C3%A9cuter-la-derni%C3%A8re-commande-en-tant-que-root/</guid>
            <description>Dans la catégorie Historique Shell
Si vous avez oublié d&#39;exécuter une commande avec les privilèges root, vous pouvez simplement la répéter en utilisant:
$ sudo !! $ su -c &amp;quot;!!&amp;quot; Exemple:
$ adduser bob -bash: /usr/sbin/adduser: Permission denied $ sudo !! $ sudo adduser bob id bob uid=1007(bob) gid=1007(bob) groups=1007(bob) $ useradd bill -bash: /usr/sbin/useradd: Permission denied $ su -c &amp;quot;!!&amp;quot; $ su -c &amp;quot;useradd bill&amp;quot; Password: id bill uid=1007(bill) gid=1007(bill) groups=1007(bill) Cette syntaxe avec points d&#39;exclamation est appelée event designator.</description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie Historique Shell</strong></p>
<p>Si vous avez oublié d'exécuter une commande avec les privilèges root, vous pouvez simplement la répéter en utilisant:</p>
<pre><code>$ sudo !!
$ su -c &quot;!!&quot;
</code></pre><p>Exemple:</p>
<pre><code>$ adduser bob
-bash: /usr/sbin/adduser: Permission denied 
$ sudo !! 
$ sudo adduser bob
id bob uid=1007(bob) gid=1007(bob) groups=1007(bob)

$ useradd bill
-bash: /usr/sbin/useradd: Permission denied 
$ su -c &quot;!!&quot; 
$ su -c &quot;useradd bill&quot; 
Password: 
id bill uid=1007(bill) gid=1007(bill) groups=1007(bill)
</code></pre><p>Cette syntaxe avec points d'exclamation est appelée <em>event designator</em>. Il désigne une référence dans l'historique des commandes shell.
Bang-Bang (!!) répète la commande la plus récente.
Il est également possible de rejouer en mode root la commande la plus récente qui débute avec un string donné.</p>
<p>Exemple:</p>
<pre><code>$ whoami
olivier

$ uptime
15:19  up 7 days,  5:45, 3 users, load averages: 2.39 2.20 2.27

$ sudo !w
$ sudo whoami
root
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Formater clé usb en fat32 depuis OSX</title>
            <link>https://leandeep.com/formater-cl%C3%A9-usb-en-fat32-depuis-osx/</link>
            <pubDate>Thu, 15 May 2014 19:54:00 +0000</pubDate>
            
            <guid>https://leandeep.com/formater-cl%C3%A9-usb-en-fat32-depuis-osx/</guid>
            <description>Lister les disques pour récupérer le nom de la clé à formater
diskutil list Démonter la clé à formater
diskutil unmountDisk /dev/disk2 Formater la clé au format fat32 et lui donner le nom &amp;ldquo;USB&amp;rdquo;
diskutil eraseDisk FAT32 USB /dev/disk2 Formater la clé en FAT32 avec l’option de zone d’amorce en MBR pour qu’elle soit lisible sur tous les OS
diskutil eraseDisk FAT32 USB MBR /dev/disk2 </description>
            <content type="html"><![CDATA[<p><strong>Lister les disques pour récupérer le nom de la clé à formater</strong></p>
<pre><code>diskutil list
</code></pre><p><strong>Démonter la clé à formater</strong></p>
<pre><code>diskutil unmountDisk /dev/disk2
</code></pre><p><strong>Formater la clé au format fat32 et lui donner le nom &ldquo;USB&rdquo;</strong></p>
<pre><code>diskutil eraseDisk FAT32 USB /dev/disk2
</code></pre><p><strong>Formater la clé en FAT32 avec l’option de zone d’amorce en MBR pour qu’elle soit lisible sur tous les OS</strong></p>
<pre><code>diskutil eraseDisk FAT32 USB MBR /dev/disk2
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Réutiliser le dernier argument de la dernière commande</title>
            <link>https://leandeep.com/r%C3%A9utiliser-le-dernier-argument-de-la-derni%C3%A8re-commande/</link>
            <pubDate>Sat, 10 May 2014 21:38:00 +0000</pubDate>
            
            <guid>https://leandeep.com/r%C3%A9utiliser-le-dernier-argument-de-la-derni%C3%A8re-commande/</guid>
            <description>Dans la catégorie Historique Shell:
Si vous voulez réutiliser le dernier argument de votre dernière commande pour votre nouvelle commande vous pouvez utiliser cette commande:
!$ Exemple:
$ mv server.js backend/ $ du -sh !$ $ du -sh backend/ 1.2G backend/ </description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie Historique Shell:</strong></p>
<p>Si vous voulez réutiliser le dernier argument de votre dernière commande pour votre nouvelle commande vous pouvez utiliser cette commande:</p>
<pre><code>!$
</code></pre><p>Exemple:</p>
<pre><code>$ mv server.js backend/ 
$ du -sh !$ 
$ du -sh backend/ 
1.2G  backend/
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Réutiliser le 1er argument de la dernière commande</title>
            <link>https://leandeep.com/r%C3%A9utiliser-le-1er-argument-de-la-derni%C3%A8re-commande/</link>
            <pubDate>Thu, 08 May 2014 15:23:00 +0000</pubDate>
            
            <guid>https://leandeep.com/r%C3%A9utiliser-le-1er-argument-de-la-derni%C3%A8re-commande/</guid>
            <description>Dans la catégorie Historique Shell:
Si vous voulez réutiliser le premier argument de votre dernière commande pour votre nouvelle commande vous pouvez utiliser cette commande:
!^ Exemple:
$ host www.google.com 8.8.8.8 Using domain server: Name: 8.8.8.8 Address: 8.8.8.8#53 Aliases: www.google.com has address ... www.google.com has IPv6 address ... # Envoyer 1 seul ping $ ping -c1 !^ $ ping -c1 www.google.com PING www.google.com ... </description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie Historique Shell:</strong></p>
<p>Si vous voulez réutiliser le premier argument de votre dernière commande pour votre nouvelle commande vous pouvez utiliser cette commande:</p>
<pre><code>!^
</code></pre><p>Exemple:</p>
<pre><code>$ host www.google.com 8.8.8.8
Using domain server:
Name: 8.8.8.8
Address: 8.8.8.8#53
Aliases: 

www.google.com has address ...
www.google.com has IPv6 address ...

# Envoyer 1 seul ping
$ ping -c1 !^ 
$ ping -c1 www.google.com
PING www.google.com ...
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Rapidement changer l&#39;extension d&#39;un fichier</title>
            <link>https://leandeep.com/rapidement-changer-lextension-dun-fichier/</link>
            <pubDate>Tue, 06 May 2014 22:14:00 +0000</pubDate>
            
            <guid>https://leandeep.com/rapidement-changer-lextension-dun-fichier/</guid>
            <description>Dans la catégorie fichiers et répertoires:
Pour rapidement renommer un fichier avec une nouvelle extension, on peut utiliser les brakcets.
Exemple:
$ ls fichier* fichier.rtf $ mv fichier.{rtf,txt} $ ls fichier* fichier.txt Cette commande permet également d&#39;ajouter une extension à un fichier s&#39;il n&#39;y en a pas.
$ ls file* file $ mv file{,.docx} $ ls file* file.docx </description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie fichiers et répertoires:</strong></p>
<p>Pour rapidement renommer un fichier avec une nouvelle extension, on peut utiliser les <em>brakcets</em>.</p>
<p>Exemple:</p>
<pre><code>$ ls fichier*
fichier.rtf

$ mv fichier.{rtf,txt}
$ ls fichier*
fichier.txt
</code></pre><p>Cette commande permet également d'ajouter une extension à un fichier s'il n'y en a pas.</p>
<pre><code>$ ls file*
file
$ mv file{,.docx}
$ ls file*
file.docx
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Rapidement backuper un fichier</title>
            <link>https://leandeep.com/rapidement-backuper-un-fichier/</link>
            <pubDate>Sun, 04 May 2014 23:05:00 +0000</pubDate>
            
            <guid>https://leandeep.com/rapidement-backuper-un-fichier/</guid>
            <description>Dans la catégorie fichiers et répertoires:
Vous êtes sur un serveur et vous voulez rapidement créer le backup d&#39;une fichier. Les brackets permettent de le faire. Elles permettent de créer plusieurs arguments quand un argument est prévu par une commande.
$ cp file{,.bak} Exemples:
$ sudo cp ~/.ssh/id_rsa.pub{,.bak} $ ls ~/.ssh/id_rsa.pub ~/.ssh/id_rsa.pub ~/.ssh/id_rsa.pub.bak ... $ mkdir -p ~/Dev/{frontend,backend} $ ls ~/Dev/ frontend backend $ echo 192.168.0.{0..4} 192.168.0.0 192.168.0.1 192.168.0.2 192.168.0.3 192.</description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie fichiers et répertoires:</strong></p>
<p>Vous êtes sur un serveur et vous voulez rapidement créer le backup d'une fichier. Les brackets permettent de le faire. Elles permettent de créer plusieurs arguments quand un argument est prévu par une commande.</p>
<pre><code>$ cp file{,.bak}
</code></pre><p>Exemples:</p>
<pre><code>$ sudo cp ~/.ssh/id_rsa.pub{,.bak}
$ ls ~/.ssh/id_rsa.pub
~/.ssh/id_rsa.pub   ~/.ssh/id_rsa.pub.bak   ...

$ mkdir -p ~/Dev/{frontend,backend}
$ ls ~/Dev/
frontend   backend

$ echo 192.168.0.{0..4}
192.168.0.0   192.168.0.1   192.168.0.2   192.168.0.3   192.168.0.4
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Monter automatiquement les disques au démarrage du système</title>
            <link>https://leandeep.com/monter-automatiquement-les-disques-au-d%C3%A9marrage-du-syst%C3%A8me/</link>
            <pubDate>Fri, 02 May 2014 22:59:00 +0000</pubDate>
            
            <guid>https://leandeep.com/monter-automatiquement-les-disques-au-d%C3%A9marrage-du-syst%C3%A8me/</guid>
            <description>Afficher proprement les points de montage du système Dans la catégorie Administration Système:
$ mount | column -t Pour filtrer sur un type de système de fichier, vous pouvez utiliser la commande suivante.
Exemple pour un filesystem apfs
$ mount -t apfs | column -t  Monter automatiquement un disk interne Créer vos répertoire de montage puis monter manuellement une première fois vos disques:
cd ~ mkdir hdd1_mount sudo mount /dev/sda1 ~/hdd1_mount Le disque va être monté.</description>
            <content type="html"><![CDATA[<h2 id="afficher-proprement-les-points-de-montage-du-systme">Afficher proprement les points de montage du système</h2>
<p><strong>Dans la catégorie Administration Système:</strong></p>
<pre><code>$ mount | column -t
</code></pre><p>Pour filtrer sur un type de système de fichier, vous pouvez utiliser la commande suivante.</p>
<p>Exemple pour un filesystem apfs</p>
<pre><code>$ mount -t apfs | column -t
</code></pre><br/>
<h2 id="monter-automatiquement-un-disk-interne">Monter automatiquement un disk interne</h2>
<p>Créer vos répertoire de montage puis monter manuellement une première fois vos disques:</p>
<pre><code>cd ~
mkdir hdd1_mount
sudo mount /dev/sda1 ~/hdd1_mount
</code></pre><p>Le disque va être monté. Ouvrez le fichier /etc/mtab et copiez la dernière ligne. Exemple: <code>/dev/sda1 /home/olivier/hdd1_mount ext4 rw,relatime,data=ordered 0 0</code></p>
<p>Editez ensuite le fichier /etc/fstab et ajouter en bas du fichoer la ligne que vous avez précédemment copié.</p>
<br/>
<h2 id="monter-automatiquement-un-disque-ou-cl-usb">Monter automatiquement un disque ou clé usb</h2>
<p>Installez simplement le package suivant:</p>
<pre><code>sudo apt-get install usbmount
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Utiliser une boucle dans le terminal</title>
            <link>https://leandeep.com/utiliser-une-boucle-dans-le-terminal/</link>
            <pubDate>Thu, 01 May 2014 22:51:00 +0000</pubDate>
            
            <guid>https://leandeep.com/utiliser-une-boucle-dans-le-terminal/</guid>
            <description>Dans la catégorie Scripts Shell:
Si vous voulez exécuter plusieurs fois les mêmes actions sur une liste d&#39;éléments, vous pouvez utiliser une boucle directement dans le terminal sans avoir besoin de script.
for VAR in LIST &amp;gt; do &amp;gt; # utilisez $VAR &amp;gt; done Exemple:
$ for USER in olivier bob bill &amp;gt; do &amp;gt; sudo passwd -l $USER &amp;gt; logger -t bad-boy $USER &amp;gt; done Locking password for user olivier.</description>
            <content type="html"><![CDATA[<p><strong>Dans la catégorie Scripts Shell:</strong></p>
<p>Si vous voulez exécuter plusieurs fois les mêmes actions sur une liste d'éléments, vous pouvez utiliser une boucle directement dans le terminal sans avoir besoin de script.</p>
<pre><code>for VAR in LIST
&gt; do
&gt; # utilisez $VAR
&gt; done
</code></pre><p>Exemple:</p>
<pre><code>$ for USER in olivier bob bill
&gt; do
&gt;  sudo passwd -l $USER
&gt;  logger -t bad-boy $USER
&gt;  done
Locking password for user olivier.
passwd: Success 
Locking password for user bob.
passwd: Success
Locking password for user bill.
passwd: Success
</code></pre><p>Les commandes ci-dessus peuvent être écrites sur une ligne:</p>
<pre><code>for USER in olivier bob bill; do sudo passwd -l $USER; logger -t bad-boy $USER; done
</code></pre><p>Autre exemple plus utile: convertir tous les mp4 d'un dossier en mp3:</p>
<pre><code>for FILE in *\ *
do
ffmpeg -f mp4 -i ${FILE} -f mp3 &quot;${FILE%.mp4}.mp3&quot;
done
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Débuter avec Hugo</title>
            <link>https://leandeep.com/d%C3%A9buter-avec-hugo/</link>
            <pubDate>Wed, 02 Apr 2014 00:00:00 +0000</pubDate>
            
            <guid>https://leandeep.com/d%C3%A9buter-avec-hugo/</guid>
            <description>&lt;h2 id=&#34;tape-1-installer-hugo&#34;&gt;Étape 1. Installer Hugo&lt;/h2&gt;
&lt;p&gt;Allez sur la page de téléchargements de
&lt;a href=&#34;https://github.com/spf13/hugo/releases&#34;&gt;hugo&lt;/a&gt; et téléchargez la version
appropriée à votre système d&#39;exploitation et votre architecture.&lt;/p&gt;
&lt;p&gt;Sauvegardez le fichier téléchargé à un endroit précis, afin de l&#39;utiliser dans
l&#39;étape suivante.&lt;/p&gt;
&lt;p&gt;Des informations plus complètes sont disponibles sur la page
&lt;a href=&#34;https://leandeep.com/overview/installing/&#34;&gt;installing hugo&lt;/a&gt;&lt;/p&gt;</description>
            <content type="html"><![CDATA[<h2 id="tape-1-installer-hugo">Étape 1. Installer Hugo</h2>
<p>Allez sur la page de téléchargements de
<a href="https://github.com/spf13/hugo/releases">hugo</a> et téléchargez la version
appropriée à votre système d'exploitation et votre architecture.</p>
<p>Sauvegardez le fichier téléchargé à un endroit précis, afin de l'utiliser dans
l'étape suivante.</p>
<p>Des informations plus complètes sont disponibles sur la page
<a href="/overview/installing/">installing hugo</a></p>
<h2 id="tape-2-compilez-la-documentation">Étape 2. Compilez la documentation</h2>
<p>Hugo possède son propre site d'exemple qui se trouve être également le site que
vous lisez actuellement.</p>
<p>Suivez les instructions suivante :</p>
<ol>
<li>Clonez le <a href="http://github.com/spf13/hugo">dépôt de hugo</a></li>
<li>Allez dans ce dépôt</li>
<li>Lancez Hugo en mode serveur et compilez la documentation</li>
<li>Ouvrez votre navigateur sur http://localhost:1313</li>
</ol>
<p>Voici les commandes génériques correspondantes :</p>
<pre><code>git clone https://github.com/spf13/hugo
cd hugo
/chemin/ou/vous/avez/installe/hugo server --source=./docs
&gt; 29 pages created
&gt; 0 tags index created
&gt; in 27 ms
&gt; Web Server is available at http://localhost:1313
&gt; Press ctrl+c to stop
</code></pre>
<p>Lorsque vous avez cela, continuez le reste de ce guide sur votre version locale.</p>
<h2 id="tape-3-changer-le-site-de-documentation">Étape 3. Changer le site de documentation</h2>
<p>Arrêtez le processus de Hugo en pressant ctrl+c.</p>
<p>Maintenant, nous allons relancer hugo, mais cette fois avec Hugo en mode de
surveillance.</p>
<pre><code>/chemin/vers/hugo/de/l-etape/1/hugo server --source=./docs --watch
&gt; 29 pages created
&gt; 0 tags index created
&gt; in 27 ms
&gt; Web Server is available at http://localhost:1313
&gt; Watching for changes in /Users/spf13/Code/hugo/docs/content
&gt; Press ctrl+c to stop
</code></pre>
<p>Ouvrez votre <a href="https://vim.spf13.com">éditeur favori</a> et changer l'une des
sources des pages de contenu.
Open your <a href="http://vim.spf13.com">favorite editor</a> and change one of the source
content pages. Que diriez-vous de modifier ce fichier pour <em>résoudre une faute
de typo</em>.</p>
<p>Les fichiers de contenu peuvent être trouvés dans <code>docs/content/</code>. Sauf
indication contraire, les fichiers sont situés au même emplacement relatif que
l'URL, dans notre cas <code>docs/content/overview/quickstart.md</code>.</p>
<p>Modifiez et sauvegardez ce fichier. Notez ce qu'il se passe dans le terminal.</p>
<pre><code>&gt; Change detected, rebuilding site

&gt; 29 pages created
&gt; 0 tags index created
&gt; in 26 ms
</code></pre>
<p>Rechargez la page dans votre navigateur et voyez que le problème de typo est
maintenant résolu.</p>
<p>Notez à quel point cela a été rapide. Essayez de recharger le site avant qu'il
soit fini de compiler.
Notice how quick that was. Try to refresh the site before it's finished
building. Je paris que vous n'y arrivez pas.
Le fait d'avoir des réactions presque instantanées vous permet d'avoir votre
créativité fluide sans avoir à attendre de longues compilations.</p>
<h2 id="step-4-amusez-vous">Step 4. Amusez-vous</h2>
<p>Le meilleur moyen d'apprendre quelque chose est de s'amuser avec.</p>]]></content>
        </item>
        
        <item>
            <title>Introduction aux modèles (Hu)go</title>
            <link>https://leandeep.com/introduction-aux-mod%C3%A8les-hugo/</link>
            <pubDate>Wed, 02 Apr 2014 00:00:00 +0000</pubDate>
            
            <guid>https://leandeep.com/introduction-aux-mod%C3%A8les-hugo/</guid>
            <description>Hugo utilise l&#39;excellente librairie go html/template pour son moteur de modèles. c&#39;est un moteur extrêmement léger qui offre un très petit nombre de fonctions logiques. À notre expérience, c&#39;est juste ce qu&#39;il faut pour créer un bon site web statique. Si vous avez déjà utilisé d&#39;autre moteurs de modèles pour différents langages ou frameworks, vous allez retrouver beaucoup de similitudes avec les modèles go.
Ce document est une introduction sur l&#39;utilisation de Go templates.</description>
            <content type="html"><![CDATA[<p>Hugo utilise l'excellente librairie <a href="http://golang.org/">go</a> <a href="http://golang.org/pkg/html/template/">html/template</a> pour
son moteur de modèles. c'est un moteur extrêmement léger qui offre un très petit
nombre de fonctions logiques. À notre expérience, c'est juste ce qu'il faut pour
créer un bon site web statique. Si vous avez déjà utilisé d'autre moteurs de
modèles pour différents langages ou frameworks, vous allez retrouver beaucoup de
similitudes avec les modèles go.</p>
<p>Ce document est une introduction sur l'utilisation de Go templates. La
<a href="http://golang.org/pkg/html/template/">documentation go</a> fourni plus de détails.</p>
<h2 id="introduction-aux-modles-go">Introduction aux modèles Go</h2>
<p>Go templates fournit un langage de modèles très simple. Il adhère à la
conviction que les modèles ou les vues doivent avoir une logique des plus
élémentaires. L'une des conséquences de cette simplicité est que les modèles
seront plus rapides a être analysés.</p>
<p>Une caractéristique unique de Go templates est qu'il est conscient du contenu.
Les variables et le contenu va être nettoyé suivant le contexte d'utilisation.
Plus de détails sont disponibles dans la <a href="http://golang.org/pkg/html/template/">documentation go</a>.</p>
<h2 id="syntaxe-basique">Syntaxe basique</h2>
<p>Les modèles en langage Go sont des fichiers HTML avec l'ajout de variables et
fonctions.</p>
<p><strong>Les variables Go et les fonctions sont accessibles avec {{ }}</strong></p>
<p>Accès à une variable prédéfinie &ldquo;foo&rdquo;:</p>
<pre><code>{{ foo }}
</code></pre>
<p><strong>Les paramètres sont séparés par des espaces</strong></p>
<p>Appel de la fonction add avec 1 et 2 en argument**</p>
<pre><code>{{ add 1 2 }}
</code></pre>
<p><strong>Les méthodes et les champs sont accessibles par un point</strong></p>
<p>Accès au paramètre de la page &ldquo;bar&rdquo;</p>
<pre><code>{{ .Params.bar }}
</code></pre>
<p><strong>Les parenthèses peuvent être utilisées pour grouper des éléments ensemble</strong></p>
<pre><code>{{ if or (isset .Params &quot;alt&quot;) (isset .Params &quot;caption&quot;) }} Caption {{ end }}
</code></pre><h2 id="variables">Variables</h2>
<p>Chaque modèle go a une structure (objet) mis à sa disposition. Avec Hugo, à
chaque modèle est passé soit une page, soit une structure de nœud, suivant quel
type de page vous rendez. Plus de détails sont disponibles sur la page des
<a href="/layout/variables">variables</a>.</p>
<p>Une variable est accessible par son nom.</p>
<pre><code>&lt;title&gt;{{ .Title }}&lt;/title&gt;
</code></pre>
<p>Les variables peuvent également être définies et appelées.</p>
<pre><code>{{ $address := &quot;123 Main St.&quot;}}
{{ $address }}
</code></pre>
<h2 id="functions">Functions</h2>
<p>Go templace est livré avec quelques fonctions qui fournissent des
fonctionnalités basiques. Le système de Go template fourni également un
mécanisme permettant aux applications d'étendre les fonctions disponible. Les
<a href="/layout/functions">fonctions de modèle Hugo</a> fourni quelques fonctionnalités
supplémentaires que nous espérons qu'elles seront utiles pour vos sites web.
Les functions sont appelées en utilisant leur nom suivi par les paramètres
requis séparés par des espaces. Des fonctions de modèles ne peuvent pas être
ajoutées sans recompiler Hugo.</p>
<p><strong>Exemple:</strong></p>
<pre><code>{{ add 1 2 }}
</code></pre>
<h2 id="inclusions">Inclusions</h2>
<p>Lorsque vous incluez un autre modèle, vous devez y passer les données qu'il sera
en mesure d'accèder. Pour passer le contexte actuel, pensez à ajouter un point.
La localisation du modèle sera toujours à partir du répertoire /layout/ dans
Hugo.</p>
<p><strong>Exemple:</strong></p>
<pre><code>{{ template &quot;chrome/header.html&quot; . }}
</code></pre>
<h2 id="logique">Logique</h2>
<p>Go templates fourni les itérations et la logique conditionnèle des plus basique.</p>
<h3 id="itration">Itération</h3>
<p>Comme en go, les modèles go utilisent fortement <em>range</em> pour itérer dans une
map, un array ou un slice. Les exemples suivant montre différentes façons
d'utiliser <em>range</em></p>
<p><strong>Exemple 1: En utilisant le context</strong></p>
<pre><code>{{ range array }}
    {{ . }}
{{ end }}
</code></pre>
<p><strong>Exemple 2: En déclarant un nom de variable</strong></p>
<pre><code>{{range $element := array}}
    {{ $element }}
{{ end }}
</code></pre>
<p><strong>Exemple 2: En déclarant un nom de varialbe pour la clé et la valeur</strong></p>
<pre><code>{{range $index, $element := array}}
    {{ $index }}
    {{ $element }}
{{ end }}
</code></pre>
<h3 id="conditions">Conditions</h3>
<p><em>If</em>, <em>else</em>, <em>with</em>, <em>or</em>, <em>&amp;</em>, <em>and</em> fournissent la base pour la logique
conditionnelle avec Go templates. Comme <em>range</em>, chaque déclaration est fermé
avec <code>end</code>.</p>
<p>Go templates considère les valeurs suivante comme <em>false</em> :</p>
<ul>
<li>false</li>
<li>0</li>
<li>tout array, slice, map ou chaine d'une longueur de zéro</li>
</ul>
<p><strong>Exemple 1: If</strong></p>
<pre><code>{{ if isset .Params &quot;title&quot; }}&lt;h4&gt;{{ index .Params &quot;title&quot; }}&lt;/h4&gt;{{ end }}
</code></pre>
<p><strong>Exemple 2: If -&gt; Else</strong></p>
<pre><code>{{ if isset .Params &quot;alt&quot; }}
    {{ index .Params &quot;alt&quot; }}
{{else}}
    {{ index .Params &quot;caption&quot; }}
{{ end }}
</code></pre>
<p><strong>Exemple 3: And &amp; Or</strong></p>
<pre><code>{{ if and (or (isset .Params &quot;title&quot;) (isset .Params &quot;caption&quot;))
    (isset .Params &quot;attr&quot;)}}
</code></pre><p><strong>Exemple 4: With</strong></p>
<p>Une manière alternative d'écrire un &ldquo;if&rdquo; et de référencer cette même valeur est
d'utiliser &ldquo;with&rdquo;. Cela permet de remplacer le contexte <code>.</code> par cet valeur et
saute le bloc si la variable est absente.</p>
<p>Le premier exemple peut être simplifié à ceci :</p>
<pre><code>{{ with .Params.title }}&lt;h4&gt;{{ . }}&lt;/h4&gt;{{ end }}
</code></pre>
<p><strong>Exemple 5: If -&gt; Else If</strong></p>
<pre><code>{{ if isset .Params &quot;alt&quot; }}
    {{ index .Params &quot;alt&quot; }}
{{ else if isset .Params &quot;caption&quot; }}
    {{ index .Params &quot;caption&quot; }}
{{ end }}
</code></pre>
<h2 id="pipes"><em>Pipes</em></h2>
<p>L'un des composants le plus puissant de Go templates est la capacité d'empiler
les action l'une après l'autre. Cela est fait en utilisant les <em>pipes</em>.
Empruntés aux <em>pipes</em> unix, le concept est simple. Chaque sortie de <em>pipeline</em>
devient l'entrée du <em>pipe</em> suivant.</p>
<p>À cause de la syntaxe très simple de Go templates, le <em>pipe</em> est essentiel pour
être capable d'enchainer les appels de fonctions. Une limitation des <em>pipes</em>
est qu'il ne peuvent fonctionner seulement avec une seule valeur et cette valeur
devient le dernier paramètre du prochain <em>pipeline</em>.</p>
<p>Quelques exemples simple devrait vous aider à comprendre comment utiliser les
<em>pipes</em>.</p>
<p><strong>Exemple 1 :</strong></p>
<pre><code>{{ if eq 1 1 }} Same {{ end }}
</code></pre>
<p>est identique à</p>
<pre><code>{{ eq 1 1 | if }} Same {{ end }}
</code></pre>
<p>Il semble étrange de placer le <em>if</em> à la fin, mais il fournit une bonne
illustration de la façon d'utiliser les tuyaux.</p>
<p><strong>Exemple 2 :</strong></p>
<pre><code>{{ index .Params &quot;disqus_url&quot; | html }}
</code></pre>
<p>Accès au paramètre de page nommé &ldquo;disqus_url&rdquo; et échappement du HTML</p>
<p><strong>Exemple 3 :</strong></p>
<pre><code>{{ if or (or (isset .Params &quot;title&quot;) (isset .Params &quot;caption&quot;))
    (isset .Params &quot;attr&quot;)}}
Stuff Here
{{ end }}
</code></pre><p>Peut être réécrit en</p>
<pre><code>{{  isset .Params &quot;caption&quot; | or isset .Params &quot;title&quot; |
    or isset .Params &quot;attr&quot; | if }}
Stuff Here
{{ end }}
</code></pre><h2 id="contexte-alias-le-point">Contexte (alias. le point)</h2>
<p>Le concept le plus facilement négligé pour comprendre les modèles go est que
{{ . }} fait toujours référence au contexte actuel. Dans le plus haut niveau de
votre modèle, ce sera l'ensemble des données mis à votre disposition. Dans une
itération, ce sera la valeur de l'élément actuel. Enfin, dans une boucle, le
contexte change. . ne fera plus référence aux données disponibles dans la page
entière. Si vous avez besoin y d'accèder depuis l'intérieur d'une boucle, il est
judicieux d'y définir comme variable au lieu de dépendre du contexte.</p>
<p><strong>Exemple:</strong></p>
<pre><code>{{ $title := .Site.Title }}
{{ range .Params.tags }}
&lt;li&gt; &lt;a href=&quot;{{ $baseurl }}/tags/{{ . | urlize }}&quot;&gt;
    {{ . }}&lt;/a&gt; - {{ $title }} &lt;/li&gt;
{{ end }}
</code></pre><p>Notez que, une fois que nous sommes entrés dans la boucle, la valeur de
{{ . }} a changée. Nous avons défini une variable en dehors de la boucle, afin
d'y avoir accès dans la boucle.</p>
<h1 id="les-paramtres-dhugo">Les Paramètres d'Hugo</h1>
<p>Hugo fournit l'option de passer des valeurs au modèle depuis la configuration du
site, ou depuis les métadonnées de chaque partie du contenu. Vous pouvez définir
n'importe quelle valeur de n'importe quel type (supporté par votre section
liminaire / format de configuration) et les utiliser comme vous le souhaitez
dans votre modèle.</p>
<h2 id="utiliser-les-paramtres-de-contenu-page">Utiliser les paramètres de contenu (page)</h2>
<p>Dans chaque partie du contenu, vous pouvez fournir des variables pour être
utilisées par le modèle. Cela se passe dans la
<a href="/content/front-matter">section liminaire</a>.</p>
<p>Un exemple de cela est utilisé par ce site de documentation. La plupart des
pages bénéficient de la présentation de la table des matières. Quelques fois,
la table des matières n'a pas beaucoup de sens. Nous avons défini une variable
dans notre section liminaire de quelques pages pour désactiver la table des
matières.</p>
<p>Ceci est un exemple de section liminaire :</p>
<pre><code>---
title: &quot;Permalinks&quot;
date: &quot;2013-11-18&quot;
aliases:
  - &quot;/doc/permalinks/&quot;
groups: [&quot;extras&quot;]
groups_weight: 30
notoc: true
---
</code></pre><p>Ceci est le code correspondant dans le modèle :</p>
<pre><code>  {{ if not .Params.notoc }}
    &lt;div id=&quot;toc&quot; class=&quot;well col-md-4 col-sm-6&quot;&gt;
    {{ .TableOfContents }}
    &lt;/div&gt;
  {{ end }}
</code></pre>
<h2 id="utiliser-les-paramtres-de-site-config">Utiliser les paramètres de site (config)</h2>
<p>Dans votre configuration de plus haut niveau (ex <code>config.yaml</code>), vous pouvez
définir des paramètres de site, dont les valeurs vous seront accessibles.</p>
<p>Pour les instances, vous pourriez délarer :</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">params:
  CopyrightHTML: <span style="color:#e6db74">&#34;Copyright &amp;#xA9; 2013 John Doe. All Rights Reserved.&#34;</span>
  TwitterUser: <span style="color:#e6db74">&#34;spf13&#34;</span>
  SidebarRecentLimit: <span style="color:#ae81ff">5</span>
</code></pre></div><p>Avec un pied de page, vous devriez déclarer un <code>&lt;footer&gt;</code> qui est affiché
seulement si le paramètre <code>CopyrightHTML</code> est déclaré, et si il l'est, vous
devriez le déclarer comme HTML-safe, afin d'éviter d'échapper les entités HTML.
Cela vous permettra de le modifier facilement dans votre configuration au lieu
de le chercher dans votre modèle.</p>
<pre><code>{{if .Site.Params.CopyrightHTML}}&lt;footer&gt;
&lt;div class=&quot;text-center&quot;&gt;{{.Site.Params.CopyrightHTML | safeHtml}}&lt;/div&gt;
&lt;/footer&gt;{{end}}
</code></pre><p>Une alternative au &ldquo;if&rdquo; et d'appeler la même valeur est d'utiliser &ldquo;with&rdquo;. Cela
modifiera le contexte et passera le bloc si la variable est absente :</p>
<pre><code>{{with .Site.Params.TwitterUser}}&lt;span class=&quot;twitter&quot;&gt;
&lt;a href=&quot;https://twitter.com/{{.}}&quot; rel=&quot;author&quot;&gt;
&lt;img src=&quot;/images/twitter.png&quot; width=&quot;48&quot; height=&quot;48&quot; title=&quot;Twitter: {{.}}&quot;
 alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
&lt;/span&gt;{{end}}
</code></pre><p>Enfin, si vous souhaitez extraire des &ldquo;constantes magiques&rdquo; de vos mises en
page, vous pouvez le faire comme dans l'exemple suivant :</p>
<pre><code>&lt;nav class=&quot;recent&quot;&gt;
  &lt;h1&gt;Recent Posts&lt;/h1&gt;
  &lt;ul&gt;{{range first .Site.Params.SidebarRecentLimit .Site.Recent}}
    &lt;li&gt;&lt;a href=&quot;{{.RelPermalink}}&quot;&gt;{{.Title}}&lt;/a&gt;&lt;/li&gt;
  {{end}}&lt;/ul&gt;
&lt;/nav&gt;
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Migrer vers Hugo depuis Jekyll</title>
            <link>https://leandeep.com/migrer-vers-hugo-depuis-jekyll/</link>
            <pubDate>Mon, 10 Mar 2014 00:00:00 +0000</pubDate>
            
            <guid>https://leandeep.com/migrer-vers-hugo-depuis-jekyll/</guid>
            <description>&lt;h2 id=&#34;dplacez-le-contenu-statique-vers-static&#34;&gt;Déplacez le contenu statique vers &lt;code&gt;static&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Jekyll a une règle comme quoi tout répertoire qui ne commence pas par &lt;code&gt;_&lt;/code&gt; sera
copié tel-quel dans le répertoire &lt;code&gt;_site&lt;/code&gt;. Hugo garde tout le contenu statique
dans le répertoire &lt;code&gt;static&lt;/code&gt;. Vous devez donc déplacer tout ce type de contenu
là-dedans. Avec Jekylll, l&#39;arborescence ressemblant à ceci :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;▾ &amp;lt;root&amp;gt;/
    ▾ images/
        logo.png
&lt;/code&gt;&lt;/pre&gt;</description>
            <content type="html"><![CDATA[<h2 id="dplacez-le-contenu-statique-vers-static">Déplacez le contenu statique vers <code>static</code></h2>
<p>Jekyll a une règle comme quoi tout répertoire qui ne commence pas par <code>_</code> sera
copié tel-quel dans le répertoire <code>_site</code>. Hugo garde tout le contenu statique
dans le répertoire <code>static</code>. Vous devez donc déplacer tout ce type de contenu
là-dedans. Avec Jekylll, l'arborescence ressemblant à ceci :</p>
<pre><code>▾ &lt;root&gt;/
    ▾ images/
        logo.png
</code></pre>
<p>doit devenir</p>
<pre><code>▾ &lt;root&gt;/
    ▾ static/
        ▾ images/
            logo.png
</code></pre>
<p>En outre, vous allez devoir déplacer tous les fichiers présents à la racine vers
le répertoire <code>static</code>.</p>
<h2 id="crez-votre-configuration-hugo">Créez votre configuration Hugo</h2>
<p>Hugo peut lire votre fichier de configuration au format JSON, YAML et TOML. Hugo
supporte également les paramètres de configuration. Plus d'informations sur la
<a href="/overview/configuration/">documentation de configuration Hugo</a></p>
<h2 id="dfiniez-votre-rpertoire-de-publication-sur--site">Définiez votre répertoire de publication sur <code>_site</code></h2>
<p>La valeur par défaut pour Jekyll est d'utiliser le répertoire <code>_site</code> pour
publier le contenu. Pour Hugo, le répertoire de publication est <code>public</code>. Si,
comme moi, vous avez [lié <code>_site</code> vers un sous-module git sur la branche
<code>gh-pages</code>](<a href="http://blog.blindgaenger.net/generate_github_pages_in_a_submodule.ht">http://blog.blindgaenger.net/generate_github_pages_in_a_submodule.ht</a>
ml), vous allez vouloir avoir quelques alternatives :</p>
<ol>
<li>
<p>Changez votre lien du sous-module <code>gh-pages</code> pour pointer sur public au lieu
de <code>_site</code> (recommendé).</p>
<pre><code> git submodule deinit _site
 git rm _site
 git submodule add -b gh-pages
     git@github.com:your-username/your-repo.git public
</code></pre>
</li>
<li>
<p>Ou modifiez la configuration de Hugo pour utiliser le répertoire <code>_site</code> au
lieu de <code>public</code>.</p>
<pre><code> {
     ..
     &quot;publishdir&quot;: &quot;_site&quot;,
     ..
 }
</code></pre>
</li>
</ol>
<h2 id="convertir-un-thme-jekyll-pour-hugo">Convertir un thème Jekyll pour Hugo</h2>
<p>C'est la majeure partie du travail. La documentation est votre ami.
Vous devriez vous référer à [la documentation des thèmes de Jekyll]
(<a href="http://jekyllrb.com/docs/templates/">http://jekyllrb.com/docs/templates/</a>) si vous devez vous rafraîchir la mémoire
sur la façon dont vous avez construit votre blog et [les thèmes de Hugo]
(/layout/templates/) pour apprendre la manière de faire sur Hugo.</p>
<p>Pour vous donner un point de référence, la conversion du thème pour
<a href="http://heyitsalex.net/">heyitsalex.net</a> ne m'a pris que quelques heures.</p>
<h2 id="convertir-les-extensions-jekyll-vers-des-shortcodes-hugo">Convertir les extensions Jekyll vers des shortcodes Hugo</h2>
<p>Jekyll support les <a href="http://jekyllrb.com/docs/plugins/">extensions</a>; Hugo lui a
les <a href="/doc/shortcodes/">shortcodes</a>. C'est assez banal les porter.</p>
<h3 id="implmentation">Implémentation</h3>
<p>Comme exemple, j'utilise une extension pour avoir un [<code>image_tag</code>](https://githu
b.com/alexandre-normand/alexandre-normand/blob/74bb12036a71334fdb7dba84e073382fc
06908ec/_plugins/image_tag.rb) presonnalisé pour générer les images avec une
légende sur Jekyll. J'ai vu que Hugo implémente un shortcode qui fait exactement
la même chose.</p>
<p>Extension Jekyll :</p>
<pre><code>module Jekyll
  class ImageTag &lt; Liquid::Tag
    @url = nil
    @caption = nil
    @class = nil
    @link = nil
    // Patterns
    IMAGE_URL_WITH_CLASS_AND_CAPTION =
    IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK =
        /(\w+)(\s+)((https?:\/\/|\/)(\S+))(\s+)&quot;(.*?)&quot;(\s+)-&gt;
        ((https?:\/\/|\/)(\S+))(\s*)/i
    IMAGE_URL_WITH_CAPTION = /((https?:\/\/|\/)(\S+))(\s+)&quot;(.*?)&quot;/i
    IMAGE_URL_WITH_CLASS = /(\w+)(\s+)((https?:\/\/|\/)(\S+))/i
    IMAGE_URL = /((https?:\/\/|\/)(\S+))/i
    def initialize(tag_name, markup, tokens)
      super
      if markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION_AND_LINK
        @class   = $1
        @url     = $3
        @caption = $7
        @link = $9
      elsif markup =~ IMAGE_URL_WITH_CLASS_AND_CAPTION
        @class   = $1
        @url     = $3
        @caption = $7
      elsif markup =~ IMAGE_URL_WITH_CAPTION
        @url     = $1
        @caption = $5
      elsif markup =~ IMAGE_URL_WITH_CLASS
        @class = $1
        @url   = $3
      elsif markup =~ IMAGE_URL
        @url = $1
      end
    end
    def render(context)
      if @class
        source = &quot;&lt;figure class='#{@class}'&gt;&quot;
      else
        source = &quot;&lt;figure&gt;&quot;
      end
      if @link
        source += &quot;&lt;a href=\&quot;#{@link}\&quot;&gt;&quot;
      end
      source += &quot;&lt;img src=\&quot;#{@url}\&quot;&gt;&quot;
      if @link
        source += &quot;&lt;/a&gt;&quot;
      end
      source += &quot;&lt;figcaption&gt;#{@caption}&lt;/figcaption&gt;&quot; if @caption
      source += &quot;&lt;/figure&gt;&quot;
      source
    end
  end
end
Liquid::Template.register_tag('image', Jekyll::ImageTag)
</code></pre><p>Écrite en tant que shortcode Hugo:</p>
<pre><code>&lt;!-- image --&gt;
&lt;figure {{ with .Get &quot;class&quot; }}class=&quot;{{.}}&quot;{{ end }}&gt;
    {{ with .Get &quot;link&quot;}}&lt;a href=&quot;{{.}}&quot;&gt;{{ end }}
        &lt;img src=&quot;{{ .Get &quot;src&quot; }}&quot;
            {{ if or (.Get &quot;alt&quot;) (.Get &quot;caption&quot;) }}
                alt=&quot;{{ with .Get &quot;alt&quot;}}
                        {{.}}
                     {{else}}
                        {{ .Get &quot;caption&quot; }}
                     {{ end }}&quot;
               {{ end }} /&gt;
    {{ if .Get &quot;link&quot;}}&lt;/a&gt;{{ end }}
    {{ if or (or (.Get &quot;title&quot;) (.Get &quot;caption&quot;)) (.Get &quot;attr&quot;)}}
    &lt;figcaption&gt;{{ if isset .Params &quot;title&quot; }}
        {{ .Get &quot;title&quot; }}{{ end }}
        {{ if or (.Get &quot;caption&quot;) (.Get &quot;attr&quot;)}}&lt;p&gt;
        {{ .Get &quot;caption&quot; }}
        {{ with .Get &quot;attrlink&quot;}}&lt;a href=&quot;{{.}}&quot;&gt; {{ end }}
            {{ .Get &quot;attr&quot; }}
        {{ if .Get &quot;attrlink&quot;}}&lt;/a&gt; {{ end }}
        &lt;/p&gt; {{ end }}
    &lt;/figcaption&gt;
    {{ end }}
&lt;/figure&gt;
&lt;!-- image --&gt;
</code></pre><h3 id="utilisation">Utilisation</h3>
<p>J'ai simplement changé :</p>
<pre><code>{% image
    full http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg
    &quot;One of my favorite touristy-type photos. I secretly waited for the
    good light while we were &quot;having fun&quot; and took this. Only regret: a
    stupid pole in the top-left corner of the frame I had to clumsily get
    rid of at post-processing.&quot;
    -&gt;http://www.flickr.com/photos/alexnormand/4829260124/in/
        set-72157624547713078/ %}
</code></pre><p>pour cela (cet exemple utilise une version légèrement étendue nommée <code>fig</code>,
différente de la <code>figure</code> intégrée) :</p>
<pre><code>{{% fig class=&quot;full&quot;
    src=&quot;http://farm5.staticflickr.com/4136/4829260124_57712e570a_o_d.jpg&quot;
    title=&quot;One of my favorite touristy-type photos. I secretly waited for the
    good light while we were having fun and took this. Only regret: a stupid
    pole in the top-left corner of the frame I had to clumsily get rid of at
    post-processing.&quot;
    link=&quot;http://www.flickr.com/photos/alexnormand/4829260124/in/
            set-72157624547713078/&quot; %}}
</code></pre><p>Comme bonus, les paramètres nommés des shortcodes sont plus lisibles.</p>
<h2 id="touches-finales">Touches finales</h2>
<h3 id="corriger-le-contenu">Corriger le contenu</h3>
<p>Suivant le nombre de modifications que vous avez effectué sur chaque articles
avec Jekyll, cette étape requierra plus ou moins d'efforts. Il n'y a pas de
règles rigoureuses ici, si ce n'est que <code>hugo server --watch</code> est votre ami.
Testez vos modifications et corrigez les erreurs au besoin.</p>
<h3 id="nettoyez-le-tout">Nettoyez le tout</h3>
<p>Vous voudrez sûrement supprimer votre configuration Jekyll maintenant que tout
est fini. Exact, pensez à supprimer tout ce qui est inutilisé.</p>
<h2 id="un-exemple-pratique">Un exemple pratique</h2>
<p><a href="http://heyitsalex.net/">Hey, it's Alex</a> a été migré de Jekyll vers Hugo en
moins de temps qu'une journée père enfant. Vous pouvez trouver toutes les
modification en regardant ce [diff](<a href="https://github.com/alexandre-normand/alexand">https://github.com/alexandre-normand/alexand</a>
re-normand/compare/869d69435bd2665c3fbf5b5c78d4c22759d7613a&hellip;b7f6605b1265e83b4b
81495423294208cc74d610).</p>]]></content>
        </item>
        
        <item>
            <title>Créer une variable d&#39;environnement multiligne</title>
            <link>https://leandeep.com/cr%C3%A9er-une-variable-denvironnement-multiligne/</link>
            <pubDate>Sat, 08 Feb 2014 23:31:00 +0000</pubDate>
            
            <guid>https://leandeep.com/cr%C3%A9er-une-variable-denvironnement-multiligne/</guid>
            <description>Si vous voulez définir une variable d&#39;environnement qui comporte plusieurs lignes dans votre .zshrc, vous pouvez utiliser le pattern suivant:
VAR1=$(cat &amp;lt;&amp;lt;EOF ligne 1 ligne 2 ligne 3 EOF ) export VOTRE_VARIABLE=$VAR1 Ou directement utiliser:
export VOTRE_VARIABLE=$(cat &amp;lt;&amp;lt;EOF ligne 1 ligne 2 ligne 3 EOF ) </description>
            <content type="html"><![CDATA[<p>Si vous voulez définir une variable d'environnement qui comporte plusieurs lignes dans votre <code>.zshrc</code>, vous pouvez utiliser le pattern suivant:</p>
<pre><code>VAR1=$(cat &lt;&lt;EOF
ligne 1
ligne 2
ligne 3
EOF
)
export VOTRE_VARIABLE=$VAR1
</code></pre><p>Ou directement utiliser:</p>
<pre><code>export VOTRE_VARIABLE=$(cat &lt;&lt;EOF
ligne 1
ligne 2
ligne 3
EOF
)
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Ce que je retiens de la conférence AppsWorld London (22 et 23 octobre 2013)</title>
            <link>https://leandeep.com/ce-que-je-retiens-de-la-conf%C3%A9rence-appsworld-london-22-et-23-octobre-2013/</link>
            <pubDate>Thu, 24 Oct 2013 14:04:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ce-que-je-retiens-de-la-conf%C3%A9rence-appsworld-london-22-et-23-octobre-2013/</guid>
            <description>I attended the AppsWorld on October 22 and 23, 2013.
Appsworld was 2 days full of discussions around new upcoming platforms (TV apps, Automotive apps with General Motors, PSA Peugeot Citroen, new Mobile OSs…), new technologies, new tools for developers, new services developed by third party companies and new ways to monetize your growing business.
Many interesting topics where discussed but in this summary I will focus on how majors companies are facing the digitalization of the world.</description>
            <content type="html"><![CDATA[<p>I attended the AppsWorld on October 22 and 23, 2013.</p>
<p>Appsworld was 2 days full of discussions around new upcoming platforms (TV apps, Automotive apps with General Motors, PSA Peugeot Citroen, new Mobile OSs…), new technologies, new tools for developers, new services developed by third party companies and new ways to monetize your growing business.</p>
<p>Many interesting topics where discussed but in this summary I will focus on <strong>how majors companies are facing the digitalization of the world</strong>.</p>
<p>I was really impressed by the presentation made by Kevin Flowers (Vice President and CTO of Coca Cola Company). As he said “The shelf is moving. How do we access the shelf ?”. To answer this question they did the 5 points below:</p>
<ul>
<li>API Management Strategy &ndash;&gt; Key insight !</li>
<li>Leverage existing Integrations</li>
<li>Security Partnership</li>
<li>Set API Achievement Goal</li>
<li>Clear Individual Objective</li>
</ul>
<p>In Coca Cola Company they developed their first API. It simplified their development, accelerated the program, created more demand, demonstrated the possible and it opens data for outsourced development teams.</p>
<p>Kevin Flowers: “Hackathons are not only for Google”.
Indeed they also organized Hackathons not only for developers but also for non-technical persons with brilliant ideas.</p>
<p>The experience was insightful:</p>
<ul>
<li>It increases the innovation, invention and creativity in your company.</li>
<li>Mix skills. Cross functional teams</li>
<li>HUGE employee engagement</li>
</ul>
<p>The conference was also focused on HTML5 and if this is the right choice for large companies. The answer is not surprising: yes and no! On the one hand, yes because HTML5 is everywhere and the upcoming platforms are using it. We should not see the web as a platform anymore but more like a real OS. It allows cross-platforming especially if you develop responsive web app. On the other hand no because we can have performance leaks, more complexity in some case&hellip;</p>
<p>The consortium finally found a compromise with hybrid apps (not especially with Phonegap but with homemade solutions for IOS and Android to keep great performances).</p>
<p><img src="/images/IMG_2695.JPG" alt="image"></p>
<p>*Steeve Wozniak comme speaker :) *</p>
]]></content>
        </item>
        
        <item>
            <title>Effacer toutes les images et containers Docker</title>
            <link>https://leandeep.com/effacer-toutes-les-images-et-containers-docker/</link>
            <pubDate>Sun, 20 Oct 2013 22:03:00 +0000</pubDate>
            
            <guid>https://leandeep.com/effacer-toutes-les-images-et-containers-docker/</guid>
            <description>Effacer tous les containers docker rm $(docker ps -a -q) Effacer toutes les images docker rmi $(docker images -q) </description>
            <content type="html"><![CDATA[<h2 id="effacer-tous-les-containers">Effacer tous les containers</h2>
<pre><code>docker rm $(docker ps -a -q)
</code></pre><h2 id="effacer-toutes-les-images">Effacer toutes les images</h2>
<pre><code>docker rmi $(docker images -q)
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Rapidement remplacer des chaines de caractères dans Vim</title>
            <link>https://leandeep.com/rapidement-remplacer-des-chaines-de-caract%C3%A8res-dans-vim/</link>
            <pubDate>Wed, 24 Jul 2013 23:14:00 +0000</pubDate>
            
            <guid>https://leandeep.com/rapidement-remplacer-des-chaines-de-caract%C3%A8res-dans-vim/</guid>
            <description>Raccourci clavier Il est possible d&#39;ajouter un raccourci clavier pour rapidement remplacer une chaine de caractère sélectionnée en mode visuel.
Editer le fichier ~/.vimrc et ajouter la ligne suivante:
vnoremap &amp;lt;C-r&amp;gt; &amp;quot;hy:%s/&amp;lt;C-r&amp;gt;h//gc&amp;lt;left&amp;gt;&amp;lt;left&amp;gt;&amp;lt;left&amp;gt; En pressant ctrl + r en mode visuel, un prompt va s&#39;afficher pour entrer le texte qui remplacer l&#39;ancien. Appuyer sur enter et confirmer ou annuler chaque changement par y ou n.
 Si vous ne voulez pas confirmer les changements vous pouvez aussi supprimer le c à la fin de la commande VIM :%s/old_text/new_text/gc</description>
            <content type="html"><![CDATA[<h2 id="raccourci-clavier">Raccourci clavier</h2>
<p>Il est possible d'ajouter un raccourci clavier pour rapidement remplacer une chaine de caractère sélectionnée en mode visuel.</p>
<p>Editer le fichier ~/.vimrc et ajouter la ligne suivante:</p>
<pre><code>vnoremap &lt;C-r&gt; &quot;hy:%s/&lt;C-r&gt;h//gc&lt;left&gt;&lt;left&gt;&lt;left&gt;
</code></pre><p>En pressant <code>ctrl + r</code> en mode visuel, un <em>prompt</em> va s'afficher pour entrer le texte qui remplacer l'ancien. Appuyer sur <code>enter</code> et confirmer ou annuler chaque changement par <code>y</code> ou <code>n</code>.</p>
<blockquote>
<p>Si vous ne voulez pas confirmer les changements vous pouvez aussi supprimer le <code>c</code> à la fin de la commande VIM <code>:%s/old_text/new_text/gc</code></p>
</blockquote>
<h2 id="slection-verticale">Sélection verticale</h2>
<p>Sélectionner la première colonne et entrer cTEXT_REMPLACEMENT<!-- raw HTML omitted -->.</p>
<p>Example:</p>
<pre><code>[a]aa
[b]bb
[c]cc
[d]dd

c123&lt;Esc&gt;

123aa
123bb
123cc
123dd</code></pre>]]></content>
        </item>
        
        <item>
            <title>Exécuter une action sur tous les fichiers ayant un pattern dans leur nom</title>
            <link>https://leandeep.com/ex%C3%A9cuter-une-action-sur-tous-les-fichiers-ayant-un-pattern-dans-leur-nom/</link>
            <pubDate>Tue, 23 Jul 2013 15:46:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ex%C3%A9cuter-une-action-sur-tous-les-fichiers-ayant-un-pattern-dans-leur-nom/</guid>
            <description>Tout est dans le titre. Il s&#39;agit d&#39;un quick tip qui montre comment exécuter une command linux sur les fichiers qui respectent un pattern particulier:
find . -name &#39;*.png&#39; -exec echo {} \; </description>
            <content type="html"><![CDATA[<p>Tout est dans le titre. Il s'agit d'un <em>quick tip</em> qui montre comment exécuter une command linux sur les fichiers qui respectent un pattern particulier:</p>
<pre><code>find . -name '*.png' -exec echo {} \;
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Convertir les vidéos d&#39;un dossier en mp3</title>
            <link>https://leandeep.com/convertir-les-vid%C3%A9os-dun-dossier-en-mp3/</link>
            <pubDate>Mon, 13 May 2013 23:03:00 +0000</pubDate>
            
            <guid>https://leandeep.com/convertir-les-vid%C3%A9os-dun-dossier-en-mp3/</guid>
            <description>Convertir les .mp4 d&#39;un dossier en MP3:
mkdir outputs for f in *.mp4; do ffmpeg -i &amp;quot;$f&amp;quot; -c:a libmp3lame &amp;quot;outputs/${f%.mp4}.mp3&amp;quot;; done Convertir les .m4a, .mov et .flac d&#39;un dossier en MP3:
mkdir outputs for f in *.{m4a,mov,flac}; do ffmpeg -i &amp;quot;$f&amp;quot; -c:a libmp3lame &amp;quot;outputs/${f%.*}.mp3&amp;quot;; done Convertir toutes les vidéos d&#39;un dossier en MP3:
mkdir outputs for f in *; do ffmpeg -i &amp;quot;$f&amp;quot; -c:a libmp3lame &amp;quot;outputs/${f%.*}.mp3&amp;quot;; done </description>
            <content type="html"><![CDATA[<p>Convertir les .mp4 d'un dossier en MP3:</p>
<pre><code>mkdir outputs
for f in *.mp4; do ffmpeg -i &quot;$f&quot; -c:a libmp3lame &quot;outputs/${f%.mp4}.mp3&quot;; done
</code></pre><p>Convertir les .m4a, .mov et .flac d'un dossier en MP3:</p>
<pre><code>mkdir outputs
for f in *.{m4a,mov,flac}; do ffmpeg -i &quot;$f&quot; -c:a libmp3lame &quot;outputs/${f%.*}.mp3&quot;; done
</code></pre><p>Convertir toutes les vidéos d'un dossier en MP3:</p>
<pre><code>mkdir outputs
for f in *; do ffmpeg -i &quot;$f&quot; -c:a libmp3lame &quot;outputs/${f%.*}.mp3&quot;; done
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Démarrer un PC à distance à travers un VPN</title>
            <link>https://leandeep.com/d%C3%A9marrer-un-pc-%C3%A0-distance-%C3%A0-travers-un-vpn/</link>
            <pubDate>Mon, 18 Feb 2013 08:24:00 +0000</pubDate>
            
            <guid>https://leandeep.com/d%C3%A9marrer-un-pc-%C3%A0-distance-%C3%A0-travers-un-vpn/</guid>
            <description>Pour démarrer un PC à distance via VPN, c&#39;est assez simple.
Il faut configurer le BIOS de la machine pour qu&#39;elle accepte le boot via Wake-On-Lan. En général, c&#39;est disponible sur tous les PCs.
Ensuite il faut un VPN. Dans mon cas j&#39;utilise un OpenVPN Bridge pour avoir accès aux machines grâce aux IPs locales que je connais déjà.
Ensuite si mon PC distant est éteint il me suffit d&#39;exécuter la commande suivante qui va broadcaster un paquet &amp;ldquo;magique&amp;rdquo; sur tout mon réseau domestique.</description>
            <content type="html"><![CDATA[<p>Pour démarrer un PC à distance via VPN, c'est assez simple.</p>
<p>Il faut configurer le BIOS de la machine pour qu'elle accepte le boot via Wake-On-Lan. En général, c'est disponible sur tous les PCs.</p>
<p>Ensuite il faut un VPN. Dans mon cas j'utilise un OpenVPN Bridge pour avoir accès aux machines grâce aux IPs locales que je connais déjà.</p>
<p>Ensuite si mon PC distant est éteint il me suffit d'exécuter la commande suivante qui va <em>broadcaster</em> un paquet &ldquo;magique&rdquo; sur tout mon réseau domestique.</p>
<pre><code>wakeonlan -i ip_broadcast -p 1234 adresse_mac_de_mon_pc

# ip_broadcast en général 192.168.1.255 ou 192.168.0.255 avec nos box ADSL classiques
</code></pre>]]></content>
        </item>
        
        <item>
            <title>Failover strategies avec Amazon EC2</title>
            <link>https://leandeep.com/failover-strategies-avec-amazon-ec2/</link>
            <pubDate>Sat, 26 Jan 2013 19:02:00 +0000</pubDate>
            
            <guid>https://leandeep.com/failover-strategies-avec-amazon-ec2/</guid>
            <description>downtime &amp;lt; 10 minutes Pour avoir un downtime &amp;lt; 10 minutes il y a cette première stratégie:
On crée un clone de l&#39;environnement de production prêt à être lancé à n&#39;importe quel moment sur une autre zone de disponibilité si l&#39;environnement de production venait à crasher. L&#39;outil Cloudformation fournit gratuitement par AWS peut peut aider à configurer plusieurs environnements.
 Un peu de redondance Remarque: Transférer des données entre instances dans la même zone de disponibilité est gratuit.</description>
            <content type="html"><![CDATA[<h2 id="downtime--10-minutes">downtime &lt; 10 minutes</h2>
<p>Pour avoir un downtime &lt; 10 minutes il y a cette première stratégie:</p>
<p><img src="/images/downtime-10-min.png" alt="image"></p>
<p>On crée un clone de l'environnement de production prêt à être lancé à n'importe quel moment sur une autre zone de disponibilité si l'environnement de production venait à crasher. L'outil Cloudformation fournit gratuitement par AWS peut peut aider à configurer plusieurs environnements.</p>
<br/>
<h2 id="un-peu-de-redondance">Un peu de redondance</h2>
<p>Remarque: Transférer des données entre instances dans la même zone de disponibilité est gratuit. Par contre, entre 2 zones différentes le coût est de $0.01 par gigabyte.</p>
<p><img src="/images/un-peu-redondance.png" alt="image"></p>
<br/>
<h2 id="redondance-totale">Redondance totale</h2>
<p><img src="/images/redondance-totale.png" alt="image"></p>
]]></content>
        </item>
        
        <item>
            <title>Ma présentation des technologies cross-platforms pour le Web &amp; Mobile</title>
            <link>https://leandeep.com/ma-pr%C3%A9sentation-des-technologies-cross-platforms-pour-le-web-mobile/</link>
            <pubDate>Tue, 22 Jan 2013 21:55:00 +0000</pubDate>
            
            <guid>https://leandeep.com/ma-pr%C3%A9sentation-des-technologies-cross-platforms-pour-le-web-mobile/</guid>
            <description>Voici une présentation que j&#39;ai donné dans une soirée dédiée au développement Web/ Mobile sur Boston le 21 janvier 2013. J&#39;ai pu présenter mon retour d&#39;expérience sur le développement d&#39;application hybrides avec Phonegap. J&#39;ai en effet commencé à l&#39;utiliser en 2009 pour développer une application pour iOS et Blackberry Torch via la même codebase.
 </description>
            <content type="html"><![CDATA[<p>Voici une présentation que j'ai donné dans une soirée dédiée au développement Web/ Mobile sur Boston le 21 janvier 2013. J'ai pu présenter mon retour d'expérience sur le développement d'application hybrides avec Phonegap. J'ai en effet commencé à l'utiliser en 2009 pour développer une application pour iOS et Blackberry Torch via la même codebase.</p>

    <iframe
        src="//www.slideshare.net/slideshow/embed_code/key/8G7vWvZyxQ076f"
        title="SlideShare Presentation"
        height="485"
        width="595"
        frameborder="0"
        marginwidth="0"
        marginheight="0"
        scrolling="no"
        style="border: 1px solid #CCC; border-width: 1px; margin-bottom: 20px; width: 100%;"
        allowfullscreen="true">
    </iframe>





]]></content>
        </item>
        
        <item>
            <title>Commandes linux à savoir</title>
            <link>https://leandeep.com/commandes-linux-%C3%A0-savoir/</link>
            <pubDate>Wed, 16 Jan 2013 19:40:00 +0000</pubDate>
            
            <guid>https://leandeep.com/commandes-linux-%C3%A0-savoir/</guid>
            <description>Chercher une string dans les fichiers d&#39;un répertoire de manière récursive grep -r &amp;quot;password&amp;quot; ~/Dev i stands for ignore case. r ou R stands for recursive. l stands for &amp;quot;show the file name, not the result itself&amp;quot;.  Alternative: utiliser ack (https://beyondgrep.com/install/) $ ack &amp;quot;http://&amp;quot; ~/Dev/
  Autre alternative: utiliser ag (https://github.com/ggreer/the_silver_searcher) $ ag &amp;quot;password&amp;quot; ~/Dev
  Localiser un fichier sudo find / -name &amp;quot;*filename&amp;quot;  Liste des ports par défaut des utilitaires de base vi /etc/services  Créer un groupe sudo groupadd -g 4001 mon_groupe  Ajouter/ Retirer un groupe à un utilisateur # delete gpasswd –d group user # add gpasswd –a group user # Alternative sudo usermod -aG mon_groupe olivier  Ajouter un nouvel utilisateur sans droit de login useradd –s /sbin/nologin user Si useradd/adduser ne fonctionne pas, il est possible de créer un utilisateur manuellement:</description>
            <content type="html"><![CDATA[<h2 id="chercher-une-string-dans-les-fichiers-dun-rpertoire-de-manire-rcursive">Chercher une string dans les fichiers d'un répertoire de manière récursive</h2>
<pre><code>grep -r &quot;password&quot; ~/Dev

i stands for ignore case.
r ou R stands for recursive.
l stands for &quot;show the file name, not the result itself&quot;.
</code></pre><blockquote>
<p>Alternative: utiliser ack (<a href="https://beyondgrep.com/install/">https://beyondgrep.com/install/</a>)
<code>$ ack &quot;http://&quot; ~/Dev/</code></p>
</blockquote>
<blockquote>
<p>Autre alternative: utiliser ag (<a href="https://github.com/ggreer/the_silver_searcher">https://github.com/ggreer/the_silver_searcher</a>)
<code>$ ag &quot;password&quot; ~/Dev</code></p>
</blockquote>
<br/>
<h2 id="localiser-un-fichier">Localiser un fichier</h2>
<pre><code>sudo find / -name &quot;*filename&quot;
</code></pre><br/>
<h2 id="liste-des-ports-par-dfaut-des-utilitaires-de-base">Liste des ports par défaut des utilitaires de base</h2>
<pre><code>vi /etc/services
</code></pre><br/>
<h2 id="crer-un-groupe">Créer un groupe</h2>
<pre><code>sudo groupadd -g 4001 mon_groupe
</code></pre><br/>
<h2 id="ajouter-retirer-un-groupe--un-utilisateur">Ajouter/ Retirer un groupe à un utilisateur</h2>
<pre><code># delete
gpasswd –d group user

# add
gpasswd –a group user 

# Alternative
sudo usermod -aG mon_groupe olivier

</code></pre><br/>
<h2 id="ajouter-un-nouvel-utilisateur-sans-droit-de-login">Ajouter un nouvel utilisateur sans droit de login</h2>
<pre><code>useradd –s /sbin/nologin user
</code></pre><p>Si useradd/adduser ne fonctionne pas, il est possible de créer un utilisateur manuellement:</p>
<ul>
<li>Ajouter une entrée pour l'utilisateur dans /etc/passwd</li>
<li>Idem dans le fichier /etc/group</li>
<li>Créer le répertoire home de l'utilisateur</li>
<li>Créer le password pour l'utilisateur avec <code>passwd</code></li>
</ul>
<br/>
<h2 id="voir-toutes-les-variables-denvironnement-du-systme">Voir toutes les variables d'environnement du système</h2>
<pre><code>env

# ou 
printenv
</code></pre><br/>
<h2 id="rediriger-stdout-and-stderr-en-bash">Rediriger STDOUT and STDERR en Bash</h2>
<pre><code>Rediriger STDOUT vers un fichier en ajoutant &gt; entre les commandes. 
Rediriger STDOUT vers une autre commande STDIN en ajoutant | entre les commandes.
Rediriger STDERR vers un fichier en ajoutant 2&gt; entre les commandes.
Rediriger STDERR vers STDOUT en ajoutant 2&gt;&amp;1 entre les commandes.
</code></pre><br/>
<h2 id="dupliquer-un-flux-de-donnes">Dupliquer un flux de données</h2>
<p>Utiliser la commande <code>tee</code></p>
<pre><code>ifconfig -a | tee net.txt
</code></pre><p>Exemple:
Faire tourner un script Bash et à la fois voir son output dans le terminal et l'enregistrer dans une fichier:</p>
<pre><code>bash_script 2&gt;&amp;1 | tee bash_script.log 
</code></pre><br/>
<h2 id="retourner-les-premires-lignes-dun-fichier">Retourner les premières lignes d'un fichier</h2>
<pre><code>head fichier
# inverse de tail 
</code></pre><br/>
<h2 id="diffrence-entre-hardlink-et-symlink">Différence entre hardlink et symlink</h2>
<ul>
<li>
<p>Symlinks point to another file by name, if you change the contents of the file, but not the name it will point to the file with new content. If you remove the source or change the name to it, the symlink it no longer works.</p>
</li>
<li>
<p>Hardlinks point to the file by <code>inode</code> number, if you modify the file name or even delete <strong>it still works until every hard link to it is removed.</strong></p>
</li>
</ul>
<blockquote>
<p>An inodeis a data structure used to represent a filesystem object. Lots of fields are stored in an inode ex: Inode number, direct/indirect disk blocks, number of blocks, change and modification time, File deletiontime, size, type, group, owner, permissions, etc.</p>
</blockquote>
<br/>
<h2 id="forcer-un-check-filesystem-lors-du-prochain-reboot">Forcer un check filesystem lors du prochain reboot</h2>
<pre><code>touch /forcefsck
</code></pre><br/>
<h2 id="voir-les-ports-utiliss-par-les-process">Voir les ports utilisés par les process</h2>
<pre><code>netstat -tulpn
</code></pre><br/>
<h2 id="utiliser-une-machine-comme-router-entre-2-subnets">Utiliser une machine comme router entre 2 subnets</h2>
<pre><code>echo &quot;1&quot; &gt; /proc/sys/net/ipv4/ip_forward
</code></pre><br/>
<h2 id="diffrence-entre-un-process-et-thread">Différence entre un process et thread?</h2>
<p>Threads sont utilisées pour des petites tâches alors que les process sont utilisés par des tâches plus &ldquo;lourdes&rdquo; comme l'exécution d'applications.</p>
<br/>
<h2 id="diffrence-entre-exec-and-fork">Différence entre exec and fork?</h2>
<p>Fork duplique le process actuel.
Exec exécutes un process en utilisant l'executable cible et vous n'avez pas 2 processes qui font tourner le même code ou qui hérite du même état.</p>
<br/>
<h2 id="diffrence-entre-les-2-commandes-">Différence entre les 2 commandes ?</h2>
<pre><code>omyvar=helloo
export myvar=hello
</code></pre><ul>
<li>1er cas: omyvar est restreint uniquement au shell</li>
<li>2ème cas: exporter la variable la rend accessible à n'importe quel process</li>
</ul>
<br/>
<h2 id="limiter-la-mmoire-utilise-par-un-process">Limiter la mémoire utilisée par un process</h2>
<p>Soit en utilisant <code>ulimit</code> pour un changement temporaire ou <code>sysctl -a</code> pour un changement permanent</p>
<br/>
<h2 id="voir-les-logs-system-systemd">Voir les logs system (systemd)</h2>
<pre><code>journalctl -f 
</code></pre><br/>
<h2 id="voir-les-logs-system-et-filtrer">Voir les logs system et filtrer</h2>
<pre><code>journalctl -f -u le_filtre
</code></pre><br/>
<h2 id="nettoyer-les-logs-de-plus-de-2-jours-systemd">Nettoyer les logs de plus de 2 jours (systemd)</h2>
<pre><code>journalctl --vacuum-time=2d
</code></pre><br/>
<h2 id="ne-garder-que-500-mo-de-logs-systemd">Ne garder que 500 Mo de logs (systemd)</h2>
<pre><code>journalctl --vacuum-size=500M
</code></pre><br/>
<h2 id="montagedmontage-nfs">Montage/Démontage NFS</h2>
<pre><code># Montage
mount -t nfs SERVER:MONTAGE_SUR_BAIE ./dossier_local/

# Démontage
umount ./dossier_local
</code></pre><br/>
<h2 id="afficher-les-paramtres-kernel-configurs-dans-etcsysctlconf">Afficher les paramètres kernel configurés dans /etc/sysctl.conf</h2>
<pre><code>sysctl -p
</code></pre><br/>
<h2 id="afficher-les-erreurs-kernel-en-mode-readable">Afficher les erreurs kernel en mode readable</h2>
<pre><code>dmesg -T
</code></pre><br/>
<h2 id="debug-rseau-avec-tcpdump">Debug réseau avec TCPdump</h2>
<p>Ouvrir dans 1er terminal:</p>
<pre><code>tcpdump -vnni any host dns_a_filtrer

tcpdump -vnni any port 5000

tcpdump -vnni any not dst net 192.168.0.1/8

tcpdump -vnni eth0 not dst net 192.168.0.1/8
</code></pre><p>Dans un second terminal:</p>
<pre><code>ping dns_a_filtrer

docker pull dns_a_filtrer

curl dns_a_filtrer
</code></pre><br/>
<h2 id="monitoring-simple-de-host">Monitoring (simple) de host</h2>
<pre><code># IO par disque
sar -d

# Etat des IO disque
sar -b

# Etat du Swap
sar -W

# Etat de la mémoire
sar -r

# Etat du CPU
sar -u

# All
sar -A
</code></pre><br/>
<h2 id="copier-tout-un-dossier-et-grer-les-io-errors">Copier tout un dossier et gérer les IO Errors</h2>
<p>Workaround:</p>
<pre><code>rsync -auv --delete --ignore-errors /Volumes/Olivier/* /Volumes/LaCie/
</code></pre><br/>
<h2 id="redhat">Redhat</h2>
<p><strong>Lister les services</strong></p>
<pre><code>systemctl list-units --type=service
</code></pre><br/>
<h2 id="systemd-et-cgroup">Systemd et cgroup</h2>
<p><img src="/images/Linux_kernel_unified_hierarchy_cgroups_and_systemd.png" alt="image"></p>
<!-- raw HTML omitted -->
<br/>
<h2 id="linux-filesystem-hierarchy">Linux Filesystem Hierarchy</h2>
<p><img src="/images/linux_filesystem_hierarchy.png" alt="image"></p>
<!-- raw HTML omitted -->
<p>Lien vers le standard: <a href="https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html">https://refspecs.linuxfoundation.org/FHS_3.0/fhs-3.0.html</a></p>
<br/>
<h2 id="raccourcis-pour-le-terminal">Raccourcis pour le terminal</h2>
<table>
<thead>
<tr>
<th>Key combination</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ctrl + A</td>
<td>Move to the beginning of the line</td>
</tr>
<tr>
<td>Ctrl + E</td>
<td>Move to the end of the line</td>
</tr>
<tr>
<td>Alt + B</td>
<td>Move to the previous word</td>
</tr>
<tr>
<td>Alt + F</td>
<td>Move to the next word</td>
</tr>
<tr>
<td>Ctrl + U</td>
<td>Erase to the beginning of the line</td>
</tr>
<tr>
<td>Ctrl + K</td>
<td>Erase to the end of the line</td>
</tr>
<tr>
<td>Ctrl + W</td>
<td>Erase the previous word</td>
</tr>
<tr>
<td>Ctrl + P</td>
<td>Browse previously entered commands</td>
</tr>
<tr>
<td>Ctrl + R</td>
<td>Reverse search for previously entered commands</td>
</tr>
</tbody>
</table>
<br/>
<h2 id="crer-un-soft-ou-symbolic-link-sur-un-fichier">Créer un soft (ou symbolic) link sur un fichier</h2>
<pre><code>ln -s dossier_cible nom_du_lien
</code></pre><p>Par exemple:</p>
<pre><code>$ ln -s /etc/hostname name
$ ls -l
total 12
-rw-rw-r--. 1 olivier olivier   13 Jan 16 21:14 hello.txt
lrwxrwxrwx. 1 olivier olivier   13 Jun 16 22:32 name -&gt; /etc/hostname

$ cat name
localdev.local
</code></pre><blockquote>
<p>Si on efface le fichier original sur lequel point le soft link alors ce dernier devient inutile parce qu'il va pointer sur un fichier qui n'existe plus. Les soft links peuvent aussi pointer sur des fichiers dans un autre file system.</p>
</blockquote>
<br/>
<h2 id="crer-un-hard-link">Créer un hard link</h2>
<p>Exemple:</p>
<pre><code>$ echo &quot;Hello World!&quot; &gt; hello.txt
$ ln hello.txt bye.txt

$ ls -l
total 16
-rw-rw-r--. 2 fedora fedora   13 Jun 16 21:14 bye.txt
-rw-rw-r--. 2 fedora fedora   13 Jun 16 21:14 hello.txt
lrwxrwxrwx. 1 fedora fedora   13 Jun 16 22:32 name -&gt; /etc/hostname

$ cat hello.txt
Hello World!

$ cat bye.txt
Hello World!

$ echo &quot;1234&quot; &gt; hello.txt
$ cat bye.txt
1234

$ cat hello.txt
1234

$ rm hello.txt
$ cat bye.txt
1234

$ ls -l
total 12
-rw-rw-r--. 1 olivier olivier    13 Jun 16 22:39 bye.txt
lrwxrwxrwx. 1 olivier olivier   13 Jun 16 22:32 name -&gt; /etc/hostname
</code></pre><p>Dans l'exemple précédent, on a créé un hard link en utilisant la commande <code>ln</code>.
Quand on a fait un changement dans le fichier original hello.txt file, le changement a été répercuté sur le fichier bye.txt.</p>
<p>Mais comme bye.txt est un hard link, même si on efface hello.txt le hard link existe toujours et son contenu reste le même que le contenu original.</p>
<br/>
<h2 id="fichiers-tar">Fichiers tar</h2>
<p><strong>Extraire un tar</strong></p>
<pre><code>$ tar -xzvf files.tar.gz
hello.txt
bye.txt
</code></pre><blockquote>
<p>Le fichier files.tar.gz est compressé avec gzip. Si le fichier termine par .tar.bz2, alors il est compressé avec bzip2.</p>
</blockquote>
<pre><code>$ tar -xjvf files.tar.bz2
hello.txt
bye.txt
</code></pre><br/>
<p><strong>Créer un tar</strong></p>
<pre><code>$ tar -czvf files.tar.gz hello.c bye.txt
hello.txt
bye.txt

$ ls
bye.txt  files.tar.gz  hello.txt
</code></pre><br/>
<h2 id="lire-un-fichier-etcpasswd">Lire un fichier /etc/passwd</h2>
<pre><code>root❌0:0:root:/root:/bin/bash
bin❌1:1:bin:/bin:/sbin/nologin
daemon❌2:2:daemon:/sbin:/sbin/nologin
adm❌3:4:adm:/var/adm:/sbin/nologin
lp❌4:7:lp:/var/spool/lpd:/sbin/nologin
sync❌5:0:sync:/sbin:/bin/sync
shutdown❌6:0:shutdown:/sbin:/sbin/shutdown
halt❌7:0:halt:/sbin:/sbin/halt
mail❌8:12:mail:/var/spool/mail:/sbin/nologin
operator❌11:0:operator:/root:/sbin/nologin
games❌12💯games:/usr/games:/sbin/nologin
ftp❌14:50:FTP User:/var/ftp:/sbin/nologin
nobody❌99:99:Nobody:/:/sbin/nologin
systemd-timesync❌999:998:systemd Time Synchronization:/:/sbin/nologin
systemd-network❌192:192:systemd Network Management:/:/sbin/nologin
systemd-resolve❌193:193:systemd Resolver:/:/sbin/nologin
dbus❌81:81:System message bus:/:/sbin/nologin
sshd❌74:74:Privilege-separated SSH:/var/empty/sshd:/sbin/nologin
chrony❌998:995::/var/lib/chrony:/sbin/nologin
systemd-coredump❌994:994:systemd Core Dumper:/:/sbin/nologin
olivier❌1000:1000:Olivier:/home/olivier:/bin/bash

# Please note --&gt; &quot;❌&quot; = &quot;: x :&quot; (sans espace)
</code></pre><table>
<thead>
<tr>
<th>FIELD</th>
<th>MEANING</th>
</tr>
</thead>
<tbody>
<tr>
<td>username</td>
<td>the username</td>
</tr>
<tr>
<td>password</td>
<td>the password of the user</td>
</tr>
<tr>
<td>uid</td>
<td>Numeric user id</td>
</tr>
<tr>
<td>gid</td>
<td>Numeric group id of user</td>
</tr>
<tr>
<td>gecos</td>
<td>arbitary field</td>
</tr>
<tr>
<td>/home/dirname</td>
<td>Home directory of the user</td>
</tr>
<tr>
<td>shell</td>
<td>Which shell to use for the user</td>
</tr>
</tbody>
</table>
<br/>
<h2 id="etcgroup">/etc/group</h2>
<p>Si un utilisateur est membre du groupe <code>wheel</code>cela signifie qu'il a accès à sudo.</p>
<blockquote>
<p>To be able to use sudo command, you must have your user mentioned in the /etc/sudoers file. The best way to edit the file is to use visudo command as root user.</p>
</blockquote>
<br/>
<h2 id="she-bang-ou-sha-bang-dans-les-fichiers-excutables">she-bang ou sha-bang dans les fichiers exécutables</h2>
<p>she-bang ou sha-bang est la première ligne d'un script qui débute par <code>#!</code> suivi du path de l'exécutable du script.</p>
<p>Example: <code>#!/bin/bash</code></p>
<br/>
<h2 id="lister-les-dossiers-les-plus-lourds">Lister les dossiers les plus lourds</h2>
<pre><code>du --max-depth=7 /* | sort -n
</code></pre><br/>
<h2 id="obtenir-mon-ip-externe-via-google">Obtenir mon IP externe via google</h2>
<pre><code>dig TXT +short o-o.myaddr.l.google.com @ns1.google.com | awk -F'&quot;' '{ print $2}'
</code></pre><br/>
<h2 id="obtenir-le-header-rponse--une-requte">Obtenir le header réponse à une requête</h2>
<p>Tout simplement <code>curl -I http://www.example.org</code>.</p>
]]></content>
        </item>
        
        <item>
            <title>Installer CouchDB sur un Raspberry</title>
            <link>https://leandeep.com/installer-couchdb-sur-un-raspberry/</link>
            <pubDate>Sat, 22 Dec 2012 19:47:00 +0000</pubDate>
            
            <guid>https://leandeep.com/installer-couchdb-sur-un-raspberry/</guid>
            <description>Installation de CouchDB sudo apt-get update sudo apt-get install couchdb  Configuration  On configure le port et la bind_address  sudo vim /etc/couchdb/local.ini # Port par defaut: 5984 port = 5984 # Changer le bind address to 0.0.0.0 pour que la base soit accessible de partout bind_address = 0.0.0.0  Pour que CouchDB puisse démarrer au boot du Pi, on modifie le fichier  /var/init.d/couchdb et on ajoute cette variable d&#39;environnement pour ne plus être gêné par sudo:  COUCHDB_USER=couchdb  Si vous aviez déjà créé votre DB, vous devrez changer les permissions du dossier database_dir pour l&#39;utilisateur couchdb:  sudo chown -R couchdb /var/lib/couchdb/1.</description>
            <content type="html"><![CDATA[<h2 id="installation-de-couchdb">Installation de CouchDB</h2>
<pre><code>sudo apt-get update
sudo apt-get install couchdb
</code></pre><br/>
<h2 id="configuration">Configuration</h2>
<ol>
<li>On configure le port et la bind_address</li>
</ol>
<pre><code>sudo vim /etc/couchdb/local.ini

# Port par defaut: 5984
port = 5984
# Changer le bind address to 0.0.0.0 pour que la base soit accessible de partout
bind_address = 0.0.0.0
</code></pre><br/>
<ol start="2">
<li>Pour que CouchDB puisse démarrer au boot du Pi, on modifie le fichier <code> /var/init.d/couchdb</code> et on ajoute cette variable d'environnement pour ne plus être gêné par <code>sudo</code>:</li>
</ol>
<pre><code>COUCHDB_USER=couchdb
</code></pre><br/>
<ol start="3">
<li>Si vous aviez déjà créé votre DB, vous devrez changer les permissions du dossier database_dir pour l'utilisateur couchdb:</li>
</ol>
<pre><code>sudo chown -R couchdb /var/lib/couchdb/1.2.0
</code></pre>]]></content>
        </item>
        
        <item>
            <title>static method vs class method en programmation orientée objet</title>
            <link>https://leandeep.com/static-method-vs-class-method-en-programmation-orient%C3%A9e-objet/</link>
            <pubDate>Mon, 12 Nov 2012 21:03:00 +0000</pubDate>
            
            <guid>https://leandeep.com/static-method-vs-class-method-en-programmation-orient%C3%A9e-objet/</guid>
            <description>Qu&#39;est-ce qu&#39;une class method ? Une méthode de classe est une méthode qui est liée à une classe plutôt qu&#39;à ses objets. Tout comme la méthode statique, il n&#39;est pas nécessaire de créer une instance de classe pour appeler la méthode.
 Différence entre static method et class method Les static methods ne connaissent rien à propos de la classe et ne peuvent utiliser que les paramètres. Les class methods fonctionnent avec la classe et ses paramètres sont toujours ceux de la classe elle-même.</description>
            <content type="html"><![CDATA[<h2 id="quest-ce-quune-class-method-">Qu'est-ce qu'une class method ?</h2>
<p>Une méthode de classe est une méthode qui est liée à une classe plutôt qu'à ses objets. Tout comme la méthode statique, il n'est pas nécessaire de créer une instance de classe pour appeler la méthode.</p>
<br/>
<h2 id="diffrence-entre-static-method-et-class-method">Différence entre static method et class method</h2>
<p>Les static methods ne connaissent rien à propos de la classe et ne peuvent utiliser que les paramètres.
Les class methods fonctionnent avec la classe et ses paramètres sont toujours ceux de la classe elle-même.
La class method peut être appelée à la fois par la classe et ses instances.</p>
<pre><code>Class.classmethod()
</code></pre><p>Ou aussi:</p>
<pre><code>Class().classmethod()
</code></pre><p>Mais peu importe, la class method est toujours attachée à une classe avec comme premier argument la classe elle-même.</p>
<pre><code>def classMethod(cls, args...)
</code></pre><br/>
<h2 id="quand-utiliser-des-class-methods-">Quand utiliser des class methods ?</h2>
<p><strong>Pour créer des factory methods:</strong></p>
<blockquote>
<p>Les Factory methods sont ces méthodes qui retournent un objet classe (comme constructor) pour différents use cases.</p>
</blockquote>
<blockquote>
<p>C'est similaire à surcharger une fonctione en C++. Mais puisque Python n'a pas de mécanisme similaire les class methods et static methods sont utilisées.</p>
</blockquote>
<pre><code>from datetime import date

# random Person
class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

    @classmethod
    def from_birth_year(cls, name, birth_year):
        return cls(name, date.today().year - birth_year)

    def display(self):
        print(&quot;{} a {} ans&quot;.format(self.name, self.age))

person = Person('Adam', 19)
person.display()

person1 = Person.from_birth_year('John',  1985)
person1.display()
</code></pre><br/>
<p>Output</p>
<pre><code>Adam a 19 ans
John a 31 ans
</code></pre><br/>
<p><strong>Corriger la création d'une instance en héritage:</strong></p>
<p>Quand on dérive une classe en implémentant une factory méthode comme class méthode, cela permet d'avoir une création d'instance correcte de la classe dérivée.</p>
<p>On aurait pu créer une static method pour l'exemple précédent mais l'objet qu'elle crée sera hardcodé comme <em>Base class</em>.</p>
<p>Mais quand on utilise une class method, cela crée une instance correcte de la classe dérivée.</p>
<pre><code>from datetime import date

# random Person
class Person:
    def __init__(self, name, age):
        self.name = name
        self.age = age

    @staticmethod
    def from_fathers_age(name, father_age, father_person_age_diff):
        return Person(name, date.today().year - father_age + father_person_age_diff)

    @classmethod
    def from_birth_year(cls, name, birth_year):
        return cls(name, date.today().year - birth_year)

    def display(self):
        print(&quot;{} a {} ans&quot;.format(self.name, self.age))

class Man(Person):
    sex = 'Male'

man = Man.from_birth_year('John', 1985)
print(isinstance(man, Man))

man1 = Man.from_fathers_age('John', 1965, 20)
print(isinstance(man1, Man))
</code></pre><br/>
<p>Output:</p>
<pre><code>True
False
</code></pre><p>Ici en utilisant une static method pour créer une instance de classe cela nous oblige à hardcoder le type d'instance pendant sa création: <code>def from_fathers(... return Person(name...</code> .</p>
<p>Cela pose clairement un problème pour l'héritage Personne à Man.</p>
<p>La méthode <code>from_fathers_age</code> ne retourne pas un objet <code>Man</code> mais l'objet de classe de base de <code>Person</code>.</p>
<br/>
<p>Cela viole le paradigme OOP&hellip;</p>
]]></content>
        </item>
        
        <item>
            <title>Héritage vs Composition en programmation orientée objet </title>
            <link>https://leandeep.com/h%C3%A9ritage-vs-composition-en-programmation-orient%C3%A9e-objet/</link>
            <pubDate>Fri, 09 Nov 2012 21:02:00 +0000</pubDate>
            
            <guid>https://leandeep.com/h%C3%A9ritage-vs-composition-en-programmation-orient%C3%A9e-objet/</guid>
            <description>Introduction Petit article rapide pour rappeler la différence entre héritage et composition en POO et la représentation UML.
 Rappel héritage (&amp;ldquo;est un&amp;rdquo;) L&#39;héritage est une relation de spécialisation/généralisation entre deux classes. Elle indique qu’une classe dite classe fille spécialise une autre classe dite classe mère. En d&#39;autres termes, une classe fille possède les attributs et les méthodes de la classe mère plus d’autres qui lui sont propres. On parle aussi de super classe et de sous classe.</description>
            <content type="html"><![CDATA[<h2 id="introduction">Introduction</h2>
<p>Petit article rapide pour rappeler la différence entre héritage et composition en POO et la représentation UML.</p>
<br/>
<h2 id="rappel-hritage-est-un">Rappel héritage (&ldquo;est un&rdquo;)</h2>
<p>L'héritage est une relation de spécialisation/généralisation entre deux classes. Elle indique qu’une classe dite classe fille spécialise une autre classe dite classe mère.
En d'autres termes, une classe fille possède les attributs et les méthodes de la classe mère plus d’autres qui lui sont propres. On parle aussi de super classe et de sous classe.</p>
<br/>
<h2 id="example-dhritage-en-python">Example d'héritage en Python</h2>
<pre><code>class classeMere:
    &quot;&quot;&quot;une classe mère&quot;&quot;&quot;
    ...

class classeFille(classeMere):
    &quot;&quot;&quot;une classe fille qui hérite de la classe mère&quot;&quot;&quot;
    ...

</code></pre><br/>
<h2 id="constructeur">Constructeur</h2>
<p>Le constructeur de la classe fille doit faire un appel explicite au constructeur de la classe mère afin d’initialiser les attributs hérités de celle-ci. Pour cela on aura deux syntaxes à notre disposition.</p>
<p>Dans la première syntaxe possible, on fait précéder <code>__init__</code> du nom de la classe mère :</p>
<p><strong>1ère syntaxe</strong></p>
<pre><code>class classeFille(classeMere):
    &quot;&quot;&quot;documentation de la classe fille&quot;&quot;&quot;
    def __init__(self, parametre1, parametre2, ...):
        classeMere.__init__(self, parametre1, ...)
        ...
</code></pre><br/>
<p><strong>2ème syntaxe</strong></p>
<pre><code>class classeFille(classeMere):
    &quot;&quot;&quot;documentation de la classe fille&quot;&quot;&quot;
    def __init__(self, parametre1, parametre2, ...):
        super().__init__(parametre1, ...)
        ...
</code></pre><br/>
<h2 id="reprsentation-uml">Représentation UML</h2>
<p><img src="/images/heritage.png" alt="image"></p>
<br/>
<h2 id="rappel-composition-a-un">Rappel composition (&ldquo;a un&rdquo;)</h2>
<p>La relation de composition modélise une relation d’inclusion entre les instances de deux classes. Les objets de la classe conteneur possèdent donc un attribut qui est un objet de la classe contenue.</p>
<p>Dans certains cas il est tout à fait possible techniquement d’utiliser une relation de composition à la place d’une relation d’héritage.</p>
<p>Au lieu d’avoir une classe B qui hérite d’une classe A, on déclare dans B un attribut qui sera une instance de la classe A.</p>
<br/>
<h2 id="example-de-composition-en-python">Example de composition en Python</h2>
<pre><code>class point:
    def __init__(self,x,y):
        self.__x = x
        self.__y = y
    def getx(self):
        return self.__x
    def gety(self):
        return self.__y

class disque:
    def __init__(self,x,y,r):
        self.__r = r
        self.__centre = point(x,y)
    def surface(self):
        return 3.14 * self.__r**2
    def getCentre(self):
        return self.__centre

cd = disque(-1, 2, 5)
print(&quot;abscisse du centre :&quot;,cd.getCentre().getx())
print(&quot;ordonnée du centre :&quot;,cd.getCentre().gety())
</code></pre><br/>
<h2 id="reprsentation-uml-1">Représentation UML</h2>
<p><img src="/images/composition-agregation.png" alt="image"></p>
<br/>
<h2 id="hritage-vs-composition-en-python">Héritage vs Composition en Python</h2>
<p><strong>Exemples simples</strong></p>
<pre><code># Héritage
class Vehicule:
	pass

class Bicycle(Vehicule)
	pass

#######################################

# Composition
class Engine:
	pass

class Car:
	def __init__(self):
    	self.engine = Engine()

</code></pre><br/>
<h2 id="choisir-entre-composition-et-hritage-">Choisir entre composition et héritage ?</h2>
<p>On choisit l’héritage quand la relation entre classes est bien de la forme <code>est un</code>, ou pour les anglicistes <code>is a</code>.</p>
<p>On choisit la composition quand la relation entre classes est bien de la forme <code>a un</code>, ou pour les anglicistes <code>has a</code>.</p>
<p>Si l'on suit les recommandations du best seller &ldquo;Design Patterns - Elements of Reusable Object Oriented Software&rdquo; (du Gang of 4), il vaut mieux utiliser la composition.</p>
<p><img src="/images/best-seller-design-patterns-OOP.png" alt="image"></p>
<p>Object composition consiste à voir les objets comme des boites noires. C'est plus simple que de faire de l'héritage où il faut connaître les détails de l'objet pour l'utiliser</p>
<p>&mdash; Mis à jour 21/05/2019 &mdash;</p>
<p>La conférence &ldquo;PyCon Cleveland 2019&rdquo; a une vidéo intéressante sur le sujet: <a href="https://www.youtube.com/watch?time_continue=1&amp;v=YXiaWtc0cgE">https://www.youtube.com/watch?time_continue=1&amp;v=YXiaWtc0cgE</a></p>
<br/>
<p><strong>Quand utiliser l'héritage ?</strong></p>
<ol>
<li>
<p>Quand la base classe et la classe dérivée appartiennent au même module/ package et sous le contrôle des mêmes développeurs.</p>
</li>
<li>
<p>Quand il y a une bonne doc (exmple JSONEncoder)</p>
</li>
<li>
<p>Quand l'objet dérivé a un lien de type &ldquo;est un&rdquo; au lieu des &ldquo;a un&rdquo;</p>
</li>
<li>
<p>Ils ne sont pas concurrent mais complémentaire</p>
</li>
<li>
<p>Quand on utilise l'héritage, il ne faut pas oublier le principe de substitution de Liskov</p>
</li>
</ol>
]]></content>
        </item>
        
        <item>
            <title>Obliger les classes dérivées à implémenter certaines méthodes en Python</title>
            <link>https://leandeep.com/obliger-les-classes-d%C3%A9riv%C3%A9es-%C3%A0-impl%C3%A9menter-certaines-m%C3%A9thodes-en-python/</link>
            <pubDate>Mon, 29 Oct 2012 21:12:00 +0000</pubDate>
            
            <guid>https://leandeep.com/obliger-les-classes-d%C3%A9riv%C3%A9es-%C3%A0-impl%C3%A9menter-certaines-m%C3%A9thodes-en-python/</guid>
            <description>Pour être notifié dès l&#39;instanciation d&#39;une classe que des méthodes n&#39;ont pas été implémentées on peut utiliser le module ABC (Abstract Base Classes). On crée alors avec le module ABC une classe de base dont on va se servir pour dériver notre sous-classe. Dans la classe de base on créera des méthodes abstraites à implémenter dans la sous-classe.
 Exemple:
from abc import ABCMeta, abstractmethod class Base(metaclass=ABCMeta): @abstractmethod def foo(self): pass @abstractmethod def bar(self): pass class Concrete(Base): def foo(self): pass # on ne déclare pas bar() volontairement assert issubclass(Concrete, Base) c = Concrete() TypeError: &amp;quot;Can&#39;t instantiate abstract class Concrete with abstract methods bar&amp;quot;  Sans le module ABC n&#39;avait pas été présent, on aurait obtenu NotImplementedError si une méthode non implémentée avait été appelée.</description>
            <content type="html"><![CDATA[<p>Pour être notifié dès l'instanciation d'une classe que des méthodes n'ont pas été implémentées on peut utiliser le module <code>ABC</code> (Abstract Base Classes).
On crée alors avec le module <code>ABC</code> une classe de base dont on va se servir pour dériver notre sous-classe. Dans la classe de base on créera des méthodes abstraites à implémenter dans la sous-classe.</p>
<br/>
<p>Exemple:</p>
<pre><code>from abc import ABCMeta, abstractmethod

class Base(metaclass=ABCMeta):
	@abstractmethod
    def foo(self):
    	pass
        
    @abstractmethod
    def bar(self):
	    pass

</code></pre><pre><code>class Concrete(Base):
	def foo(self):
    	pass
        
        # on ne déclare pas bar() volontairement 

</code></pre><pre><code>assert issubclass(Concrete, Base)
</code></pre><pre><code>c = Concrete()
TypeError:
&quot;Can't instantiate abstract class Concrete with abstract methods bar&quot;
</code></pre><blockquote>
<p>Sans le module <code>ABC</code> n'avait pas été présent, on aurait obtenu <code>NotImplementedError</code> si une méthode non implémentée avait été appelée.
Avec <code>ABC</code> on est alerté dès l'instanciation de la classe que la méthode n'existe pas.</p>
</blockquote>
]]></content>
        </item>
        
    </channel>
</rss>
